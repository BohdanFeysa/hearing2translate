{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ", willkommen zu unserer Präsentation von DeepL, einem neuen Korpus für die deutsche Textanalyse auf Dokument- und Satzebene.", "metrics": {"bleu_score": 65.14613449066714, "chrf_score": 78.04154742195148, "xcomet_score": 0.8583961725234985, "xcomet_qe_score": 0.8227298259735107, "metricx_score": 6.2176055908203125, "metricx_qe_score": 5.7607622146606445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "\"My name is Regina Stodden and I will guide you through the first part of the presentation.", "metrics": {"bleu_score": 4.480836160121357, "chrf_score": 33.88768237180214, "xcomet_score": 0.9555523991584778, "xcomet_qe_score": 0.9768273830413818, "metricx_score": 24.59184455871582, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Let's first define text simplification.\" Textsemantik ist ein", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 21.08507719278503, "xcomet_score": 0.5145538449287415, "xcomet_qe_score": 0.8561317920684814, "metricx_score": 21.305944442749023, "metricx_qe_score": 18.817140579223633, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Prozess der Anpassung eines Textes, um die Textverständlichkeit für eine bestimmte Zielgruppe zu verbessern, wie zum Beispiel Menschen mit Leseschwierigkeiten oder Nicht-Muttersprachlern.", "metrics": {"bleu_score": 31.751446882324117, "chrf_score": 68.69295425050785, "xcomet_score": 0.9824000597000122, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 1.4304277896881104, "metricx_qe_score": 1.42129647731781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textnormalisierungsmodell zu trainieren, benötigen wir parallele Paare von Texten, z. B. von Dokumenten oder Sätzen.", "metrics": {"bleu_score": 25.91641360720012, "chrf_score": 58.36187418242651, "xcomet_score": 0.9998074769973755, "xcomet_qe_score": 1.0, "metricx_score": 0.8612489700317383, "metricx_qe_score": 1.1449166536331177, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dem Beispiel hier sehen Sie ein paralleles Satzpaar aus einem komplexen deutschen Satz und seiner Übersetzung in einfache Sprache.", "metrics": {"bleu_score": 62.472375173961176, "chrf_score": 81.32255107990366, "xcomet_score": 0.9976520538330078, "xcomet_qe_score": 0.9929038286209106, "metricx_score": 0.636231541633606, "metricx_qe_score": 0.7318116426467896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie Sie im Beispiel sehen können, wie zum Beispiel lexikalische Substitution, Klammerdelation, Klammerdelation, Re-Ordination oder Insertion von Wörtern.", "metrics": {"bleu_score": 50.40054329042919, "chrf_score": 70.37117825970992, "xcomet_score": 0.6655636429786682, "xcomet_qe_score": 0.7702854871749878, "metricx_score": 6.82197904586792, "metricx_qe_score": 6.015870571136475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unseren neuen Korpus vor, den wir entwerfen, denn in den letzten Jahren gab es einige Probleme mit dem vorhandenen Korpus.", "metrics": {"bleu_score": 17.21331553634764, "chrf_score": 52.797768570157224, "xcomet_score": 0.8414618968963623, "xcomet_qe_score": 0.7591110467910767, "metricx_score": 3.2996485233306885, "metricx_qe_score": 3.8697776794433594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sind diese Korpora hier zum Beispiel zu klein, um ein Textvervollständigungsmodell zu trainieren.", "metrics": {"bleu_score": 37.67471803151816, "chrf_score": 63.65109042295973, "xcomet_score": 0.9555100202560425, "xcomet_qe_score": 0.9335794448852539, "metricx_score": 1.1199668645858765, "metricx_qe_score": 2.289121627807617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The other three models which are proposed in recent years are all automatically aligned, which means they can be error prone in their alignments.", "metrics": {"bleu_score": 1.7604145271371072, "chrf_score": 22.940360608663703, "xcomet_score": 0.902187705039978, "xcomet_qe_score": 0.9891522526741028, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unseren neuen Korpus dlan vor, der in zwei Unterkorpora unterteilt ist, dlan apa und dlan web.", "metrics": {"bleu_score": 22.27227312202059, "chrf_score": 52.66355928413902, "xcomet_score": 0.8860633969306946, "xcomet_qe_score": 0.8431752920150757, "metricx_score": 5.540065765380859, "metricx_qe_score": 5.210859775543213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dlan apa basiert auf Nachrichtentexten.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 80.22229641182246, "xcomet_score": 0.9027218818664551, "xcomet_qe_score": 0.8695294857025146, "metricx_score": 4.402778625488281, "metricx_qe_score": 5.07122802734375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Deep-Lane APA haben wir 483 Dokumente manuell ausgerichtet.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 47.05182960563775, "xcomet_score": 0.8609460592269897, "xcomet_qe_score": 0.8509798049926758, "metricx_score": 3.825228452682495, "metricx_qe_score": 3.9711716175079346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ergibt ungefähr 30.000, 13.000 parallele Satzpaare.", "metrics": {"bleu_score": 29.84745896009822, "chrf_score": 59.99341930040932, "xcomet_score": 0.965526282787323, "xcomet_qe_score": 0.9117690920829773, "metricx_score": 4.706242084503174, "metricx_qe_score": 5.09743070602417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Deep-Lane-Web. Dieser Korpus umfasst verschiedene Domains. Und wir haben auch alle diese 750 Dokumente auf der einen Seite manuell und auf der anderen Seite mit automatischen Ausrichtungsmethoden ausgerichtet.", "metrics": {"bleu_score": 10.105385745342533, "chrf_score": 55.13274719270751, "xcomet_score": 0.8572221994400024, "xcomet_qe_score": 0.7782217860221863, "metricx_score": 4.196325778961182, "metricx_qe_score": 4.348147869110107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergibt das 30.450 Satzpaare.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 70.54195826612712, "xcomet_score": 0.9951846599578857, "xcomet_qe_score": 0.9934605360031128, "metricx_score": 0.17431709170341492, "metricx_qe_score": 0.2977753281593323, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert, zum Beispiel nach der Art der Semantik.", "metrics": {"bleu_score": 56.38653104251221, "chrf_score": 70.99063451433626, "xcomet_score": 0.8892486095428467, "xcomet_qe_score": 0.8855549693107605, "metricx_score": 2.812624454498291, "metricx_qe_score": 3.752091884613037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel die Nachrichten oder die Sprachlerntexte.", "metrics": {"bleu_score": 50.87877386719346, "chrf_score": 72.59807167864521, "xcomet_score": 0.9966678619384766, "xcomet_qe_score": 0.9943994283676147, "metricx_score": 0.18583709001541138, "metricx_qe_score": 0.20386230945587158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Ebenen, wie zum Beispiel lexikalische Semantik, strukturelle Semantik oder die übergeordnete Semantikebene.", "metrics": {"bleu_score": 24.26438274389041, "chrf_score": 47.85643256128203, "xcomet_score": 0.9980452060699463, "xcomet_qe_score": 1.0, "metricx_score": 0.3086870014667511, "metricx_qe_score": 0.6682149767875671, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem können Sie sehen, dass unser Dplain-Korpus eine große Vielfalt an verschiedenen Semantik-Transformationen aufweist.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 72.00686779494903, "xcomet_score": 0.9034698009490967, "xcomet_qe_score": 0.9530573487281799, "metricx_score": 1.8127598762512207, "metricx_qe_score": 2.4311888217926025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir beispielsweise im Dplain-API-Korpus viel mehr Reorderings und Wortadditions als im Dplain-Web-Korpus.", "metrics": {"bleu_score": 10.074708078532293, "chrf_score": 43.86859841175576, "xcomet_score": 0.8159506320953369, "xcomet_qe_score": 0.9574921131134033, "metricx_score": 7.030858993530273, "metricx_qe_score": 5.684784412384033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite haben wir im Webkorpus viel mehr Rephrasierungen.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 53.13339404822312, "xcomet_score": 0.9992176294326782, "xcomet_qe_score": 1.0, "metricx_score": 3.9055469036102295, "metricx_qe_score": 2.93629789352417, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also lasst uns jetzt sehen, was wir mit diesem Korpus machen können.", "metrics": {"bleu_score": 59.5640359271809, "chrf_score": 71.5130123732044, "xcomet_score": 0.9823528528213501, "xcomet_qe_score": 0.9448950290679932, "metricx_score": 0.9947642087936401, "metricx_qe_score": 1.1004784107208252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Omar und jetzt werde ich über die Anwendungsfälle für unseren Datensatz Deep-Lane sprechen.", "metrics": {"bleu_score": 21.042990347620457, "chrf_score": 56.86056987760507, "xcomet_score": 0.8529322743415833, "xcomet_qe_score": 0.8266263604164124, "metricx_score": 4.114047050476074, "metricx_qe_score": 3.9350504875183105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den ersten Anwendungsfall können wir also automatische Ausrichtungsmethoden bewerten.", "metrics": {"bleu_score": 49.616830003403614, "chrf_score": 70.96693286184703, "xcomet_score": 0.9967378377914429, "xcomet_qe_score": 1.0, "metricx_score": 0.2927742302417755, "metricx_qe_score": 0.10980816185474396, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Anreizmethoden, aber im Kontext der maschinellen Übersetzungen. Where we have two parallel documents written in different languages and we want to extract alignments of sentences in post documents. Aber", "metrics": {"bleu_score": 22.118839948719074, "chrf_score": 51.20900114079746, "xcomet_score": 0.5850071907043457, "xcomet_qe_score": 0.6489473581314087, "metricx_score": 22.46213150024414, "metricx_qe_score": 19.114797592163086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in unserem Anwendungsfall versuchen wir, Ausrichtungen zwischen Sätzen zweier paralleler Dokumente mit derselben Sprache und gleichem Inhalt zu extrahieren, die jedoch auf einer anderen Kom", "metrics": {"bleu_score": 17.780460868364322, "chrf_score": 56.37664830534237, "xcomet_score": 0.8056004047393799, "xcomet_qe_score": 0.7999312877655029, "metricx_score": 6.859124183654785, "metricx_qe_score": 5.205941677093506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "plexitätsstufe liegen. Und jetzt, da wir unseren Datensatz Deepplane haben, der manuell ausgerichtete Sätze enthält, können wir diese Sätze als goldene Standardausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten. Und", "metrics": {"bleu_score": 35.743304759298105, "chrf_score": 60.9113310891203, "xcomet_score": 0.6440240144729614, "xcomet_qe_score": 0.7129092216491699, "metricx_score": 10.461977005004883, "metricx_qe_score": 7.182441234588623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen, und wir haben alle diese Anpassungen und die Codes veröffentlicht, um unsere Experimente in der Arbeit durchzuführen.", "metrics": {"bleu_score": 33.20549993806187, "chrf_score": 73.12448302700338, "xcomet_score": 0.9712399244308472, "xcomet_qe_score": 0.9675483703613281, "metricx_score": 1.921325445175171, "metricx_qe_score": 1.5484551191329956, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste Ausrichtung, die automatische Ausrichtungsmethode, die für die deutsche Textverkleinerung verwendet werden sollte, die Methode der Massenausrichtung ist. Und", "metrics": {"bleu_score": 34.97066970025422, "chrf_score": 58.66387018204423, "xcomet_score": 0.8163732290267944, "xcomet_qe_score": 0.8292704224586487, "metricx_score": 4.237376689910889, "metricx_qe_score": 3.7733781337738037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch den Code finden, um diese Methode in Ihrem eigenen Dokument in der Arbeit auszuführen.", "metrics": {"bleu_score": 14.907696716954744, "chrf_score": 61.20495479887234, "xcomet_score": 0.9899548292160034, "xcomet_qe_score": 0.9725785851478577, "metricx_score": 2.0009500980377197, "metricx_qe_score": 2.2596261501312256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserem Papier gezeigt haben, ist der Fall der automatischen Textverfeinerung. By fine-tuning language models to produce simplified text from the complex input text.", "metrics": {"bleu_score": 22.51049289168876, "chrf_score": 46.06219891013082, "xcomet_score": 0.8270259499549866, "xcomet_qe_score": 0.9422816038131714, "metricx_score": 19.685165405273438, "metricx_qe_score": 12.19152545928955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle fein abgestimmt.", "metrics": {"bleu_score": 59.4603557501361, "chrf_score": 82.02646042961548, "xcomet_score": 0.987072229385376, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5659465789794922, "metricx_qe_score": 0.6209328174591064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das Modell von Long im Part fein abgestimmt, um Dokumente auf Ebene der Vereinfachungen zu produzieren. Und wir haben auch die normale Basislänge, die normale Basisimport, fein abgestimmt, um Satzebene-Simplifizierungen zu erzeugen.", "metrics": {"bleu_score": 9.961757329676683, "chrf_score": 57.660492068466084, "xcomet_score": 0.5624119639396667, "xcomet_qe_score": 0.5577144622802734, "metricx_score": 13.718533515930176, "metricx_qe_score": 13.57657241821289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "You can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper.", "metrics": {"bleu_score": 1.5880117714047368, "chrf_score": 19.446419437289297, "xcomet_score": 0.9290543794631958, "xcomet_qe_score": 0.8949922323226929, "metricx_score": 24.6782169342041, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We concluded that this basic fine-tuning could produce or could get scores better than the baseline scores. Und wir schlagen diese Ergebnisse als einen Benchmark, einen Basisbenchmark, für das Problem der automatischen Textverkleinerung in der Zukunft vor.", "metrics": {"bleu_score": 15.680618628209563, "chrf_score": 44.330188564291056, "xcomet_score": 0.8824533224105835, "xcomet_qe_score": 0.9356435537338257, "metricx_score": 17.745019912719727, "metricx_qe_score": 16.945167541503906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen.", "metrics": {"bleu_score": 79.46548462807742, "chrf_score": 84.5119924869581, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.19325855374336243, "metricx_qe_score": 0.32145971059799194, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9926378726959229, "xcomet_qe_score": 1.0, "metricx_score": 1.4178515672683716, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Sadam Shukurovsky und in diesem Vortrag geht es um die Abhängigkeitsstruktur der Koordination.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 81.47059089981447, "xcomet_score": 0.6028174161911011, "xcomet_qe_score": 0.6403529644012451, "metricx_score": 7.827489376068115, "metricx_qe_score": 6.536709785461426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, sind verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpusrichtlinien angenommen werden. So sind", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 85.88216974868791, "xcomet_score": 0.9263997077941895, "xcomet_qe_score": 0.931751549243927, "metricx_score": 10.295125961303711, "metricx_qe_score": 5.714381217956543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel in universellen Abhängigkeiten die Struktur der Koordinatenkoordination, Lisa, Bart und Maggie. Ist so, dass die erste Konjunktion die Kopf der ganzen Koordinatenstruktur ist.", "metrics": {"bleu_score": 35.460762741007535, "chrf_score": 77.61123073844158, "xcomet_score": 0.8285764455795288, "xcomet_qe_score": 0.8427979946136475, "metricx_score": 5.898502349853516, "metricx_qe_score": 6.623587608337402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall also Lisa.", "metrics": {"bleu_score": 32.159351091190125, "chrf_score": 57.16662065908482, "xcomet_score": 0.9996218681335449, "xcomet_qe_score": 0.9975420236587524, "metricx_score": 0.34654515981674194, "metricx_qe_score": 0.34963399171829224, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein ähnlicher Ansatz wird in der Meaning Text Theory von Y. G. Miltschkow angenommen, wo wiederum die gesamte Koordinatenstruktur von der ersten Konjunktion angeführt wird.", "metrics": {"bleu_score": 49.49179908031713, "chrf_score": 67.52239765081197, "xcomet_score": 0.8740226030349731, "xcomet_qe_score": 0.9233660697937012, "metricx_score": 4.331893444061279, "metricx_qe_score": 3.722442150115967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Ansätze sind also asymmetrisch,", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 82.24677940823271, "xcomet_score": 0.9895073771476746, "xcomet_qe_score": 0.9871300458908081, "metricx_score": 0.31799593567848206, "metricx_qe_score": 0.18235638737678528, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder?", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4482758620689653, "xcomet_score": 0.8458765149116516, "xcomet_qe_score": 0.6457641124725342, "metricx_score": 0.8862438201904297, "metricx_qe_score": 0.4225817620754242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie heben eine der Konjunktionen hervor.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 85.6859213126352, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5261910557746887, "metricx_qe_score": 1.2985155582427979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun gibt es auch symmetrische Ansätze für kodierte, kodierte Strukturen, wie den Prag-Ansatz,", "metrics": {"bleu_score": 6.917184228205474, "chrf_score": 51.50707652529467, "xcomet_score": 0.6918070912361145, "xcomet_qe_score": 0.7502272725105286, "metricx_score": 11.633513450622559, "metricx_qe_score": 8.166810989379883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "den konjunktivführenden Ansatz, der in Prag-abhängigen Baumbanken verwendet wird, bei denen kodierte Strukturen von der Konjunktion angeführt werden.", "metrics": {"bleu_score": 25.422541413895544, "chrf_score": 51.53870508217142, "xcomet_score": 0.8751161098480225, "xcomet_qe_score": 0.8930248022079468, "metricx_score": 5.454518795013428, "metricx_qe_score": 3.7078309059143066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also erhalten wir Abhängigkeiten von und zu allen den Verträgen. Und", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 48.51868842777563, "xcomet_score": 0.7886364459991455, "xcomet_qe_score": 0.7934633493423462, "metricx_score": 6.503062725067139, "metricx_qe_score": 5.356002330780029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich gibt es auch einen mehrköpfigen Ansatz, der zum Beispiel in der Wortgrammatik von Dikotsen verwendet wird. Where, so to say, all conjuncts are heads of the coordinate structure,", "metrics": {"bleu_score": 18.34283688193615, "chrf_score": 46.27244109288581, "xcomet_score": 0.673566460609436, "xcomet_qe_score": 0.7157200574874878, "metricx_score": 11.118245124816895, "metricx_qe_score": 9.408447265625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "so we get dependencies from the governor here loves to all", "metrics": {"bleu_score": 0.0, "chrf_score": 13.69087824347619, "xcomet_score": 0.2866874039173126, "xcomet_qe_score": 0.7960491180419922, "metricx_score": 17.886865615844727, "metricx_qe_score": 23.700542449951172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "conjuncts separately, these about and make. Jetzt ist der Zweck", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 16.349408517717357, "xcomet_score": 0.13946697115898132, "xcomet_qe_score": 0.12907345592975616, "metricx_score": 24.261953353881836, "metricx_qe_score": 23.23197364807129, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dieses Papiers, ein neues Argument für die symmetrischen Strukturen der Koordination wie diese beiden und gegen die asymmetrischen Strukturen der Koordination wie diese zu liefern.", "metrics": {"bleu_score": 19.230188007838606, "chrf_score": 62.280966783969085, "xcomet_score": 0.8192170858383179, "xcomet_qe_score": 0.8067268133163452, "metricx_score": 4.6476359367370605, "metricx_qe_score": 4.859106063842773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay,", "metrics": {"bleu_score": 0.0, "chrf_score": 9.803921568627452, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5152789354324341, "metricx_qe_score": 0.1790972501039505, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "das Argument basiert auf dem Prinzip der Abhängigkeit und der Minimierung, das ich auf der Grundlage dieser Beispiele erklären werde. In der englischen Grammatik,", "metrics": {"bleu_score": 27.034823519968793, "chrf_score": 72.56910364639103, "xcomet_score": 0.7428629398345947, "xcomet_qe_score": 0.7526259422302246, "metricx_score": 11.450496673583984, "metricx_qe_score": 11.639286041259766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie Sie vielleicht wissen, werden direkte Objekte bevorzugt, wenn sie dem Verb nahe stehen, während Adjektive weiter entfernt sein können.", "metrics": {"bleu_score": 16.650173161392598, "chrf_score": 63.958538132990974, "xcomet_score": 0.935184121131897, "xcomet_qe_score": 0.9421370029449463, "metricx_score": 2.2170522212982178, "metricx_qe_score": 1.7420481443405151, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So ist es beispielsweise in \"March read it yesterday\" in Ordnung, weil das direkte Objekt \"it\" nahe am Verb steht. Während \"March read yesterday\" es ist, ist es", "metrics": {"bleu_score": 20.31552942077615, "chrf_score": 59.16765019937307, "xcomet_score": 0.7080056667327881, "xcomet_qe_score": 0.731024980545044, "metricx_score": 14.58406925201416, "metricx_qe_score": 15.548101425170898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.873770695879497, "xcomet_score": 0.14595873653888702, "xcomet_qe_score": 0.10526026785373688, "metricx_score": 3.370163679122925, "metricx_qe_score": 2.083487033843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "weil hier zwischen dem Verb und dem direkten Objekt ein Adjektiv steht, \"yesterday\".", "metrics": {"bleu_score": 55.81600587827485, "chrf_score": 84.58867526851716, "xcomet_score": 0.9785089492797852, "xcomet_qe_score": 0.9821715950965881, "metricx_score": 1.2162624597549438, "metricx_qe_score": 1.5758346319198608, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch verbessert werden, wenn das direkte Objekt sehr schwer und sehr lang ist, da es", "metrics": {"bleu_score": 83.71837576365554, "chrf_score": 97.81195270399887, "xcomet_score": 0.8901013135910034, "xcomet_qe_score": 0.9166264533996582, "metricx_score": 7.6130218505859375, "metricx_qe_score": 4.674324989318848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann in die Position nach dem Adjektiv verschoben werden kann.", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 51.56104302889559, "xcomet_score": 0.9545291662216187, "xcomet_qe_score": 0.9128775596618652, "metricx_score": 4.828949928283691, "metricx_qe_score": 5.427000045776367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird hier veranschaulicht.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beide Sätze sind also in Ordnung.", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 72.80149781288439, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.065510094165802, "metricx_qe_score": 0.10262922942638397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "March hat gestern dieses absolut faszinierende Buch über die Beatles gelesen. Es", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 27.278243878652418, "xcomet_score": 0.17475545406341553, "xcomet_qe_score": 0.22670918703079224, "metricx_score": 12.357758522033691, "metricx_qe_score": 14.674273490905762, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ist in Ordnung, wo wir stattdessen dieses lange und dünne haben.", "metrics": {"bleu_score": 21.18854509032766, "chrf_score": 42.71265120058646, "xcomet_score": 0.7541632056236267, "xcomet_qe_score": 0.6990068554878235, "metricx_score": 6.942805767059326, "metricx_qe_score": 6.818439483642578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen, dass Marge gestern dieses absolut faszinierende Buch über Bienen gelesen", "metrics": {"bleu_score": 36.65882729601238, "chrf_score": 48.77091682649522, "xcomet_score": 0.9756633043289185, "xcomet_qe_score": 0.9811692833900452, "metricx_score": 1.7386523485183716, "metricx_qe_score": 0.4073106646537781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hat. Der Grund dafür ist, dass dies möglich ist, weil, obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass direkte Objekte neben dem Verb stehen sollten, Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, das besagt, dass kürzere Abhängigkeiten bevorzugt werden. Also ähm,", "metrics": {"bleu_score": 64.99862400782325, "chrf_score": 82.26808457792805, "xcomet_score": 0.7714450359344482, "xcomet_qe_score": 0.7391948699951172, "metricx_score": 10.272368431091309, "metricx_qe_score": 11.406442642211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese beiden ähm Bäume äh nur äh zeigen äh die Länge der wichtigen Abhängigkeiten, also äh die, die äh nicht konstant unter diesen beiden Strukturen. Also", "metrics": {"bleu_score": 12.193246424251138, "chrf_score": 53.45256831816633, "xcomet_score": 0.7868876457214355, "xcomet_qe_score": 0.7677180767059326, "metricx_score": 20.234071731567383, "metricx_qe_score": 20.324769973754883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier haben wir eine Abhängigkeit von rot zu dem Adjunk von Länge sieben, gemessen in Wörtern, und von rot zu Buch von Länge vier, also zu insgesamt elf. Wenn Sie sich bewegen,", "metrics": {"bleu_score": 7.087648989046158, "chrf_score": 40.212854348805784, "xcomet_score": 0.4737427234649658, "xcomet_qe_score": 0.5615100860595703, "metricx_score": 14.880217552185059, "metricx_qe_score": 13.766960144042969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn Sie diese beiden Bestandteile tauschen, wird die Summe dieser beiden Abhängigkeiten sechs, richtig?", "metrics": {"bleu_score": 25.459845316736796, "chrf_score": 60.582458282339516, "xcomet_score": 0.9603331089019775, "xcomet_qe_score": 0.9543830156326294, "metricx_score": 1.295224666595459, "metricx_qe_score": 1.054037094116211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also elf, sechs, viel kürzer.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 42.47950397561076, "xcomet_score": 0.9403826594352722, "xcomet_qe_score": 0.9379295110702515, "metricx_score": 1.5768184661865234, "metricx_qe_score": 1.4207791090011597, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb klingt das ganz in Ordnung, oder?", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 46.28594011044034, "xcomet_score": 0.9866976737976074, "xcomet_qe_score": 0.9851901531219482, "metricx_score": 0.29550111293792725, "metricx_qe_score": 0.40696603059768677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.873770695879497, "xcomet_score": 0.14595873653888702, "xcomet_qe_score": 0.10526026785373688, "metricx_score": 3.370163679122925, "metricx_qe_score": 2.083487033843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es verstößt gegen ein Prinzip, aber es erfüllt ein anderes.", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 81.36222776338944, "xcomet_score": 0.9989591836929321, "xcomet_qe_score": 0.9844347238540649, "metricx_score": 0.024536658078432083, "metricx_qe_score": 0.0807921513915062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, was", "metrics": {"bleu_score": 0.0, "chrf_score": 27.898550724637676, "xcomet_score": 0.7322772741317749, "xcomet_qe_score": 0.8090654015541077, "metricx_score": 3.032573699951172, "metricx_qe_score": 0.40794751048088074, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir getan haben, war, dass wir verschiedene Statistiken aus der verbesserten Version der Bench of the Bench Tree Bank extrahiert haben und das Papier gesehen haben, warum wir keine universellen Abhängigkeiten verwenden würden. Und diese Statistiken bestätigen die Beobachtung, die schon oft gemacht wurde, dass linke Konjunktionen tendenziell kürzer sind.", "metrics": {"bleu_score": 19.944262508570798, "chrf_score": 63.329825879146725, "xcomet_score": 0.7087069153785706, "xcomet_qe_score": 0.6373391151428223, "metricx_score": 8.694642066955566, "metricx_qe_score": 9.779581069946289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also Salz und Pfeffer und nicht Pfeffer und Salz, gemessen in Silben.", "metrics": {"bleu_score": 33.428661215627315, "chrf_score": 77.45123930788384, "xcomet_score": 0.9294313192367554, "xcomet_qe_score": 0.8507397770881653, "metricx_score": 1.0828465223312378, "metricx_qe_score": 4.172242164611816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und auch die Beobachtung, die im Vorbeigehen gemacht wurde, dass diese Tendenz mit der Längendifferenz zunimmt.", "metrics": {"bleu_score": 15.936357366603362, "chrf_score": 51.825018574192036, "xcomet_score": 0.9414392113685608, "xcomet_qe_score": 0.940693199634552, "metricx_score": 5.2498297691345215, "metricx_qe_score": 4.315656661987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied in der Länge der beiden Konjunktionen zunimmt, ist die kürzere Konjunktion stärker, oder?", "metrics": {"bleu_score": 15.005212294966274, "chrf_score": 59.018603615947384, "xcomet_score": 0.9779011011123657, "xcomet_qe_score": 0.9647879600524902, "metricx_score": 1.6538560390472412, "metricx_qe_score": 3.4319980144500732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Proportion ist also größer der linke, kurze Konjunktiv. Aber was in diesem", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 55.906381237761295, "xcomet_score": 0.4787333309650421, "xcomet_qe_score": 0.45347434282302856, "metricx_score": 14.778857231140137, "metricx_qe_score": 12.171728134155273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Papier neu ist, ist, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn die Gouvea auf der linken Seite fehlen. Richtig? Also der Gouverneur ist auf der linken Seite.", "metrics": {"bleu_score": 25.697337936725553, "chrf_score": 52.29612721765032, "xcomet_score": 0.45791056752204895, "xcomet_qe_score": 0.4016490578651428, "metricx_score": 15.6864652633667, "metricx_qe_score": 18.554962158203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "viel schlimmer,", "metrics": {"bleu_score": 0.0, "chrf_score": 7.873770695879497, "xcomet_score": 0.14595873653888702, "xcomet_qe_score": 0.10526026785373688, "metricx_score": 3.370163679122925, "metricx_qe_score": 2.083487033843994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel habe ich Bart und Lisa gesehen. So ist der Gouverneur, er ist auf der linken Seite. Es fehlt", "metrics": {"bleu_score": 22.169194554223, "chrf_score": 57.94412259148055, "xcomet_score": 0.6621195077896118, "xcomet_qe_score": 0.6995056867599487, "metricx_score": 7.262063026428223, "metricx_qe_score": 5.926563739776611, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im zweiten Beispiel, Homer kam und niesen.", "metrics": {"bleu_score": 18.70274255449444, "chrf_score": 66.87568196687891, "xcomet_score": 0.8647435307502747, "xcomet_qe_score": 0.8908549547195435, "metricx_score": 11.134182929992676, "metricx_qe_score": 11.609179496765137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir eine Koordination von zwei Verben und es gibt keinen externen externen Regler, oder?", "metrics": {"bleu_score": 9.880782578056978, "chrf_score": 51.58806089052811, "xcomet_score": 0.7701857089996338, "xcomet_qe_score": 0.8486653566360474, "metricx_score": 5.443309307098389, "metricx_qe_score": 5.331183910369873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In solchen Fällen bevorzugt die linke Konjunktion, kürzer zu sein, je größer der Unterschied zwischen den beiden.", "metrics": {"bleu_score": 17.45740482830457, "chrf_score": 58.44168971815174, "xcomet_score": 0.9109535217285156, "xcomet_qe_score": 0.9052669405937195, "metricx_score": 3.0440781116485596, "metricx_qe_score": 3.000603437423706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Gubner auf der rechten Seite ist, wie hier links, regiert es die Koordination des Netzwerks, und dieser Effekt verschwindet.", "metrics": {"bleu_score": 17.09417137783765, "chrf_score": 49.72425238250695, "xcomet_score": 0.5403398275375366, "xcomet_qe_score": 0.5998369455337524, "metricx_score": 10.727689743041992, "metricx_qe_score": 11.278048515319824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir gezeigt, dass wir die Länge in Buchstaben, die erste Spalte, in Silben, die mittlere Spalte, und in Wörtern, die", "metrics": {"bleu_score": 23.14391085545536, "chrf_score": 50.086240854976424, "xcomet_score": 0.669795036315918, "xcomet_qe_score": 0.8031200170516968, "metricx_score": 13.404869079589844, "metricx_qe_score": 9.631534576416016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "rechte Spalte, messen.", "metrics": {"bleu_score": 8.697972365316721, "chrf_score": 27.253549595018832, "xcomet_score": 0.1980244219303131, "xcomet_qe_score": 0.1126069650053978, "metricx_score": 5.952192306518555, "metricx_qe_score": 6.42539119720459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also konzentriere ich mich auf die rechte. What we see here is that when the governor is on the left. The tendency for the left conjunct to be shorter grows steadily with the absolute difference in words. And the same is observed when there is no governor, as in coordination of sentences.", "metrics": {"bleu_score": 0.9010837781632643, "chrf_score": 26.91541891837853, "xcomet_score": 0.24960409104824066, "xcomet_qe_score": 0.5497883558273315, "metricx_score": 23.44781494140625, "metricx_qe_score": 22.651878356933594, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But when the governor is on the right, this tendency disappears.", "metrics": {"bleu_score": 3.4015426186864377, "chrf_score": 17.8345444825201, "xcomet_score": 0.8301222324371338, "xcomet_qe_score": 1.0, "metricx_score": 21.033565521240234, "metricx_qe_score": 24.325241088867188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir zeigen in der Arbeit, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für symmetrische Strukturen wie diese beiden liefert. Also lesen Sie das Papier für", "metrics": {"bleu_score": 65.90229418828025, "chrf_score": 89.53146573413031, "xcomet_score": 0.8765692710876465, "xcomet_qe_score": 0.8960526585578918, "metricx_score": 5.779207706451416, "metricx_qe_score": 1.9773876667022705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die vollständige Vereinbarung und Argumente, sorry,", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 46.97993849945809, "xcomet_score": 0.17870719730854034, "xcomet_qe_score": 0.16223099827766418, "metricx_score": 12.453588485717773, "metricx_qe_score": 8.880354881286621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und sprechen Sie mit uns über die Poster-Session.", "metrics": {"bleu_score": 11.417530270031051, "chrf_score": 50.26082525459971, "xcomet_score": 0.8969062566757202, "xcomet_qe_score": 0.8955869078636169, "metricx_score": 5.174717903137207, "metricx_qe_score": 2.9044458866119385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9926378726959229, "xcomet_qe_score": 1.0, "metricx_score": 1.4178515672683716, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Xiangbing, PhD student an der University of Washington.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 70.36924852026267, "xcomet_score": 0.8448517322540283, "xcomet_qe_score": 0.8425842523574829, "metricx_score": 1.5343178510665894, "metricx_qe_score": 0.6292007565498352, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute präsentiere ich unsere Arbeit von der Vorverarbeitung von Daten über Sprachmodelle bis hin zu Downstream-Aufgaben, die den Weg der politischen Voreingenommenheit verfolgen, die zu unfairen NLP-Modellen führt.", "metrics": {"bleu_score": 5.072624986933127, "chrf_score": 32.00613047715478, "xcomet_score": 0.820600152015686, "xcomet_qe_score": 0.8235574960708618, "metricx_score": 2.965566635131836, "metricx_qe_score": 2.762810230255127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The language models are trained on large-scale web crawl data.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 20.432108485926125, "xcomet_score": 0.944090723991394, "xcomet_qe_score": 1.0, "metricx_score": 14.447936058044434, "metricx_qe_score": 13.348525047302246, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren prädaten Daten gut abgedeckt.", "metrics": {"bleu_score": 37.99178428257963, "chrf_score": 75.3424875406434, "xcomet_score": 0.8844661712646484, "xcomet_qe_score": 0.8618382811546326, "metricx_score": 3.645784378051758, "metricx_qe_score": 5.3498616218566895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Laut einer Umfrage des C4-Korpus können wir sehen, dass die New York Times, Los Angeles Times, The Guardian, Huffington Post, etc. in den Trainingsdaten von Sprachmodellen gut abgedeckt sind.", "metrics": {"bleu_score": 33.89765679716094, "chrf_score": 65.44790581364606, "xcomet_score": 0.930126428604126, "xcomet_qe_score": 0.9226677417755127, "metricx_score": 1.2415179014205933, "metricx_qe_score": 0.986284077167511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This has created a mixed blessing for language model applications.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 18.843639845651083, "xcomet_score": 0.8074368238449097, "xcomet_qe_score": 0.9110934734344482, "metricx_score": 24.319604873657227, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf der einen Seite waren sie in der Lage, aus verschiedenen Perspektiven zu lernen, was Demokratie und die Vielfalt von Ideen feiert.", "metrics": {"bleu_score": 22.40474044138693, "chrf_score": 63.9223773440186, "xcomet_score": 0.9188752174377441, "xcomet_qe_score": 0.9419644474983215, "metricx_score": 3.359832525253296, "metricx_qe_score": 1.6673634052276611, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und können zu potenziellen Fairnessproblemen in nachgelagerten Aufgabenanwendungen führen.", "metrics": {"bleu_score": 68.7941939352187, "chrf_score": 91.82807178227944, "xcomet_score": 0.9833656549453735, "xcomet_qe_score": 0.9725565910339355, "metricx_score": 0.7899162769317627, "metricx_qe_score": 0.749700665473938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "To this end, we propose to investigate the political bias propagation pipeline from pre-training data to language models to downstream tasks, specifically by asking the following questions. Zuerst, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle die Trainingsdaten dabei spielen könnten, solche politischen Voreingenommenheiten zu haben?", "metrics": {"bleu_score": 12.375603640073978, "chrf_score": 45.336356520568216, "xcomet_score": 0.8175421953201294, "xcomet_qe_score": 0.9385947585105896, "metricx_score": 10.155529975891113, "metricx_qe_score": 14.16222095489502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie funktionieren Sprachmodelle mit unterschiedlichen politischen Neigungen bei Downstream-Aufgaben und ob dies zu Fairnessproblemen in NLP-Anwendungen führen könnte?", "metrics": {"bleu_score": 25.319096689413083, "chrf_score": 61.98039654689095, "xcomet_score": 0.978792130947113, "xcomet_qe_score": 0.9498631954193115, "metricx_score": 1.660058617591858, "metricx_qe_score": 1.5115636587142944, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere haben wir vorgeschlagen, Sprachmodelle mit unterschiedlichen Prompt-Formaten zu testen, indem wir politische Fragebögen wie den politischen Kompass-Test verwenden.", "metrics": {"bleu_score": 15.821285888349262, "chrf_score": 61.040584223043425, "xcomet_score": 0.9766323566436768, "xcomet_qe_score": 0.967604398727417, "metricx_score": 4.96484375, "metricx_qe_score": 3.9085311889648438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies gewährleistet eine automatische Bewertung, die auf der politischen Wissenschaftsliteratur basiert.", "metrics": {"bleu_score": 10.652684899188593, "chrf_score": 44.65341706528223, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8156388998031616, "metricx_qe_score": 0.6122798323631287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen also, dass erste Sprachmodelle unterschiedliche politische Neigungen aufweisen.", "metrics": {"bleu_score": 29.420957081163703, "chrf_score": 76.33764316480658, "xcomet_score": 0.9666417837142944, "xcomet_qe_score": 0.9749721884727478, "metricx_score": 2.1853883266448975, "metricx_qe_score": 1.3075706958770752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie besetzen alle vier Quadranten des politischen Spektrums.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 86.16261369727033, "xcomet_score": 0.9825257062911987, "xcomet_qe_score": 0.9926671981811523, "metricx_score": 0.7148317694664001, "metricx_qe_score": 0.8278083205223083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass GPT-4 das liberale Sprachmodell von allen ist und GPT-Theorien im Allgemeinen sozial liberaler sind als BERT-Theorien und ihre Variationen.", "metrics": {"bleu_score": 38.13415545749341, "chrf_score": 64.6379955408298, "xcomet_score": 0.9290576577186584, "xcomet_qe_score": 0.9429212212562561, "metricx_score": 2.6786587238311768, "metricx_qe_score": 1.2923874855041504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens wollen wir untersuchen, inwieweit die politischen Vorurteile von Sprachmodellen tatsächlich in den Trainingsdaten enthalten sind.", "metrics": {"bleu_score": 44.219732271776664, "chrf_score": 71.7740906374513, "xcomet_score": 0.9898223876953125, "xcomet_qe_score": 0.9966616630554199, "metricx_score": 0.3670760691165924, "metricx_qe_score": 0.344976544380188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also könnten wir ein kontrolliertes Experiment durchführen, indem wir die Sprachmodell-Checkpoints weiter auf sechs verschiedenen politischen Korpora vortrainieren, die in Nachrichten und soziale Medien unterteilt sind und weiter in ihre politische Ausrichtung unterteilt sind.", "metrics": {"bleu_score": 46.63348631417516, "chrf_score": 78.57657504929139, "xcomet_score": 0.8974794149398804, "xcomet_qe_score": 0.9398101568222046, "metricx_score": 5.087026119232178, "metricx_qe_score": 4.724974155426025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch das weitere prädiktive Training von Sprachmodellen auf solchen parteiischen Korpora können wir sehen, dass sich auch die ideologischen Koordinaten des Sprachmodells entsprechend verschieben.", "metrics": {"bleu_score": 53.88058943574727, "chrf_score": 80.79115841653558, "xcomet_score": 0.9485255479812622, "xcomet_qe_score": 0.9039614200592041, "metricx_score": 1.018646478652954, "metricx_qe_score": 1.7343237400054932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel für Roberta weiter verfeinert und weiter auf dem linksliegenden Reddit-Korpus trainiert, können wir eine erhebliche liberale Verschiebung in Bezug auf ihre sehen. In Bezug auf diese politischen Voreingenommenheiten.", "metrics": {"bleu_score": 7.173095622076889, "chrf_score": 50.23812390204253, "xcomet_score": 0.7405691742897034, "xcomet_qe_score": 0.7973076105117798, "metricx_score": 13.678661346435547, "metricx_qe_score": 13.848339080810547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung aufnehmen können, die in unserer modernen Gesellschaft vorherrscht.", "metrics": {"bleu_score": 58.111170763716785, "chrf_score": 79.89066040294406, "xcomet_score": 0.9875885248184204, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7160740494728088, "metricx_qe_score": 0.4866216778755188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also teilen wir das Pretraining der Corpora in Pre-45. Präsident der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten auf.", "metrics": {"bleu_score": 33.98508136320299, "chrf_score": 71.9397638886719, "xcomet_score": 0.8941705822944641, "xcomet_qe_score": 0.9030131101608276, "metricx_score": 6.255410194396973, "metricx_qe_score": 5.773935794830322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir trainieren die Sprachmodelle separat auf den beiden verschiedenen zeitlichen Corpora.", "metrics": {"bleu_score": 31.702331385234313, "chrf_score": 69.06139473399092, "xcomet_score": 0.9702081680297852, "xcomet_qe_score": 0.9103615283966064, "metricx_score": 1.1440398693084717, "metricx_qe_score": 2.2613039016723633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We can see that language models generally had a political leaning that is further away from the center after twenty seventeen. So this indicates that language models can also", "metrics": {"bleu_score": 1.2414943415352928, "chrf_score": 23.337533992745012, "xcomet_score": 0.4444440007209778, "xcomet_qe_score": 0.7300267219543457, "metricx_score": 22.464107513427734, "metricx_qe_score": 23.256486892700195, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "pick up the like polarization in our society. Zuletzt, aber nicht am wenigsten, bewer", "metrics": {"bleu_score": 3.0098043843528286, "chrf_score": 13.958056946084444, "xcomet_score": 0.23200495541095734, "xcomet_qe_score": 0.25330647826194763, "metricx_score": 22.894046783447266, "metricx_qe_score": 22.098161697387695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ten wir Sprachmodelle mit unterschiedlichen politischen Implikationen in Bezug auf die Erkennung von Hassrede und Fake-News-Erkennung für NLP-Anwendungen, die oft Sprachmodelle beinhalten und erhebliche Auswirkungen haben könnten.", "metrics": {"bleu_score": 20.114200788861936, "chrf_score": 58.96974103199988, "xcomet_score": 0.7819362878799438, "xcomet_qe_score": 0.7860217094421387, "metricx_score": 6.366727828979492, "metricx_qe_score": 5.484615325927734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sehen wir, dass, wenn wir die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in zwei Teile aufteilen, Different demographics or political leaning of news media, we can see a pattern that,", "metrics": {"bleu_score": 7.195213544257117, "chrf_score": 35.26568282473976, "xcomet_score": 0.5439831018447876, "xcomet_qe_score": 0.6784843802452087, "metricx_score": 16.7421817779541, "metricx_qe_score": 14.919208526611328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "for example, for hate speech detection, left-leaning language models are better. Bei der Erkennung von Hassrede, die soziale Minderheitengruppen ins Visier nimmt. Allerdings sind wir besser darin, Hassrede zu erkennen, die stärkere Gruppen in unserer Gesellschaft ins Visier nimmt. Und", "metrics": {"bleu_score": 11.838152366639104, "chrf_score": 42.27354172387565, "xcomet_score": 0.4352097511291504, "xcomet_qe_score": 0.5201462507247925, "metricx_score": 21.498159408569336, "metricx_qe_score": 19.81336212158203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "umgekehrt sind weiße Sprachmodelle besser darin, Hassrede zu erkennen, die weiße und Männer ins Visier nimmt, aber schlechter darin, Hassrede zu erkennen, die schwarze LGBTQ+- und andere Minderheiten ins Visier nimmt.", "metrics": {"bleu_score": 14.644504358943005, "chrf_score": 51.542431668968106, "xcomet_score": 0.7779868841171265, "xcomet_qe_score": 0.7992038726806641, "metricx_score": 4.825527667999268, "metricx_qe_score": 3.648423433303833, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends treten auch bei der Erkennung von Fake News auf, wo wir feststellen, dass linkslastige Sprachmodelle besser darin sind, Fehlinformationen aus ihrer gegensätzlichen politischen Ausrichtung zu erkennen, und umgekehrt.", "metrics": {"bleu_score": 25.79766417513125, "chrf_score": 60.23741610663691, "xcomet_score": 0.982113242149353, "xcomet_qe_score": 0.9982842206954956, "metricx_score": 0.3680136203765869, "metricx_qe_score": 0.3303806185722351, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Film zeigen wir viele qualitative Beispiele, um zu zeigen, dass Sprachmodelle mit unterschiedlichen politischen Bedeutungen sind. Geben Sie unterschiedliche Vorhersagen für Beispiele von Hassrede und Fehlinformationen basierend", "metrics": {"bleu_score": 34.89571331320155, "chrf_score": 64.9403148003127, "xcomet_score": 0.6596294045448303, "xcomet_qe_score": 0.5776800513267517, "metricx_score": 12.561894416809082, "metricx_qe_score": 12.35494613647461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "auf ihren sozialen Kategorien. Es gibt eine Reihe weiterer Beispiele im Anhang, um dies weiter zu betonen. Dies deutet darauf hin, dass es ein Fairness-Problem gibt, das sehr dringend ist, was die politischen Voreingenommenheiten von Sprachmodellen betrifft.", "metrics": {"bleu_score": 9.146293676747309, "chrf_score": 61.63889183211754, "xcomet_score": 0.8137359023094177, "xcomet_qe_score": 0.7858461141586304, "metricx_score": 6.696577072143555, "metricx_qe_score": 7.177844047546387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn ein Rechliningsmodell fein abgestimmt wäre, um Hassrede oder Fehlinformationen oder was auch immer zu erkennen und auf einer populären Social-Media-Plattform zu implementieren. Dies würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen möglicherweise marginalisiert werden und Hassreden, die Minderheitengruppen ins Visier nehmen, ohne jegliche Kontrolle ausbrechen könnten.", "metrics": {"bleu_score": 22.318094352251187, "chrf_score": 61.18409400108169, "xcomet_score": 0.7726696133613586, "xcomet_qe_score": 0.8602205514907837, "metricx_score": 3.6899611949920654, "metricx_qe_score": 4.9056549072265625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat also die Alarmglocke für uns läuten lassen, um die Fairnessprobleme anzuerkennen und anzugehen, die durch sprachmodelle und politische Vorurteile verursacht werden.", "metrics": {"bleu_score": 5.6858409674376205, "chrf_score": 46.194328703393225, "xcomet_score": 0.9259700775146484, "xcomet_qe_score": 0.937741756439209, "metricx_score": 2.403195858001709, "metricx_qe_score": 1.1054915189743042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also ein bisschen Diskussion.", "metrics": {"bleu_score": 7.16047614494885, "chrf_score": 14.908720042586655, "xcomet_score": 0.7525796890258789, "xcomet_qe_score": 0.9724511504173279, "metricx_score": 1.3654323816299438, "metricx_qe_score": 0.7741227149963379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten auch betonen, dass wir das einzigartige Dilemma in Bezug auf sprachmodelle, politische Voreingenommenheiten, zwischen", "metrics": {"bleu_score": 48.2457299495954, "chrf_score": 77.54657300524931, "xcomet_score": 0.8231561183929443, "xcomet_qe_score": 0.8352996110916138, "metricx_score": 11.084490776062012, "metricx_qe_score": 9.297981262207031, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Cila und Karibdis, aufgedeckt haben.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 22.764863296089942, "xcomet_score": 0.22091449797153473, "xcomet_qe_score": 0.14638857543468475, "metricx_score": 17.763877868652344, "metricx_qe_score": 19.764923095703125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die politischen Meinungen in den Trainingsdaten des Sprachmodells nicht bereinigen, werden die Vorurteile von den Vortrainingsdaten auf Sprachmodelle und nachgelagerte Aufgaben übertragen, was letztendlich Fairnessprobleme verursacht.", "metrics": {"bleu_score": 17.939908213951202, "chrf_score": 58.899463039022635, "xcomet_score": 0.9667388796806335, "xcomet_qe_score": 0.9568131566047668, "metricx_score": 0.7182334661483765, "metricx_qe_score": 0.754122257232666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, irgendwie zu sanitieren, riskieren wir auch Zensur oder Ausschluss.", "metrics": {"bleu_score": 39.495229895988196, "chrf_score": 64.95465571513613, "xcomet_score": 0.9073363542556763, "xcomet_qe_score": 0.9467127919197083, "metricx_score": 3.284909725189209, "metricx_qe_score": 2.9805550575256348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und welche Sprachmonitoreingaben beibehalten werden sollten.", "metrics": {"bleu_score": 30.23858407554745, "chrf_score": 61.10520440576926, "xcomet_score": 0.9819350242614746, "xcomet_qe_score": 0.984319806098938, "metricx_score": 0.7187517285346985, "metricx_qe_score": 0.7717411518096924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also ein bisschen wie das elektrische Trolley-Problem.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 92.01441893603447, "xcomet_score": 0.9805029630661011, "xcomet_qe_score": 0.9796573519706726, "metricx_score": 0.6678054928779602, "metricx_qe_score": 1.3079848289489746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, great.", "metrics": {"bleu_score": 35.35533905932737, "chrf_score": 52.90627164833901, "xcomet_score": 0.9828640222549438, "xcomet_qe_score": 0.9942677021026611, "metricx_score": 0.6357739567756653, "metricx_qe_score": 0.7277308702468872, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "I think that's pretty much all I have for today.", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 11.702189372648581, "xcomet_score": 0.9498496055603027, "xcomet_qe_score": 1.0, "metricx_score": 22.590612411499023, "metricx_qe_score": 24.08650016784668, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thanks for your time. Please find", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 14.532756301597418, "xcomet_score": 0.3284693956375122, "xcomet_qe_score": 0.8149622082710266, "metricx_score": 6.600666522979736, "metricx_qe_score": 3.8077728748321533, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,", "metrics": {"bleu_score": 0.0, "chrf_score": 91.10491360491362, "xcomet_score": 0.993188738822937, "xcomet_qe_score": 0.994185209274292, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Jenny, eine Doktorandin in der ersten Studienjahr an der Carnegie Mellon University. Und heute werde ich Ihre Arbeit vorstellen, anal positionality, die Design-Biasen von Datensätzen und Modellen charakterisieren.", "metrics": {"bleu_score": 15.069228960836636, "chrf_score": 56.25732903485216, "xcomet_score": 0.6255956292152405, "xcomet_qe_score": 0.7989565134048462, "metricx_score": 5.418735504150391, "metricx_qe_score": 4.805058479309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Leuten an der University of Washington und dem Allen Institute for AI durchgeführt, nämlich Sebastian Santi, Ronan Labrosse, Katerina Raneva und Martin Sapp.", "metrics": {"bleu_score": 55.60441483540001, "chrf_score": 77.2780810487618, "xcomet_score": 0.782884418964386, "xcomet_qe_score": 0.75081467628479, "metricx_score": 2.622807502746582, "metricx_qe_score": 2.9387991428375244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Beginnen wir also damit, sich vorzustellen, dass Sie für eine Zeitung arbeiten und durch Kommentare zu Ihrem Artikel durchsuchen, um toxische Inhalte zu entfernen.", "metrics": {"bleu_score": 15.559274181899394, "chrf_score": 57.84506466893774, "xcomet_score": 0.9668817520141602, "xcomet_qe_score": 0.963100254535675, "metricx_score": 5.238957405090332, "metricx_qe_score": 5.068589687347412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich für eine beliebte API wie die Perspektiv-API für die Erkennung von Toxizität entscheiden. Und das funktioniert wirklich gut, wenn Sie Carl Jones sind,", "metrics": {"bleu_score": 43.49027161877214, "chrf_score": 64.69784999324341, "xcomet_score": 0.8807735443115234, "xcomet_qe_score": 0.8989357948303223, "metricx_score": 2.5770883560180664, "metricx_qe_score": 1.9224656820297241, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wo die Perspektiv-API in der Lage ist, toxische Instanzen korrekt zu erkennen.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 74.30498857573556, "xcomet_score": 0.832118570804596, "xcomet_qe_score": 0.7455145120620728, "metricx_score": 2.9813244342803955, "metricx_qe_score": 3.2670977115631104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist bei Aditya Sharma nicht", "metrics": {"bleu_score": 18.168644632623682, "chrf_score": 48.715474041395375, "xcomet_score": 0.9588873982429504, "xcomet_qe_score": 0.9656764268875122, "metricx_score": 5.445314407348633, "metricx_qe_score": 3.0746421813964844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wirklich der Fall, wo die perspektivische API nicht wirklich so sensibel gegenüber beleidigenden Begriffen ist, die in indischen Kontexten häufiger vorkommen.", "metrics": {"bleu_score": 33.8796999974464, "chrf_score": 62.56170348514476, "xcomet_score": 0.7892194390296936, "xcomet_qe_score": 0.7964582443237305, "metricx_score": 4.125025272369385, "metricx_qe_score": 5.205532073974609, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Beispiel für einen Designbias, bei dem wir systematische Leistungsunterschiede der Technologie zwischen Bevölkerungsgruppen sehen.", "metrics": {"bleu_score": 32.23991481175862, "chrf_score": 71.42785120286311, "xcomet_score": 0.9359291791915894, "xcomet_qe_score": 0.9437737464904785, "metricx_score": 1.0098471641540527, "metricx_qe_score": 0.48579874634742737, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Design-Biasen wie die, die wir gerade gesehen haben, können aufgrund der Positionierung der NLP-Forscher und Modellentwickler auftreten.", "metrics": {"bleu_score": 35.37053193768171, "chrf_score": 70.80862088533915, "xcomet_score": 0.9867854118347168, "xcomet_qe_score": 1.0, "metricx_score": 0.6902110576629639, "metricx_qe_score": 0.5193130970001221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Positionierung ist einfach die Perspektiven, die Menschen aufgrund ihrer demografischen Identität und Lebenserfahrungen haben.", "metrics": {"bleu_score": 32.13533542196591, "chrf_score": 74.11847411920274, "xcomet_score": 0.9630329608917236, "xcomet_qe_score": 0.9655911922454834, "metricx_score": 1.5503602027893066, "metricx_qe_score": 1.3111817836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in der kritischen Studienlandschaft weit verbreitet ist, insbesondere in feministischen und queer akademischen Räumen. Und", "metrics": {"bleu_score": 17.855149299161603, "chrf_score": 59.28111314561949, "xcomet_score": 0.956282377243042, "xcomet_qe_score": 0.9594005346298218, "metricx_score": 1.4745864868164062, "metricx_qe_score": 0.5317397117614746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "als Forscher kann die Positionalität den Forschungsprozess und seine Ergebnisse und Ergebnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann. Und so ist", "metrics": {"bleu_score": 40.588153399233, "chrf_score": 80.68921129914341, "xcomet_score": 0.7431390285491943, "xcomet_qe_score": 0.7917854189872742, "metricx_score": 8.132306098937988, "metricx_qe_score": 6.920612335205078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "eine Frage, die die Leute stellen könnten, ob Datenmengen und Modelle eine Position haben?", "metrics": {"bleu_score": 14.085916416769418, "chrf_score": 54.83630952939406, "xcomet_score": 0.8968600034713745, "xcomet_qe_score": 0.9050406813621521, "metricx_score": 3.520982503890991, "metricx_qe_score": 2.9144465923309326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen nicht zu sagen, dass Modelle und Daten selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen von echten Menschen und können daher bestimmte Positionierungen gegenüber anderen darstellen.", "metrics": {"bleu_score": 37.73779026845908, "chrf_score": 73.34838171283937, "xcomet_score": 0.9726381301879883, "xcomet_qe_score": 0.9764317870140076, "metricx_score": 0.8276066780090332, "metricx_qe_score": 0.5040780305862427, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Arbeiten haben also anekdotische Beweise für eine Positionalität vorgelegt, wie kulturelle Lücken in Modellen und Datensätzen sowie theoretische Definitionen der Modellpositionalität.", "metrics": {"bleu_score": 13.105719079008516, "chrf_score": 63.946043088983274, "xcomet_score": 0.9686096906661987, "xcomet_qe_score": 0.9646019339561462, "metricx_score": 1.5706486701965332, "metricx_qe_score": 1.4511933326721191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings untersuchen diese Arbeiten nicht wirklich, ob Endbenutzer mit den Datensätzen und Modellen selbst vergleichbar sind. Und die Positionierung von Modellen und Datensätzen wird immer wichtiger, da NLP-Aufgaben subjektiver und sozialer werden. Und es ist herausfordernd, zu charakterisieren, wie diese Positionierungen verzerrt sind, weil nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind.", "metrics": {"bleu_score": 38.66448238854812, "chrf_score": 68.76526612527788, "xcomet_score": 0.8866697549819946, "xcomet_qe_score": 0.918499231338501, "metricx_score": 1.2241953611373901, "metricx_qe_score": 1.4360013008117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Datensatz- und Modellpositionalität zu untersuchen, vergleichen wir die Anmerkungen mit echten Benutzern mit vorhandenen Datensätzen und Modellen.", "metrics": {"bleu_score": 29.870695791014903, "chrf_score": 64.72201201116464, "xcomet_score": 0.9366316795349121, "xcomet_qe_score": 0.9265809059143066, "metricx_score": 0.8530998229980469, "metricx_qe_score": 0.9370870590209961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir tun dies durch unser Framework, NL-Positionalität.", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 52.29839991749652, "xcomet_score": 0.9715454578399658, "xcomet_qe_score": 0.9847621917724609, "metricx_score": 0.6668676733970642, "metricx_qe_score": 0.9986245632171631, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "R framework works in two main steps.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 21.383206437720947, "xcomet_score": 0.6868897676467896, "xcomet_qe_score": 0.9073401093482971, "metricx_score": 24.032882690429688, "metricx_qe_score": 20.662395477294922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The first step is to re-annotate datasets with diverse annotators. Und wir entscheiden", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 25.892744567167735, "xcomet_score": 0.3520374298095703, "xcomet_qe_score": 0.3934975266456604, "metricx_score": 23.6524658203125, "metricx_qe_score": 24.280630111694336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uns dafür, dies zu tun, anstatt uns die Demografie der ursprünglichen Datensatz-Annotationen anzusehen, da in der Regel nur wenige Annotatoren jede Instanz annotieren, und weil Demografien selten gesammelt und geteilt werden.", "metrics": {"bleu_score": 15.499999679101586, "chrf_score": 52.44254295503037, "xcomet_score": 0.785251796245575, "xcomet_qe_score": 0.8201186656951904, "metricx_score": 5.807901382446289, "metricx_qe_score": 5.7929205894470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und so entscheiden wir uns dafür, Daten neu zu annotieren, um beispielsweise viele Anmerkungen zu erhalten und eine reichhaltige Datensammlung zu erhalten.", "metrics": {"bleu_score": 15.919638844359847, "chrf_score": 49.976407628344035, "xcomet_score": 0.9436442852020264, "xcomet_qe_score": 0.9375750422477722, "metricx_score": 4.001055717468262, "metricx_qe_score": 4.018765449523926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen dann die Anmerkungen nach demografischen Merkmalen und vergleichen sie mit den Modellen und Datensätzen unter Verwendung eines Pearson's R-Korrelationswerts. Und so unterscheidet sich unser Framework tatsächlich von der Literatur zur Diskrepanz der Annotatoren, indem es Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Labels vergleicht, im Gegensatz zu einer Betrachtung der Annotatorenvereinbarung oder der Modellierung von Annotatorenverteilungen.", "metrics": {"bleu_score": 26.37305345660182, "chrf_score": 65.64202404516644, "xcomet_score": 0.8518171310424805, "xcomet_qe_score": 0.8863946199417114, "metricx_score": 4.053942680358887, "metricx_qe_score": 4.3814544677734375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird weitgehend durch Lab in the Wild, eine Online-Crowdsourcing-Plattform, ermöglicht, die ehemalige HCI-Kollaboratorin. Und", "metrics": {"bleu_score": 27.57185986366082, "chrf_score": 65.85288572215545, "xcomet_score": 0.8374447822570801, "xcomet_qe_score": 0.8600380420684814, "metricx_score": 6.888049602508545, "metricx_qe_score": 6.942195415496826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentierplattform, auf der wir vielfältige Freiwillige rekrutieren können,", "metrics": {"bleu_score": 74.47819789879651, "chrf_score": 86.6609767519462, "xcomet_score": 0.9386991262435913, "xcomet_qe_score": 0.759231448173523, "metricx_score": 2.2363483905792236, "metricx_qe_score": 5.388862133026123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im Gegensatz zu Plattformen wie M- Turk, die hauptsächlich Teilnehmer aus den USA oder Indien haben. Darüber hinaus ist Lab in the Wild in der Lage, hochwertige Daten zu erhalten. Wir hosten", "metrics": {"bleu_score": 43.66155726827093, "chrf_score": 64.47053914337633, "xcomet_score": 0.7927619218826294, "xcomet_qe_score": 0.784040093421936, "metricx_score": 6.849838733673096, "metricx_qe_score": 4.269999980926514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zwei Aufgaben auf Lab in the Wild, eine davon ist soziale Akzeptanz. Und die Art und Weise, wie das funktioniert, ist, dass die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz lesen und dann schreiben, wie sozial akzeptabel eine Situation ist.", "metrics": {"bleu_score": 21.842588239803845, "chrf_score": 69.21737871814098, "xcomet_score": 0.9486722350120544, "xcomet_qe_score": 0.9370021820068359, "metricx_score": 2.2888216972351074, "metricx_qe_score": 2.836965799331665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um sich weiterhin mit dem Thema zu beschäftigen, können sie ihre Antworten mit denen anderer KI vergleichen.", "metrics": {"bleu_score": 21.966685075366733, "chrf_score": 49.62405730658092, "xcomet_score": 0.8786453008651733, "xcomet_qe_score": 0.9042040109634399, "metricx_score": 2.5235562324523926, "metricx_qe_score": 0.6946689486503601, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Anmerkungen dann mit Social Chemistry, Delphi und GPT-4 verglichen.", "metrics": {"bleu_score": 53.36129799268556, "chrf_score": 78.84258598932455, "xcomet_score": 0.9937229156494141, "xcomet_qe_score": 0.9913986921310425, "metricx_score": 0.8670941591262817, "metricx_qe_score": 2.162851333618164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann ein sehr ähnliches Setup für die Aufgabe der Erkennung von Toxizität und Hassrede repliziert, bei der sie eine Instanz aus Dinhate lesen und schreiben werden, ob sie glauben, dass es sich um eine Hassrede handelt. Wir haben", "metrics": {"bleu_score": 7.813651034814239, "chrf_score": 40.07820500501268, "xcomet_score": 0.7262628674507141, "xcomet_qe_score": 0.8025872707366943, "metricx_score": 8.503583908081055, "metricx_qe_score": 4.543337821960449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "diese Anmerkungen dann mit dynahate, perspective api, rewire api, hate roberta und gpt four verglichen. Unsere Studie", "metrics": {"bleu_score": 6.108557268562174, "chrf_score": 46.99643532861293, "xcomet_score": 0.796535849571228, "xcomet_qe_score": 0.753815770149231, "metricx_score": 7.668075084686279, "metricx_qe_score": 9.348492622375488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "am Ende umfasste über sechzehntausend Anmerkungen von über tausend Annotatoren aus siebenundachtzig Ländern.", "metrics": {"bleu_score": 8.251974815664543, "chrf_score": 37.993984661624346, "xcomet_score": 0.8893439769744873, "xcomet_qe_score": 0.896837592124939, "metricx_score": 5.923464775085449, "metricx_qe_score": 5.405062675476074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So sind wir nun besser gerüstet, um zu beantworten, mit wem sich NLP-Datensätze und Modelle am besten decken.", "metrics": {"bleu_score": 17.90330496260186, "chrf_score": 52.78546168042065, "xcomet_score": 0.95201176404953, "xcomet_qe_score": 0.9665278196334839, "metricx_score": 2.846731424331665, "metricx_qe_score": 1.9499430656433105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass es in NLP eine Positionierung gibt.", "metrics": {"bleu_score": 18.360281349467954, "chrf_score": 47.88526525727476, "xcomet_score": 0.9901115894317627, "xcomet_qe_score": 0.9890294671058655, "metricx_score": 0.7161078453063965, "metricx_qe_score": 0.6956824064254761, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel stellen wir fest, dass Datensätze und Modelle am besten mit englischsprachigen Ländern übereinstimmen.", "metrics": {"bleu_score": 20.124833529317485, "chrf_score": 60.38763954871317, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.35068798065185547, "metricx_qe_score": 0.2682049870491028, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Analyse der sozial akzeptablen Verhaltensweisen des GPT-4 finden wir, dass es am besten mit konfuzianischen und englischsprachigen Ländern übereinstimmt.", "metrics": {"bleu_score": 9.963981113649664, "chrf_score": 46.76791857272411, "xcomet_score": 0.9732561111450195, "xcomet_qe_score": 0.9938114881515503, "metricx_score": 1.2819617986679077, "metricx_qe_score": 1.443368911743164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Dinahite auch am besten mit englischsprachigen Ländern übereinstimmt.", "metrics": {"bleu_score": 26.924333182417303, "chrf_score": 51.11109209403292, "xcomet_score": 0.8231935501098633, "xcomet_qe_score": 0.8301933407783508, "metricx_score": 3.382211208343506, "metricx_qe_score": 2.8018088340759277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch die meisten zusätzlichen Übereinstimmungen mit Menschen, die eine Hochschulbildung haben.", "metrics": {"bleu_score": 3.8477237177211134, "chrf_score": 36.400427667822235, "xcomet_score": 0.9128878116607666, "xcomet_qe_score": 0.9800931811332703, "metricx_score": 0.3399547040462494, "metricx_qe_score": 0.06121315807104111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der GPT-4- und der sozialen Akzeptanzaufgabe finden wir also, dass es am besten mit Menschen mit Hochschul- oder Graduiertenausbildung übereinstimmt. Und wir finden das gleiche für Donut Hate, wo es am besten zu Menschen mit einer Hochschulausbildung passt.", "metrics": {"bleu_score": 5.126335900863836, "chrf_score": 39.698765134688024, "xcomet_score": 0.7576065063476562, "xcomet_qe_score": 0.7489482164382935, "metricx_score": 5.962749481201172, "metricx_qe_score": 5.394721031188965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jedoch Modelle und Datensätze an bestimmte Populationen angepasst werden, bleiben einige unberücksichtigt.", "metrics": {"bleu_score": 28.484948571503086, "chrf_score": 50.28008379895176, "xcomet_score": 0.9878982305526733, "xcomet_qe_score": 0.9876331686973572, "metricx_score": 0.24221916496753693, "metricx_qe_score": 0.18855836987495422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger mit nichtbinären Menschen im Vergleich zu den männlichen und weiblichen Gegenstücken übereinstimmen.", "metrics": {"bleu_score": 45.027081958582315, "chrf_score": 70.5208061755557, "xcomet_score": 0.9672644138336182, "xcomet_qe_score": 0.9748482704162598, "metricx_score": 0.46430137753486633, "metricx_qe_score": 0.4650713801383972, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden dies in der GPT-4-Sozialakzeptanzaufgabe sowie in der Dignity Hate Task-Analyse. Angesichts der Tatsache,", "metrics": {"bleu_score": 35.025412310639744, "chrf_score": 55.20231945409545, "xcomet_score": 0.7486284375190735, "xcomet_qe_score": 0.7597067356109619, "metricx_score": 7.456818580627441, "metricx_qe_score": 8.36707878112793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass es eine Position in Allee und Lp gibt, was können wir dagegen tun?", "metrics": {"bleu_score": 45.608395453519385, "chrf_score": 60.622436465815625, "xcomet_score": 0.6942105293273926, "xcomet_qe_score": 0.6599509716033936, "metricx_score": 11.113809585571289, "metricx_qe_score": 13.552830696105957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben ein paar Empfehlungen dazu.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 59.80033665325859, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21344402432441711, "metricx_qe_score": 0.26075464487075806, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist, eine Aufzeichnung aller relevanten Designentscheidungen während des gesamten Forschungsprozesses zu führen. Und", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 73.85344870108419, "xcomet_score": 0.9452493190765381, "xcomet_qe_score": 0.881263792514801, "metricx_score": 0.8921610116958618, "metricx_qe_score": 0.3137410879135132, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die andere ist, die NLP-Forschung mit einem Perspektivismus zu betreiben.", "metrics": {"bleu_score": 24.107473040766184, "chrf_score": 63.27337880451077, "xcomet_score": 0.9237942695617676, "xcomet_qe_score": 0.9093409776687622, "metricx_score": 3.8067047595977783, "metricx_qe_score": 3.800720691680908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften zu erstellen.", "metrics": {"bleu_score": 63.019085559238604, "chrf_score": 77.10663493131908, "xcomet_score": 0.9986236095428467, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.35815340280532837, "metricx_qe_score": 0.32743629813194275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ein gutes Beispiel dafür ist die Muscogee-Initiative.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 62.75796726447956, "xcomet_score": 0.8052073121070862, "xcomet_qe_score": 0.8075956106185913, "metricx_score": 5.76017951965332, "metricx_qe_score": 4.916345596313477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich meine, wir möchten betonen, dass inklusives NLP nicht nur bedeutet, dass", "metrics": {"bleu_score": 32.407795496999476, "chrf_score": 55.870534594603946, "xcomet_score": 0.8896154165267944, "xcomet_qe_score": 0.8587749004364014, "metricx_score": 6.561031818389893, "metricx_qe_score": 4.035068988800049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "alle Technologien für alle funktionieren.", "metrics": {"bleu_score": 45.48019047027906, "chrf_score": 82.54432328305383, "xcomet_score": 0.910865068435669, "xcomet_qe_score": 0.9326093196868896, "metricx_score": 6.576948165893555, "metricx_qe_score": 6.560419082641602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und so schließt unsere Präsentation ab.", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 54.91964785300076, "xcomet_score": 0.9659522175788879, "xcomet_qe_score": 0.9581258296966553, "metricx_score": 1.7506718635559082, "metricx_qe_score": 0.9776060581207275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn Sie mehr erfahren möchten, können Sie sich gerne unser Dashboard für die aktuellsten Analyseergebnisse und unsere Arbeit ansehen.", "metrics": {"bleu_score": 52.01592023534245, "chrf_score": 76.43228251658576, "xcomet_score": 0.9944214820861816, "xcomet_qe_score": 0.9734442830085754, "metricx_score": 0.9229975938796997, "metricx_qe_score": 1.2895739078521729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9926378726959229, "xcomet_qe_score": 1.0, "metricx_score": 1.4178515672683716, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Si Yu Yuan von der Fudan University.", "metrics": {"bleu_score": 43.66835442847811, "chrf_score": 84.93776693137195, "xcomet_score": 0.8774204254150391, "xcomet_qe_score": 0.9239652156829834, "metricx_score": 0.34244152903556824, "metricx_qe_score": 0.2715303897857666, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin hier, um unsere Arbeit vorzustellen, die Unterscheidung von Sprechwissen aus großen Sprachmodellen für die eingeschränkte Sp", "metrics": {"bleu_score": 30.143352515082135, "chrf_score": 37.492823785812995, "xcomet_score": 0.780137300491333, "xcomet_qe_score": 0.7466237545013428, "metricx_score": 7.848204612731934, "metricx_qe_score": 8.374467849731445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "rachplanung. In everyday life, humans often plan their actions by following step-by-step instructions in the form of guaranteed scripts.", "metrics": {"bleu_score": 2.2731543567022867, "chrf_score": 19.008774958143366, "xcomet_score": 0.4639999270439148, "xcomet_qe_score": 0.4124060571193695, "metricx_score": 23.120559692382812, "metricx_qe_score": 18.1890926361084, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Arbeiten haben Sprachmodelle genutzt, um für abstrakte Ziele von stereotypischen Aktivitäten wie \"Kuchen backen\" zu planen und", "metrics": {"bleu_score": 12.836520024977334, "chrf_score": 66.45723420731088, "xcomet_score": 0.8942394256591797, "xcomet_qe_score": 0.9052060842514038, "metricx_score": 3.5618467330932617, "metricx_qe_score": 0.809958815574646, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können.", "metrics": {"bleu_score": 48.30656008874588, "chrf_score": 63.793722095151786, "xcomet_score": 0.9554697275161743, "xcomet_qe_score": 0.9595874547958374, "metricx_score": 1.8998146057128906, "metricx_qe_score": 2.279642343521118, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings konzentriert sich die bisherige Arbeit hauptsächlich auf die Planung abstrakter Ziele und stereotypischer Aktivitäten.", "metrics": {"bleu_score": 34.234749558690204, "chrf_score": 71.87513179582204, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2968900203704834, "metricx_qe_score": 0.33864131569862366, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Planung von Zielen mit spezifischen Einschränkungen, wie zum Beispiel die Herstellung eines Schokoladenkuchens, bleibt jedoch unerforscht.", "metrics": {"bleu_score": 37.51840463233444, "chrf_score": 72.00019052169924, "xcomet_score": 0.9950054883956909, "xcomet_qe_score": 0.9904986619949341, "metricx_score": 1.7486085891723633, "metricx_qe_score": 1.25441575050354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung. Which imposes different constraints on the goals of planning.", "metrics": {"bleu_score": 29.4467310498826, "chrf_score": 51.78621757390979, "xcomet_score": 0.945956826210022, "xcomet_qe_score": 0.9584920406341553, "metricx_score": 19.203134536743164, "metricx_qe_score": 14.557563781738281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "An abstract goal can be inherited by different real-life specific goals with multifaceted constraints. A good planner", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 19.301913232511218, "xcomet_score": 0.31928277015686035, "xcomet_qe_score": 0.8550407886505127, "metricx_score": 24.94051170349121, "metricx_qe_score": 23.321414947509766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "should write scripts that are reasonable and faithful to constraints.", "metrics": {"bleu_score": 2.17212999031354, "chrf_score": 13.965645980957575, "xcomet_score": 0.5839229822158813, "xcomet_qe_score": 0.9290784597396851, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier bewerten und verbessern wir zunächst die eingeschränkte Sprachplanungskompetenz großer Sprachmodelle.", "metrics": {"bleu_score": 20.23302501778005, "chrf_score": 46.131895546547746, "xcomet_score": 0.9914906024932861, "xcomet_qe_score": 1.0, "metricx_score": 0.5973968505859375, "metricx_qe_score": 0.2571054697036743, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Since no data set of specific goals exists to support our study. We have to acquire these goals first. As shown", "metrics": {"bleu_score": 1.6466642419110007, "chrf_score": 15.718376503166215, "xcomet_score": 0.8197762370109558, "xcomet_qe_score": 0.8739736676216125, "metricx_score": 12.796842575073242, "metricx_qe_score": 11.210826873779297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in the table, we extend the abstract goals with multifaceted constraints for human in-loop data acquisition using instruct GPT.", "metrics": {"bleu_score": 2.2789551664661816, "chrf_score": 23.594601804094903, "xcomet_score": 0.8673940896987915, "xcomet_qe_score": 0.9195890426635742, "metricx_score": 19.68855857849121, "metricx_qe_score": 19.25717544555664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We sample one hundred specific goals and evaluate the scripts generated from large language models.", "metrics": {"bleu_score": 2.0274685852177114, "chrf_score": 28.45082506858333, "xcomet_score": 0.9607255458831787, "xcomet_qe_score": 0.9946318864822388, "metricx_score": 18.72275161743164, "metricx_qe_score": 21.031742095947266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die Gesamtgenauigkeit der Ergebnisse.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2685028314590454, "metricx_qe_score": 0.3559974730014801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass alle Sprachtechnologie-Modelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen.", "metrics": {"bleu_score": 43.819512537676886, "chrf_score": 81.43322036280577, "xcomet_score": 0.9786167740821838, "xcomet_qe_score": 0.9682621955871582, "metricx_score": 0.41125282645225525, "metricx_qe_score": 0.4123696982860565, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Then we conduct detailed analysis to investigate why language models fail. Die Ergebnisse", "metrics": {"bleu_score": 1.9869571647551538, "chrf_score": 19.08774103385067, "xcomet_score": 0.38863566517829895, "xcomet_qe_score": 0.5703122615814209, "metricx_score": 25.0, "metricx_qe_score": 24.139163970947266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in der Abbildung zeigen, dass die semantische Vollständigkeit in generierten Sätzen akzeptabel ist, aber die Treue zu den Einschränkungen kann nicht garantiert werden.", "metrics": {"bleu_score": 33.12767002218064, "chrf_score": 66.55611551871708, "xcomet_score": 0.8827841281890869, "xcomet_qe_score": 0.8639872074127197, "metricx_score": 4.647866249084473, "metricx_qe_score": 4.186166286468506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir tauchen in eine feinere Unterteilung der Themenkategorien von Einschränkungen ein, die in WikiHow definiert sind.", "metrics": {"bleu_score": 15.733304984782075, "chrf_score": 58.987356025068514, "xcomet_score": 0.9873361587524414, "xcomet_qe_score": 0.9816871881484985, "metricx_score": 0.8579924702644348, "metricx_qe_score": 1.4021855592727661, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Heatmap in der Abbildung zeigt, dass die Planungsleistung von Instruktoren, GPTs, für Mädchen verschiedener Kategorien erheblich variiert.", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 87.212405063103, "xcomet_score": 0.7590489387512207, "xcomet_qe_score": 0.7797163724899292, "metricx_score": 6.42082405090332, "metricx_qe_score": 6.575869560241699, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vorherige Studien haben gezeigt, dass die Ausgabequalität von Sprachmodellen stark variiert, was zu einer schlechten Leistung führt.", "metrics": {"bleu_score": 67.71164277807225, "chrf_score": 79.40658582785579, "xcomet_score": 0.9902758598327637, "xcomet_qe_score": 0.9797916412353516, "metricx_score": 0.49653249979019165, "metricx_qe_score": 0.4808754026889801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher haben wir die Idee des übergenerierten Zens-Filters übernommen, um die Generierungseigenschaften zu verbessern.", "metrics": {"bleu_score": 18.801961527567503, "chrf_score": 55.85409284116275, "xcomet_score": 0.8836627006530762, "xcomet_qe_score": 0.8365113139152527, "metricx_score": 4.687298774719238, "metricx_qe_score": 4.299522399902344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We first show constraint types with examples for instructGPT and obtain specific goals based on the said abstract goals.", "metrics": {"bleu_score": 1.9146030690102511, "chrf_score": 20.53844048031315, "xcomet_score": 0.8037333488464355, "xcomet_qe_score": 0.9012971520423889, "metricx_score": 20.251752853393555, "metricx_qe_score": 22.919301986694336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann gibt instrGPT übergenerierte Schlüssel für bestimmte Ziele ab.", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 39.13539053723913, "xcomet_score": 0.8897982239723206, "xcomet_qe_score": 0.898363471031189, "metricx_score": 3.321347236633301, "metricx_qe_score": 4.544559001922607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes wird ein Filtermodell entwickelt, um die wahrscheinlichen Skripte auszuwählen.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 72.44592684255365, "xcomet_score": 0.9614529013633728, "xcomet_qe_score": 0.9590417146682739, "metricx_score": 1.7511041164398193, "metricx_qe_score": 1.0008565187454224, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We convert scripts and goals into instruct-gpt embeddings and calculate cosine similarity as similarity scores to measure semantic similarity.", "metrics": {"bleu_score": 1.7324044975269597, "chrf_score": 22.160536753702374, "xcomet_score": 0.9275774955749512, "xcomet_qe_score": 0.9595996737480164, "metricx_score": 21.969730377197266, "metricx_qe_score": 16.767539978027344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus vermeiden wir das Skript, das die Schlüsselwörter des Zielkriteriums enthält.", "metrics": {"bleu_score": 47.855439210937384, "chrf_score": 59.158835824225996, "xcomet_score": 0.8123443722724915, "xcomet_qe_score": 0.8103439807891846, "metricx_score": 9.04069709777832, "metricx_qe_score": 7.312203407287598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir behalten das Skript nur, wenn das Zielziel das höchste in der Zielkategorie erreicht.", "metrics": {"bleu_score": 47.60297106711672, "chrf_score": 66.57376437242432, "xcomet_score": 0.8855280876159668, "xcomet_qe_score": 0.8436629772186279, "metricx_score": 3.715938091278076, "metricx_qe_score": 3.5502820014953613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann instructiongpt sicherer, qualitativ hochwertigere Sätze generieren.", "metrics": {"bleu_score": 22.416933501922287, "chrf_score": 49.11074037344849, "xcomet_score": 0.9427071809768677, "xcomet_qe_score": 0.952154278755188, "metricx_score": 4.558844089508057, "metricx_qe_score": 4.303081035614014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Methode verbessert die Planierbarkeit sowohl in der semantischen Vollständigkeit als auch in der Treue zu den Einschränkungen.", "metrics": {"bleu_score": 28.52636439147137, "chrf_score": 67.83375907331578, "xcomet_score": 0.9703017473220825, "xcomet_qe_score": 0.9518993496894836, "metricx_score": 0.8258219361305237, "metricx_qe_score": 1.0804762840270996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Since large language models are costly to deploy, it is essential to enable language planning ability of smaller and specialized models.", "metrics": {"bleu_score": 1.795137899831049, "chrf_score": 21.81178611601295, "xcomet_score": 0.9889868497848511, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Creating datasets is an essential step to its end. Allerdings ermöglichen frü", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 19.819033715540996, "xcomet_score": 0.31529340147972107, "xcomet_qe_score": 0.16462424397468567, "metricx_score": 23.719791412353516, "metricx_qe_score": 23.805238723754883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "here Studien keine Planung für spezifische Ziele, und die manuelle Datensatzanmerkung ist teuer.", "metrics": {"bleu_score": 50.59974314883429, "chrf_score": 63.2393530101404, "xcomet_score": 0.8380696773529053, "xcomet_qe_score": 0.8355339765548706, "metricx_score": 11.054132461547852, "metricx_qe_score": 11.708979606628418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um eingeschränkte Sprachplanungsdatenbanken aus großen Sprachmodellen zu destillieren.", "metrics": {"bleu_score": 61.3370601087477, "chrf_score": 88.81125962847776, "xcomet_score": 0.9751930236816406, "xcomet_qe_score": 0.9692314863204956, "metricx_score": 1.1275103092193604, "metricx_qe_score": 0.9912240505218506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We apply our method for building a data set of constrained language planning named as code script.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 18.938667526408487, "xcomet_score": 0.8759242296218872, "xcomet_qe_score": 0.8709437251091003, "metricx_score": 10.44834041595459, "metricx_qe_score": 9.295228958129883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt generieren wir fünfundfünfzigtausend spezifische Ziele mit Skripten.", "metrics": {"bleu_score": 59.694917920196445, "chrf_score": 79.53659212055257, "xcomet_score": 0.9962217807769775, "xcomet_qe_score": 0.9902145862579346, "metricx_score": 0.6665054559707642, "metricx_qe_score": 1.0804531574249268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die Qualität der Validierung und der Testsets zu gewährleisten, bitten wir die von der Cloud gesponserten Arbeiter, die falschen Proben zu finden und zu überarbeiten.", "metrics": {"bleu_score": 30.492595274248742, "chrf_score": 55.13258791665001, "xcomet_score": 0.8821239471435547, "xcomet_qe_score": 0.9446992874145508, "metricx_score": 2.9327993392944336, "metricx_qe_score": 3.1668713092803955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die eingeschränkte Verteilung von Code-Script.", "metrics": {"bleu_score": 30.719343730842187, "chrf_score": 71.07181205977933, "xcomet_score": 0.883049726486206, "xcomet_qe_score": 0.9548201560974121, "metricx_score": 5.164793491363525, "metricx_qe_score": 3.846879720687866, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass Code-Script in den generierten spezifischen Zielen eine höhere Plausibilität aufweist.", "metrics": {"bleu_score": 8.47178590796544, "chrf_score": 54.26959439315107, "xcomet_score": 0.7775660753250122, "xcomet_qe_score": 0.7728650569915771, "metricx_score": 5.578839302062988, "metricx_qe_score": 5.067140579223633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit Code-Script können wir kleinere, aber spezialisiertere Modelle für die eingeschränkte Sprachplanung trainieren.", "metrics": {"bleu_score": 51.497322032579355, "chrf_score": 85.69725938971494, "xcomet_score": 0.8646672964096069, "xcomet_qe_score": 0.8385319709777832, "metricx_score": 2.671933174133301, "metricx_qe_score": 1.9005022048950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass T five fine-tune auf dem Code-White die Qualität von Scripts verbessern kann, die höher sind als die der meisten großen Sprachmodelle, was darauf hindeutet, dass kleinere Modelle größere Modelle übertreffen können, wenn sie richtig auf geeigneten Datensätzen trainiert werden.", "metrics": {"bleu_score": 38.7962606115838, "chrf_score": 65.39580041223603, "xcomet_score": 0.7107460498809814, "xcomet_qe_score": 0.7401668429374695, "metricx_score": 10.792479515075684, "metricx_qe_score": 10.040528297424316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir das eingeschränkte Sprachplanungsproblem etabli", "metrics": {"bleu_score": 9.469167282754096, "chrf_score": 54.44724989422852, "xcomet_score": 0.8680686950683594, "xcomet_qe_score": 0.9154359698295593, "metricx_score": 2.8469393253326416, "metricx_qe_score": 1.9446752071380615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ert, die eingeschränkte Sprachplanungsfähigkeit großer Sprachmodelle bewertet und eine Overgeneration-Filtermethode für große Sprachmodelle entwickelt.", "metrics": {"bleu_score": 8.231648683151372, "chrf_score": 52.64561318776008, "xcomet_score": 0.7125734090805054, "xcomet_qe_score": 0.719498872756958, "metricx_score": 9.678786277770996, "metricx_qe_score": 10.561178207397461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen Script-Datensatz, CodeScript, für die eingeschränkte Sprachplanung zu generieren.", "metrics": {"bleu_score": 32.99615684205933, "chrf_score": 64.10204745700543, "xcomet_score": 0.9026048183441162, "xcomet_qe_score": 0.903622031211853, "metricx_score": 1.2770813703536987, "metricx_qe_score": 2.0872154235839844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass der CodeScript-Datensatz eine wertvolle Ressource für die Forschung zur Sprachplanung sein kann.", "metrics": {"bleu_score": 25.038143490374946, "chrf_score": 66.56414068471544, "xcomet_score": 0.9830710887908936, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.26712968945503235, "metricx_qe_score": 0.6285256743431091, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thanks for your time. Please find", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 14.532756301597418, "xcomet_score": 0.3465687930583954, "xcomet_qe_score": 0.8030292987823486, "metricx_score": 7.511114597320557, "metricx_qe_score": 4.326180934906006, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "more details of Co-Script in our paper.", "metrics": {"bleu_score": 5.11459870708889, "chrf_score": 22.471057715246207, "xcomet_score": 0.9374154806137085, "xcomet_qe_score": 0.9772162437438965, "metricx_score": 13.77645492553711, "metricx_qe_score": 18.071561813354492, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Xu Heng.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 79.92975019932899, "xcomet_score": 0.8230292797088623, "xcomet_qe_score": 0.8640121817588806, "metricx_score": 0.011433914303779602, "metricx_qe_score": 0.07496648281812668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unser Papier vorstellen, ob die im Jahr 2003 benannten Entitätstaggereignisse in 2023 noch funktionieren? Lassen", "metrics": {"bleu_score": 9.74812453975988, "chrf_score": 39.3067395651547, "xcomet_score": 0.6653456687927246, "xcomet_qe_score": 0.706449031829834, "metricx_score": 7.477756023406982, "metricx_qe_score": 6.235566139221191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie uns loslegen.", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 13.819619905525652, "xcomet_score": 0.6162595748901367, "xcomet_qe_score": 0.7952062487602234, "metricx_score": 4.497795581817627, "metricx_qe_score": 4.931593894958496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Our paper investigated the problem of generalization using the named entity recognition task, or the NER task.", "metrics": {"bleu_score": 1.9428574714033409, "chrf_score": 24.904738112668163, "xcomet_score": 0.9889867305755615, "xcomet_qe_score": 0.9769250154495239, "metricx_score": 21.390226364135742, "metricx_qe_score": 22.561119079589844, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We observe that models have been using Conll two thousand and three to develop ner for almost twenty years. And this naturally raises several problems. Firstly, can these models generalize to modern data", "metrics": {"bleu_score": 1.2193311110766474, "chrf_score": 19.97640426334929, "xcomet_score": 0.7618889808654785, "xcomet_qe_score": 0.7517231702804565, "metricx_score": 16.233903884887695, "metricx_qe_score": 14.35898494720459, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "?", "metrics": {"bleu_score": 0.0, "chrf_score": 1.9762845849802373, "xcomet_score": 0.268505334854126, "xcomet_qe_score": 0.16029773652553558, "metricx_score": 17.63105010986328, "metricx_qe_score": 24.46620750427246, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir neue Tags entwickeln, was ist für eine gute Verallgemeinerung nötig? Gleichzeitig,", "metrics": {"bleu_score": 36.00565854285029, "chrf_score": 60.374661535070594, "xcomet_score": 0.894277811050415, "xcomet_qe_score": 0.8980344533920288, "metricx_score": 5.613276958465576, "metricx_qe_score": 4.825109958648682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir eine schlechte Verallgemeinerung beobachten, was verursacht den Leistungsabfall dieser Modelle?", "metrics": {"bleu_score": 32.875714520515146, "chrf_score": 69.79584739372265, "xcomet_score": 0.9735179543495178, "xcomet_qe_score": 0.9656526446342468, "metricx_score": 0.6619225144386292, "metricx_qe_score": 0.7231594324111938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Conll-Datensatz entwickelt.", "metrics": {"bleu_score": 59.90228521313677, "chrf_score": 89.0172928489356, "xcomet_score": 0.930320680141449, "xcomet_qe_score": 0.880075216293335, "metricx_score": 3.573812961578369, "metricx_qe_score": 2.6064352989196777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Datensatz, den wir von Reuters News von zwanzig zwanzig gesammelt und dann mit den gleichen Conll-Zweitausenddrei-Annotation-Richtlinien annotiert haben.", "metrics": {"bleu_score": 41.1650405963801, "chrf_score": 65.51163562953724, "xcomet_score": 0.706264853477478, "xcomet_qe_score": 0.6860837936401367, "metricx_score": 10.39828872680664, "metricx_qe_score": 13.279019355773926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We then fine-tuned over twenty models on colon 2003. We evaluated them on both the colon", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 16.037408503149408, "xcomet_score": 0.2017892599105835, "xcomet_qe_score": 0.49699971079826355, "metricx_score": 21.27897834777832, "metricx_qe_score": 17.325963973999023, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "03 test set and the colon plus plus test set. Und zuletzt, aber nicht am wenigsten, haben", "metrics": {"bleu_score": 2.276859592073037, "chrf_score": 17.40483021828121, "xcomet_score": 0.22920437157154083, "xcomet_qe_score": 0.1705411672592163, "metricx_score": 21.93768310546875, "metricx_qe_score": 19.131410598754883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir die prozentuale Veränderung in F1 berechnet, um die Verallgemeinerung jedes Modells zu bewerten. Also,", "metrics": {"bleu_score": 47.18372009351201, "chrf_score": 66.7628239741398, "xcomet_score": 0.8922338485717773, "xcomet_qe_score": 0.8797489404678345, "metricx_score": 9.057942390441895, "metricx_qe_score": 10.174851417541504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "was ist für eine gute Verallgemeinerung nötig?", "metrics": {"bleu_score": 7.966506956353643, "chrf_score": 30.666419080452506, "xcomet_score": 0.9888389110565186, "xcomet_qe_score": 0.9840415120124817, "metricx_score": 0.219853937625885, "metricx_qe_score": 0.25130292773246765, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Durch unsere Experimente haben wir festgestellt, dass es drei Hauptzutaten gibt,", "metrics": {"bleu_score": 39.553325358771794, "chrf_score": 56.310512918100386, "xcomet_score": 0.9835551977157593, "xcomet_qe_score": 0.9836207628250122, "metricx_score": 1.4351541996002197, "metricx_qe_score": 0.08789779245853424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die benötigt werden. The first one", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 15.038981934127285, "xcomet_score": 0.31149864196777344, "xcomet_qe_score": 0.3786408603191376, "metricx_score": 21.2081356048584, "metricx_qe_score": 22.447345733642578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "is the model architecture. Through our experiments, we found that the transformer models normally generalize better to new data.", "metrics": {"bleu_score": 2.0540268312306345, "chrf_score": 27.582971335998568, "xcomet_score": 0.635392427444458, "xcomet_qe_score": 0.9166111946105957, "metricx_score": 18.773569107055664, "metricx_qe_score": 15.130929946899414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Komponente ist die Modellgröße.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9996070861816406, "xcomet_qe_score": 0.997445821762085, "metricx_score": 0.19619479775428772, "metricx_qe_score": 0.2841184735298157, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass in der Regel größere Modelle zu einer besseren Verallgemeinerung führen.", "metrics": {"bleu_score": 43.047918551920176, "chrf_score": 79.02040172881591, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12243235111236572, "metricx_qe_score": 0.1358739733695984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zuletzt, aber nicht am wenigsten, wissen wir alle, dass die Anzahl der Feinabstimmungsexempel die Leistung einer Downstream-Aufgabe direkt beeinflusst.", "metrics": {"bleu_score": 28.43645022037128, "chrf_score": 47.481332202971274, "xcomet_score": 0.9589874744415283, "xcomet_qe_score": 0.9727742671966553, "metricx_score": 1.8344014883041382, "metricx_qe_score": 1.360257863998413, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir auch festgestellt, dass eine größere Anzahl von Feinabstimmungsexemplaren tatsächlich auch zu einer besseren Verallgemeinerung", "metrics": {"bleu_score": 14.883068827552616, "chrf_score": 52.07071798830019, "xcomet_score": 0.9502031803131104, "xcomet_qe_score": 0.9493763446807861, "metricx_score": 3.267854690551758, "metricx_qe_score": 1.433120846748352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "führt. To our next question, what causes the performance drop of some models? Wir hatten zwei Hypothesen.", "metrics": {"bleu_score": 7.2643397661757225, "chrf_score": 27.86298002647377, "xcomet_score": 0.8105384111404419, "xcomet_qe_score": 0.8701149225234985, "metricx_score": 17.041088104248047, "metricx_qe_score": 16.487003326416016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste ist adaptive Überanpassung, die Überanpassung ist durch die wiederholte Verwendung desselben Testsets verursacht, und dies zeigt sich normalerweise als Rückgang der Leistung auf einem neuen Testset.", "metrics": {"bleu_score": 18.693505838851927, "chrf_score": 59.19564225469712, "xcomet_score": 0.940358579158783, "xcomet_qe_score": 0.9205034375190735, "metricx_score": 1.89632248878479, "metricx_qe_score": 2.427180767059326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist die zeitliche Drift, die die Leistungsabnahme ist, die durch die zunehmende zeitliche Lücke zwischen den Trainings- und den Testdaten verursacht wird.", "metrics": {"bleu_score": 38.27912081811668, "chrf_score": 70.60529270034905, "xcomet_score": 0.9478562474250793, "xcomet_qe_score": 0.9275980591773987, "metricx_score": 1.2800453901290894, "metricx_qe_score": 1.4980233907699585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für adaptive Überanpassung haben wir gesehen, dass die rote beste Passlinie aus dem Diagramm auf der rechten Seite einen Gradienten hat, der größer als eins ist.", "metrics": {"bleu_score": 11.146727460890448, "chrf_score": 42.79654755046239, "xcomet_score": 0.8190122842788696, "xcomet_qe_score": 0.7740552425384521, "metricx_score": 1.869309902191162, "metricx_qe_score": 1.670372486114502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies bedeutet, dass jede Verbesserungseinheit, die wir auf Kernel 2003 erzielt haben, sich in mehr als einer Verbesserungseinheit auf Kernel 2003 niederschlägt, was bedeutet, dass es keine abnehmenden Erträge gibt.", "metrics": {"bleu_score": 24.735124939523608, "chrf_score": 58.50983336185082, "xcomet_score": 0.7546833753585815, "xcomet_qe_score": 0.7601111531257629, "metricx_score": 10.474597930908203, "metricx_qe_score": 9.234899520874023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das zeigt uns, dass adaptive Überanpassung in diesem Fall nicht beobachtet wird.", "metrics": {"bleu_score": 22.502659477089228, "chrf_score": 67.04370478740313, "xcomet_score": 0.9967222213745117, "xcomet_qe_score": 0.9884190559387207, "metricx_score": 0.567049503326416, "metricx_qe_score": 0.8606347441673279, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So was mit temporaler Trift. Für", "metrics": {"bleu_score": 6.770186228657864, "chrf_score": 15.821213178921106, "xcomet_score": 0.4158567488193512, "xcomet_qe_score": 0.6826412081718445, "metricx_score": 11.977163314819336, "metricx_qe_score": 6.619383335113525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die zeitliche Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten zu re-trainen oder weiter zu pre-trainen, und wir haben festgestellt, dass die Leistung mit größerer zeitlicher Lücke abnimmt. Und das bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall die zeitliche Verschiebung ist.", "metrics": {"bleu_score": 53.802342703397215, "chrf_score": 72.91719001928946, "xcomet_score": 0.7868325710296631, "xcomet_qe_score": 0.8654675483703613, "metricx_score": 5.852138519287109, "metricx_qe_score": 5.170866012573242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Schlussfolgerung ist, dass wir für eine gute Verallgemeinerung ein besseres Modellarchitektur, eine größere Modellgröße sowie mehr Feinabstimmungsebenen benötigen.", "metrics": {"bleu_score": 56.333167591361615, "chrf_score": 79.9139470007994, "xcomet_score": 0.9608452320098877, "xcomet_qe_score": 0.9623186588287354, "metricx_score": 2.5799951553344727, "metricx_qe_score": 3.0162220001220703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und diese gehen Hand in Hand. Wir können nicht nur eine Zutat haben, sondern alle anderen.", "metrics": {"bleu_score": 20.522120509305022, "chrf_score": 48.11862007403829, "xcomet_score": 0.8518421649932861, "xcomet_qe_score": 0.7953317165374756, "metricx_score": 2.879277467727661, "metricx_qe_score": 5.287527561187744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig haben wir festgestellt, dass der Leistungsabfall hier durch zeitliche Verschiebungen verursacht wird und überraschenderweise nicht durch adaptives Überfitting, obwohl Conll 2003 seit über zwanzig Jahren verwendet wird.", "metrics": {"bleu_score": 52.163707891677454, "chrf_score": 77.81963953199795, "xcomet_score": 0.8776439428329468, "xcomet_qe_score": 0.8678380846977234, "metricx_score": 2.7875404357910156, "metricx_qe_score": 2.6547529697418213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also, zurück zu der Frage, die wir im Titel unseres Papiers aufgeworfen haben: Funktionieren Concol 2003-Taggertags noch in 2023? Und", "metrics": {"bleu_score": 4.085892079136997, "chrf_score": 43.548306908839216, "xcomet_score": 0.8848921060562134, "xcomet_qe_score": 0.9495590925216675, "metricx_score": 5.734854698181152, "metricx_qe_score": 5.708619594573975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir haben festgestellt, dass die Antwort tatsächlich ein lautes Ja ist.", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 73.1172616791848, "xcomet_score": 0.9661933183670044, "xcomet_qe_score": 0.9653613567352295, "metricx_score": 0.790864109992981, "metricx_qe_score": 0.6194725036621094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We hope our paper calls for more research on how to improve generalizations of the models.", "metrics": {"bleu_score": 1.8074696761828841, "chrf_score": 16.56802038377574, "xcomet_score": 0.847518801689148, "xcomet_qe_score": 0.9957518577575684, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, bitte stellen Sie sicher, dass Sie sich unser Papier, unseren Datensatz ansehen. Und wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren.", "metrics": {"bleu_score": 32.394320578801306, "chrf_score": 56.01475656314487, "xcomet_score": 0.9506375789642334, "xcomet_qe_score": 0.9715220332145691, "metricx_score": 1.118930459022522, "metricx_qe_score": 0.651055097579956, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9980669021606445, "xcomet_qe_score": 1.0, "metricx_score": 0.9967510104179382, "metricx_qe_score": 0.7514567971229553, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich werde über unsere Arbeit zur Lösung indirekter Äquivalenzausdrücke für die Entitätsauswahl sprechen, in der wir den altentities-Korpus einführen. Und", "metrics": {"bleu_score": 27.809355999594505, "chrf_score": 47.478999882618616, "xcomet_score": 0.8808347582817078, "xcomet_qe_score": 0.8815003633499146, "metricx_score": 4.286246299743652, "metricx_qe_score": 3.510094165802002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Javad Hosseini und dies ist eine gemeinsame Arbeit mit Philipp Radlinski, Silvia Parati und Anil Krish.", "metrics": {"bleu_score": 24.62292439135324, "chrf_score": 61.225329330341296, "xcomet_score": 0.7747229337692261, "xcomet_qe_score": 0.7708536386489868, "metricx_score": 5.5739874839782715, "metricx_qe_score": 7.35717248916626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten.", "metrics": {"bleu_score": 89.79542144404238, "chrf_score": 97.26493180481332, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3646099269390106, "metricx_qe_score": 0.43163084983825684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ich stelle mir diese alternative Frage: Wollten", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 41.21997932498399, "xcomet_score": 0.8104378581047058, "xcomet_qe_score": 0.8625910878181458, "metricx_score": 5.667482376098633, "metricx_qe_score": 2.593385696411133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie mit \"einfach für mich\" oder \"ich habe ein Gefühl\" sagen?", "metrics": {"bleu_score": 3.21858262703621, "chrf_score": 15.482038033142755, "xcomet_score": 0.23564687371253967, "xcomet_qe_score": 0.5426385402679443, "metricx_score": 7.725275039672852, "metricx_qe_score": 8.31425666809082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier möchte ein Benutzer zwischen diesen beiden Optionen wählen.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 83.97275248934463, "xcomet_score": 0.9430789947509766, "xcomet_qe_score": 0.9941459894180298, "metricx_score": 0.7513760328292847, "metricx_qe_score": 1.1118160486221313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die offensichtlichste Sache ist die Verwendung einer direkten Referenz, zum Beispiel, indem man den Namen des Songs oder seine Position sagt, die erste.", "metrics": {"bleu_score": 9.956420673405146, "chrf_score": 41.39414146324104, "xcomet_score": 0.9533312320709229, "xcomet_qe_score": 0.9444254636764526, "metricx_score": 2.411957263946533, "metricx_qe_score": 4.7783331871032715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But sometimes an indirect reference is more appropriate to have a more natural conversation.", "metrics": {"bleu_score": 2.458476536482737, "chrf_score": 19.672089713802414, "xcomet_score": 0.9894382953643799, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This could happen when the user cannot remember the name of the song. All the pronunciations are too similar to each", "metrics": {"bleu_score": 1.727223799216787, "chrf_score": 15.474892846506174, "xcomet_score": 0.2325555384159088, "xcomet_qe_score": 0.7801163196563721, "metricx_score": 18.003196716308594, "metricx_qe_score": 17.542104721069336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "other and hard to disambiguate.", "metrics": {"bleu_score": 3.5275023606301383, "chrf_score": 8.015426079422365, "xcomet_score": 0.3233591914176941, "xcomet_qe_score": 0.7440954446792603, "metricx_score": 23.44831085205078, "metricx_qe_score": 24.722761154174805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Oder wenn der Benutzer eine Präferenz angeben möchte.", "metrics": {"bleu_score": 51.33450480401705, "chrf_score": 62.84719262454902, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08684855699539185, "metricx_qe_score": 0.11648329347372055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele für direkte Referenzen, zum Beispiel die neuere oder die, die nicht energetisch ist.", "metrics": {"bleu_score": 20.76047003130265, "chrf_score": 48.3420514325681, "xcomet_score": 0.7956236600875854, "xcomet_qe_score": 0.8026198148727417, "metricx_score": 6.882033348083496, "metricx_qe_score": 6.6192851066589355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in Konversationssystemen und auch für die Benchmarking von LLMs Entityunderstand. Wir sind", "metrics": {"bleu_score": 30.928520903947533, "chrf_score": 76.34529639806344, "xcomet_score": 0.698661208152771, "xcomet_qe_score": 0.729235053062439, "metricx_score": 8.103364944458008, "metricx_qe_score": 8.883597373962402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uns eines öffentlichen Datensatzes, eines größeren öffentlichen Datensatzes für eine Aufgabe, nicht bewusst, also sammeln wir einen mit der Cloud-Annotation.", "metrics": {"bleu_score": 12.962472880491877, "chrf_score": 51.529514185165326, "xcomet_score": 0.5904073715209961, "xcomet_qe_score": 0.5773385763168335, "metricx_score": 10.247657775878906, "metricx_qe_score": 9.263397216796875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezepte.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 90.24661576351653, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15354201197624207, "metricx_qe_score": 0.1801653653383255, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensammlungsmethode betont die Informalität mit einem Cartoon-Vollendungssatz.", "metrics": {"bleu_score": 2.5795879170461364, "chrf_score": 38.54248070375899, "xcomet_score": 0.911602795124054, "xcomet_qe_score": 0.8831255435943604, "metricx_score": 5.505138397216797, "metricx_qe_score": 6.157780647277832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Cartoon hat drei Sprachblasen.", "metrics": {"bleu_score": 16.341219448835542, "chrf_score": 56.64404683958229, "xcomet_score": 0.9727380275726318, "xcomet_qe_score": 0.9225057363510132, "metricx_score": 0.5400007367134094, "metricx_qe_score": 1.3745216131210327, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der ersten Blase sagt Bob, erinnere dich an das Lied, das wir gestern gehört haben. Und", "metrics": {"bleu_score": 53.1572228769392, "chrf_score": 72.3537654002525, "xcomet_score": 0.8879092335700989, "xcomet_qe_score": 0.8306965827941895, "metricx_score": 6.753236770629883, "metricx_qe_score": 6.235307216644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "damit setzt Bob den Dialogkontext.", "metrics": {"bleu_score": 9.22364410103253, "chrf_score": 45.40400511784098, "xcomet_score": 0.9874088764190674, "xcomet_qe_score": 0.9656420946121216, "metricx_score": 1.10233736038208, "metricx_qe_score": 1.6810038089752197, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Rede von Alice fragt sie: \"Meinst du, ich soll mich entspannen, oder ich muss mich beeilen?\" Welches ist", "metrics": {"bleu_score": 6.601618238283769, "chrf_score": 33.48406581758308, "xcomet_score": 0.2922244071960449, "xcomet_qe_score": 0.4988888204097748, "metricx_score": 9.989923477172852, "metricx_qe_score": 8.421537399291992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die alternative Frage?", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 42.034948039677765, "xcomet_score": 0.8983339071273804, "xcomet_qe_score": 0.9410306811332703, "metricx_score": 0.7138074040412903, "metricx_qe_score": 1.2923262119293213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in der dritten Sprachblase verwendet Bob eine indirekte Anrede, um eine dieser Entitäten auszuwählen, zum Beispiel die neue. Wir bieten", "metrics": {"bleu_score": 32.07714281451773, "chrf_score": 75.42958132145239, "xcomet_score": 0.7654661536216736, "xcomet_qe_score": 0.7105749845504761, "metricx_score": 7.136713027954102, "metricx_qe_score": 5.828921794891357, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die ersten und zweiten Sprachblasen automatisch an, aber die dritte wird vom Anotator ausgefüllt.", "metrics": {"bleu_score": 6.859315219085803, "chrf_score": 51.69258609521988, "xcomet_score": 0.8638158440589905, "xcomet_qe_score": 0.8606733679771423, "metricx_score": 3.4178555011749268, "metricx_qe_score": 4.191582679748535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Sprachblase wird aus einer Handynummer ausgewählt.", "metrics": {"bleu_score": 16.72502564961871, "chrf_score": 53.120950818252275, "xcomet_score": 0.6023745536804199, "xcomet_qe_score": 0.5776837468147278, "metricx_score": 13.084914207458496, "metricx_qe_score": 14.66634750366211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert.", "metrics": {"bleu_score": 51.56626918239821, "chrf_score": 69.55137607873154, "xcomet_score": 0.9697390794754028, "xcomet_qe_score": 0.997085690498352, "metricx_score": 0.5556178092956543, "metricx_qe_score": 0.45188143849372864, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We always use a simple template.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 8.815980804809866, "xcomet_score": 0.928668737411499, "xcomet_qe_score": 1.0, "metricx_score": 14.994329452514648, "metricx_qe_score": 13.603075981140137, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Do you mean a or b,", "metrics": {"bleu_score": 0.0, "chrf_score": 5.63063063063063, "xcomet_score": 0.9411700963973999, "xcomet_qe_score": 0.9710831642150879, "metricx_score": 6.638125419616699, "metricx_qe_score": 8.309012413024902, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "where a and b are samples from Wikipedia?", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 26.953804206001664, "xcomet_score": 0.781346321105957, "xcomet_qe_score": 0.8646889925003052, "metricx_score": 16.45685577392578, "metricx_qe_score": 20.653596878051758, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenmethoden, die wir verwendet haben.", "metrics": {"bleu_score": 48.83499409416458, "chrf_score": 73.7486283737664, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.10708659142255783, "metricx_qe_score": 0.1686188280582428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir höher in der Liste gehen, werden die Entitäten sich mehr ähneln und es ist normalerweise schwieriger, die Unklarheiten zu beseitigen.", "metrics": {"bleu_score": 9.119675426861836, "chrf_score": 38.90964752946346, "xcomet_score": 0.9208666086196899, "xcomet_qe_score": 0.8881858587265015, "metricx_score": 2.226626396179199, "metricx_qe_score": 1.744006872177124, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The first one is uniform attraction.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 12.6002289337383, "xcomet_score": 0.5608296394348145, "xcomet_qe_score": 0.8382441997528076, "metricx_score": 14.901761054992676, "metricx_qe_score": 12.2576322555542, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen \"The Return\".", "metrics": {"bleu_score": 73.03869312694913, "chrf_score": 81.35824820107905, "xcomet_score": 0.9626709222793579, "xcomet_qe_score": 0.9491757154464722, "metricx_score": 1.1524267196655273, "metricx_qe_score": 0.933397650718689, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die dritte ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben,", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 89.84709278700022, "xcomet_score": 0.9700139760971069, "xcomet_qe_score": 0.8934118747711182, "metricx_score": 0.3016999661922455, "metricx_qe_score": 0.2800518870353699, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben,", "metrics": {"bleu_score": 82.4236750264605, "chrf_score": 97.03513820225659, "xcomet_score": 0.9810934066772461, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5228944420814514, "metricx_qe_score": 0.5977120995521545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel das gleiche Genre oder den gleichen Künstler für ein Lied.", "metrics": {"bleu_score": 33.260249505555045, "chrf_score": 63.41130062954626, "xcomet_score": 0.9642127752304077, "xcomet_qe_score": 0.9416334629058838, "metricx_score": 0.6021258234977722, "metricx_qe_score": 0.6711914539337158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "When we show this alternative question to the annotators, they know the name of these entities, but they don't necessarily know about the entity. O was", "metrics": {"bleu_score": 1.6934096677198087, "chrf_score": 23.80700534669578, "xcomet_score": 0.8231887221336365, "xcomet_qe_score": 0.7580372095108032, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir tun, ist, dass wir einige Hintergrundinformationen über die beiden Entitäten zeigen.", "metrics": {"bleu_score": 18.20705281109213, "chrf_score": 61.98993091307328, "xcomet_score": 0.9687937498092651, "xcomet_qe_score": 0.9760693311691284, "metricx_score": 1.7445929050445557, "metricx_qe_score": 2.8884239196777344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Songs zeigen wir einfach einen Google-Suchlink zu jedem Song. Und dann bitten Sie die Anmerkungen, mindestens einige der Songs zu hören und über jeden Song zu lesen.", "metrics": {"bleu_score": 32.241318603049926, "chrf_score": 59.321168568660035, "xcomet_score": 0.9047011137008667, "xcomet_qe_score": 0.9194297194480896, "metricx_score": 5.735074520111084, "metricx_qe_score": 5.85057258605957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist zum Beispiel das Google-Suchergebnis für den Song Easy.", "metrics": {"bleu_score": 49.19533018641346, "chrf_score": 76.63499551431381, "xcomet_score": 0.8922040462493896, "xcomet_qe_score": 0.8812892436981201, "metricx_score": 4.109208583831787, "metricx_qe_score": 3.8351950645446777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für die Rezept- und Buchdomäne zeigen wir einige Hintergrundtexte aus Wikipedia.", "metrics": {"bleu_score": 49.05378138718246, "chrf_score": 69.6304635024949, "xcomet_score": 0.9780106544494629, "xcomet_qe_score": 0.9760328531265259, "metricx_score": 0.48188886046409607, "metricx_qe_score": 0.7016535997390747, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für Rezepte zeigen wir zusätzlich ihre Bilder erneut aus Wikipedia, damit die Anmerkungen wissen, wie sie aussehen.", "metrics": {"bleu_score": 43.09809162747323, "chrf_score": 62.47903516075392, "xcomet_score": 0.8930784463882446, "xcomet_qe_score": 0.9053966999053955, "metricx_score": 5.159526348114014, "metricx_qe_score": 4.9000678062438965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Anotatoren, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste, und sie mit drei bis fünf indirekten Referenzausdrücken zu beschreiben.", "metrics": {"bleu_score": 63.15074994395737, "chrf_score": 82.07009456599266, "xcomet_score": 0.9584106206893921, "xcomet_qe_score": 0.9504327774047852, "metricx_score": 0.7207217216491699, "metricx_qe_score": 0.8206818699836731, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die mit Klaviermusik.", "metrics": {"bleu_score": 16.341219448835542, "chrf_score": 67.04625579931307, "xcomet_score": 0.9811041951179504, "xcomet_qe_score": 0.9925582408905029, "metricx_score": 0.6693575382232666, "metricx_qe_score": 0.23225867748260498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele aus unserem Datensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die ohne Worte, nicht die mit dem zwölfjährigen Jungen oder die fiktive oder kommt aus Aserbaidschan und so.", "metrics": {"bleu_score": 5.416924540787014, "chrf_score": 56.859172405299255, "xcomet_score": 0.9139865636825562, "xcomet_qe_score": 0.9347960948944092, "metricx_score": 2.4632277488708496, "metricx_qe_score": 3.071077585220337, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Entitätenkorpus hat sechstausend alternative Fragen über drei Domänen hinweg, und er hat vierzigtausend indirekte Referenzausdrücke.", "metrics": {"bleu_score": 2.8265205879007453, "chrf_score": 39.31881405796723, "xcomet_score": 0.9087194204330444, "xcomet_qe_score": 0.908877968788147, "metricx_score": 2.59600830078125, "metricx_qe_score": 1.8717143535614014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit dem T5X-XLarge-Modell werden unten zusammengefasst.", "metrics": {"bleu_score": 34.56543232731582, "chrf_score": 78.83322196344048, "xcomet_score": 0.9656537771224976, "xcomet_qe_score": 0.9360812902450562, "metricx_score": 1.8560082912445068, "metricx_qe_score": 1.3194574117660522, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf genau die gleichen Hintergrundkenntnisse wie die Anmerkenden hat, dann ist die Genauigkeit wirklich hoch. Es liegt bei etwa zweiundneunzig bis fünfundneunzig Prozent.", "metrics": {"bleu_score": 37.92611111696206, "chrf_score": 63.837741594761596, "xcomet_score": 0.9341427087783813, "xcomet_qe_score": 0.9214431047439575, "metricx_score": 1.8086328506469727, "metricx_qe_score": 1.2770798206329346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist nicht realistisch.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 60.726544199480216, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.07705473899841309, "metricx_qe_score": 0.16071665287017822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell Zugriff auf teilweise überlappende Hintergrundwissen hat, liegt die Genauigkeit zwischen zweiundachtzig und siebenundachtzig Prozent, was realistischer ist.", "metrics": {"bleu_score": 36.74497686602869, "chrf_score": 72.15900597052513, "xcomet_score": 0.9472246766090393, "xcomet_qe_score": 0.9432898759841919, "metricx_score": 1.4557048082351685, "metricx_qe_score": 1.651792049407959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn das Sprachmodell das Hintergrundwissen abruft.", "metrics": {"bleu_score": 55.55238068023578, "chrf_score": 73.88238661742061, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.2512856423854828, "metricx_qe_score": 0.223150834441185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "If the language model has access only to entity names, then the accuracy is only sixty percent, so there is a lot of room for improvement.", "metrics": {"bleu_score": 1.6934096677198087, "chrf_score": 18.127247073140936, "xcomet_score": 0.9892259836196899, "xcomet_qe_score": 0.9984413385391235, "metricx_score": 23.822673797607422, "metricx_qe_score": 24.269311904907227, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We've also shown that the models are domain generalizable.", "metrics": {"bleu_score": 2.5450723423460606, "chrf_score": 17.426336210208255, "xcomet_score": 0.9298739433288574, "xcomet_qe_score": 0.9805087447166443, "metricx_score": 24.336000442504883, "metricx_qe_score": 22.238187789916992, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Here is a link to our dataset.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 16.258131200970976, "xcomet_score": 0.9824318885803223, "xcomet_qe_score": 1.0, "metricx_score": 7.567511558532715, "metricx_qe_score": 5.79020881652832, "linguapy_score": [1, "NYNORSK"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.998066782951355, "xcomet_qe_score": 1.0, "metricx_score": 0.6838431358337402, "metricx_qe_score": 0.3409268260002136, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Papi von der University of Trento und Fondazione Bruno Kessler und ich werde kurz das Paper \"Attention as a Guide for Simultaneous Speech Translation\" vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist.", "metrics": {"bleu_score": 33.003868415996415, "chrf_score": 73.00438702283442, "xcomet_score": 0.9587324261665344, "xcomet_qe_score": 0.9695808291435242, "metricx_score": 1.8747329711914062, "metricx_qe_score": 1.989680528640747, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was ist Simultane Sprachübersetzung?", "metrics": {"bleu_score": 23.643540225079384, "chrf_score": 83.79305851974902, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.07138031721115112, "metricx_qe_score": 0.1317136585712433, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Simultane Sprachübersetzung, oder SimulST, ist der Prozess der Übersetzung von gesprochener Sprache in Text in einer anderen Sprache in Echtzeit, was eine sprachübergreifende Kommunikation ermöglicht.", "metrics": {"bleu_score": 22.609974392037643, "chrf_score": 66.0459903238959, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4936726689338684, "metricx_qe_score": 0.7356511354446411, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was sind die Probleme der aktuellen SimulSt-Modelle?", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 74.02491333835029, "xcomet_score": 0.9871007204055786, "xcomet_qe_score": 0.9855830669403076, "metricx_score": 0.19195657968521118, "metricx_qe_score": 0.28173235058784485, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezifische Architekturen werden in der Regel trainiert, indem zusätzliche Module optimiert werden.", "metrics": {"bleu_score": 7.0667300294268145, "chrf_score": 54.401177083860375, "xcomet_score": 0.9893702268600464, "xcomet_qe_score": 0.9793062806129456, "metricx_score": 1.3188292980194092, "metricx_qe_score": 1.973507285118103, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, zum Beispiel das Training mit unterschiedlichen Optimierungszielen,", "metrics": {"bleu_score": 31.843164596791894, "chrf_score": 80.39141241294205, "xcomet_score": 0.9980623722076416, "xcomet_qe_score": 0.9958111047744751, "metricx_score": 0.4817306697368622, "metricx_qe_score": 0.5070052146911621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das Training und die Wartung mehrerer Modelle, um verschiedene Latenzregime zu erreichen.", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 81.23752957515833, "xcomet_score": 0.9881261587142944, "xcomet_qe_score": 0.9893254041671753, "metricx_score": 0.6424560546875, "metricx_qe_score": 0.940867006778717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit einer Latenz von zwei Sekunden und so weiter. So,", "metrics": {"bleu_score": 38.13707100324892, "chrf_score": 71.05084739780558, "xcomet_score": 0.9466774463653564, "xcomet_qe_score": 0.9448333382606506, "metricx_score": 4.238544464111328, "metricx_qe_score": 2.236325263977051, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "was ist unsere Lösung?", "metrics": {"bleu_score": 34.98330125272253, "chrf_score": 64.97297139008359, "xcomet_score": 0.9800840616226196, "xcomet_qe_score": 0.983100175857544, "metricx_score": 0.036368537694215775, "metricx_qe_score": 0.21273481845855713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwenden Sie bereits vorhandene offizielle SD-Modelle, ohne zu trainieren oder eine spezifische Architektur für SD zu übernehmen.", "metrics": {"bleu_score": 17.12473044894657, "chrf_score": 54.19570182808232, "xcomet_score": 0.5440030694007874, "xcomet_qe_score": 0.7084139585494995, "metricx_score": 11.714557647705078, "metricx_qe_score": 10.344139099121094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie für jedes Latenzregime nur ein Modell und behandeln Sie die Latenz durch bestimmte Parameter.", "metrics": {"bleu_score": 10.521495173810226, "chrf_score": 45.927510181439615, "xcomet_score": 0.953807532787323, "xcomet_qe_score": 1.0, "metricx_score": 0.9889380931854248, "metricx_qe_score": 0.8547902703285217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und es nutzt das Wissen, das ich bereits durch das Modell erlangt habe, durch den Aufmerksamkeitmechanismus zwischen Audio-Eingabe und Textausgabe, das heißt den Kre", "metrics": {"bleu_score": 14.132052098159443, "chrf_score": 69.6955763719379, "xcomet_score": 0.7225114107131958, "xcomet_qe_score": 0.7036516666412354, "metricx_score": 6.450814247131348, "metricx_qe_score": 5.198192119598389, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "uzaufmerksamkeitmechanismus. Und Sie können ein Beispiel auf der rechten Seite sehen.", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 39.60302104592149, "xcomet_score": 0.874228298664093, "xcomet_qe_score": 0.8723611235618591, "metricx_score": 6.409973621368408, "metricx_qe_score": 6.765490531921387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung ist, ein Attention, oder Encoder-Decoder Attention, vorzuschlagen. Und es ist eine Strategie, bei der wir entscheiden, ob wir eine Teilübersetzung basierend auf dem Punkt der Aufmerksamkeit senden oder nicht.", "metrics": {"bleu_score": 40.57152599472995, "chrf_score": 69.02750296785956, "xcomet_score": 0.7592228651046753, "xcomet_qe_score": 0.6129393577575684, "metricx_score": 6.484188079833984, "metricx_qe_score": 7.548275947570801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "A word is omitted if the attention is not concentrated, that is, this sum is below a certain threshold alpha, towards the last lambda speech frames, meaning that the received information is not stable enough. Zum Beispiel,", "metrics": {"bleu_score": 1.2744039505750158, "chrf_score": 22.116700655477732, "xcomet_score": 0.3509640097618103, "xcomet_qe_score": 0.7415311932563782, "metricx_score": 21.660667419433594, "metricx_qe_score": 16.289024353027344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir einen Sprechabschnitt erhalten, der \"Ich werde darüber sprechen\" enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt, Und wir werden uns die Kreuzaugengewichte ansehen. Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen, also Lambda-Sprachrahmen, verweist.", "metrics": {"bleu_score": 44.493641261780816, "chrf_score": 69.6265495721619, "xcomet_score": 0.7441654205322266, "xcomet_qe_score": 0.726695716381073, "metricx_score": 6.319101810455322, "metricx_qe_score": 5.299354553222656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This means that the first two words will be omitted. Während die Summe der Kreuzentropie über einem bestimmten Verhältnis alpha liegt, werden wir das letzte Wort nicht auslassen und warten auf einen weiteren Sprechverlauf.", "metrics": {"bleu_score": 14.219389639501664, "chrf_score": 44.91051646557978, "xcomet_score": 0.641505241394043, "xcomet_qe_score": 0.6924911737442017, "metricx_score": 10.021768569946289, "metricx_qe_score": 5.965216636657715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitermachen und eine weitere Rede erhalten, und unser Modell drei Wörter vorhersagt, und wir werden uns diese Kreuz-Attentionen ansehen. Wir werden sehen, dass keine Wörter auf die letzten Lambda-Speech Frames verweisen.", "metrics": {"bleu_score": 18.772266185346027, "chrf_score": 60.875129109134704, "xcomet_score": 0.7475042343139648, "xcomet_qe_score": 0.7774748802185059, "metricx_score": 7.6577253341674805, "metricx_qe_score": 8.271002769470215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This means that these three words will be omitted.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 12.950244403984183, "xcomet_score": 0.5770822763442993, "xcomet_qe_score": 0.9810227155685425, "metricx_score": 12.626070976257324, "metricx_qe_score": 7.1450090408325195, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "If you look at the main results of that. We plot the simultaneous speech translation results on graphs in which we have blue on one side that measures the translation quality and average lagging. Das ist die Latenzmaßnahme. Und wir betrachten auch die computergestützte durchschnittliche Verzögerung, die die Rechenzeiten des Modells für die Vorhersage der Ausgabe berücksichtigt.", "metrics": {"bleu_score": 17.381578513831357, "chrf_score": 42.702279416756895, "xcomet_score": 0.5524810552597046, "xcomet_qe_score": 0.6704956889152527, "metricx_score": 11.926905632019043, "metricx_qe_score": 9.55849838256836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So wollen wir, dass unsere Kurven auf dieser Grafik so hoch wie möglich sind.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 56.11641891784469, "xcomet_score": 0.9619342088699341, "xcomet_qe_score": 0.9291704893112183, "metricx_score": 0.6804871559143066, "metricx_qe_score": 1.0127841234207153, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But also we want that they are shifted on the left.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 10.589430894308943, "xcomet_score": 0.9679890871047974, "xcomet_qe_score": 0.9919346570968628, "metricx_score": 25.0, "metricx_qe_score": 24.001127243041992, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen mit prärialen Strategien, die auch auf Offline-Modelle angewendet werden, die die Wartezeitstrategie und die lokale Vereinbarung sind.", "metrics": {"bleu_score": 17.855149299161596, "chrf_score": 58.020088375535586, "xcomet_score": 0.7297353744506836, "xcomet_qe_score": 0.7288774847984314, "metricx_score": 3.281888008117676, "metricx_qe_score": 4.157689571380615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen auch mit der State-of-the-Art-Architektur, die speziell für die simultane Übersetzung entwickelt wurde.", "metrics": {"bleu_score": 34.74643242368985, "chrf_score": 73.33363144759528, "xcomet_score": 0.9445218443870544, "xcomet_qe_score": 0.8968197703361511, "metricx_score": 1.7948362827301025, "metricx_qe_score": 2.4949638843536377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese sind alle Ergebnisse der Simultaneous Speech Translation Strategie auf Deutsch. Und", "metrics": {"bleu_score": 9.238430210261097, "chrf_score": 54.46220786069418, "xcomet_score": 0.7719850540161133, "xcomet_qe_score": 0.7776346206665039, "metricx_score": 4.799296855926514, "metricx_qe_score": 3.3022139072418213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sehen, dass Adult alle Strategien, die auf Offline-Modellen angewendet werden, übertrifft, da ihre Kurven nach links verschoben sind.", "metrics": {"bleu_score": 29.340680870384166, "chrf_score": 74.23425650301625, "xcomet_score": 0.8946309089660645, "xcomet_qe_score": 0.8613007664680481, "metricx_score": 4.684159278869629, "metricx_qe_score": 5.983360767364502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen auch, dass, wenn wir die tatsächlich verstrichene Zeit oder die rechnerbewusste Zeit", "metrics": {"bleu_score": 29.029556598856026, "chrf_score": 48.717845090220735, "xcomet_score": 0.8116143941879272, "xcomet_qe_score": 0.8108202219009399, "metricx_score": 15.521944999694824, "metricx_qe_score": 13.245628356933594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "berücksichtigen, dies die schnellste Strategie ist. If you want to discover", "metrics": {"bleu_score": 3.7644257151903666, "chrf_score": 16.002111314611316, "xcomet_score": 0.21400977671146393, "xcomet_qe_score": 0.23986917734146118, "metricx_score": 24.35367202758789, "metricx_qe_score": 20.261249542236328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "more results, read our paper. And we also released open source the code and models and simultaneous output to facilitate the reproducibility of our", "metrics": {"bleu_score": 1.7179060012299232, "chrf_score": 23.710402117355695, "xcomet_score": 0.2632162868976593, "xcomet_qe_score": 0.42840689420700073, "metricx_score": 16.68107795715332, "metricx_qe_score": 12.644765853881836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.13886114954948425, "metricx_qe_score": 0.35219353437423706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying und mein Kollege Zhi Yang und ich werden unsere Forschung über Multi-Teach präsentieren, die Multi-Modell-Seriell-Lernen durch Anweisung anpassen.", "metrics": {"bleu_score": 46.43411317447943, "chrf_score": 58.9961901063527, "xcomet_score": 0.6702496409416199, "xcomet_qe_score": 0.6746007204055786, "metricx_score": 7.378757953643799, "metricx_qe_score": 6.747927665710449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen prärtrainierte Sprachmodelle für verschiedene Downstream-Aufgaben auf eine parametergenau und dateneffiziente Weise wiederverwendet werden.", "metrics": {"bleu_score": 28.342395988956223, "chrf_score": 67.99685721240233, "xcomet_score": 0.9347937703132629, "xcomet_qe_score": 0.938177227973938, "metricx_score": 1.2059965133666992, "metricx_qe_score": 1.1688481569290161, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In letzter Zeit haben viele Studien gezeigt, dass Anweisungstuning es großen Sprachmodellen ermöglicht, auf unvorhergesehenen Aufgaben in einer durchdachten Weise zu reagieren, indem sie natürliche Anweisungen befolgen. Allerdings konzentrierten sich", "metrics": {"bleu_score": 36.50233132518788, "chrf_score": 56.17528287458218, "xcomet_score": 0.7708544731140137, "xcomet_qe_score": 0.8060768842697144, "metricx_score": 7.2617268562316895, "metricx_qe_score": 8.951623916625977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die meisten bisherigen Arbeiten zur Anweisungseingabe auf die Verbesserung der Serioschussleistung bei Aufgaben, die nur mit Sprache durchgeführt werden, während Computer Vision und multimodale Aufgaben ausgespart wurden.", "metrics": {"bleu_score": 28.72825463059374, "chrf_score": 61.7249484269732, "xcomet_score": 0.8704020977020264, "xcomet_qe_score": 0.8737413883209229, "metricx_score": 8.01812744140625, "metricx_qe_score": 8.583243370056152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher wollen wir in dieser Arbeit untersuchen, ob die Anweisungssynchronisierung bei multimodalen prädiktiven Modellen tatsächlich die Verallgemeinerung auf multimodale Aufgaben verbessern kann.", "metrics": {"bleu_score": 54.37363168675964, "chrf_score": 72.91255291027848, "xcomet_score": 0.972659707069397, "xcomet_qe_score": 0.9530363082885742, "metricx_score": 1.5536417961120605, "metricx_qe_score": 1.492304801940918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich entdeckten wir bei unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Anweisungssätzen zwischen rlp und multimodal.", "metrics": {"bleu_score": 23.954331500621716, "chrf_score": 61.34335006180822, "xcomet_score": 0.9406009912490845, "xcomet_qe_score": 0.9366321563720703, "metricx_score": 2.904392719268799, "metricx_qe_score": 3.9518890380859375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als 1600 Sprach-Only-Anweisungstests.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 56.26099219520743, "xcomet_score": 0.9132980704307556, "xcomet_qe_score": 0.8678613305091858, "metricx_score": 4.513476848602295, "metricx_qe_score": 5.494007110595703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt jedoch keinen groß angelegten, öffentlich zugänglichen, multimodalen Anweisungstest.", "metrics": {"bleu_score": 14.211672443220438, "chrf_score": 58.66586014995035, "xcomet_score": 0.952241063117981, "xcomet_qe_score": 0.9147014021873474, "metricx_score": 1.784479022026062, "metricx_qe_score": 1.4849591255187988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher motiviert uns dies, einen multimodalen Anweisungstuning-Datensatz zu erstellen.", "metrics": {"bleu_score": 15.909385168481824, "chrf_score": 59.65651585930054, "xcomet_score": 0.9493930339813232, "xcomet_qe_score": 0.9542739391326904, "metricx_score": 1.13968825340271, "metricx_qe_score": 1.183850646018982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier präsentieren wir Multi-InstRCT, den ersten multimodalen Anweisungstuning-Benchmark-Datensatz, der aus zweiundsechzig verschiedenen multimodalen Aufgaben besteht, die zehn verschiedene Kategorien abdecken.", "metrics": {"bleu_score": 18.21734347045388, "chrf_score": 64.7309279219639, "xcomet_score": 0.9285523891448975, "xcomet_qe_score": 0.9283291101455688, "metricx_score": 2.6363227367401123, "metricx_qe_score": 2.3566949367523193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben sind aus einundzwanzig bestehenden Open-Source-Datensätzen abgeleitet, und jede Aufgabe ist mit fünf Experten geschriebenen Anweisungen ausgestattet.", "metrics": {"bleu_score": 36.327039079325615, "chrf_score": 76.94050808338282, "xcomet_score": 0.9957555532455444, "xcomet_qe_score": 0.9831530451774597, "metricx_score": 1.923803448677063, "metricx_qe_score": 2.1890451908111572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um multimodale Anweisungstuning auf unserem vorgeschlagenen Datensatz zu untersuchen, nehmen wir OFA, ein einheitliches multimodales prädiktives Modell, als unser Basismodell.", "metrics": {"bleu_score": 47.8219647449668, "chrf_score": 75.4329462261125, "xcomet_score": 0.9400215148925781, "xcomet_qe_score": 0.9463425874710083, "metricx_score": 2.4803481101989746, "metricx_qe_score": 2.319300413131714, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 80.0344206362081, "xcomet_score": 0.9611788988113403, "xcomet_qe_score": 0.937485933303833, "metricx_score": 0.9789639711380005, "metricx_qe_score": 1.1489359140396118, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instruction-Datensatz. To unify the processing of various input and output data types. We follow the method from", "metrics": {"bleu_score": 22.743363869750482, "chrf_score": 50.184561232827264, "xcomet_score": 0.781146764755249, "xcomet_qe_score": 0.7935286164283752, "metricx_score": 9.70926284790039, "metricx_qe_score": 7.903127670288086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "OFA and formulate all the tasks in a unified sequence-to-sequence format,", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 31.815558351130875, "xcomet_score": 0.775324821472168, "xcomet_qe_score": 0.7564921975135803, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in which the input text, images, instructions, and bounding boxes are represented in the same token space.", "metrics": {"bleu_score": 2.568331954752977, "chrf_score": 24.155499182687276, "xcomet_score": 0.9976013898849487, "xcomet_qe_score": 1.0, "metricx_score": 22.85256004333496, "metricx_qe_score": 23.561256408691406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Okay, now I'm going to talk about multimodal instruction tuning.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 19.804966734636526, "xcomet_score": 0.9123120307922363, "xcomet_qe_score": 1.0, "metricx_score": 9.07291316986084, "metricx_qe_score": 15.802578926086426, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir also dreiundfünfzig Aufgaben aus der neggroup für das Training und nehmen zehntausend Instanzen pro Aufgabe.", "metrics": {"bleu_score": 42.34885228074744, "chrf_score": 72.67068275393592, "xcomet_score": 0.8493518829345703, "xcomet_qe_score": 0.8629675507545471, "metricx_score": 5.767848968505859, "metricx_qe_score": 7.4126386642456055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für das Testen reservieren wir die gesamte Common Sense Reasoning Group für das Testen und wählen zusätzliche fünf Aufgaben aus der vqa- und der mische Gruppe aus.", "metrics": {"bleu_score": 16.71952819686743, "chrf_score": 65.89996991698297, "xcomet_score": 0.7893321514129639, "xcomet_qe_score": 0.7655848264694214, "metricx_score": 5.281257152557373, "metricx_qe_score": 5.415441513061523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We use all the instances in the test set for each task.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 13.235164143747372, "xcomet_score": 0.9817894697189331, "xcomet_qe_score": 0.9983978271484375, "metricx_score": 7.4389214515686035, "metricx_qe_score": 5.826681613922119, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In addition, we randomly sample twenty tasks from the test set of natural instruction as on synTask for NLP.", "metrics": {"bleu_score": 2.159701133933343, "chrf_score": 12.950756740167325, "xcomet_score": 0.7964504361152649, "xcomet_qe_score": 0.8138144016265869, "metricx_score": 12.044681549072266, "metricx_qe_score": 9.074501037597656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also verwenden wir ein prärtrainiertes OFA-Large-Modell als Basismodell.", "metrics": {"bleu_score": 17.0653267718276, "chrf_score": 63.397407522045924, "xcomet_score": 0.9760164618492126, "xcomet_qe_score": 0.9805486798286438, "metricx_score": 1.2687572240829468, "metricx_qe_score": 1.3969730138778687, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings mischen wir alle Instanzen für alle Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9679558277130127, "xcomet_qe_score": 0.8991085290908813, "metricx_score": 0.269223690032959, "metricx_qe_score": 0.27577927708625793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jede Instanz wird zufällig mit einer der fünf Anweisungs-Templates kombiniert.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 84.11680967158705, "xcomet_score": 0.966691255569458, "xcomet_qe_score": 0.9537942409515381, "metricx_score": 1.549682378768921, "metricx_qe_score": 1.4692577123641968, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also während des Tests für jede Aufgabe führen wir insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungen in jedem", "metrics": {"bleu_score": 29.39918700508725, "chrf_score": 67.11663243753824, "xcomet_score": 0.8696829080581665, "xcomet_qe_score": 0.8621194958686829, "metricx_score": 7.905832290649414, "metricx_qe_score": 4.317519187927246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Experiment bewerten. Wir berichten über die mittlere und maximale Leistung und die Standardabweichung der Leistung über alle fünf Experimente hinweg.", "metrics": {"bleu_score": 29.694551474502376, "chrf_score": 67.76067570570099, "xcomet_score": 0.8678181767463684, "xcomet_qe_score": 0.8617174029350281, "metricx_score": 2.103424310684204, "metricx_qe_score": 2.8183043003082275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Aufgabe eine mehrmodulare Klassifizierungsaufgabe ist, berichten wir über Genauigkeit.", "metrics": {"bleu_score": 3.6937808403073613, "chrf_score": 43.4737130831531, "xcomet_score": 0.9643657207489014, "xcomet_qe_score": 0.9568673372268677, "metricx_score": 1.4249179363250732, "metricx_qe_score": 1.6704574823379517, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine mehrmodulare Generierungsaufgabe handelt, berichten wir über Rouge L. Für NLP-Aufgaben berichten wir auch über Rouge L.", "metrics": {"bleu_score": 23.114663823833634, "chrf_score": 57.789001863569126, "xcomet_score": 0.9360947012901306, "xcomet_qe_score": 0.8652317523956299, "metricx_score": 2.1195452213287354, "metricx_qe_score": 1.5471187829971313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Evaluierungsmetrik namens Sensitivität eingeführt.", "metrics": {"bleu_score": 13.76074141597786, "chrf_score": 56.57140741274389, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1929701566696167, "metricx_qe_score": 0.32225513458251953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie misst also die Fähigkeit des Modells, konsistent die gleichen Ausgaben für die gleiche Aufgabe zu produzieren, unabhängig von der Ausführung der Anweisung.", "metrics": {"bleu_score": 43.94378594926315, "chrf_score": 63.22997534772672, "xcomet_score": 0.9455214738845825, "xcomet_qe_score": 0.8926483392715454, "metricx_score": 3.559671640396118, "metricx_qe_score": 3.6962080001831055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Hauptergebnis.", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 84.83671401062706, "xcomet_score": 0.9841932058334351, "xcomet_qe_score": 0.9698138236999512, "metricx_score": 0.1317095309495926, "metricx_qe_score": 0.31674325466156006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann die Anweisungseinstellung die Leistung von OS auf Multi-Modallaufgaben erheblich verbessern.", "metrics": {"bleu_score": 16.9743842334312, "chrf_score": 58.83986188930525, "xcomet_score": 0.8295103907585144, "xcomet_qe_score": 0.8623923659324646, "metricx_score": 6.285113334655762, "metricx_qe_score": 5.315983295440674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Auch Transfer Learning from Natural Instruction Dataset kann Vorteile für die Anweisungstuning bringen.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 31.476676136748967, "xcomet_score": 0.914903998374939, "xcomet_qe_score": 0.9333399534225464, "metricx_score": 5.810053825378418, "metricx_qe_score": 5.446516036987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir sehen, dass das Modell mit zunehmender Anzahl von Aufgaben eine bessere Leistung und gleichzeitig eine geringere Empfindlichkeit erreicht.", "metrics": {"bleu_score": 54.995114848455124, "chrf_score": 76.7049645207402, "xcomet_score": 0.9438533186912537, "xcomet_qe_score": 0.9927875995635986, "metricx_score": 0.39531272649765015, "metricx_qe_score": 0.457820326089859, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir auch ein Experiment gemacht,", "metrics": {"bleu_score": 51.697315395717055, "chrf_score": 58.79265357053779, "xcomet_score": 0.9845058917999268, "xcomet_qe_score": 0.9847900867462158, "metricx_score": 1.0153846740722656, "metricx_qe_score": 0.15736886858940125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bei dem wir eine Anweisung gegen fünf Anweisungen verwendet haben.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 53.82620913614428, "xcomet_score": 0.9365321397781372, "xcomet_qe_score": 0.939559280872345, "metricx_score": 1.2458523511886597, "metricx_qe_score": 1.2814626693725586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann die Verwendung mehr Anweisungen die Gesamtleistung des Modells verbessern und seine Empfindlichkeit erheblich reduzieren.", "metrics": {"bleu_score": 50.2589910168054, "chrf_score": 66.79701090433572, "xcomet_score": 0.9833636283874512, "xcomet_qe_score": 0.9835682511329651, "metricx_score": 0.4800363779067993, "metricx_qe_score": 0.5184758901596069, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So zeigt dies die Wirkung verschiedener Feinabstimmungsstrategien auf die Modellempfindlichkeit.", "metrics": {"bleu_score": 9.00746750211399, "chrf_score": 64.25559061621064, "xcomet_score": 0.9593032598495483, "xcomet_qe_score": 0.9570722579956055, "metricx_score": 0.8846052289009094, "metricx_qe_score": 0.774850070476532, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, kann das Modell durch Transferlernen aus einem natürlichen Anweisungssatz eine viel bessere Empfindlichkeit erreichen als das ursprüngliche OFA-Modell.", "metrics": {"bleu_score": 55.64648974307584, "chrf_score": 78.66426602280652, "xcomet_score": 0.9401899576187134, "xcomet_qe_score": 0.9130144119262695, "metricx_score": 0.896883487701416, "metricx_qe_score": 1.4140667915344238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We also can see transfer learning from natural instruction dataset can help OFA to achieve much better performance on the natural instruct dataset. Insgesamt haben wir einen ersten, groß ang", "metrics": {"bleu_score": 1.526608193588886, "chrf_score": 22.233449358507954, "xcomet_score": 0.4376195967197418, "xcomet_qe_score": 0.656838059425354, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "elegten, multimodalen Anweisungstuning-Datensatz vorgeschlagen, der die Zero-Shot-Fähigkeit von OFA erheblich verbessert. Wir haben verschiedene Transfer-Lerntechniken untersucht und ihre Vorteile gezeigt.", "metrics": {"bleu_score": 6.4262985129346895, "chrf_score": 46.047571527047864, "xcomet_score": 0.6313565969467163, "xcomet_qe_score": 0.59659743309021, "metricx_score": 7.554324150085449, "metricx_qe_score": 7.164586067199707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine neue Metrik namens Sensitivität entwickelt.", "metrics": {"bleu_score": 21.10534063187263, "chrf_score": 69.40849871472699, "xcomet_score": 0.9969096183776855, "xcomet_qe_score": 0.9853104948997498, "metricx_score": 0.28878557682037354, "metricx_qe_score": 0.3986119329929352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also noch eine Sache, wir sammeln einen viel größeren Multi-Modal Instruction Tuning Datensatz mit rund einhundertfünfzig zusätzlichen Vision und Sprachaufgaben, und wir werden sie alle veröffentlichen.", "metrics": {"bleu_score": 7.16225087951744, "chrf_score": 43.79945374551425, "xcomet_score": 0.8306795358657837, "xcomet_qe_score": 0.8930487036705017, "metricx_score": 5.939655780792236, "metricx_qe_score": 5.7482523918151855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also ein QR-Code für unsere Daten und das Modell.", "metrics": {"bleu_score": 40.637982820134425, "chrf_score": 69.86556590082742, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21628203988075256, "metricx_qe_score": 0.2287195771932602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9926378726959229, "xcomet_qe_score": 1.0, "metricx_score": 1.4178515672683716, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen,", "metrics": {"bleu_score": 0.0, "chrf_score": 91.10491360491362, "xcomet_score": 0.9963463544845581, "xcomet_qe_score": 0.9950644969940186, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ich bin Koustaph Sinha und freue mich, Sie zu unserem Vortrag über unser ACL 2023-Papier zu begrüßen, in dem wir feststellen, dass", "metrics": {"bleu_score": 17.89570640154152, "chrf_score": 46.74437033694674, "xcomet_score": 0.759195864200592, "xcomet_qe_score": 0.8111381530761719, "metricx_score": 5.057588577270508, "metricx_qe_score": 4.571844100952148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beurteilungen der Akzeptanz von Sprachmodellen nicht immer robust gegenüber dem Kontext sind.", "metrics": {"bleu_score": 21.97281387499715, "chrf_score": 60.17880852616994, "xcomet_score": 0.959187388420105, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 4.807102203369141, "metricx_qe_score": 3.6663239002227783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This is a joint work with John Gauthier, Aaron Mueller, Kanishka Mishra, Karen Fentress, Roger Levy, and Atina Wylie.", "metrics": {"bleu_score": 31.011575752288344, "chrf_score": 56.53579264433447, "xcomet_score": 0.7914174795150757, "xcomet_qe_score": 0.7198750972747803, "metricx_score": 18.243438720703125, "metricx_qe_score": 21.823612213134766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit untersuchen wir das Minimal-Pair-Paradigma erneut.", "metrics": {"bleu_score": 21.721856265678966, "chrf_score": 66.13051631968177, "xcomet_score": 0.9758766889572144, "xcomet_qe_score": 0.8270425200462341, "metricx_score": 0.36972978711128235, "metricx_qe_score": 0.4476715326309204, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das minimale Paar zum Paradigma bewertet also im Grunde Sprachmodelle zusätzlich zu Akzeptanzurteilen,", "metrics": {"bleu_score": 4.246549372656572, "chrf_score": 54.715703786928636, "xcomet_score": 0.7850084900856018, "xcomet_qe_score": 0.8049106597900391, "metricx_score": 7.758036136627197, "metricx_qe_score": 7.276523113250732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die auch Grammatikalität wie Blimp-Syntax oder Akzeptanz in Bezug auf Stereotypen wie Cross-Pairs beinhalten können.", "metrics": {"bleu_score": 8.225964699966557, "chrf_score": 51.71521249109979, "xcomet_score": 0.7179498076438904, "xcomet_qe_score": 0.7217870354652405, "metricx_score": 5.234264850616455, "metricx_qe_score": 5.717543601989746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesem minimalen Paar-Paradigma ist die typische Art, Sprachmodelle zu bewerten, dass man eine akzeptable Satz oder einen grammatikalischen Satz zeigt und dann einen unakzeptablen Satz oder einen ungrammatischen Satz. Und", "metrics": {"bleu_score": 22.17022120140345, "chrf_score": 68.70970320056315, "xcomet_score": 0.8571702837944031, "xcomet_qe_score": 0.811163604259491, "metricx_score": 3.2341370582580566, "metricx_qe_score": 3.1302247047424316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dann ist die Hoffnung, dass das Modell im Grunde mehr Wahrscheinlichkeit auf die akzeptable Menge legt.", "metrics": {"bleu_score": 14.879641171245488, "chrf_score": 51.391912613743486, "xcomet_score": 0.8809084296226501, "xcomet_qe_score": 0.8608202934265137, "metricx_score": 7.031754493713379, "metricx_qe_score": 6.34932279586792, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz eines Modells gegenüber längeren Sätzen zu bewerten.", "metrics": {"bleu_score": 59.485907024027185, "chrf_score": 82.09706510171463, "xcomet_score": 0.9832488298416138, "xcomet_qe_score": 0.8998249173164368, "metricx_score": 1.0375758409500122, "metricx_qe_score": 1.5708523988723755, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Tagen kommen große Sprachmodelle mit immer längeren Kontextfenstern heraus.", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 66.6400281186536, "xcomet_score": 0.9728400707244873, "xcomet_qe_score": 0.9635520577430725, "metricx_score": 1.8109420537948608, "metricx_qe_score": 2.019562244415283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es von entscheidender Bedeutung, dass wir die Akzeptanz der Modelle über den gesamten Kontextfenster hinweg bewerten. Und das ist es, was wir hier versuchen.", "metrics": {"bleu_score": 19.505135653265878, "chrf_score": 63.71972295068107, "xcomet_score": 0.9654109477996826, "xcomet_qe_score": 0.9532806873321533, "metricx_score": 1.3439849615097046, "metricx_qe_score": 1.1501275300979614, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen, die Pipeline zu überdenken, indem wir das Modell bitten, die Akzeptanz auf längeren und längeren Sequenzen zu bewerten.", "metrics": {"bleu_score": 54.16124426311167, "chrf_score": 77.70834409497769, "xcomet_score": 0.8795812129974365, "xcomet_qe_score": 0.834600567817688, "metricx_score": 2.0338003635406494, "metricx_qe_score": 3.5019235610961914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also der Ansatz. Was wir also tun, ist,", "metrics": {"bleu_score": 38.05803001674947, "chrf_score": 82.87158037631005, "xcomet_score": 0.7082560062408447, "xcomet_qe_score": 0.2110530138015747, "metricx_score": 3.3253977298736572, "metricx_qe_score": 3.3757636547088623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dass wir diese längeren Sequenzen simulieren. Wir überprüfen die Datensätze selbst und erstellen dann Sätze neu, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen.", "metrics": {"bleu_score": 63.86806506668796, "chrf_score": 86.49399879660574, "xcomet_score": 0.8958827257156372, "xcomet_qe_score": 0.885847806930542, "metricx_score": 3.4888429641723633, "metricx_qe_score": 4.77509069442749, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir hier beispielsweise ein typisches Paar von Grammatikalität aus dem Blimp-Datensatz aus dem Fall der abhängigen Insel gewählt.", "metrics": {"bleu_score": 6.7602298845717375, "chrf_score": 52.31911175136996, "xcomet_score": 0.8568344116210938, "xcomet_qe_score": 0.8165838122367859, "metricx_score": 4.464198112487793, "metricx_qe_score": 5.191198348999023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, längere Sequenzen zu rekonstruieren, die akzeptabel sind und die dieselbe Übereinstimmung der grammatischen Struktur aufweisen.", "metrics": {"bleu_score": 27.96635629164385, "chrf_score": 65.14805840984336, "xcomet_score": 0.9870734214782715, "xcomet_qe_score": 0.9936894178390503, "metricx_score": 1.1295305490493774, "metricx_qe_score": 1.146528959274292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir extrahieren grammatische Sätze aus adjungierten Sprachen. Und dann fügen wir es als Präfix sowohl der akzeptablen Abfrage als auch der inakzeptablen Abfrage hinzu.", "metrics": {"bleu_score": 40.644776765505945, "chrf_score": 75.843522805719, "xcomet_score": 0.8332319259643555, "xcomet_qe_score": 0.8246549367904663, "metricx_score": 3.7497501373291016, "metricx_qe_score": 3.589614152908325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir dasselbe tun, indem wir unakzeptable Sätze aus der gleichen Übereinstimmung auswählen, und das könnte auch verwendet werden, um die Akzeptanz des Modells zu testen.", "metrics": {"bleu_score": 49.387782522975165, "chrf_score": 78.10663054186467, "xcomet_score": 0.976402997970581, "xcomet_qe_score": 0.9656678438186646, "metricx_score": 2.056483030319214, "metricx_qe_score": 2.137529134750366, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können auch dasselbe tun, indem wir Sätze aus einer anderen Teilmenge oder einem anderen Datensatz auswählen.", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 96.46657280795931, "xcomet_score": 0.9979338645935059, "xcomet_qe_score": 0.9903430938720703, "metricx_score": 0.5985816121101379, "metricx_qe_score": 1.476314663887024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das nennen wir also das Mismatch-Szenario.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 51.55980683014598, "xcomet_score": 0.9998226165771484, "xcomet_qe_score": 0.9988470077514648, "metricx_score": 1.3978654146194458, "metricx_qe_score": 1.8131654262542725, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also hier kommen die Sätze immer noch aus relevanten Datensätzen, aber es ist nicht von dem gleichen Datensatz, mit dem Sie bewertet haben.", "metrics": {"bleu_score": 27.604814041821232, "chrf_score": 52.825643456187635, "xcomet_score": 0.9217021465301514, "xcomet_qe_score": 0.9281753301620483, "metricx_score": 2.6139914989471436, "metricx_qe_score": 1.8031730651855469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können das Gleiche für Unakzeptanzfälle tun.", "metrics": {"bleu_score": 10.729256185679601, "chrf_score": 36.61484951584196, "xcomet_score": 0.9962742328643799, "xcomet_qe_score": 0.9741313457489014, "metricx_score": 0.4206300973892212, "metricx_qe_score": 0.4606577754020691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig unabhängigen Bereich wie Wikipedia auswählen.", "metrics": {"bleu_score": 29.633403702962482, "chrf_score": 69.12193656647352, "xcomet_score": 0.9785014986991882, "xcomet_qe_score": 0.9826781749725342, "metricx_score": 0.5211958885192871, "metricx_qe_score": 0.32958677411079407, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies wird uns also sagen, ob die Akzeptanzurichtungen des Modells tatsächlich von einem Kontext beeinflusst werden. Whether the context is coming from a different subset of the dataset or whether it's completely irrelevant to the current sentence that we are looking at. So", "metrics": {"bleu_score": 17.98210822552302, "chrf_score": 46.78504341137017, "xcomet_score": 0.7646974325180054, "xcomet_qe_score": 0.8098291754722595, "metricx_score": 14.570871353149414, "metricx_qe_score": 9.837535858154297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie macht das Modell das?", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 36.93839929415516, "xcomet_score": 0.9284400939941406, "xcomet_qe_score": 0.9563493728637695, "metricx_score": 1.2244600057601929, "metricx_qe_score": 1.3655108213424683, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst schauen wir uns die Wikipedia-Sätze an, die für das aktuelle Abfragepaar völlig irrelevant sind. Und dort stellen wir fest, dass die MPP-Urteile für beliebige Kontextlinien meist robust sind.", "metrics": {"bleu_score": 64.86802664285585, "chrf_score": 80.69322189513943, "xcomet_score": 0.9646708369255066, "xcomet_qe_score": 0.9403961896896362, "metricx_score": 2.05708646774292, "metricx_qe_score": 2.1917877197265625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge auf bis zu 1024 erhöht, um die OPT- und GPT-2-Modelle zu maximieren.", "metrics": {"bleu_score": 32.91598889023261, "chrf_score": 60.4073653242557, "xcomet_score": 0.9894683361053467, "xcomet_qe_score": 0.9711443185806274, "metricx_score": 1.433037281036377, "metricx_qe_score": 1.566721796989441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben hier in der orangefarbenen gepunkteten Linie gesehen, dass die MPP-Urteile relativ stabil sind.", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 91.17543411309175, "xcomet_score": 0.9994083642959595, "xcomet_qe_score": 1.0, "metricx_score": 0.9185815453529358, "metricx_qe_score": 1.3856937885284424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert, wenn wir Sätze aus derselben Datenmenge auswählen? Also", "metrics": {"bleu_score": 40.637982820134425, "chrf_score": 72.10546586354404, "xcomet_score": 0.9781811833381653, "xcomet_qe_score": 0.9770323634147644, "metricx_score": 1.4182467460632324, "metricx_qe_score": 0.29950252175331116, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hier wählen wir oder erstellen Sätze aus akzeptablen und inakzeptablen Domänen aus dem gleichen limbo person-Text-Daten-Set.", "metrics": {"bleu_score": 25.459845316736786, "chrf_score": 55.481901912625155, "xcomet_score": 0.7901185750961304, "xcomet_qe_score": 0.7393360137939453, "metricx_score": 6.5698137283325195, "metricx_qe_score": 7.285168647766113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dort sehen wir, dass die MPP-Urteile entweder signifikant ansteigen oder abnehmen, wenn Sie akzeptable oder inakzeptable Präfixe hinzufügen.", "metrics": {"bleu_score": 33.813434051244194, "chrf_score": 73.52226271501216, "xcomet_score": 0.960904598236084, "xcomet_qe_score": 0.9798741936683655, "metricx_score": 1.0689077377319336, "metricx_qe_score": 1.1802819967269897, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur abgleichen, das heißt, wenn wir die Sätze aus den gleichen Phänomenen im Schuldigen auswählen, Personentext Jim. Wir sehen einen massiven Anstieg oder einen massiven Rückgang des MPP-Urteils für das Modell, abhängig davon, ob das gewählte Präfix akzeptabel oder inakzeptabel ist.", "metrics": {"bleu_score": 39.83616420475339, "chrf_score": 68.76525434080793, "xcomet_score": 0.5894696712493896, "xcomet_qe_score": 0.5693647861480713, "metricx_score": 10.090974807739258, "metricx_qe_score": 13.35659408569336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nun, das ist sehr groß, und dieser Effekt nimmt mit der gesamten Kontextlänge zu. Und das würde wahrscheinlich neuere Sprachmodelle beeinflussen, die einen großen Kontextfenster haben. Also,", "metrics": {"bleu_score": 10.68478470576066, "chrf_score": 57.62898620136959, "xcomet_score": 0.9127207398414612, "xcomet_qe_score": 0.9136879444122314, "metricx_score": 6.1777238845825195, "metricx_qe_score": 2.3629791736602783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "warum beeinflusst das passende Präfix das Sprachmodell so stark?", "metrics": {"bleu_score": 16.080471747592078, "chrf_score": 55.34301405108531, "xcomet_score": 0.9408941268920898, "xcomet_qe_score": 0.9568771123886108, "metricx_score": 2.1563880443573, "metricx_qe_score": 1.916795253753662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabephrase zu stören, indem wir versuchten, die relevante Struktur zu erhalten, indem wir dem Input wie Lärm hinzufügten.", "metrics": {"bleu_score": 47.456729354016275, "chrf_score": 69.85190664653263, "xcomet_score": 0.87200528383255, "xcomet_qe_score": 0.8465425372123718, "metricx_score": 4.803744792938232, "metricx_qe_score": 4.612137794494629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und nachdem wir mehrere dieser Störungen durchgeführt hatten, Wir stellen fest, dass keines dieser Rauschen das Modell tatsächlich dazu bringt, seinen Kurs zu ändern, wie es uns zeigt, die MPP-Entwicklungsraten. Grundsätzlich stellen", "metrics": {"bleu_score": 35.943181914939714, "chrf_score": 64.07418731455772, "xcomet_score": 0.6561347246170044, "xcomet_qe_score": 0.7268509864807129, "metricx_score": 10.53316879272461, "metricx_qe_score": 7.66181755065918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fest, dass die Modelle auf ähnliche Weise empfindlich auf Perturbationssätze reagieren. Das heißt,", "metrics": {"bleu_score": 25.459845316736796, "chrf_score": 56.041058966243796, "xcomet_score": 0.8950124979019165, "xcomet_qe_score": 0.8742386102676392, "metricx_score": 7.5291242599487305, "metricx_qe_score": 4.3758463859558105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wenn wir die Sätze in der akzeptablen Domäne stören, sehen wir eine ähnliche Zunahme aller Störungen. Und wenn wir die Sätze in der unakzeptablen Domäne stören, sehen wir eine ähnliche Abnahme der MPP-Urteile.", "metrics": {"bleu_score": 35.23527062673471, "chrf_score": 66.10030844333991, "xcomet_score": 0.8953286409378052, "xcomet_qe_score": 0.8875102996826172, "metricx_score": 3.5075221061706543, "metricx_qe_score": 4.737756729125977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind, dass Sprachmodelle auf latente syntaktische und semantische Merkmale sensibel sind, die über die Sätze hinweg geteilt werden.", "metrics": {"bleu_score": 27.40899731303482, "chrf_score": 60.413688134836306, "xcomet_score": 0.9823383092880249, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.0904954671859741, "metricx_qe_score": 1.0418602228164673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und die MPP-Bewertung, die Art und Weise, wie wir sie derzeit mit kurzen und einzeiligen Eingaben durchführen, kann das abstrakte Wissen des Sprachmodells im gesamten Kontextfenster nicht", "metrics": {"bleu_score": 33.53671881116034, "chrf_score": 65.29851097530485, "xcomet_score": 0.8319766521453857, "xcomet_qe_score": 0.7861799597740173, "metricx_score": 6.342592239379883, "metricx_qe_score": 7.058414459228516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "vollständig erfassen. Please read our paper for more details of our", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 17.667499891028786, "xcomet_score": 0.32427680492401123, "xcomet_qe_score": 0.2724088430404663, "metricx_score": 22.564739227294922, "metricx_qe_score": 21.659591674804688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihr Zuhören.", "metrics": {"bleu_score": 22.957488466614336, "chrf_score": 79.51063763967204, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.19108456373214722, "metricx_qe_score": 0.2614968717098236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Yuxin Zhang von der Penn State University.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 92.21577416896909, "xcomet_score": 0.9154219627380371, "xcomet_qe_score": 0.9123141765594482, "metricx_score": 0.38024410605430603, "metricx_qe_score": 0.5297848582267761, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Heute werde ich unsere Arbeit vorstellen, die exemplarische, mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und mentalen Darstellungen.", "metrics": {"bleu_score": 19.1208175750425, "chrf_score": 37.86837744742325, "xcomet_score": 0.7750911116600037, "xcomet_qe_score": 0.7961862683296204, "metricx_score": 4.612837314605713, "metricx_qe_score": 5.905547618865967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Semantisches Parsing ist also die Aufgabe, semantische Darstellungen von Benutzeranfragen zu erstellen, wie z. B. SQL und Lambda-Kalkül.", "metrics": {"bleu_score": 19.28576545653752, "chrf_score": 67.21868771311944, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5917752385139465, "metricx_qe_score": 0.7661387920379639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und Crosslingual Semantic Parsing ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsdarstellungen zu übersetzen.", "metrics": {"bleu_score": 51.61040075276384, "chrf_score": 67.05627839265789, "xcomet_score": 0.9615870118141174, "xcomet_qe_score": 0.9709451794624329, "metricx_score": 1.584915041923523, "metricx_qe_score": 2.771439790725708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in dieser Abbildung gezeigt, müssen wir die Abfrage in mehrere natürliche Sprachen übersetzen, indem wir neuronale Modelle verwenden,", "metrics": {"bleu_score": 36.67895179344572, "chrf_score": 69.25884970482382, "xcomet_score": 0.9279733300209045, "xcomet_qe_score": 0.8873261213302612, "metricx_score": 6.334441661834717, "metricx_qe_score": 3.44507098197937, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um SQL, Lambda oder Funql und etc. Existing cross-lingual semantic parsing models are separately proposed and evaluated on datasets of limited tasks and", "metrics": {"bleu_score": 1.7911710595643588, "chrf_score": 24.944334223371207, "xcomet_score": 0.27291983366012573, "xcomet_qe_score": 0.26403236389160156, "metricx_score": 23.770063400268555, "metricx_qe_score": 22.072729110717773, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "applications, for instance. Es gibt Lücken in der Berichterstattung über bestimmte natürliche Sprachen, die", "metrics": {"bleu_score": 9.672649511413097, "chrf_score": 45.21321162208901, "xcomet_score": 0.24606235325336456, "xcomet_qe_score": 0.15535716712474823, "metricx_score": 17.858264923095703, "metricx_qe_score": 17.90308952331543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Chinesisch fehlt, und. Klicken Sie auf die Abdeckung bestimmter Mini-Representationen.", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 43.96620363235876, "xcomet_score": 0.6411884427070618, "xcomet_qe_score": 0.39151591062545776, "metricx_score": 11.342487335205078, "metricx_qe_score": 12.433552742004395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "\"The lambda calculus is missing.\" Oder sie werden nur auf einem bestimmten neuronalen Modell bewertet.", "metrics": {"bleu_score": 4.814971807094068, "chrf_score": 46.31480992648206, "xcomet_score": 0.9152635335922241, "xcomet_qe_score": 0.9398561716079712, "metricx_score": 7.5309038162231445, "metricx_qe_score": 6.20793342590332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel gibt es nur ein einziges Modell, um sie zu bewerten.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 90.75286527013824, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.21661248803138733, "metricx_qe_score": 0.2891947329044342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir zum Ziel, einen Exemplar", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 19.094740363849716, "xcomet_score": 0.22201073169708252, "xcomet_qe_score": 0.42524030804634094, "metricx_score": 12.621285438537598, "metricx_qe_score": 8.433882713317871, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zu vorschlagen, der einen einheitlichen Datensatz für die semantische Analyse in mehreren natürlichen Sprachen und -repräsentationen bereitstellt.", "metrics": {"bleu_score": 26.801651563557787, "chrf_score": 57.661635937569656, "xcomet_score": 0.7450560331344604, "xcomet_qe_score": 0.6625500321388245, "metricx_score": 6.562330722808838, "metricx_qe_score": 5.695067405700684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält 92 Sets in verschiedenen Domänen, fünf semantische Parsing Tasks, acht Millionen Darstellungen und 22 natürliche Sprachen in fünf Sprachfamilien. Und", "metrics": {"bleu_score": 19.81463247873555, "chrf_score": 59.7053129674922, "xcomet_score": 0.5773380994796753, "xcomet_qe_score": 0.5701757669448853, "metricx_score": 12.043877601623535, "metricx_qe_score": 10.409399032592773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "um unseren Benchmark besser zu bewerten, haben wir die sechs Einstellungen für das Training und die Bewertung berücksichtigt.", "metrics": {"bleu_score": 7.535838128770536, "chrf_score": 51.83153471973091, "xcomet_score": 0.9449061155319214, "xcomet_qe_score": 0.94191575050354, "metricx_score": 0.6985318660736084, "metricx_qe_score": 0.8937027454376221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist translate test.", "metrics": {"bleu_score": 17.965205598154213, "chrf_score": 34.2641121519558, "xcomet_score": 0.8855250477790833, "xcomet_qe_score": 0.8996101021766663, "metricx_score": 2.7550430297851562, "metricx_qe_score": 1.461535930633545, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden die Google Translate API, um die Quelle in die Zielsprache zu übersetzen, und verwenden dann das monolinguale Modell, um eine Bewertung zu trainieren. Und", "metrics": {"bleu_score": 28.72825463059374, "chrf_score": 53.59760585545678, "xcomet_score": 0.8921141624450684, "xcomet_qe_score": 0.859790563583374, "metricx_score": 4.187638759613037, "metricx_qe_score": 1.897469401359558, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zum Beispiel trainieren wir das englische Modell auf englischen Abfragen und übersetzen während der Inferenz die deutsche Abfrage mit der API in Englisch und verwenden dann das trainierte Modell, um die SQL-Abfrage vorherzusagen. Und", "metrics": {"bleu_score": 44.48826043304888, "chrf_score": 78.75111438920786, "xcomet_score": 0.9178892374038696, "xcomet_qe_score": 0.9176998138427734, "metricx_score": 1.0795137882232666, "metricx_qe_score": 0.43742430210113525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir testen auch ein monolinguales Modell.", "metrics": {"bleu_score": 18.575057999133602, "chrf_score": 47.6472312868767, "xcomet_score": 0.9846223592758179, "xcomet_qe_score": 0.9747858047485352, "metricx_score": 0.7220983505249023, "metricx_qe_score": 0.3585514724254608, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Einstellung ist die Quellsprache die gleiche wie die Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch.", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 85.84416474781003, "xcomet_score": 0.9649401307106018, "xcomet_qe_score": 0.9646639227867126, "metricx_score": 0.136317640542984, "metricx_qe_score": 0.21535587310791016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die monolinguale Field-Shot-Einstellung getestet, indem wir monolinguale Modelle mit nur zehn Prozent der Trainingsdaten trainiert haben.", "metrics": {"bleu_score": 23.41812326184748, "chrf_score": 68.42949338682651, "xcomet_score": 0.8152264356613159, "xcomet_qe_score": 0.7921079397201538, "metricx_score": 3.849158763885498, "metricx_qe_score": 4.738497734069824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir haben ein multilinguales Modell, das wir für alle Sprachen trainieren.", "metrics": {"bleu_score": 32.41793626541015, "chrf_score": 60.199890601957684, "xcomet_score": 0.9770305156707764, "xcomet_qe_score": 0.9686923027038574, "metricx_score": 1.4165818691253662, "metricx_qe_score": 1.151750087738037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir die deutschen, englischen und chinesischen Abfragen zusammengefügt, um ein mehrsprachiges Modell zu trainieren.", "metrics": {"bleu_score": 40.4727200247809, "chrf_score": 81.17994671061199, "xcomet_score": 0.9836792945861816, "xcomet_qe_score": 0.9895697236061096, "metricx_score": 0.5912140607833862, "metricx_qe_score": 0.7590703964233398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und während der Inferenz können wir dieses Modell verwenden. Um deutsche Anfragen oder chinesische Anfragen zu übersetzen, etc. Und", "metrics": {"bleu_score": 59.415598205628065, "chrf_score": 83.02109515258765, "xcomet_score": 0.9377275705337524, "xcomet_qe_score": 0.8744783401489258, "metricx_score": 3.724039316177368, "metricx_qe_score": 1.2062277793884277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir betrachten auch Crosslingual Zero Shot und Few Shot Transfer, bei dem", "metrics": {"bleu_score": 6.837203339116283, "chrf_score": 47.22454454543288, "xcomet_score": 0.6471952795982361, "xcomet_qe_score": 0.6768869757652283, "metricx_score": 8.308279037475586, "metricx_qe_score": 7.040865421295166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir auf einer Quelle trainieren und auf eine andere Sprache übertragen.", "metrics": {"bleu_score": 14.334389232407714, "chrf_score": 45.10989840713455, "xcomet_score": 0.8952057361602783, "xcomet_qe_score": 0.9011892080307007, "metricx_score": 6.788822174072266, "metricx_qe_score": 5.769391059875488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings werden wir auf englische Abfragen oder die Kombination aus englischen und deutschen Few-Shot-Abfragen trainieren, um ein mehrsprachiges Modell zu trainieren, das die SQL-Ausgabe vorhersagt.", "metrics": {"bleu_score": 33.94828928639167, "chrf_score": 79.48155460601627, "xcomet_score": 0.8808197975158691, "xcomet_qe_score": 0.9309858083724976, "metricx_score": 4.2493157386779785, "metricx_qe_score": 3.873116970062256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden auch viele interessante Ergebnisse.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 65.97021778246963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.061011966317892075, "metricx_qe_score": 0.07045558840036392, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf die Analyse von monolingualen Modellen bewerten wir zwei Gruppen von Modellen. Einschließlich Encoder Pdr, was für Multilingual Pretrained Encoders mit pointerbasierten Decodern steht, wie xlnr plus pdr und mbird plus pdr. Und", "metrics": {"bleu_score": 20.12788513843773, "chrf_score": 52.822909828856076, "xcomet_score": 0.7484070658683777, "xcomet_qe_score": 0.802280604839325, "metricx_score": 7.942805767059326, "metricx_qe_score": 8.69905948638916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir untersuchen auch Encoder-Decoder-Modelle, die multilingual trainierte Encoder-Decoder-Modelle wie Mbart und MT5 sind", "metrics": {"bleu_score": 6.219512039648859, "chrf_score": 55.60043614314141, "xcomet_score": 0.9023269414901733, "xcomet_qe_score": 0.9208618402481079, "metricx_score": 2.39511775970459, "metricx_qe_score": 4.8562445640563965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": ". We found that encoder decoder obtains the best performance on all nine datasets.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 23.061411944366238, "xcomet_score": 0.9245260953903198, "xcomet_qe_score": 0.9320186376571655, "metricx_score": 24.362770080566406, "metricx_qe_score": 23.918861389160156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir bewerten auf mt five und example xlmr plus pdr auf multilingualer Einstellung.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 20.492012824904577, "xcomet_score": 0.6711045503616333, "xcomet_qe_score": 0.7462347745895386, "metricx_score": 9.589677810668945, "metricx_qe_score": 7.745265007019043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden, dass Encoder-Decoder oder Encoder-PTR durch das Training in einer Mischung verschiedener Sprachen verbessert werden können. Und", "metrics": {"bleu_score": 46.09603493497927, "chrf_score": 74.08013166824612, "xcomet_score": 0.901344895362854, "xcomet_qe_score": 0.9141078591346741, "metricx_score": 1.882771611213684, "metricx_qe_score": 2.176391124725342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir fanden heraus, dass dies daran liegt, dass die meisten großen natürlichen Sprachen eine Leistungssteigerung erzielen können, mit Ausnahme der englischen Leistung, die in sieben Datensätzen abfällt und nur in drei Datensätzen zunimmt.", "metrics": {"bleu_score": 32.77911870414944, "chrf_score": 64.32342201307198, "xcomet_score": 0.9352295398712158, "xcomet_qe_score": 0.9645865559577942, "metricx_score": 1.135213017463684, "metricx_qe_score": 0.8589677214622498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich denke, das ist als Kurse der Multilingualität bekannt.", "metrics": {"bleu_score": 7.510002314354895, "chrf_score": 27.509214788597653, "xcomet_score": 0.8331289291381836, "xcomet_qe_score": 0.9426422119140625, "metricx_score": 7.957403182983398, "metricx_qe_score": 3.6221601963043213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Cross-Link-Performance-Gewichte verglichen.", "metrics": {"bleu_score": 11.737849637633069, "chrf_score": 29.065410630484184, "xcomet_score": 0.5504810810089111, "xcomet_qe_score": 0.8011767864227295, "metricx_score": 4.909506797790527, "metricx_qe_score": 5.6735053062438965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung ist die blaue Linie die Crosslingual Few-shot-Transfer,", "metrics": {"bleu_score": 16.309710371282524, "chrf_score": 52.60086187189148, "xcomet_score": 0.8095457553863525, "xcomet_qe_score": 0.8772172331809998, "metricx_score": 6.412467956542969, "metricx_qe_score": 5.826058387756348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die orangefarbene Linie ist der Crosslingual Zero-shot-Transfer, während", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 57.540265927891674, "xcomet_score": 0.815000057220459, "xcomet_qe_score": 0.8444676399230957, "metricx_score": 6.249271392822266, "metricx_qe_score": 7.228927135467529, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die grüne Linie die monolinguale Einstellung ist.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 33.48778707591812, "xcomet_score": 0.9185816049575806, "xcomet_qe_score": 0.9377843737602234, "metricx_score": 3.273747444152832, "metricx_qe_score": 2.421518087387085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass durch den Vergleich der grünen und orangefarbenen Linie, die vor dem Null-Shot-Setting gefunden wurde, die Cross-Lingual-Transfer-Funktionslücke signifikant ist. Und durch den Vergleich der blauen und orangefarbenen Linie, die nach dem Few-Shot-Setting gefunden wurde, ist die Transferlücke schnell verkürzt.", "metrics": {"bleu_score": 3.0051539414543766, "chrf_score": 36.06663917802806, "xcomet_score": 0.6376436948776245, "xcomet_qe_score": 0.6608947515487671, "metricx_score": 7.379162311553955, "metricx_qe_score": 7.595467567443848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir finden auch einige andere interessante Erkenntnisse.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 87.33374743632812, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1051962599158287, "metricx_qe_score": 0.02310710772871971, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel übertrifft die Encoder-Decoder-Architektur die vorherige Arbeit und erzielt vergleichbare Ergebnisse.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 76.13835764999943, "xcomet_score": 0.998938798904419, "xcomet_qe_score": 1.0, "metricx_score": 0.6088783144950867, "metricx_qe_score": 0.7527866363525391, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Training auf Englisch natürlicher Sprache kann die Leistung von few-shot auf Zielsprachen erheblich verbessern. Und wir fanden, dass mehrsprachige Sprachmodelle wie Codas und Bloom für die semantische Kreuzlinguistik noch nicht ausgereift sind.", "metrics": {"bleu_score": 13.221480420392126, "chrf_score": 52.22844577096246, "xcomet_score": 0.7952086925506592, "xcomet_qe_score": 0.8304922580718994, "metricx_score": 5.39497184753418, "metricx_qe_score": 4.301344394683838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir den Exemplar als einen einheitlichen Benchmark für die semantische Analyse aus verschiedenen Blickwinkeln mit mehreren natürlichen Sprachen und Minirepräsentationen entwickelt.", "metrics": {"bleu_score": 22.656720908801994, "chrf_score": 64.29513624192302, "xcomet_score": 0.6897381544113159, "xcomet_qe_score": 0.7064682245254517, "metricx_score": 7.438528060913086, "metricx_qe_score": 6.585160732269287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine umfassende Benchmark-Studie zu drei repräsentativen Arten von multilingualen Sprachmodellen durchgeführt,", "metrics": {"bleu_score": 14.949751774990691, "chrf_score": 70.93069085896846, "xcomet_score": 0.9827196598052979, "xcomet_qe_score": 0.9841442108154297, "metricx_score": 0.36638081073760986, "metricx_qe_score": 0.11535415053367615, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und unsere Ergebnisse zeigen viele interessante Erkenntnisse", "metrics": {"bleu_score": 53.29462628216855, "chrf_score": 78.71784845917693, "xcomet_score": 0.9825705289840698, "xcomet_qe_score": 0.9742958545684814, "metricx_score": 0.2993212640285492, "metricx_qe_score": 0.20944418013095856, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und so weiter.", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 89.11315536315534, "xcomet_score": 0.9975719451904297, "xcomet_qe_score": 0.9842172861099243, "metricx_score": 0.37729543447494507, "metricx_qe_score": 0.5145196318626404, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und willkommen, um unser Papier und Code zu besuchen.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 20.761176993663383, "xcomet_score": 0.7927494645118713, "xcomet_qe_score": 0.8754658699035645, "metricx_score": 4.39249324798584, "metricx_qe_score": 5.2516679763793945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihr Zuhören.", "metrics": {"bleu_score": 22.957488466614336, "chrf_score": 79.51063763967204, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21596919000148773, "metricx_qe_score": 0.2538357079029083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Aydil Bilal und ich werde eine kurze Zusammenfassung des Papiers \"Prompting Part-of-Speech Translation: Assessing Strategies and Performance\" geben.", "metrics": {"bleu_score": 26.01278440403792, "chrf_score": 60.481080428765225, "xcomet_score": 0.6488238573074341, "xcomet_qe_score": 0.7347057461738586, "metricx_score": 9.262080192565918, "metricx_qe_score": 6.853455543518066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14421530067920685, "metricx_qe_score": 0.18184146285057068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Param ist ein 540 Milliarden Parameter großes Sprachmodell, das im vergangenen Jahr 2022 vorgestellt wurde.", "metrics": {"bleu_score": 32.10676291352672, "chrf_score": 64.32460493272103, "xcomet_score": 0.8269009590148926, "xcomet_qe_score": 0.8238784074783325, "metricx_score": 6.653694152832031, "metricx_qe_score": 7.434649467468262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es wird auf einer großen Sammlung von Texten trainiert, die 780 Milliarden Token umfassen.", "metrics": {"bleu_score": 24.207623565172998, "chrf_score": 74.68786809420037, "xcomet_score": 0.9184129238128662, "xcomet_qe_score": 0.922059178352356, "metricx_score": 1.8708891868591309, "metricx_qe_score": 2.7325899600982666, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The time of publication, it achieves state-of-the-art in hundreds of NLP tasks.", "metrics": {"bleu_score": 3.1443446386286733, "chrf_score": 16.99401207953223, "xcomet_score": 0.9174398183822632, "xcomet_qe_score": 0.9718963503837585, "metricx_score": 22.75325584411621, "metricx_qe_score": 22.205596923828125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir die erste systematische Studie der Prompting von Sprachmodellen für maschinelle Übersetzung.", "metrics": {"bleu_score": 26.029050838873406, "chrf_score": 66.36158586637477, "xcomet_score": 0.9195263385772705, "xcomet_qe_score": 0.9198978543281555, "metricx_score": 2.4573934078216553, "metricx_qe_score": 3.5860342979431152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Übersetzungsfähigkeit solcher Modelle anhand der besten Praktiken der IMT-Community bewertet.", "metrics": {"bleu_score": 12.959609420490482, "chrf_score": 52.0374343610726, "xcomet_score": 0.9636673927307129, "xcomet_qe_score": 0.960056483745575, "metricx_score": 5.3066887855529785, "metricx_qe_score": 5.213228702545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies beinhaltet die Verwendung der neuesten Testsets, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden.", "metrics": {"bleu_score": 20.8795826063924, "chrf_score": 66.96069345125619, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26047593355178833, "metricx_qe_score": 0.2642512917518616, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir vergleichen zwei hochmoderne Systeme, also die leistungsstärksten Systeme, unter Verwendung der WMT-Bewertung.", "metrics": {"bleu_score": 3.684549161313771, "chrf_score": 32.49279484241084, "xcomet_score": 0.9793343544006348, "xcomet_qe_score": 0.9776097536087036, "metricx_score": 1.8759421110153198, "metricx_qe_score": 2.4165892601013184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We use state-of-the-art neural network metrics and additionally also show expert-based human evaluation results. Finally, we provide some recommendations for", "metrics": {"bleu_score": 1.875533370859678, "chrf_score": 18.049180230048258, "xcomet_score": 0.8126164674758911, "xcomet_qe_score": 0.9375091791152954, "metricx_score": 5.907171249389648, "metricx_qe_score": 2.945469617843628, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "prompt selection strategies.", "metrics": {"bleu_score": 1.683602693167689, "chrf_score": 17.5104358602288, "xcomet_score": 0.17038211226463318, "xcomet_qe_score": 0.2603374123573303, "metricx_score": 23.81844139099121, "metricx_qe_score": 23.795135498046875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The prompting has a big influence on the performance of the LLMs for translation, as we can see in a simple experiment where we used one-shot prompting and provided two different prompts for each sentence.", "metrics": {"bleu_score": 1.3113617852675474, "chrf_score": 28.612323638059195, "xcomet_score": 0.9815812110900879, "xcomet_qe_score": 0.978556752204895, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Sätze, 516 von 1000, die Differenz", "metrics": {"bleu_score": 27.901593935858266, "chrf_score": 65.28349543381331, "xcomet_score": 0.7670741081237793, "xcomet_qe_score": 0.7597520351409912, "metricx_score": 7.708452224731445, "metricx_qe_score": 5.860939025878906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der beobachteten ist von mehr als einem Unschärfepunkt. Und dies", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 45.784036139916765, "xcomet_score": 0.5102500915527344, "xcomet_qe_score": 0.6440297365188599, "metricx_score": 20.325429916381836, "metricx_qe_score": 17.215328216552734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "kann in extremen Fällen bis zu vierzig Blutpunkte betragen.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 23.992288463667528, "xcomet_score": 0.8876992464065552, "xcomet_qe_score": 0.8877872228622437, "metricx_score": 3.9210433959960938, "metricx_qe_score": 2.927886962890625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, eine gute Anreizestrategie zu wählen.", "metrics": {"bleu_score": 37.81790427652475, "chrf_score": 62.184123015185136, "xcomet_score": 0.9821215271949768, "xcomet_qe_score": 0.9889090657234192, "metricx_score": 0.9959447383880615, "metricx_qe_score": 0.5962580442428589, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten haben wir uns für eine fünf-Schuss-Prompting-Strategie entschieden, bei der wir jede bereitgestellte Satzzeile mit der entsprechenden Sprache markieren.", "metrics": {"bleu_score": 27.92132263568056, "chrf_score": 64.84672290358763, "xcomet_score": 0.8594303727149963, "xcomet_qe_score": 0.8501960039138794, "metricx_score": 3.709599018096924, "metricx_qe_score": 4.708975791931152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, in dem wir Übersetzungen von Deutsch ins Englische durchführen, sind die deutschen Sätze, die Quell-Sätze, mit einem deutschen Doppelpunkt markiert, und die englischen Übersetzungen mit einem englischen Doppelpunkt. We saw that", "metrics": {"bleu_score": 55.061134077814685, "chrf_score": 81.46952491572833, "xcomet_score": 0.8532030582427979, "xcomet_qe_score": 0.8784801959991455, "metricx_score": 4.388892650604248, "metricx_qe_score": 4.532663822174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "the actual form of the prompting doesn't have a big influence in the case of several-shot prompting. Es ist entscheidend", "metrics": {"bleu_score": 1.7316314614810704, "chrf_score": 21.62554423215319, "xcomet_score": 0.3260250687599182, "xcomet_qe_score": 0.7240705490112305, "metricx_score": 25.0, "metricx_qe_score": 24.968006134033203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für Null- und Einschussanregung.", "metrics": {"bleu_score": 12.975849993980741, "chrf_score": 19.466582497210247, "xcomet_score": 0.8004559874534607, "xcomet_qe_score": 0.8395602703094482, "metricx_score": 8.97523021697998, "metricx_qe_score": 8.03530216217041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn wir, wie in unserem Fall, zu Fünf-Schussanregung gehen, gibt es fast keinen Unterschied zur tatsächlichen Form der Anregung. Es sind", "metrics": {"bleu_score": 54.61382722602005, "chrf_score": 61.79388839190197, "xcomet_score": 0.5853996276855469, "xcomet_qe_score": 0.6456292867660522, "metricx_score": 12.910569190979004, "metricx_qe_score": 7.6886491775512695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Beispiele, die den größten Teil des Weges tragen. Die", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 40.51562406068569, "xcomet_score": 0.5524730086326599, "xcomet_qe_score": 0.6284827589988708, "metricx_score": 13.498512268066406, "metricx_qe_score": 10.427339553833008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit mit dem Quellsatz.", "metrics": {"bleu_score": 17.699051342800775, "chrf_score": 56.7230316296353, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.22554300725460052, "metricx_qe_score": 0.39840805530548096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist wichtig, die Beispiele aus qualitativ hochwertigen Übersetzungen auszuwählen.", "metrics": {"bleu_score": 58.59059370151705, "chrf_score": 85.36110414294178, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08593825250864029, "metricx_qe_score": 0.11125435680150986, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere vergleichen wir die Auswahl von Prompts aus den Trainingsdaten der WMT-Überprüfungen oder den Daten.", "metrics": {"bleu_score": 3.8275613602956104, "chrf_score": 55.88952956758888, "xcomet_score": 0.8209826946258545, "xcomet_qe_score": 0.8197106122970581, "metricx_score": 10.475399017333984, "metricx_qe_score": 11.06960678100586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The dev data is much more accurate and of higher quality than the train data, and the results show better performance when using the", "metrics": {"bleu_score": 1.506189323093867, "chrf_score": 19.947916500973836, "xcomet_score": 0.32244008779525757, "xcomet_qe_score": 0.6659990549087524, "metricx_score": 10.09830093383789, "metricx_qe_score": 5.664536952972412, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dev data.", "metrics": {"bleu_score": 0.0, "chrf_score": 3.6579471799047942, "xcomet_score": 0.17442026734352112, "xcomet_qe_score": 0.24306389689445496, "metricx_score": 20.834680557250977, "metricx_qe_score": 23.93419647216797, "linguapy_score": [1, "ESTONIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Trotzdem haben spezialisierte State-of-the-Art-Systeme einen erheblichen Vorteil gegenüber den PAMP-Übersetzungen.", "metrics": {"bleu_score": 28.997844147152072, "chrf_score": 78.93138346272957, "xcomet_score": 0.9865270853042603, "xcomet_qe_score": 0.9710007905960083, "metricx_score": 3.986778736114502, "metricx_qe_score": 5.436804294586182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber PAMP kommt unserem kommerziellen System ziemlich nahe.", "metrics": {"bleu_score": 14.923729480049115, "chrf_score": 60.85113331755082, "xcomet_score": 0.9177526235580444, "xcomet_qe_score": 0.9070057272911072, "metricx_score": 6.110771656036377, "metricx_qe_score": 7.9149489402771, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Fall haben wir uns für Google Translate entschieden.", "metrics": {"bleu_score": 61.91566827062977, "chrf_score": 76.11848233448897, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7310307621955872, "metricx_qe_score": 1.6504507064819336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der GMM-Analyse gewonnen haben, die wir mit dem MPN-Framework durchgeführt haben, sind, dass die Flussigkeit von Palm mit den fortschrittlichsten Systemen vergleichbar ist. Der Hauptunterschied liegt jedoch in der Genauigkeit.", "metrics": {"bleu_score": 15.104265760341297, "chrf_score": 59.9306002892231, "xcomet_score": 0.7378987669944763, "xcomet_qe_score": 0.8230334520339966, "metricx_score": 6.781946182250977, "metricx_qe_score": 5.648961067199707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In particular, the most common errors are omission errors.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 11.18800848342499, "xcomet_score": 0.992603063583374, "xcomet_qe_score": 1.0, "metricx_score": 23.20370864868164, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint, dass Palm manchmal eine bessere Klangübersetzung erzeugt, indem es Teile des Originalsatzes weglässt, die in der Übersetzung enthalten sind.", "metrics": {"bleu_score": 13.858909661779084, "chrf_score": 60.654423846443116, "xcomet_score": 0.9117521047592163, "xcomet_qe_score": 0.8490811586380005, "metricx_score": 3.76296329498291, "metricx_qe_score": 3.4014079570770264, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings ist die Stil-awkward-Kategorie für PUN niedriger als für die State-of-the-art-Systeme, was ein zusätzliches Signal ist. That param provides really fluent output, but still with some problems of accuracy.", "metrics": {"bleu_score": 11.28475397287092, "chrf_score": 36.679722438000105, "xcomet_score": 0.5643510818481445, "xcomet_qe_score": 0.6459471583366394, "metricx_score": 17.893831253051758, "metricx_qe_score": 14.445244789123535, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das war's für diese wirklich kurze Übersicht.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 62.20970684118531, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18166464567184448, "metricx_qe_score": 0.20826402306556702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Details, bitte kommen Sie zur vollständigen Präsentation des Papiers.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 64.66274969807219, "xcomet_score": 0.9247006177902222, "xcomet_qe_score": 0.9369192719459534, "metricx_score": 0.9987983703613281, "metricx_qe_score": 1.150386095046997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9980669021606445, "xcomet_qe_score": 1.0, "metricx_score": 0.8462307453155518, "metricx_qe_score": 0.5566104650497437, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Davi, ein Doktorand an der Saarland University in Deutschland.", "metrics": {"bleu_score": 31.138788080750665, "chrf_score": 70.64405832276978, "xcomet_score": 0.8883299827575684, "xcomet_qe_score": 0.9696144461631775, "metricx_score": 2.203155517578125, "metricx_qe_score": 2.293865203857422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Video möchte ich unsere jüngste Arbeit vorstellen, weaker than you think, eine kritische Betrachtung der wöchentlichen Überwachung.", "metrics": {"bleu_score": 17.896429192677505, "chrf_score": 41.37136380787412, "xcomet_score": 0.8264584541320801, "xcomet_qe_score": 0.8092005252838135, "metricx_score": 9.482939720153809, "metricx_qe_score": 11.159415245056152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This is joint work with Xiao Yusen, Mario Smusba, Gerd Stephan and Dietrich Klacko.", "metrics": {"bleu_score": 3.2244357206306944, "chrf_score": 34.344787628254394, "xcomet_score": 0.6398187875747681, "xcomet_qe_score": 0.6434059143066406, "metricx_score": 9.674304962158203, "metricx_qe_score": 8.485710144042969, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung zu schwacher Überwachung und schwach überwachtem Lernen beginnen.", "metrics": {"bleu_score": 40.07271049288471, "chrf_score": 81.09785774934379, "xcomet_score": 0.9889398813247681, "xcomet_qe_score": 0.9831065535545349, "metricx_score": 0.5046766996383667, "metricx_qe_score": 1.5597505569458008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In Weak Supervision, we do not manually label the data.", "metrics": {"bleu_score": 3.1157290929555894, "chrf_score": 14.201330539732524, "xcomet_score": 0.9456884264945984, "xcomet_qe_score": 0.960577130317688, "metricx_score": 6.560595989227295, "metricx_qe_score": 5.260467052459717, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Instead, we label the data using weak labeling sources, such as simple heuristic rules, knowledge bases, or low-quality crowdsourcing, as illustrated in the figure on the right.", "metrics": {"bleu_score": 1.5883027492953543, "chrf_score": 23.179387877777007, "xcomet_score": 0.962944507598877, "xcomet_qe_score": 0.9711205959320068, "metricx_score": 23.253726959228516, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Anmerkungen sind die weak Anmerkungen viel billiger, doch sie sind auch verrauscht, was bedeutet, dass ein gewisses Maß an Anmerkungen falsch ist.", "metrics": {"bleu_score": 27.678618300959723, "chrf_score": 51.708745702674655, "xcomet_score": 0.7855347394943237, "xcomet_qe_score": 0.7743653059005737, "metricx_score": 5.610050678253174, "metricx_qe_score": 6.9148640632629395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "If we directly train neural networks on weakly labeled data, the neural networks tend to memorize the label noise and do not generalize.", "metrics": {"bleu_score": 1.65345928425853, "chrf_score": 20.334311017085387, "xcomet_score": 0.9763939380645752, "xcomet_qe_score": 0.9872215986251831, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise, so that the trained models still generalize well.", "metrics": {"bleu_score": 1.5234719529996685, "chrf_score": 26.355239684801923, "xcomet_score": 0.9792636632919312, "xcomet_qe_score": 0.9944939613342285, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In jüngster Zeit in WSL, also steht WSL für Weakly Supervised Learning, wird behauptet, dass die Menschen nur Modelle mit den wöchentlichen Bezeichnungsdaten trainieren und eine hohe Leistung auf sauberen Testsets erzielen.", "metrics": {"bleu_score": 16.55843632002035, "chrf_score": 53.22900607362472, "xcomet_score": 0.7837167978286743, "xcomet_qe_score": 0.8313091993331909, "metricx_score": 10.384308815002441, "metricx_qe_score": 9.080431938171387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Technisch ist diese Behauptung nicht falsch, aber es gibt einen Haken. Which is that people do assume that there is an additional clean validation set available for model selection. We cast doubt on this problem", "metrics": {"bleu_score": 8.667842943607575, "chrf_score": 34.35824328800543, "xcomet_score": 0.8690409660339355, "xcomet_qe_score": 0.8905495405197144, "metricx_score": 14.807567596435547, "metricx_qe_score": 14.30604076385498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "setting, as this implies that additional manual annotations are required in weakly supervised learning.", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 16.938198589787746, "xcomet_score": 0.7947984933853149, "xcomet_qe_score": 0.8663515448570251, "metricx_score": 22.854856491088867, "metricx_qe_score": 20.979631423950195, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But like an elephant in the room, this necessity is often overlooked.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 16.208994927234492, "xcomet_score": 0.9960876703262329, "xcomet_qe_score": 0.9985805749893188, "metricx_score": 24.32257080078125, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die oben genannte Zweifel lässt uns drei Forschungsfragen stellen.", "metrics": {"bleu_score": 13.134549472120794, "chrf_score": 70.31430056301076, "xcomet_score": 0.9375313520431519, "xcomet_qe_score": 0.916618824005127, "metricx_score": 1.2418675422668457, "metricx_qe_score": 1.9839353561401367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, ist saubere Validierungsdaten für WSL notwendig? Oder können wir vielleicht stattdessen einen verrauschten Validierungssatz verwenden?", "metrics": {"bleu_score": 10.267711102969956, "chrf_score": 61.38197022055216, "xcomet_score": 0.9160670042037964, "xcomet_qe_score": 0.9183567762374878, "metricx_score": 2.4192683696746826, "metricx_qe_score": 2.6607556343078613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten für die ordnungsgemäße Funktion von WSL erforderlich sind, wie viele saubere Proben benötigen wir?", "metrics": {"bleu_score": 39.50615374789255, "chrf_score": 69.02756852911492, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5734819173812866, "metricx_qe_score": 0.894248366355896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich, sollten wir nur die sauberen Proben zur Validierung verwenden, oder gibt es bessere Möglichkeiten,", "metrics": {"bleu_score": 41.001345714763985, "chrf_score": 73.49613403534944, "xcomet_score": 0.9656453132629395, "xcomet_qe_score": 0.9587464332580566, "metricx_score": 1.1059770584106445, "metricx_qe_score": 0.49937403202056885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sie zu nutzen? We addressed these research questions in our work, and our findings are as follows.", "metrics": {"bleu_score": 2.5197593442434796, "chrf_score": 18.595944336205893, "xcomet_score": 0.6880817413330078, "xcomet_qe_score": 0.7881112694740295, "metricx_score": 23.88311767578125, "metricx_qe_score": 20.817218780517578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst stellen wir fest, dass die neueren WSL-Methoden interessanterweise tatsächlich saubere weiße Datensätze benötigen, damit sie ordnungsgemäß funktionieren.", "metrics": {"bleu_score": 11.762897816355773, "chrf_score": 58.354646652293276, "xcomet_score": 0.9066925048828125, "xcomet_qe_score": 0.9134706258773804, "metricx_score": 2.253969192504883, "metricx_qe_score": 2.494818925857544, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ansonsten gibt es einen großen Leistungsabfall,", "metrics": {"bleu_score": 0.0, "chrf_score": 27.13218680996231, "xcomet_score": 0.9891752600669861, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4457893967628479, "metricx_qe_score": 0.2156968116760254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wie in dieser Abbildung dargestellt. Wenn es keine sauberen Validierungssamples gibt, können die trainierten Modelle nicht über die ursprünglichen schwachen Labels hinaus verallgemeinert werden. Meaning that the training is pointless.", "metrics": {"bleu_score": 31.066878208732792, "chrf_score": 69.33818728620803, "xcomet_score": 0.9099869728088379, "xcomet_qe_score": 0.8943451642990112, "metricx_score": 9.206062316894531, "metricx_qe_score": 7.044167518615723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This indicates that WSL approaches actually require cleanly labeled data to work properly, and the annotation cost for obtaining clean validation samples should not be overlooked. Unsere zweite Erkenntnis ist, dass die Erhöhung der", "metrics": {"bleu_score": 2.9799893137327635, "chrf_score": 24.664678768362165, "xcomet_score": 0.5608041286468506, "xcomet_qe_score": 0.7076097726821899, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anzahl der sauberen Validierungssamples die WSL-Ansätze dabei unterstützen wird, eine bessere Leistung zu erzielen, wie in der Abbildung auf der linken Seite dargestellt.", "metrics": {"bleu_score": 21.22363344155404, "chrf_score": 56.28141164918274, "xcomet_score": 0.7499418258666992, "xcomet_qe_score": 0.8162053823471069, "metricx_score": 10.850668907165527, "metricx_qe_score": 9.955743789672852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Normalerweise brauchen wir nur zwanzig Beispiele pro Klasse, um eine hohe Leistung zu erzielen.", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 85.53428139400152, "xcomet_score": 0.9971421957015991, "xcomet_qe_score": 0.9951664209365845, "metricx_score": 0.5278430581092834, "metricx_qe_score": 0.8895652294158936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But that's not the end of the story, because if we either way decide to access clean samples, then training on them directly will even achieve better performance. Die rechte Ab", "metrics": {"bleu_score": 1.3910278360331694, "chrf_score": 19.419458963982244, "xcomet_score": 0.6213350892066956, "xcomet_qe_score": 0.6926637291908264, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "bildung zeigt den Leistungsunterschied zwischen Feinabstimmungsmethoden, die direkt auf die sauberen Daten angewendet werden, und WSL-Methoden, die die sauberen Daten nur zur Validierung verwenden.", "metrics": {"bleu_score": 28.542065112754667, "chrf_score": 66.15729548302997, "xcomet_score": 0.8069847822189331, "xcomet_qe_score": 0.831842839717865, "metricx_score": 3.8797874450683594, "metricx_qe_score": 4.685021877288818, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, wenn wir zehn Proben pro Klasse haben, beginnt die direkte Feintuning-Methode, WSL-Ansätze zu schlagen.", "metrics": {"bleu_score": 27.74290545068997, "chrf_score": 64.71809029841322, "xcomet_score": 0.9671381711959839, "xcomet_qe_score": 0.989488959312439, "metricx_score": 2.6732583045959473, "metricx_qe_score": 2.1744279861450195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die behauptete Leistungsverbesserung in früheren WSL-Ansätzen leicht durch die Möglichkeit der weiteren Feinabstimmung auf den sauberen Validierungssätzen erreicht werden.", "metrics": {"bleu_score": 13.304062588217075, "chrf_score": 63.88690332912055, "xcomet_score": 0.9122623205184937, "xcomet_qe_score": 0.9223165512084961, "metricx_score": 2.5354959964752197, "metricx_qe_score": 2.1786553859710693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir aus den Abbildungen sehen können, unterliegt das Valina-Modell, das als ftw bezeichnet wird, anfangs komplizierteren WSL-Methoden wie Cosine.", "metrics": {"bleu_score": 5.595510806828872, "chrf_score": 45.80247910867317, "xcomet_score": 0.6405954360961914, "xcomet_qe_score": 0.8037211894989014, "metricx_score": 8.306591987609863, "metricx_qe_score": 8.391480445861816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings, wenn wir erlauben, die sauberen Proben weiter zu optimieren, dann funktioniert ftw genauso gut wie andere Methoden.", "metrics": {"bleu_score": 5.983278752571241, "chrf_score": 38.935350116960656, "xcomet_score": 0.9483539462089539, "xcomet_qe_score": 0.9062041640281677, "metricx_score": 3.103388786315918, "metricx_qe_score": 3.4509804248809814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Festplattenspeicher erfordern.", "metrics": {"bleu_score": 85.71061116877266, "chrf_score": 84.12139415388549, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3698810636997223, "metricx_qe_score": 0.5193819999694824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir gezeigt, dass neuere WSL-Ansätze saubere, manuell annotierte Beispiele benötigen, damit sie richtig funktionieren.", "metrics": {"bleu_score": 64.31058201682335, "chrf_score": 81.67037341403017, "xcomet_score": 0.9967339038848877, "xcomet_qe_score": 1.0, "metricx_score": 0.9081078171730042, "metricx_qe_score": 0.7433616518974304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ihre Leistungssteigerung und Praktikabilität werden stark überschätzt.", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 55.009754242118404, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3886856138706207, "metricx_qe_score": 0.3681740164756775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34020400047302246, "metricx_qe_score": 0.30098506808280945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, berichten Sie die Modellauswahlkriterien.", "metrics": {"bleu_score": 5.630400552901077, "chrf_score": 44.81904303406861, "xcomet_score": 0.9853492975234985, "xcomet_qe_score": 1.0, "metricx_score": 2.729088068008423, "metricx_qe_score": 0.8491175770759583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, berichten Sie, ob die Modellauswahl gut durch Validationssätze überprüft wurde.", "metrics": {"bleu_score": 21.023693683267553, "chrf_score": 43.0547225867645, "xcomet_score": 0.947212278842926, "xcomet_qe_score": 0.9330160617828369, "metricx_score": 5.175825119018555, "metricx_qe_score": 4.594888687133789, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit freien Schuldenbaselines verglichen werden, da beide auf demselben Datensatz basieren.", "metrics": {"bleu_score": 19.453651519702834, "chrf_score": 48.54464991344737, "xcomet_score": 0.7554747462272644, "xcomet_qe_score": 0.7938852906227112, "metricx_score": 8.628125190734863, "metricx_qe_score": 8.162139892578125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens ist die kontinuierliche Feintuning eine einfache, aber starke Baseline, die in zukünftigen Arbeiten in WSL berücksichtigt werden sollte.", "metrics": {"bleu_score": 34.19372521950972, "chrf_score": 72.51587902826013, "xcomet_score": 0.8887559175491333, "xcomet_qe_score": 0.8934183120727539, "metricx_score": 6.042881011962891, "metricx_qe_score": 6.050000190734863, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code als Open Source veröffentlicht.", "metrics": {"bleu_score": 64.069143843707, "chrf_score": 70.06581067270068, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3510192036628723, "metricx_qe_score": 0.5402681827545166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können ihn über den QR-Code auf dieser Folie finden.", "metrics": {"bleu_score": 62.38986072117496, "chrf_score": 90.89230250411595, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14408385753631592, "metricx_qe_score": 0.23889029026031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bitte überprüfen Sie ihn gerne.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 15.959481866144396, "xcomet_score": 0.6699198484420776, "xcomet_qe_score": 0.8880983591079712, "metricx_score": 2.5756800174713135, "metricx_qe_score": 1.9353468418121338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank und einen schönen Kongress.", "metrics": {"bleu_score": 19.740631366145518, "chrf_score": 39.14360467484516, "xcomet_score": 0.9945287704467773, "xcomet_qe_score": 0.99988853931427, "metricx_score": 1.014433741569519, "metricx_qe_score": 0.5430709719657898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.055890366435050964, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und ich bin Sarah Finch. Und", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 96.6586836331179, "xcomet_score": 0.9562377333641052, "xcomet_qe_score": 0.9754058122634888, "metricx_score": 2.6225712299346924, "metricx_qe_score": 0.17966464161872864, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "heute werden wir Ihnen alles über abc eval erzählen, einen neuen dimensionalen Ansatz zur Bewertung von Konversations- und KI.", "metrics": {"bleu_score": 27.653555158457866, "chrf_score": 59.81094519332767, "xcomet_score": 0.8502947688102722, "xcomet_qe_score": 0.831731379032135, "metricx_score": 4.9411821365356445, "metricx_qe_score": 4.118054389953613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP-Labor durchgeführt, geleitet von Professor Gino Choi an der Emory University, in Zusammenarbeit mit Amazon Alexa AI.", "metrics": {"bleu_score": 48.43025957347058, "chrf_score": 77.54241977240106, "xcomet_score": 0.8698891997337341, "xcomet_qe_score": 0.8792908191680908, "metricx_score": 4.164279937744141, "metricx_qe_score": 3.938077926635742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So, sagen wir, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie gut es mit dem aktuellen Stand der Technik vergleichbar ist.", "metrics": {"bleu_score": 47.901455811287484, "chrf_score": 73.26976092045358, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5862194895744324, "metricx_qe_score": 0.4933982491493225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die übliche Praxis ist die Verwendung von menschlicher Bewertung, z. B. indem menschliche Richter gebeten werden, zwischen zwei Gesprächen zu wählen, welches besser ist, oder Gespräche mit einem Likert-Skala zu bewerten.", "metrics": {"bleu_score": 11.464137601742182, "chrf_score": 53.901493737574505, "xcomet_score": 0.9490342140197754, "xcomet_qe_score": 0.962452232837677, "metricx_score": 2.2996745109558105, "metricx_qe_score": 1.429360032081604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze funktionieren gut, um eine ganzheitliche Bewertung der Gesamtqualität des Dialogs zu liefern, aber die Qualität des Dialogs hat viele Aspekte.", "metrics": {"bleu_score": 49.76448079808987, "chrf_score": 73.89923220002794, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.5340569615364075, "metricx_qe_score": 0.4792107045650482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher sollten Sie möglicherweise mehrere Dimensionen der Chat-Qualität bewerten, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.", "metrics": {"bleu_score": 52.01577580814477, "chrf_score": 70.5228477878521, "xcomet_score": 0.978233814239502, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.0920748710632324, "metricx_qe_score": 0.595227062702179, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "One approach is to simply ask human judges to evaluate several dimensions of dialogue quality, such as the relevance of model responses, using existing comparative or Likert scale methods.", "metrics": {"bleu_score": 1.526608193588886, "chrf_score": 21.93654977871471, "xcomet_score": 0.9853956699371338, "xcomet_qe_score": 0.9975987672805786, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation.", "metrics": {"bleu_score": 2.417808985590294, "chrf_score": 26.938301547836097, "xcomet_score": 0.9268010258674622, "xcomet_qe_score": 0.988350510597229, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself.", "metrics": {"bleu_score": 1.1478194892097389, "chrf_score": 25.204897327220245, "xcomet_score": 0.9900565147399902, "xcomet_qe_score": 0.9979841709136963, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We call this approach annotating behaviors in chat, or ABC eval in short.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 19.361782908680777, "xcomet_score": 0.9378175735473633, "xcomet_qe_score": 0.8665951490402222, "metricx_score": 20.814393997192383, "metricx_qe_score": 15.7784423828125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature.", "metrics": {"bleu_score": 1.4278442804983642, "chrf_score": 22.92705703768275, "xcomet_score": 0.8809224963188171, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ABC eval is capable of measuring the rates at which chat models will commit various thematic errors.", "metrics": {"bleu_score": 2.031628835361819, "chrf_score": 26.579295854431095, "xcomet_score": 0.8894071578979492, "xcomet_qe_score": 0.9728657007217407, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "For example, abc_eval measures the number of turns in which a chat model ignores its partner or says something irrelevant. Kontradiktiert sich selbst oder seinen Partner, halluziniert falsche Fakten oder verstößt gegen das allgemeine Wissen, und wenn das Modell erfolgreich ist oder nicht, zeigt es Empathie.", "metrics": {"bleu_score": 4.850109406340897, "chrf_score": 40.98109023042253, "xcomet_score": 0.6283588409423828, "xcomet_qe_score": 0.700139582157135, "metricx_score": 19.316730499267578, "metricx_qe_score": 16.473365783691406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "To determine what kind of evaluation is most effective, we selected four state-of-the-art chat models and evaluated them on one hundred human-bot conversations per model using abc eval.", "metrics": {"bleu_score": 1.4763939041893883, "chrf_score": 22.042108877806466, "xcomet_score": 0.9260074496269226, "xcomet_qe_score": 0.9415110945701599, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "For comparison, we also evaluated these conversations using three existing methods: LIKERT ratings on the turn level, LIKERT ratings on the dialogue level, and dialogue level pairwise comparisons.", "metrics": {"bleu_score": 1.4780822562194806, "chrf_score": 32.396190462117715, "xcomet_score": 0.8002470135688782, "xcomet_qe_score": 0.8779489398002625, "metricx_score": 23.48171615600586, "metricx_qe_score": 23.50563621520996, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue, since this is the standard practice for evaluating chat models along multiple dimensions. Aus unseren Analys", "metrics": {"bleu_score": 1.1524538390587937, "chrf_score": 21.871454616820014, "xcomet_score": 0.8571443557739258, "xcomet_qe_score": 0.8823702335357666, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "en dieser Bewertungsergebnisse stellten wir fest, dass abc eval Verhaltensbeschreibungen im Allgemeinen zuverlässiger sind als Beschreibungen, die durch bestehende Methoden gesammelt wurden, gemessen an der inneren Annotator-Übereinstimmung bei hundert doppelten Beschreibungen", "metrics": {"bleu_score": 5.882471646914855, "chrf_score": 45.1963625046918, "xcomet_score": 0.8293006420135498, "xcomet_qe_score": 0.8284465074539185, "metricx_score": 10.3229398727417, "metricx_qe_score": 10.71290111541748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "von Gesprächen. In addition, abc eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis. Zum Beispiel", "metrics": {"bleu_score": 1.2193311110766474, "chrf_score": 28.599434531691436, "xcomet_score": 0.4261032044887543, "xcomet_qe_score": 0.5704639554023743, "metricx_score": 24.368545532226562, "metricx_qe_score": 23.878210067749023, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "können Sie sehen, wie die Messung des Anteils von Zügen mit Selbst- und Partnerkontraktionen 5% und 10% der Gesprächsqualität erklärt, während die durchschnittlichen Lickertestergebnisse nur 4% oder weniger erklären.", "metrics": {"bleu_score": 39.16541813506835, "chrf_score": 62.25284139590887, "xcomet_score": 0.5915805101394653, "xcomet_qe_score": 0.651682436466217, "metricx_score": 10.08373737335205, "metricx_qe_score": 8.123618125915527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir überprüft, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chat-Qualität erfasst, indem wir eine schrittweise lineare Regression verwendet haben.", "metrics": {"bleu_score": 24.76980256562108, "chrf_score": 59.62537078439695, "xcomet_score": 0.9875533580780029, "xcomet_qe_score": 0.9981144666671753, "metricx_score": 0.5069222450256348, "metricx_qe_score": 0.4203507602214813, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, wie die Kombination aller abc eval-Metriken über 25% der Konversationsqualität erklärt. Und wenn Sie die Metriken nacheinander entfernen, verlieren die meisten von ihnen eine angemessene Menge an Informationen über die Qualität.", "metrics": {"bleu_score": 10.366821115295028, "chrf_score": 46.03681716411668, "xcomet_score": 0.8615484833717346, "xcomet_qe_score": 0.9125224351882935, "metricx_score": 2.083221673965454, "metricx_qe_score": 1.7091760635375977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "On the other hand, the combination of all turn-level Lickert metrics explains far less of the quality, and fewer of these metrics carry unique information.", "metrics": {"bleu_score": 1.5880117714047368, "chrf_score": 24.98948972736837, "xcomet_score": 0.8774789571762085, "xcomet_qe_score": 0.9828008413314819, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "These reliable, informative, and distinct ABC eval metrics enable us to evaluate conversational AI with a higher resolution than previous methods are able to achieve. You can see that", "metrics": {"bleu_score": 1.526608193588886, "chrf_score": 22.97656928171134, "xcomet_score": 0.7050259113311768, "xcomet_qe_score": 0.8306400775909424, "metricx_score": 24.33732032775879, "metricx_qe_score": 22.46886444091797, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in the results of our experiment that several challenges still remain and have been precisely quantified.", "metrics": {"bleu_score": 2.2796871594840864, "chrf_score": 22.998592083775723, "xcomet_score": 0.7056998014450073, "xcomet_qe_score": 0.959496259689331, "metricx_score": 25.0, "metricx_qe_score": 24.128173828125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "For example, the bots we tested have common sense violations in around twenty percent of their responses. They produce irrelevant", "metrics": {"bleu_score": 2.0540268312306345, "chrf_score": 20.384390103593457, "xcomet_score": 0.8663849830627441, "xcomet_qe_score": 0.9057567715644836, "metricx_score": 17.663496017456055, "metricx_qe_score": 21.275358200073242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "information in around fifteen percent of the responses, and they contradict themselves or their partner around ten percent of the time.", "metrics": {"bleu_score": 1.8749089613133423, "chrf_score": 25.17032589780478, "xcomet_score": 0.5057445764541626, "xcomet_qe_score": 0.5037252306938171, "metricx_score": 24.45508575439453, "metricx_qe_score": 24.07684898376465, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit dem rasanten Tempo der Verbesserungen in diesem Bereich könnten viele dieser Fehlerquoten bei neuen Modellen, die nach unserer Bewertung veröffentlicht wurden, sinken. Dennoch ist", "metrics": {"bleu_score": 30.90015909429233, "chrf_score": 59.82166721656799, "xcomet_score": 0.875816822052002, "xcomet_qe_score": 0.8074826002120972, "metricx_score": 5.836335182189941, "metricx_qe_score": 1.2325981855392456, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies ein noch stärkender Grund, zuverlässige und präzise Bewertungsmessgrößen für den Vergleich von Modellen zu verfolgen.", "metrics": {"bleu_score": 45.96770676847994, "chrf_score": 68.5703542612903, "xcomet_score": 0.9200457334518433, "xcomet_qe_score": 0.9031167030334473, "metricx_score": 3.323681592941284, "metricx_qe_score": 4.033193588256836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass abc eval von anderen in diesem Bereich als sinnvolle Maßnahme in diese Richtung genutzt werden kann.", "metrics": {"bleu_score": 45.477224609819245, "chrf_score": 63.01542286783371, "xcomet_score": 0.9766272306442261, "xcomet_qe_score": 0.9769098162651062, "metricx_score": 1.9495058059692383, "metricx_qe_score": 2.8373658657073975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir freuen uns darauf, zu sehen, wie sich die konversationale KI in den kommenden Monaten und Jahren weiterentwickelt.", "metrics": {"bleu_score": 40.873575197739754, "chrf_score": 70.3116939167452, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.24598702788352966, "metricx_qe_score": 0.2418639063835144, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank fürs Zuschauen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15433651208877563, "metricx_qe_score": 0.22429457306861877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kyle Yin und ich werde unsere Arbeit vorstellen, die den Titel \"When Does Translation Require Context:", "metrics": {"bleu_score": 44.903323241491265, "chrf_score": 78.78784105091256, "xcomet_score": 0.7664977312088013, "xcomet_qe_score": 0.7616389989852905, "metricx_score": 5.450719356536865, "metricx_qe_score": 6.092230319976807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "A Data-Driven Multilingual Exploration\" trägt.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 39.603086789729645, "xcomet_score": 0.8128371238708496, "xcomet_qe_score": 0.8530997037887573, "metricx_score": 8.836822509765625, "metricx_qe_score": 6.809074878692627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernhout, Emile Niu, Andre F. D. Martins und Graham Neubig durchgeführt.", "metrics": {"bleu_score": 45.33365750044521, "chrf_score": 72.43590999215522, "xcomet_score": 0.7724395394325256, "xcomet_qe_score": 0.7724859714508057, "metricx_score": 5.922553539276123, "metricx_qe_score": 5.2110724449157715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen also vom Kontext ab.", "metrics": {"bleu_score": 26.924761780320413, "chrf_score": 51.8035301178181, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie würden wir zum Beispiel in diesem Satz \"more\" übersetzen?", "metrics": {"bleu_score": 42.50281413416977, "chrf_score": 78.80104387636123, "xcomet_score": 0.897929847240448, "xcomet_qe_score": 0.9041027426719666, "metricx_score": 4.856912612915039, "metricx_qe_score": 5.321479797363281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der vorherige Satz war, \"Things could start to get dangerous if the ministers find out,\" dann bezieht sich Mo auf einen Spion.", "metrics": {"bleu_score": 16.170596160446447, "chrf_score": 45.47633696497421, "xcomet_score": 0.8477873802185059, "xcomet_qe_score": 0.9009854793548584, "metricx_score": 14.876422882080078, "metricx_qe_score": 11.579365730285645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der vorherige Satz war, \"Could it be anything serious, Doctor?\" dann bezieht sich Mo auf ein Geburtszeichen.", "metrics": {"bleu_score": 11.856660123276004, "chrf_score": 40.04054019225357, "xcomet_score": 0.7831312417984009, "xcomet_qe_score": 0.8541033864021301, "metricx_score": 10.732392311096191, "metricx_qe_score": 9.453596115112305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich die Bedeutung des Wortes, und daher ändert sich auch seine Übersetzung. Allerdings ist", "metrics": {"bleu_score": 42.849450901003145, "chrf_score": 78.1719549593315, "xcomet_score": 0.7963274717330933, "xcomet_qe_score": 0.7521860003471375, "metricx_score": 6.394989490509033, "metricx_qe_score": 2.2837085723876953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "es ziemlich schwierig, zu bewerten, wie gut Modelle solche Fälle übersetzen können.", "metrics": {"bleu_score": 57.95581498899424, "chrf_score": 75.04822952608093, "xcomet_score": 0.9355489015579224, "xcomet_qe_score": 0.9263260960578918, "metricx_score": 2.1159536838531494, "metricx_qe_score": 2.431954860687256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies liegt vor allem daran, dass nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was es Metriken auf Korpusaniveau wie Bleu unmöglich macht, diese Übersetzungen zu erfassen.", "metrics": {"bleu_score": 19.212952065926412, "chrf_score": 63.18866494036469, "xcomet_score": 0.9449617862701416, "xcomet_qe_score": 0.9423215389251709, "metricx_score": 0.9437547922134399, "metricx_qe_score": 0.959624707698822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und einige Leute haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachmengen, da sie normalerweise auf Domänenwissen und menschliche Kuration angewiesen sind.", "metrics": {"bleu_score": 56.21449402229132, "chrf_score": 78.94741951948522, "xcomet_score": 0.9381623268127441, "xcomet_qe_score": 0.8991153240203857, "metricx_score": 0.680672287940979, "metricx_qe_score": 0.6193339824676514, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit haben wir versucht, diese beiden Fragen zu beantworten:", "metrics": {"bleu_score": 49.73567356124543, "chrf_score": 83.18969107740524, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1951795518398285, "metricx_qe_score": 0.15199357271194458, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, wann erfordert Übersetzung Kontext?", "metrics": {"bleu_score": 18.938334565508196, "chrf_score": 53.51712863829962, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.12399060279130936, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und zweitens, wie gut gehen Modelle mit diesen Fällen um?", "metrics": {"bleu_score": 24.925832743644712, "chrf_score": 66.36498210236395, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.7351899147033691, "metricx_qe_score": 2.2329163551330566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, haben wir zunächst gemessen, wie sehr die Wortwahl beim Übersetzen vom Kontext abhängt.", "metrics": {"bleu_score": 64.50925155244735, "chrf_score": 77.23735429520922, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.16516521573066711, "metricx_qe_score": 0.10411599278450012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir cxmi als Maß für den Kontextgebrauch von maschinellen Übersetzungsmodellen eingeführt.", "metrics": {"bleu_score": 16.390623170497822, "chrf_score": 63.148138925789496, "xcomet_score": 0.9595613479614258, "xcomet_qe_score": 0.9532939195632935, "metricx_score": 1.097819209098816, "metricx_qe_score": 0.9839049577713013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und dies geschieht, indem gemessen wird, wie viel Information der Kontext C über das Ziel Y angibt, wenn die Quelle X gegeben ist. Sie können sich cxmi als die Informationen vorstellen, die durch den Kontext für das Modell gewonnen werden.", "metrics": {"bleu_score": 29.730861052591894, "chrf_score": 61.69885427366925, "xcomet_score": 0.9757813811302185, "xcomet_qe_score": 0.9560913443565369, "metricx_score": 2.876749277114868, "metricx_qe_score": 2.842576026916504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir cxmi auf punktweise cxmi, mit der Kontextnutzung auf Satz- oder Wortebene gemessen werden kann.", "metrics": {"bleu_score": 37.39214909689668, "chrf_score": 68.90447591319533, "xcomet_score": 0.9161990284919739, "xcomet_qe_score": 0.9065524339675903, "metricx_score": 3.1868505477905273, "metricx_qe_score": 3.5051355361938477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können Wörter mit hohem pxcmi als solche betrachten, die für die Übersetzung Kontext benötigen.", "metrics": {"bleu_score": 19.189459175294463, "chrf_score": 58.63851555910253, "xcomet_score": 0.9629597663879395, "xcomet_qe_score": 0.9540014863014221, "metricx_score": 3.0851025581359863, "metricx_qe_score": 3.8376667499542236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt analysieren wir Wörter mit hohem pmi, um Muster zwischen diesen Wörtern zu finden.", "metrics": {"bleu_score": 40.02916772576474, "chrf_score": 66.65743998696863, "xcomet_score": 0.9655269384384155, "xcomet_qe_score": 0.9571627974510193, "metricx_score": 5.2382402420043945, "metricx_qe_score": 6.521448612213135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen unsere Analyse auf Transkripten von Ted Talks durch, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden.", "metrics": {"bleu_score": 58.61137788133827, "chrf_score": 87.25679636910478, "xcomet_score": 0.9777828454971313, "xcomet_qe_score": 0.9795372486114502, "metricx_score": 0.7545099258422852, "metricx_qe_score": 0.7477264404296875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 69.01373793266372, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst betrachten wir die Teilsprachen, die einen hohen Mittelwert von Pcsxmi aufweisen.", "metrics": {"bleu_score": 28.65612242047131, "chrf_score": 47.37137102290146, "xcomet_score": 0.7276979684829712, "xcomet_qe_score": 0.7454854249954224, "metricx_score": 4.723297119140625, "metricx_qe_score": 5.531081199645996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ermöglicht es uns, zum Beispiel Dualpronomen im Arabischen zu finden, die einen relativ hohen p. xmi haben.", "metrics": {"bleu_score": 26.512298021756184, "chrf_score": 55.0520078336132, "xcomet_score": 0.9169563055038452, "xcomet_qe_score": 0.8990980982780457, "metricx_score": 3.7281346321105957, "metricx_qe_score": 3.9865846633911133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das kann erklärt werden, weil Englisch keine Dualpronomen hat, also muss man den Kontext kennen, um zu bestimmen, ob ein Pronomen dual ist, wenn man es ins Arabische übersetzt.", "metrics": {"bleu_score": 44.01087756255934, "chrf_score": 66.92558335427398, "xcomet_score": 0.9910824298858643, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6202640533447266, "metricx_qe_score": 0.9077610969543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in ähnlicher Weise stellen wir fest, dass bestimmte Sprachen auch Kontext erfordern, wenn wir die passende Verbform wählen wollen.", "metrics": {"bleu_score": 2.852106129996742, "chrf_score": 35.37819297987389, "xcomet_score": 0.9909040927886963, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.4490850269794464, "metricx_qe_score": 0.30571219325065613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten dann Wörterbuchartikel, die über alle ihre verschiedenen Vorkommen einen hohen Pessimismus aufweisen.", "metrics": {"bleu_score": 15.587373585261098, "chrf_score": 42.792629441165616, "xcomet_score": 0.7727824449539185, "xcomet_qe_score": 0.7616947889328003, "metricx_score": 5.2231364250183105, "metricx_qe_score": 4.4492716789245605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das hilft uns, Fälle wie diesen zu identifizieren, in denen man im Chinesischen Kontext benötigt, um Eigennamen zu übersetzen, um sicherzustellen, dass man innerhalb des Dokuments die gleiche Übersetzung verwendet.", "metrics": {"bleu_score": 55.9412951196376, "chrf_score": 79.37658645237926, "xcomet_score": 0.9999051094055176, "xcomet_qe_score": 0.9993828535079956, "metricx_score": 0.5873550772666931, "metricx_qe_score": 2.9552578926086426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und in ähnlicher Weise finden wir, dass der Kontext die richtige Formalität unterstützt, um zu übersetzen. Und", "metrics": {"bleu_score": 15.89043674656745, "chrf_score": 45.7029341142817, "xcomet_score": 0.9135438203811646, "xcomet_qe_score": 0.9113062620162964, "metricx_score": 3.133357524871826, "metricx_qe_score": 1.6506291627883911, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich betrachten wir verschiedene einzelne Token, die eine hohe PEXMI aufweisen.", "metrics": {"bleu_score": 42.803206067505954, "chrf_score": 73.66900599864698, "xcomet_score": 0.8927754759788513, "xcomet_qe_score": 0.8965398073196411, "metricx_score": 1.7987043857574463, "metricx_qe_score": 2.2436275482177734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie zum Beispiel die Ellipsenauflösung.", "metrics": {"bleu_score": 55.4733023578308, "chrf_score": 76.3077014311085, "xcomet_score": 0.9871875047683716, "xcomet_qe_score": 0.9795279502868652, "metricx_score": 0.2513912320137024, "metricx_qe_score": 0.510511577129364, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt verwenden wir unsere Ergebnisse aus unserer Analyse, um einen Benchmark für die Übersetzung von Dokumenten auf Dokumentenniveau zu entwickeln.", "metrics": {"bleu_score": 45.001473167434995, "chrf_score": 77.04920358678395, "xcomet_score": 0.983310341835022, "xcomet_qe_score": 0.9738863706588745, "metricx_score": 0.8772132396697998, "metricx_qe_score": 1.0392481088638306, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, haben wir Tags erstellt, um Wörter automatisch zu identifizieren, die mit dem Phänomen in Verbindung stehen. Und", "metrics": {"bleu_score": 48.38829735807371, "chrf_score": 78.10106865528985, "xcomet_score": 0.9603006839752197, "xcomet_qe_score": 0.9539738893508911, "metricx_score": 1.935633897781372, "metricx_qe_score": 0.6624022126197815, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir nennen unser Tag das Multilingual Discourse Aware oder MUDa-Tag.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 53.08018237840791, "xcomet_score": 0.8089874386787415, "xcomet_qe_score": 0.7501476407051086, "metricx_score": 6.9244704246521, "metricx_qe_score": 6.410278797149658, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können dann auch feststellen, dass verschiedene Sprachen unterschiedliche Proportionen dieser diskursiven Phänomene aufweisen.", "metrics": {"bleu_score": 23.446219441058627, "chrf_score": 71.20676267921498, "xcomet_score": 0.991059422492981, "xcomet_qe_score": 0.9882320165634155, "metricx_score": 0.5305174589157104, "metricx_qe_score": 0.3603895604610443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den Muda-Tagger, indem wir den Tagger auf den parallelen Korpus anwenden, den wir für die Auswertung verwenden möchten. Und wir wenden unsere Wahl der Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat. Und", "metrics": {"bleu_score": 26.532469107514945, "chrf_score": 64.51621630762415, "xcomet_score": 0.8374919891357422, "xcomet_qe_score": 0.7870138883590698, "metricx_score": 2.3612594604492188, "metricx_qe_score": 1.865887999534607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentenebene zu bewerten.", "metrics": {"bleu_score": 41.31624154858751, "chrf_score": 71.03835513372468, "xcomet_score": 0.9628392457962036, "xcomet_qe_score": 0.9581093788146973, "metricx_score": 0.4942355155944824, "metricx_qe_score": 0.8727203011512756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, wenn wir Korpus-Metriken verwenden, so dass für blau, finden wir, dass kollektive agnostische Modelle die beste Leistung haben.", "metrics": {"bleu_score": 11.601529016234949, "chrf_score": 45.080353406467985, "xcomet_score": 0.8501137495040894, "xcomet_qe_score": 0.8494715094566345, "metricx_score": 7.324007987976074, "metricx_qe_score": 6.384225845336914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But then if we use comment, context-aware models perform best. And if we use word", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 18.89661359111266, "xcomet_score": 0.5344581604003906, "xcomet_qe_score": 0.7769355773925781, "metricx_score": 21.509212493896484, "metricx_qe_score": 16.370948791503906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "f-measure, then models with or without context have comparable performance.", "metrics": {"bleu_score": 3.1934960455974277, "chrf_score": 19.646763855720785, "xcomet_score": 0.9099758863449097, "xcomet_qe_score": 0.9546561241149902, "metricx_score": 18.658700942993164, "metricx_qe_score": 19.630046844482422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Dokumentenlevel-Übersetzungs-System zu bestimmen, wenn man allein auf Korpus-Level-Metriken zurückgreift.", "metrics": {"bleu_score": 51.84161222537763, "chrf_score": 68.2765249117938, "xcomet_score": 0.9494948387145996, "xcomet_qe_score": 0.9614433646202087, "metricx_score": 4.151782989501953, "metricx_qe_score": 3.005760908126831, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt verwenden wir den MuLBenchmark, um Modelle zu bewerten, und wir stellen fest, dass kontextübergreifende Modelle bei bestimmten Diskursphänomenen wie Formalität und lexikalischer Kohäsion deutlich genauer sind als Modelle, die den Kontext nicht für bestimmte Disk", "metrics": {"bleu_score": 29.580782020847764, "chrf_score": 69.89364032492945, "xcomet_score": 0.6633158922195435, "xcomet_qe_score": 0.6779087781906128, "metricx_score": 8.705573081970215, "metricx_qe_score": 7.742686748504639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "ursphänomene verwenden. Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext auf andere Phänomene wie Auslassungen, Pronomen und Verbform verwenden.", "metrics": {"bleu_score": 25.567957494892184, "chrf_score": 59.995508307374024, "xcomet_score": 0.7308361530303955, "xcomet_qe_score": 0.6932963132858276, "metricx_score": 9.89140510559082, "metricx_qe_score": 10.55140495300293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet also darauf hin, wo wir mehr Fortschritte bei der Dokumentenlevel-Übersetzung sehen müssten.", "metrics": {"bleu_score": 12.573629486100442, "chrf_score": 53.67132720868757, "xcomet_score": 0.9830510020256042, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.4199748039245605, "metricx_qe_score": 2.12125825881958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch verschiedene kommerzielle Systeme verglichen, und unser Benchmark zeigt, dass DeepL in der Regel genauer ist als Google Translate für die Übersetzung von Dokumenten.", "metrics": {"bleu_score": 63.86806506668796, "chrf_score": 85.14474862639777, "xcomet_score": 0.9915422201156616, "xcomet_qe_score": 0.9859038591384888, "metricx_score": 0.5086100697517395, "metricx_qe_score": 0.5941272377967834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend haben wir eine datengetriebene Analyse in 14 Sprachpaaren durchgeführt, um den Kontext für eine Übersetzung zu identifizieren. Und dann verwenden wir unsere Erkenntnisse, um einen Benchmark für die maschinelle Übersetzung auf Dokumentebene zu erstellen, der uns helfen kann, zu identifizieren, welche Diskursphänomenmodelle gut oder nicht gut umgehen können, und welche Übersetzungssysteme gut in der Dokumentenübersetzung sind.", "metrics": {"bleu_score": 24.047881839487687, "chrf_score": 62.893289405238306, "xcomet_score": 0.8683192133903503, "xcomet_qe_score": 0.8643695712089539, "metricx_score": 3.7522385120391846, "metricx_qe_score": 3.233546018600464, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.15663683414459229, "metricx_qe_score": 0.3882748484611511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bis morgen.", "metrics": {"bleu_score": 0.0, "chrf_score": 8.078766097634023, "xcomet_score": 0.15088823437690735, "xcomet_qe_score": 0.11660292744636536, "metricx_score": 2.973048448562622, "metricx_qe_score": 6.313348770141602, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Janis Lawack und werde Ihnen unsere Arbeiten über Dr. Bert vorstellen, ein robustes, vorgetrainiertes Modell auf Französisch für biomedizinische und klinische Domänen.", "metrics": {"bleu_score": 3.511476270817333, "chrf_score": 38.695608942996316, "xcomet_score": 0.833649218082428, "xcomet_qe_score": 0.89305180311203, "metricx_score": 4.136739730834961, "metricx_qe_score": 3.847175121307373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation werden wir zunächst über die Sprachmodellierung in der Gesundheitsversorgung sprechen.", "metrics": {"bleu_score": 49.132705481444226, "chrf_score": 82.30971903214846, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2906121611595154, "metricx_qe_score": 0.23677322268486023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend werden wir den Hauptbeitrag unseres Artikels vorstellen.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 65.16692383375654, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09013321995735168, "metricx_qe_score": 0.07512054592370987, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben das erste biomedizinische Modell in Französisch eingeführt, das den Namen Dr. Bert trägt, das auf Roberta basiert und auf dem Nachos, einem Datensatz mit medizinischen Daten aus dem Internet, trainiert wurde.", "metrics": {"bleu_score": 31.72629746109535, "chrf_score": 64.02417960779644, "xcomet_score": 0.7436120510101318, "xcomet_qe_score": 0.7123632431030273, "metricx_score": 1.591071367263794, "metricx_qe_score": 2.2506520748138428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen auch einen Vergleich des Modells mit mehreren Trainingseinstellungen und Datenquellen durch.", "metrics": {"bleu_score": 14.949751774990691, "chrf_score": 59.542457741745395, "xcomet_score": 0.9755120277404785, "xcomet_qe_score": 0.9587681293487549, "metricx_score": 1.5309784412384033, "metricx_qe_score": 1.316102385520935, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dann präsentieren wir unsere Ergebnisse für elf biomedizinische und klinische Downstream-Aufgaben in Französisch.", "metrics": {"bleu_score": 35.00482776497398, "chrf_score": 70.92399905676635, "xcomet_score": 0.9319278001785278, "xcomet_qe_score": 0.9307591915130615, "metricx_score": 1.4036805629730225, "metricx_qe_score": 2.226344108581543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich haben wir über die Experimente geschlossen und Ihnen weitere Details darüber gegeben, wie Sie auf das Modell zugreifen können.", "metrics": {"bleu_score": 18.931747781986427, "chrf_score": 58.04191106806379, "xcomet_score": 0.7783672213554382, "xcomet_qe_score": 0.8560812473297119, "metricx_score": 4.365240573883057, "metricx_qe_score": 3.437493324279785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze geworden, um Aufgaben im Bereich der natürlichen Sprachverarbeitung zu lösen, und bietet einen enormen Leistungsgewinn im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec, FastText oder N-Gramm-Modellen.", "metrics": {"bleu_score": 34.89837015843981, "chrf_score": 69.2705127047701, "xcomet_score": 0.9939916133880615, "xcomet_qe_score": 0.9943541288375854, "metricx_score": 1.7213139533996582, "metricx_qe_score": 1.844336986541748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell auf viele andere Sprachen wie Französisch mit Camembert und auf andere Bereiche wie Biomedizin mit Permitted Birth und Biobirth übertragen, aber hauptsächlich auf Englisch.", "metrics": {"bleu_score": 13.475178211267433, "chrf_score": 48.764349029616, "xcomet_score": 0.6275162696838379, "xcomet_qe_score": 0.683547854423523, "metricx_score": 10.19904613494873, "metricx_qe_score": 10.086583137512207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind selten und basieren oft auf kontinuierlicher Übertragung aufgrund des Mangels an Domänendaten.", "metrics": {"bleu_score": 15.023426670177324, "chrf_score": 64.17855792126049, "xcomet_score": 0.8861856460571289, "xcomet_qe_score": 0.8637442588806152, "metricx_score": 5.353032112121582, "metricx_qe_score": 5.316694259643555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings hatte das französische Unternehmen bis jetzt kein Open-Source-Modell für biomedizinische Anwendungen.", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 56.15708783843172, "xcomet_score": 0.9678347110748291, "xcomet_qe_score": 0.9745553135871887, "metricx_score": 2.160853862762451, "metricx_qe_score": 0.8582048416137695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen uns die Frage, welche Datenquellen für eine breite Anwendung am besten geeignet sind. Und diese Quelldaten sind eine gute Ersatz für klinische Daten.", "metrics": {"bleu_score": 37.04267397314507, "chrf_score": 67.16913093071342, "xcomet_score": 0.8865653872489929, "xcomet_qe_score": 0.8515000939369202, "metricx_score": 2.5042600631713867, "metricx_qe_score": 1.5851601362228394, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Shubert-Modell, das auf anonymisierten Daten basiert, die wir aus dem Non-Universitätskrankenhaus erhalten haben. Nachher", "metrics": {"bleu_score": 39.21923459064418, "chrf_score": 64.40565659623624, "xcomet_score": 0.6300374269485474, "xcomet_qe_score": 0.6336187124252319, "metricx_score": 8.993340492248535, "metricx_qe_score": 8.627887725830078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "stellen wir uns die Frage, wie viele Daten wir brauchen, um ein spezialisiertes Modell auf französischen Daten zu trainieren?", "metrics": {"bleu_score": 53.781668680099195, "chrf_score": 81.95881710787387, "xcomet_score": 0.9602019786834717, "xcomet_qe_score": 0.9440652132034302, "metricx_score": 1.3529398441314697, "metricx_qe_score": 2.3968794345855713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ist es vier Gigabyte, acht Gigabyte oder mehr?", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 66.1591451822075, "xcomet_score": 0.9904079437255859, "xcomet_qe_score": 1.0, "metricx_score": 0.11000038683414459, "metricx_qe_score": 0.14434406161308289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zuerst vier von Grund auf neu entwickelte Modelle: eine erste Version von Dr. Bert mit sieben Gigabyte von Nachos, eine zweite Version mit vier Gigabyte von Nachos. Die erste Version von Shubert, die ein klinisches Modell ist, mit vier Gigabyte von Sätzen, die aus klinischen Notizen entnommen wurden. Und eine endgültige Version von Shubert, mit einer Mischung aus vier Gigabyte von natürlichen Sätzen und vier Gigabyte von klinischen Notizen.", "metrics": {"bleu_score": 25.452128129124656, "chrf_score": 57.759240139926014, "xcomet_score": 0.5108933448791504, "xcomet_qe_score": 0.5295334458351135, "metricx_score": 4.87713098526001, "metricx_qe_score": 4.507024765014648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich zu dieser Vergleichsanalyse führen wir drei Modelle ein, die auf kontextueller Voreingenommenheit trainiert wurden, um die Auswirkungen der Voreingenommenheitsstrategie zu analysieren.", "metrics": {"bleu_score": 37.03578957246191, "chrf_score": 67.72892643853147, "xcomet_score": 0.8081486225128174, "xcomet_qe_score": 0.8075965642929077, "metricx_score": 6.075844764709473, "metricx_qe_score": 5.12481164932251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "One is based on the weight of camembert and trained on four gigabytes of set of natures, another also", "metrics": {"bleu_score": 0.0, "chrf_score": 18.285511501461517, "xcomet_score": 0.34303018450737, "xcomet_qe_score": 0.6915169954299927, "metricx_score": 21.42974853515625, "metricx_qe_score": 15.354909896850586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "based on camembert but trained this time on the four gigabytes of king can logs. Und schließlich, eine Basis auf dem englischen biomedizinischen Modell Permutierte und trainiert auf vier Gigabyte Set von Natur in total haben", "metrics": {"bleu_score": 9.148054394106007, "chrf_score": 37.593014203023756, "xcomet_score": 0.14028184115886688, "xcomet_qe_score": 0.25398799777030945, "metricx_score": 22.40437126159668, "metricx_qe_score": 20.539743423461914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "wir sieben Modelle.", "metrics": {"bleu_score": 23.50540321304655, "chrf_score": 38.394470374241465, "xcomet_score": 0.9304498434066772, "xcomet_qe_score": 0.9124043583869934, "metricx_score": 3.3471779823303223, "metricx_qe_score": 2.675812244415283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, sammeln wir öffentliche und private Aufgaben, wie z. B. Nennungs- und Zustimmungsaufgaben, Part-of-Speech-Tagging und Fragebeantwortung.", "metrics": {"bleu_score": 22.13567016059383, "chrf_score": 51.141188155316684, "xcomet_score": 0.7692902088165283, "xcomet_qe_score": 0.7702399492263794, "metricx_score": 7.6783905029296875, "metricx_qe_score": 7.412862300872803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle werden mit sechs Basismodellen verglichen, die sind: Camembert Oscar 138 Gigabyte, Camembert Oscar 4 Gigabyte, Camembert CCNET 4 Gigabyte, Permitted Birth, Myobirth und Clinical Birth.", "metrics": {"bleu_score": 21.8134321293328, "chrf_score": 52.80480983939591, "xcomet_score": 0.5070487856864929, "xcomet_qe_score": 0.5078418254852295, "metricx_score": 11.506808280944824, "metricx_qe_score": 12.338027000427246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung von Highlights, dass das Modell am besten auf der Aufgabe mit Daten der gleichen Art funktioniert, wie die, auf die das Modell trainiert wurde.", "metrics": {"bleu_score": 18.485450668488085, "chrf_score": 49.779116788694324, "xcomet_score": 0.8669915795326233, "xcomet_qe_score": 0.8300996422767639, "metricx_score": 7.111649036407471, "metricx_qe_score": 7.14459228515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch die Daten aus heterogenen Quellen erhalten. Wir haben festgestellt, dass Daten aus heterogenen Quellen eine bessere Leistung zu bieten scheinen.", "metrics": {"bleu_score": 25.169669587818394, "chrf_score": 63.02461133037905, "xcomet_score": 0.9724776148796082, "xcomet_qe_score": 0.9799535274505615, "metricx_score": 1.6984318494796753, "metricx_qe_score": 1.6130355596542358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch festgestellt, dass die Verwendung von mehr Daten zu einer besseren Leistung führt.", "metrics": {"bleu_score": 76.73071548877977, "chrf_score": 82.86077431954071, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1963445544242859, "metricx_qe_score": 0.3836444020271301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheint das von Grund auf erstellte Retreining bei den meisten Aufgaben eine höhere Leistung zu erzielen.", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 64.82691339382858, "xcomet_score": 0.9148715734481812, "xcomet_qe_score": 0.9189478158950806, "metricx_score": 5.536517143249512, "metricx_qe_score": 5.289152145385742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings zeigen unsere Experimente zur Konstanteinbildung mit dem Gewicht und dem Tokenisierer von permitbert, die auf dem Vier-Gigabyte-Teil von Natur aus trainiert wurden, vergleichbare Ergebnisse wie die von Dr. Bert, Vier Gigabyte von", "metrics": {"bleu_score": 5.245447141070191, "chrf_score": 44.28709387159236, "xcomet_score": 0.37078481912612915, "xcomet_qe_score": 0.4723036289215088, "metricx_score": 12.396927833557129, "metricx_qe_score": 10.539766311645508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Grund auf neu, Das ist bei dem Modell, das auf Camembert-Weizen und Tuckeringer basiert, nicht der Fall, da es Stabilitätsprobleme aufweist.", "metrics": {"bleu_score": 16.562574029564242, "chrf_score": 50.395255986557444, "xcomet_score": 0.4881143271923065, "xcomet_qe_score": 0.3638974130153656, "metricx_score": 10.028827667236328, "metricx_qe_score": 11.322460174560547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich, als Schlussfolgerung, bietet unser vorgeschlagenes System eine bessere Leistung bei neun von elf nicht-Threads-Aufgaben und übertrifft global die Ergebnisse des generischen Modells hier. Wir beobachten auch, dass spezialisierte", "metrics": {"bleu_score": 9.20879983187038, "chrf_score": 49.686223448452246, "xcomet_score": 0.6532863974571228, "xcomet_qe_score": 0.6522716283798218, "metricx_score": 10.835675239562988, "metricx_qe_score": 11.654813766479492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daten besser sind, mehr spezialisierte Daten sind besser, aber sie skalen nicht gut.", "metrics": {"bleu_score": 25.33313470546776, "chrf_score": 60.68936898357185, "xcomet_score": 0.8345125913619995, "xcomet_qe_score": 0.7945502996444702, "metricx_score": 13.097829818725586, "metricx_qe_score": 12.965014457702637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das vorgefertigte Modell, das von Natur aus erhalten wurde, ist auf der Jugendseite und auf der ganzen Training-Serie verfügbar. Also, vielen", "metrics": {"bleu_score": 1.9716859291437636, "chrf_score": 28.80957173511078, "xcomet_score": 0.22752536833286285, "xcomet_qe_score": 0.23098155856132507, "metricx_score": 20.498640060424805, "metricx_qe_score": 18.945899963378906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dank für diese Präsentation. Wir freuen uns auf den Austausch in der anschließenden Sitzung in Toronto.", "metrics": {"bleu_score": 41.15109772030928, "chrf_score": 65.26222896005855, "xcomet_score": 0.9045308828353882, "xcomet_qe_score": 0.9158942699432373, "metricx_score": 2.307579278945923, "metricx_qe_score": 2.4085826873779297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,", "metrics": {"bleu_score": 0.0, "chrf_score": 59.166666666666664, "xcomet_score": 0.9958341121673584, "xcomet_qe_score": 0.9947034120559692, "metricx_score": 0.0, "metricx_qe_score": 0.06646481901407242, "linguapy_score": [1, "SOTHO"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "mein Name ist Matthias Lindemann, und heute werde ich Ihnen eine kurze Einführung in unsere Arbeit über die kompositorische Verallgemeinerung ohne Bäume mit Multi-Set-Tagging und latenten Permutationen geben.", "metrics": {"bleu_score": 26.92360258755782, "chrf_score": 57.565862855987994, "xcomet_score": 0.9102506637573242, "xcomet_qe_score": 0.8918801546096802, "metricx_score": 2.8587396144866943, "metricx_qe_score": 3.165602207183838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This is joint work with my advisors Alexander Koller and Ivan Titorov.", "metrics": {"bleu_score": 6.803085237372876, "chrf_score": 35.64103016670547, "xcomet_score": 0.9514447450637817, "xcomet_qe_score": 0.9492692351341248, "metricx_score": 24.235313415527344, "metricx_qe_score": 24.18317222595215, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kompositional Generalization kann als die Fähigkeit eines Lernenden verstanden werden, mit tieferer Rekursion und unbewohnten Kompositionen von Phrasen umzugehen, die während des Trainings einzeln gesehen wurden.", "metrics": {"bleu_score": 63.19211739683715, "chrf_score": 81.44654731039519, "xcomet_score": 0.7855361700057983, "xcomet_qe_score": 0.7909943461418152, "metricx_score": 8.031455993652344, "metricx_qe_score": 6.526725769042969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Semantik, beim Testen für die Kompositionalgeneralisation könnte es so aussehen.", "metrics": {"bleu_score": 6.288689277257346, "chrf_score": 40.01791341859515, "xcomet_score": 0.962841272354126, "xcomet_qe_score": 0.9218966364860535, "metricx_score": 4.645515441894531, "metricx_qe_score": 4.305893898010254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Normalerweise haben wir eine Trainingsmenge von Sätzen,", "metrics": {"bleu_score": 45.62272070865922, "chrf_score": 60.00649091619754, "xcomet_score": 0.8854674100875854, "xcomet_qe_score": 0.8518303036689758, "metricx_score": 3.239377021789551, "metricx_qe_score": 3.838935375213623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "in diesem Fall die Mädchen schliefen", "metrics": {"bleu_score": 12.872632311973014, "chrf_score": 66.01297967285082, "xcomet_score": 0.965316653251648, "xcomet_qe_score": 0.9341274499893188, "metricx_score": 4.523369789123535, "metricx_qe_score": 5.501032829284668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und Mary wusste, dass die Mädchen schliefen.", "metrics": {"bleu_score": 18.04438612975343, "chrf_score": 60.983580812551544, "xcomet_score": 0.9588299989700317, "xcomet_qe_score": 0.9609652757644653, "metricx_score": 5.194329738616943, "metricx_qe_score": 3.127207040786743, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "These utterances are paired with logical forms that represent core aspects of their meaning.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 18.048720108983854, "xcomet_score": 0.9526090621948242, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur Standard-Maschinellen-Lernbewertung stammt der Testsatz nicht aus der gleichen Verteilung, enthält aber strukturell unerwartete logische Formen.", "metrics": {"bleu_score": 13.618796864073039, "chrf_score": 57.979539292343986, "xcomet_score": 0.939020037651062, "xcomet_qe_score": 0.951122522354126, "metricx_score": 2.3017091751098633, "metricx_qe_score": 1.4374738931655884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion gesehen und wird auf einem Beispiel mit tiefer Rekursion getestet.", "metrics": {"bleu_score": 72.02093506938778, "chrf_score": 88.52952551508314, "xcomet_score": 0.9732690453529358, "xcomet_qe_score": 0.9502196311950684, "metricx_score": 0.9058858156204224, "metricx_qe_score": 1.4057667255401611, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Naive sequence to sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.", "metrics": {"bleu_score": 1.795137899831049, "chrf_score": 22.40132020199976, "xcomet_score": 0.8854758739471436, "xcomet_qe_score": 0.9151166677474976, "metricx_score": 24.120342254638672, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere scheitern sie oft daran, die systematischen Entsprechungen zwischen Eingabe und Ausgabe nachzuahmen, wie sie in den Beispielen farbcodiert sind.", "metrics": {"bleu_score": 5.865108044269315, "chrf_score": 44.42886629701398, "xcomet_score": 0.974749743938446, "xcomet_qe_score": 0.971487283706665, "metricx_score": 0.4424699544906616, "metricx_qe_score": 0.4397464692592621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, um dies zu adressieren, besteht darin, Bäume in die Modelle zu", "metrics": {"bleu_score": 26.916574623991007, "chrf_score": 52.2641473206788, "xcomet_score": 0.8793375492095947, "xcomet_qe_score": 0.9094439744949341, "metricx_score": 5.222991943359375, "metricx_qe_score": 4.136377334594727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "integrieren. The trees are intended to capture the compositional process that relates utterances with the logical forms.", "metrics": {"bleu_score": 2.0244462660665508, "chrf_score": 24.30741002225346, "xcomet_score": 0.4080592691898346, "xcomet_qe_score": 0.38051676750183105, "metricx_score": 24.26630973815918, "metricx_qe_score": 23.606706619262695, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This works well, but trees are usually not given and need to be obtained somehow.", "metrics": {"bleu_score": 2.5642993454084824, "chrf_score": 12.752742214762092, "xcomet_score": 0.9383081197738647, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann kompliziert und manchmal ein rechnerisch aufwändiger Prozess sein.", "metrics": {"bleu_score": 21.200626759025184, "chrf_score": 63.16672656387946, "xcomet_score": 0.9986497163772583, "xcomet_qe_score": 1.0, "metricx_score": 0.15588688850402832, "metricx_qe_score": 0.23202428221702576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Normalerweise beinhaltet dies eine erhebliche vorformulierte, vorformulierte Vorverarbeitung der logischen Formen, zum Beispiel, um Variable-Symbole zu behandeln.", "metrics": {"bleu_score": 16.737506462732373, "chrf_score": 47.985099320550496, "xcomet_score": 0.8570939302444458, "xcomet_qe_score": 0.8613026142120361, "metricx_score": 5.863097190856934, "metricx_qe_score": 6.4632463455200195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Erzeugung von Bäumen kann auch spezialisierte Grammatikinduktionsverfahren beinhalten.", "metrics": {"bleu_score": 30.213753973567687, "chrf_score": 67.81101858581634, "xcomet_score": 0.9110186696052551, "xcomet_qe_score": 0.8950020670890808, "metricx_score": 3.5348808765411377, "metricx_qe_score": 5.343569755554199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Papier verwenden wir keine Bäume und stellen ein neuronales Sequenz-zu-Sequenz-Modell vor, das die Entsprechungen zwischen Fragmente der Eingabe und Fragmente der Ausgabe direkt modelliert.", "metrics": {"bleu_score": 19.230188007838606, "chrf_score": 58.999507637655825, "xcomet_score": 0.888629138469696, "xcomet_qe_score": 0.8829858303070068, "metricx_score": 0.8919775485992432, "metricx_qe_score": 0.912039041519165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung zu tieferer Rekursion, ohne auf Bäume angewiesen zu sein.", "metrics": {"bleu_score": 37.39978404351137, "chrf_score": 61.498328193806586, "xcomet_score": 0.9168288707733154, "xcomet_qe_score": 0.8495138883590698, "metricx_score": 1.0429704189300537, "metricx_qe_score": 1.7575536966323853, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Our approach predicts the output from the input in two steps.", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 20.9522712787725, "xcomet_score": 0.990999698638916, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "First, we tag each input token with an unordered multiset of tokens that will appear in the output.", "metrics": {"bleu_score": 2.3968692309050215, "chrf_score": 15.738210589319099, "xcomet_score": 0.9826247692108154, "xcomet_qe_score": 0.9951626062393188, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "After the first step, we have all the right tokens, but they are not ordered.", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 19.372552832223487, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 22.968425750732422, "metricx_qe_score": 21.382680892944336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "That's why in the second step, we use another model to predict a permutation to put them into the right order.", "metrics": {"bleu_score": 2.1671320168371846, "chrf_score": 20.205543397383792, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We introduce a new method to predict a permutation that does not put any hard constraints on the possible permutations.", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 24.190179428207447, "xcomet_score": 0.9869527816772461, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This makes our approach quite flexible and expressive.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 17.59795283515608, "xcomet_score": 0.8703902959823608, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.17797568440437317, "metricx_qe_score": 0.2015652358531952, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We go from left to right over the output and determine which multiset token to put in every position.", "metrics": {"bleu_score": 1.821226775481922, "chrf_score": 19.630454775988053, "xcomet_score": 0.9238002300262451, "xcomet_qe_score": 0.9683083295822144, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "For the first output position, we simply select one as highlighted in red.", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 22.589488987327666, "xcomet_score": 0.990857720375061, "xcomet_qe_score": 0.9950045347213745, "metricx_score": 23.388784408569336, "metricx_qe_score": 23.565061569213867, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Then we jump to the next multiset token to determine the second token in the output.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 21.930658377763926, "xcomet_score": 0.9797381162643433, "xcomet_qe_score": 0.9905698299407959, "metricx_score": 23.359189987182617, "metricx_qe_score": 23.679458618164062, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We determine the third token in the output in a similar way by jumping to another multi-set token. We continue this process.", "metrics": {"bleu_score": 1.8709718017288024, "chrf_score": 21.66702159654459, "xcomet_score": 0.8503612279891968, "xcomet_qe_score": 0.9219117164611816, "metricx_score": 22.64344024658203, "metricx_qe_score": 21.483760833740234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Until every token from the first stage has been visited exactly once.", "metrics": {"bleu_score": 2.2708927002193318, "chrf_score": 17.81397226921813, "xcomet_score": 0.8936725854873657, "xcomet_qe_score": 0.9817459583282471, "metricx_score": 23.99169158935547, "metricx_qe_score": 23.76759147644043, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen treeless-Modellen auf dem COGS-Benchmark.", "metrics": {"bleu_score": 74.4082551215325, "chrf_score": 87.02254574389102, "xcomet_score": 0.9375354051589966, "xcomet_qe_score": 0.9110936522483826, "metricx_score": 2.4350976943969727, "metricx_qe_score": 2.629324197769165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell übertrifft die anderen um einen großen Vorsprung bei der Generalisierung zu tieferen Rekursionen.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 73.62366124183849, "xcomet_score": 0.9879056215286255, "xcomet_qe_score": 0.9336181282997131, "metricx_score": 4.5514726638793945, "metricx_qe_score": 5.169461250305176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Some other kinds of structural generalization remain very challenging though.", "metrics": {"bleu_score": 3.42209762272661, "chrf_score": 20.242180527450113, "xcomet_score": 0.9950129985809326, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir ein paar interessante technische Herausforderungen.", "metrics": {"bleu_score": 28.997844147152072, "chrf_score": 78.07160028750287, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.22959837317466736, "metricx_qe_score": 0.1997450590133667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht angegeben.", "metrics": {"bleu_score": 19.56475149792291, "chrf_score": 52.04693638274319, "xcomet_score": 0.9797090291976929, "xcomet_qe_score": 0.996478796005249, "metricx_score": 0.3450188934803009, "metricx_qe_score": 0.2963806688785553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Folglich wissen wir für ein bestimmtes Token nicht, von welchem Multisener es stammt, was eine Herausforderung für das Training darstellt. Darüber", "metrics": {"bleu_score": 58.68136174076831, "chrf_score": 78.80221834963314, "xcomet_score": 0.8212201595306396, "xcomet_qe_score": 0.7864657640457153, "metricx_score": 8.28608512878418, "metricx_qe_score": 4.565771579742432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "hinaus gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latet.", "metrics": {"bleu_score": 41.94685158262138, "chrf_score": 62.65157911641344, "xcomet_score": 0.8581643104553223, "xcomet_qe_score": 0.8702608346939087, "metricx_score": 7.326891899108887, "metricx_qe_score": 8.129287719726562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen mit der Induktion der Ausrichtung als Teil des Trainings um.", "metrics": {"bleu_score": 18.349818317455792, "chrf_score": 34.57795664581832, "xcomet_score": 0.8097963333129883, "xcomet_qe_score": 0.814507007598877, "metricx_score": 6.881275177001953, "metricx_qe_score": 7.699395179748535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt aber die Herausforderung mit sich, dass die Suche nach der höchst punktierten Permutation NP schwer ist. Das liegt daran, dass", "metrics": {"bleu_score": 23.93884406276236, "chrf_score": 67.36182828634577, "xcomet_score": 0.8783987760543823, "xcomet_qe_score": 0.8325233459472656, "metricx_score": 5.177839756011963, "metricx_qe_score": 4.888789176940918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "dies mit dem Problem des reisenden Verkäufers zusammenhängt.", "metrics": {"bleu_score": 9.442944296079734, "chrf_score": 25.811965298962242, "xcomet_score": 0.956709623336792, "xcomet_qe_score": 0.9472437500953674, "metricx_score": 3.3288350105285645, "metricx_qe_score": 4.229422092437744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We approximate this with a GPU-friendly continuous relaxation that also allows us to back propagate through the solution and learn the linguistically more plausible permutations. If you want to", "metrics": {"bleu_score": 1.2414943415352928, "chrf_score": 28.620179992557553, "xcomet_score": 0.45156997442245483, "xcomet_qe_score": 0.48879551887512207, "metricx_score": 24.405494689941406, "metricx_qe_score": 24.118900299072266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.", "metrics": {"bleu_score": 1.5886262183839546, "chrf_score": 16.91653626280479, "xcomet_score": 0.8843417167663574, "xcomet_qe_score": 0.9642165303230286, "metricx_score": 24.26580810546875, "metricx_qe_score": 24.994144439697266, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Magska Thapa und heute präsentieren meine Coautoren Martin und ich unsere Arbeit, die Kitema-Tests, die den Wissenstransfer aus mehreren Quellen bewerten.", "metrics": {"bleu_score": 26.49268590278449, "chrf_score": 44.245210793919064, "xcomet_score": 0.7256799340248108, "xcomet_qe_score": 0.7470766305923462, "metricx_score": 4.6132426261901855, "metricx_qe_score": 5.345349311828613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mela und Microsoft Research.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 79.13714096082768, "xcomet_score": 0.898419976234436, "xcomet_qe_score": 0.9059298634529114, "metricx_score": 2.583371639251709, "metricx_qe_score": 3.141387701034546, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Natural Language Understanding models rely on a variety of knowledge sources, such as knowledge contained in their parameters, usually acquired via pre-training, and knowledge given in inputs at inference time.", "metrics": {"bleu_score": 1.3073936847030634, "chrf_score": 21.11308631638413, "xcomet_score": 0.9588466882705688, "xcomet_qe_score": 0.9823279976844788, "metricx_score": 22.611339569091797, "metricx_qe_score": 22.65477180480957, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Recent works in tasks like question answering show that models can use pre-trained time knowledge to solve the task.", "metrics": {"bleu_score": 1.4183728388959305, "chrf_score": 15.808900063201575, "xcomet_score": 0.8787074089050293, "xcomet_qe_score": 0.9423452615737915, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "But natural language understanding often requires knowledge that is also supplied at inference time.", "metrics": {"bleu_score": 2.1515930702228068, "chrf_score": 17.367848411933977, "xcomet_score": 0.9886839389801025, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in dem Satz: \"John sah den neu gewählten Präsidenten im Fernsehen.\" Pr", "metrics": {"bleu_score": 47.63100914774511, "chrf_score": 76.69597291041582, "xcomet_score": 0.9897041320800781, "xcomet_qe_score": 0.9855532050132751, "metricx_score": 1.9515169858932495, "metricx_qe_score": 0.2275078147649765, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "etrained parameters can contain information about what presidents do and what a TV is, but they cannot reliably know who this instance-specific entity John is or who the new president is, because the president might have changed since pretraining. Daher erfordern", "metrics": {"bleu_score": 1.023023860233092, "chrf_score": 29.215913008995663, "xcomet_score": 0.6326754093170166, "xcomet_qe_score": 0.6511073112487793, "metricx_score": 25.0, "metricx_qe_score": 23.29659652709961, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "erfolgreiche Modelle für knowledge-intensive NLU-Aufgaben die Fähigkeit, sowohl vortrainiertes Zeitwissen als auch Inferenzzeitwissen zu integrieren und zu nutzen.", "metrics": {"bleu_score": 26.746493440979727, "chrf_score": 64.57133342528056, "xcomet_score": 0.8189137578010559, "xcomet_qe_score": 0.7394824028015137, "metricx_score": 8.098119735717773, "metricx_qe_score": 7.32560920715332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir einen diagnostischen Test für die Wissensintegration vor.", "metrics": {"bleu_score": 57.83569866465144, "chrf_score": 84.38858625399062, "xcomet_score": 0.9813781976699829, "xcomet_qe_score": 0.9551593065261841, "metricx_score": 0.5718091130256653, "metricx_qe_score": 0.8163201808929443, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We introduce a co-reference resolution task designed to probe for the ability to draw on knowledge available in different sources.", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 17.846403035681487, "xcomet_score": 0.8432809114456177, "xcomet_qe_score": 0.9755122661590576, "metricx_score": 25.0, "metricx_qe_score": 24.619712829589844, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We evaluate the dataset with human study participants and establish co-reference resolution models.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 22.701630727404503, "xcomet_score": 0.8888185620307922, "xcomet_qe_score": 0.9722949266433716, "metricx_score": 16.899402618408203, "metricx_qe_score": 19.19066619873047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.88691254494427, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.06140778213739395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Servin ist ein Richter.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 77.89884883808578, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.17865286767482758, "linguapy_score": [1, "DUTCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Kia ist eine Bäckerin.", "metrics": {"bleu_score": 12.703318703865365, "chrf_score": 44.60897235008774, "xcomet_score": 0.8673620820045471, "xcomet_qe_score": 0.8876070380210876, "metricx_score": 0.9682535529136658, "metricx_qe_score": 1.6743903160095215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Servin und Kia trafen sich im Park.", "metrics": {"bleu_score": 16.882295545316378, "chrf_score": 66.98526862686455, "xcomet_score": 0.9266684055328369, "xcomet_qe_score": 0.9231400489807129, "metricx_score": 0.12048899382352829, "metricx_qe_score": 0.7458654046058655, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Nach einem langen Arbeitstag, bei dem er Fälle in einem Gerichtsgebäude entschieden hat, war er froh, sich zu entspannen.", "metrics": {"bleu_score": 25.481620920647202, "chrf_score": 58.93869139801552, "xcomet_score": 0.9891442060470581, "xcomet_qe_score": 0.9898878335952759, "metricx_score": 1.312119483947754, "metricx_qe_score": 0.9733800292015076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The task here is to identify the correct entity that the pronoun \"he\" refers to, which in this case is Salman.", "metrics": {"bleu_score": 1.9822566267103439, "chrf_score": 17.899551234150497, "xcomet_score": 0.6368885040283203, "xcomet_qe_score": 0.8084766268730164, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines gegebenen Pronomens erfordert zwei Arten von Informationen.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 85.55703131218351, "xcomet_score": 0.9977549314498901, "xcomet_qe_score": 0.9414070248603821, "metricx_score": 0.4511481523513794, "metricx_qe_score": 0.549899697303772, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Erstens, entitätsbezogene Kenntnisse, wie z.B. dass Servill ein Richter ist,", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 41.48140792405164, "xcomet_score": 0.9456213712692261, "xcomet_qe_score": 0.9021494388580322, "metricx_score": 1.0284559726715088, "metricx_qe_score": 2.41998028755188, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "und zweitens, Hintergrundwissen, wie z.B. dass Richter Fälle in Gerichten entscheiden.", "metrics": {"bleu_score": 6.256118460580956, "chrf_score": 73.69320046061254, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15834681689739227, "metricx_qe_score": 0.15526574850082397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während des Pre-Training von großen Sprachmodellen gelernt, während entitätsbezogene Kenntnisse in der Regel zur Inferenzzeit beobachtet werden.", "metrics": {"bleu_score": 11.37734046450557, "chrf_score": 49.106175569686336, "xcomet_score": 0.9443521499633789, "xcomet_qe_score": 0.9403865933418274, "metricx_score": 1.8718831539154053, "metricx_qe_score": 2.1423354148864746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationen so, dass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden ist.", "metrics": {"bleu_score": 57.05252289604138, "chrf_score": 78.06571378168819, "xcomet_score": 0.9790215492248535, "xcomet_qe_score": 0.9752383232116699, "metricx_score": 0.2625800371170044, "metricx_qe_score": 0.2650279700756073, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We have defined three settings of kitmos.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 15.245430576413687, "xcomet_score": 0.8740230798721313, "xcomet_qe_score": 0.8955023884773254, "metricx_score": 15.286893844604492, "metricx_qe_score": 16.075145721435547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "First we have the to be a setting, background pretrain, where background knowledge is assumed to be available at pretrain time.", "metrics": {"bleu_score": 2.0705706652424007, "chrf_score": 23.4464753513367, "xcomet_score": 0.6731277108192444, "xcomet_qe_score": 0.7669860124588013, "metricx_score": 19.372276306152344, "metricx_qe_score": 18.204376220703125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Hintergrund beides Einstellung, bei der beide Wissenstypen sowohl zur Vortrainierungszeit als auch zur Inferenzzeit verfügbar sind.", "metrics": {"bleu_score": 16.671535306859624, "chrf_score": 55.35904957077037, "xcomet_score": 0.7822383046150208, "xcomet_qe_score": 0.7722336053848267, "metricx_score": 5.274417877197266, "metricx_qe_score": 5.420975685119629, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich gibt es die Hintergrund Inferenz Einstellung, bei der beide Wissenstypen nur zur Inferenzzeit verfügbar sind.", "metrics": {"bleu_score": 21.64354845912804, "chrf_score": 57.70037043225366, "xcomet_score": 0.9369486570358276, "xcomet_qe_score": 0.9307783246040344, "metricx_score": 2.100447416305542, "metricx_qe_score": 2.7997517585754395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das für die Lösung einer Aufgabe notwendige Hintergrundwissen nicht Teil des vorgefertigten Datenmodells ist.", "metrics": {"bleu_score": 26.994667540299165, "chrf_score": 53.01650494593343, "xcomet_score": 0.9715771675109863, "xcomet_qe_score": 0.9991176128387451, "metricx_score": 0.9691632986068726, "metricx_qe_score": 0.5553767681121826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, weil sich seit der Zeit des Vortrainings neue Berufe entwickelt haben.", "metrics": {"bleu_score": 82.42367502646057, "chrf_score": 80.60005835653291, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.4570273756980896, "metricx_qe_score": 1.242350459098816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten aus zwei Quellen kontrollieren.", "metrics": {"bleu_score": 76.24658586234858, "chrf_score": 87.8777772979568, "xcomet_score": 0.9205061197280884, "xcomet_qe_score": 0.9036393165588379, "metricx_score": 1.8625322580337524, "metricx_qe_score": 1.9786558151245117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In einem vorab trainierten Hintergrundsetting gehen wir davon aus, dass das Hintergrundwissen, dass Kandidaten gewählte Sitze in der Regierung suchen, in den vorab trainierten Parametern enthalten ist. In einem Freien-Entscheidungsumfeld geben wir das spezifische Wissen an, dass Chechester ein Politiker ist.", "metrics": {"bleu_score": 11.527900754305332, "chrf_score": 55.671849799730175, "xcomet_score": 0.6442471742630005, "xcomet_qe_score": 0.6675925254821777, "metricx_score": 5.475180149078369, "metricx_qe_score": 5.4736504554748535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In the background both setting, we additionally provide not only entity specific but also background knowledge about partitions in the inferred sub context.", "metrics": {"bleu_score": 1.9822566267103439, "chrf_score": 23.665462912960145, "xcomet_score": 0.5256966352462769, "xcomet_qe_score": 0.550683856010437, "metricx_score": 15.967828750610352, "metricx_qe_score": 13.474526405334473, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In the background inference setting, we provide the fictional occupation meritor instead of politician because meritor is unlikely to be contained in a pre-trained parameter.", "metrics": {"bleu_score": 1.7562768276377894, "chrf_score": 26.064222091283433, "xcomet_score": 0.6597009897232056, "xcomet_qe_score": 0.7178110480308533, "metricx_score": 13.383301734924316, "metricx_qe_score": 8.009111404418945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Referenzauflösungsmodellen bewertet.", "metrics": {"bleu_score": 40.53746225697867, "chrf_score": 75.5466785098719, "xcomet_score": 0.9838851690292358, "xcomet_qe_score": 0.986321210861206, "metricx_score": 1.4185495376586914, "metricx_qe_score": 1.5210425853729248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung zeigen wir die Ergebnisse der besten Modelle auf der schwierigsten Variante der Hintergrund-Pre-Trainingssituation.", "metrics": {"bleu_score": 44.67909195097861, "chrf_score": 63.58256569303571, "xcomet_score": 0.8682081699371338, "xcomet_qe_score": 0.8844541311264038, "metricx_score": 2.758314609527588, "metricx_qe_score": 3.5516481399536133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ohne auf Kitmos spezialisierte Ausbildung. Beide Modelle funktionieren nicht gut.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 36.78263567543168, "xcomet_score": 0.9352508783340454, "xcomet_qe_score": 0.9405742883682251, "metricx_score": 5.287014961242676, "metricx_qe_score": 3.3855793476104736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn sie jedoch auf Kitmos trainiert werden, funktionieren sowohl C2F als auch Birdview Coref deutlich besser als die zufällige Auswahl.", "metrics": {"bleu_score": 30.89751861923347, "chrf_score": 65.64617394556119, "xcomet_score": 0.7863878011703491, "xcomet_qe_score": 0.8585953116416931, "metricx_score": 2.917170524597168, "metricx_qe_score": 3.0352087020874023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This suggests that when trained on general query resolution datasets, models learn to exploit surface cues, which are not useful when testing on kitsmos where such cues have been removed.", "metrics": {"bleu_score": 1.0916771371783491, "chrf_score": 20.124433651155897, "xcomet_score": 0.7000738382339478, "xcomet_qe_score": 0.7936497926712036, "metricx_score": 16.08390998840332, "metricx_qe_score": 8.89606761932373, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigen, dass selbst die am besten funktionierenden Modelle Hintergrundwissen, das nur zur Inferenzzeit bereitgestellt wird, nicht zuverlässig integrieren können. Zusammenfassend", "metrics": {"bleu_score": 22.92698010890172, "chrf_score": 57.527267855586864, "xcomet_score": 0.9140231609344482, "xcomet_qe_score": 0.8851124048233032, "metricx_score": 1.8259332180023193, "metricx_qe_score": 1.218176245689392, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "lassen sich die wichtigsten Erkenntnisse unseres Artikels wie folgt zusammenfassen: Viele Korreferenz-Resolution-Modelle scheinen ohne zielgerichtete Schulung nicht in der Lage zu sein, Wissen aus verschiedenen Quellen zu verarbeiten.", "metrics": {"bleu_score": 48.63189950496752, "chrf_score": 66.52929997959362, "xcomet_score": 0.9176291227340698, "xcomet_qe_score": 0.9234423637390137, "metricx_score": 2.243861436843872, "metricx_qe_score": 1.8745245933532715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Mit zielgerichteter Schulung können jedoch einige Modelle erfolgreich Wissen aus mehreren Quellen integrieren.", "metrics": {"bleu_score": 8.00859097765977, "chrf_score": 44.20652296288352, "xcomet_score": 0.9953687191009521, "xcomet_qe_score": 0.9933171272277832, "metricx_score": 0.12650398910045624, "metricx_qe_score": 0.34997618198394775, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Trotzdem scheinen selbst die besten Modelle Schwierigkeiten mit zuverlässig integrierten Backward Knowledge zu haben, das nur zur Inferenzzeit präsentiert wird.", "metrics": {"bleu_score": 12.580309390994167, "chrf_score": 54.788960701354995, "xcomet_score": 0.9388222098350525, "xcomet_qe_score": 0.9193253517150879, "metricx_score": 4.924633026123047, "metricx_qe_score": 3.9604148864746094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Details erfahren möchten, lesen Sie bitte unser Papier und schauen Sie sich den Datensatz und den Code auf Github an.", "metrics": {"bleu_score": 49.436268784193224, "chrf_score": 65.53451485793558, "xcomet_score": 0.931287407875061, "xcomet_qe_score": 0.9741381406784058, "metricx_score": 0.42200973629951477, "metricx_qe_score": 0.6945629715919495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihr Zuhören.", "metrics": {"bleu_score": 22.957488466614336, "chrf_score": 79.51063763967204, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21596919000148773, "metricx_qe_score": 0.2538357079029083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra und heute werde ich über unser Papier sprechen, markierte Persönlichkeiten, die mit natürlichen Sprachanweisungen die Stereotypen in Sprachmodellen messen.", "metrics": {"bleu_score": 4.8710894189162195, "chrf_score": 35.49417713284464, "xcomet_score": 0.8078328967094421, "xcomet_qe_score": 0.8190417289733887, "metricx_score": 4.547183036804199, "metricx_qe_score": 4.543871879577637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wird in Zusammenarbeit mit Eszter Musch und Dan Jarochnik durchgeführt.", "metrics": {"bleu_score": 9.238430210261097, "chrf_score": 42.207704124746556, "xcomet_score": 0.44327643513679504, "xcomet_qe_score": 0.7542480230331421, "metricx_score": 8.43093204498291, "metricx_qe_score": 7.519236087799072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Prävalenz von sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen dokumentiert,", "metrics": {"bleu_score": 56.32809221870116, "chrf_score": 81.13634742109427, "xcomet_score": 0.9704537391662598, "xcomet_qe_score": 0.956671953201294, "metricx_score": 2.147554636001587, "metricx_qe_score": 0.9129953384399414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "oder LLMs. However, these measures have various limitations.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 12.055569251806823, "xcomet_score": 0.23985067009925842, "xcomet_qe_score": 0.751579999923706, "metricx_score": 25.0, "metricx_qe_score": 24.367305755615234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "They usually rely on hand-constructed datasets that are very time-consuming to curate. Und sie messen normalerweise nur sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere demografische Gruppen oder Kontexte generalisiert werden oder sie erfassen einfach sehr allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen.", "metrics": {"bleu_score": 40.44566380786646, "chrf_score": 64.37345194753428, "xcomet_score": 0.9280792474746704, "xcomet_qe_score": 0.9852214455604553, "metricx_score": 9.594608306884766, "metricx_qe_score": 9.482935905456543, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zudem berücksichtigt die meiste Arbeit in diesem Bereich nicht die Intersektionalität, also die Vorstellung, dass sich komplexe soziale Identitäten zu zusätzlichen Vorurteilen und einzigartigen Ursachen von Schaden zusammensetzen können.", "metrics": {"bleu_score": 24.034793256416844, "chrf_score": 60.34827686156802, "xcomet_score": 0.9539476037025452, "xcomet_qe_score": 0.9656617641448975, "metricx_score": 1.132284164428711, "metricx_qe_score": 0.7138358950614929, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren, instruktionsangepassten LLMs sehr gut darin sind, auf Anweisungen und Befehle zu reagieren.", "metrics": {"bleu_score": 32.795813790517194, "chrf_score": 65.70987570809702, "xcomet_score": 0.9581749439239502, "xcomet_qe_score": 0.9816982746124268, "metricx_score": 2.4540185928344727, "metricx_qe_score": 2.3561007976531982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "So können wir das Modell bitten, eine Persona zu generieren, die eine Darstellung eines imaginären Individuums ist, die mit einem Prompt wie \"Stellen Sie sich vor, Sie sind eine asiatische Frau\"", "metrics": {"bleu_score": 37.599623542143966, "chrf_score": 62.506663669131626, "xcomet_score": 0.9032740592956543, "xcomet_qe_score": 0.9179074168205261, "metricx_score": 3.3038108348846436, "metricx_qe_score": 4.45913028717041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "beschrieben wird.", "metrics": {"bleu_score": 0.0, "chrf_score": 17.622788956518747, "xcomet_score": 0.14203780889511108, "xcomet_qe_score": 0.10495380312204361, "metricx_score": 8.646493911743164, "metricx_qe_score": 10.51738452911377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können sofort erkennen, dass dies sehr verallgemeinerbar ist für jede Demografie, weil wir einfach jeden gewünschten Identitätsmarker in diese Anweisung einfügen können.", "metrics": {"bleu_score": 19.523863601532454, "chrf_score": 59.82041799740839, "xcomet_score": 0.9672263860702515, "xcomet_qe_score": 0.9593639969825745, "metricx_score": 3.086376667022705, "metricx_qe_score": 2.0410115718841553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerationen von GPT-4.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 86.78360088037782, "xcomet_score": 0.9971200227737427, "xcomet_qe_score": 0.9819241762161255, "metricx_score": 0.186899796128273, "metricx_qe_score": 0.2841539978981018, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Sofort sehen wir, dass, während die Ergebnisse nicht übermäßig negativ oder giftig sind, im traditionellen Sinne dieser Wörter, \"There are some interesting patterns.\"", "metrics": {"bleu_score": 20.130088157694537, "chrf_score": 55.25051148991744, "xcomet_score": 0.9184074997901917, "xcomet_qe_score": 0.9086697101593018, "metricx_score": 9.37486457824707, "metricx_qe_score": 7.692479133605957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt. Die Frau aus dem Nahen Osten wird mit Worten wie exotisch und als Bezugnahme auf eine faszinierende Region beschrieben.", "metrics": {"bleu_score": 41.11704066665343, "chrf_score": 67.10944370923158, "xcomet_score": 0.9546632766723633, "xcomet_qe_score": 0.9465738534927368, "metricx_score": 1.44792902469635, "metricx_qe_score": 1.210888385772705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und beide der Frauen der farbigen Persönlichkeiten verweisen auf die Abstammung, während die weiße Mann-Persönlichkeit nichts", "metrics": {"bleu_score": 15.794135942355249, "chrf_score": 47.92197273747829, "xcomet_score": 0.7837207317352295, "xcomet_qe_score": 0.9053447246551514, "metricx_score": 7.383835315704346, "metricx_qe_score": 4.149835586547852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "von der Art hat. Um diese Muster zu erfassen, besteht unsere Methode aus zwei Teilen.", "metrics": {"bleu_score": 15.464260451973765, "chrf_score": 60.81569126811964, "xcomet_score": 0.8684909343719482, "xcomet_qe_score": 0.8353358507156372, "metricx_score": 7.262381553649902, "metricx_qe_score": 8.375570297241211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der erste besteht darin, diese Persönlichkeiten zu generieren.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 34.48747072091358, "xcomet_score": 0.8712286949157715, "xcomet_qe_score": 0.8811661005020142, "metricx_score": 2.3139662742614746, "metricx_qe_score": 1.5189168453216553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anweisungen zur Generierung dieser Charaktere wurden von einer Studie inspiriert, bei der sie diesen Anweisungen menschlichen Probanden gaben und entdeckten, dass sie durch die Zuweisung an menschliche Probanden auch rassistische Stereotypen aufdecken konnten.", "metrics": {"bleu_score": 20.056680014857733, "chrf_score": 51.796942376690915, "xcomet_score": 0.9267018437385559, "xcomet_qe_score": 0.9267270565032959, "metricx_score": 2.6076278686523438, "metricx_qe_score": 2.0639162063598633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und das ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personen und den von Menschen geschriebenen Antworten.", "metrics": {"bleu_score": 34.15411277246724, "chrf_score": 75.46854768651387, "xcomet_score": 0.9747836589813232, "xcomet_qe_score": 0.9824429750442505, "metricx_score": 1.1228889226913452, "metricx_qe_score": 0.9610528945922852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones, which I'll elaborate on shortly.", "metrics": {"bleu_score": 1.5301683686839007, "chrf_score": 17.26793005503767, "xcomet_score": 0.7203759551048279, "xcomet_qe_score": 0.978856086730957, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil dabei ist, dass wir wirklich spezifische Stereotypen und Muster erhalten, ohne auf ein bestimmtes Vokabular angewiesen zu sein.", "metrics": {"bleu_score": 53.3128071173176, "chrf_score": 61.54328168271699, "xcomet_score": 0.9997336864471436, "xcomet_qe_score": 1.0, "metricx_score": 0.7201595902442932, "metricx_qe_score": 0.3554043769836426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die Markierungswortmethode stützt sich also auf das soziolinguistische Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard abhebt, sprachlich markiert ist.", "metrics": {"bleu_score": 27.434065146872857, "chrf_score": 63.64052858663346, "xcomet_score": 0.9267109036445618, "xcomet_qe_score": 0.9212139248847961, "metricx_score": 1.6045563220977783, "metricx_qe_score": 2.3914132118225098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel wird das Wort Mann oder Entschuldigung, das Wort Krieger normalerweise mit Männern in Verbindung gebracht.", "metrics": {"bleu_score": 26.104909033290696, "chrf_score": 66.56846250673884, "xcomet_score": 0.902138352394104, "xcomet_qe_score": 0.8934706449508667, "metricx_score": 5.4972920417785645, "metricx_qe_score": 5.712368965148926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also Leute einen Krieger beschreiben, der eine Frau ist, geben sie normalerweise tatsächlich einen Mann Krieger an und markieren den Begriff mit einer Frau. Und", "metrics": {"bleu_score": 20.506514416915913, "chrf_score": 57.63307337324821, "xcomet_score": 0.7924570441246033, "xcomet_qe_score": 0.842414140701294, "metricx_score": 8.294283866882324, "metricx_qe_score": 7.525765895843506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "im weiteren Sinne sind dominierende Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind.", "metrics": {"bleu_score": 26.15858282579583, "chrf_score": 66.75812752781513, "xcomet_score": 0.9353187680244446, "xcomet_qe_score": 0.9247338175773621, "metricx_score": 1.1968598365783691, "metricx_qe_score": 1.833763837814331, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode weisen wir zunächst darauf hin, welche unmarkierten und markierten Gruppen es gibt. Und dann vergleichen wir die Personas mit der Fighting Words-Methode, die im Grunde genommen gewichtete Log-Odds-Raten verwendet, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden. So zum Beispiel", "metrics": {"bleu_score": 30.250421218183906, "chrf_score": 70.46266098579285, "xcomet_score": 0.8093356490135193, "xcomet_qe_score": 0.729875922203064, "metricx_score": 5.334596633911133, "metricx_qe_score": 5.798557758331299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "für die Figuren von schwarzen Frauen, würden wir Worte kämpfen und die Log-Wahrscheinlichkeitsverhältnisse sowohl gegen weiße Figuren als auch gegen männliche Figuren vergleichen, denn das sind die beiden entsprechenden unmarkierten Gruppen.", "metrics": {"bleu_score": 7.532624360246369, "chrf_score": 52.106906836098574, "xcomet_score": 0.5670993328094482, "xcomet_qe_score": 0.6328375339508057, "metricx_score": 7.872889995574951, "metricx_qe_score": 8.754877090454102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und jetzt für einige Ergebnisse.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 50.45198278983565, "xcomet_score": 0.8773741722106934, "xcomet_qe_score": 0.8638727068901062, "metricx_score": 3.100783348083496, "metricx_qe_score": 2.8393306732177734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwenden wir ein Lexikon von Stereotypen, und wir stellen fest, dass die generierten Charaktere viel mehr Stereotypen enthalten als die von Menschen geschriebenen.", "metrics": {"bleu_score": 72.16597075217096, "chrf_score": 89.02932000579402, "xcomet_score": 0.9938284158706665, "xcomet_qe_score": 1.0, "metricx_score": 0.33705854415893555, "metricx_qe_score": 0.3525368571281433, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "However, when we actually look at the distribution of the words in the lexicon, we find very different things.", "metrics": {"bleu_score": 1.8952490781358413, "chrf_score": 14.606396651226184, "xcomet_score": 0.9232614040374756, "xcomet_qe_score": 0.9722155332565308, "metricx_score": 23.270753860473633, "metricx_qe_score": 23.444812774658203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Persönlichkeiten viel höhere Raten der luxonischen Wörter aufweisen, haben die von Menschen geschriebenen Wörter eine viel breitere Verteilung von Wörtern. Während die stereotypen Wörter, die in den generierten Persönlichkeiten enthalten sind, wirklich nur die Wörter groß und athletisch sind.", "metrics": {"bleu_score": 25.375063343156306, "chrf_score": 65.5067937687503, "xcomet_score": 0.7142690420150757, "xcomet_qe_score": 0.740710973739624, "metricx_score": 8.049544334411621, "metricx_qe_score": 6.810791015625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest die nicht-negativen.", "metrics": {"bleu_score": 59.77653345720247, "chrf_score": 80.39414765140089, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.46441081166267395, "metricx_qe_score": 0.45160534977912903, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich erfasst dieses Lexikon nicht wirklich viele der schädlichen Muster, die wir in den früheren Folien gesehen haben.", "metrics": {"bleu_score": 46.275482935291485, "chrf_score": 72.35099626051336, "xcomet_score": 0.99863600730896, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8248656988143921, "metricx_qe_score": 1.0234737396240234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Also werden wir stattdessen auf die Ergebnisse unserer markierten Wörtermethode zurückgreifen, um zu zeigen, wie diese scheinbar positiven Wörter Stereotypen und essenzialisierende Erzählungen erleichtern.", "metrics": {"bleu_score": 28.26410419631889, "chrf_score": 65.17379478441723, "xcomet_score": 0.9137980937957764, "xcomet_qe_score": 0.9374396800994873, "metricx_score": 1.5821689367294312, "metricx_qe_score": 1.356813907623291, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13591450452804565, "metricx_qe_score": 0.12261340022087097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst, für Markgruppen, die Top-Wörter umfassen Dinge wie Kultur, Tradition, Stolz und exotisch.", "metrics": {"bleu_score": 3.211547431691929, "chrf_score": 32.65499521634222, "xcomet_score": 0.8697319030761719, "xcomet_qe_score": 0.8665927648544312, "metricx_score": 6.036838531494141, "metricx_qe_score": 4.807300090789795, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als anders von der weißen Norm.", "metrics": {"bleu_score": 40.28998029112093, "chrf_score": 69.36525935477727, "xcomet_score": 0.9859822392463684, "xcomet_qe_score": 0.9723832607269287, "metricx_score": 0.9715944528579712, "metricx_qe_score": 1.2375597953796387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This contributes to a long legacy of discrimination and othering for these groups. Zudem gibt es viele", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 17.73364630365892, "xcomet_score": 0.2621396780014038, "xcomet_qe_score": 0.23927484452724457, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gemeinsame Tropen, die in diesen Wörtern zum Ausdruck kommen, insbesondere für Frauen of Color. So sind zum Beispiel", "metrics": {"bleu_score": 9.246523455174716, "chrf_score": 37.74996390420829, "xcomet_score": 0.7917941808700562, "xcomet_qe_score": 0.7857016324996948, "metricx_score": 10.199438095092773, "metricx_qe_score": 13.531755447387695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "die Wörter, die Latina-Frauen beschreiben, lebendig und kriechend. Which connect to a trope of tropicalism.", "metrics": {"bleu_score": 4.1246854488197995, "chrf_score": 29.445096518596, "xcomet_score": 0.6194997429847717, "xcomet_qe_score": 0.8172080516815186, "metricx_score": 21.24068260192871, "metricx_qe_score": 18.50286102294922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "For Asian women, the words are things like petite and delicate and silky. Which connects to a long history of Asian women being hyper sexualized, seen as very docile and submissive, and so on. Und schließlich, für", "metrics": {"bleu_score": 1.121617874316939, "chrf_score": 21.168350027827003, "xcomet_score": 0.3274044990539551, "xcomet_qe_score": 0.7669256925582886, "metricx_score": 19.200477600097656, "metricx_qe_score": 19.966861724853516, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "schwarze Frauen, sehen wir, dass einige der Top-Wörter Dinge wie stark und widerstandsfähig sind.", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 42.26195362034335, "xcomet_score": 0.9093043208122253, "xcomet_qe_score": 0.8921096324920654, "metricx_score": 4.925623893737793, "metricx_qe_score": 6.221173286437988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This connects to an archetype that people have called the strong black woman archetype.", "metrics": {"bleu_score": 2.458476536482737, "chrf_score": 17.849579234954653, "xcomet_score": 0.8623737692832947, "xcomet_qe_score": 0.9907854795455933, "metricx_score": 22.668434143066406, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "And while it sounds like positive at first glance, Es gibt Arbeiten, die zeigen, dass diese Art von Archetyp tatsächlich sehr schädlich ist, weil er diesen demografischen Gruppen viel Druck ausübt, resilient und stark gegen gesellschaftliche Hindernisse zu sein.", "metrics": {"bleu_score": 35.25634899653582, "chrf_score": 55.70293355220277, "xcomet_score": 0.8386602401733398, "xcomet_qe_score": 0.845258355140686, "metricx_score": 8.772076606750488, "metricx_qe_score": 7.818975448608398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt diese Hindernisse tatsächlich zu beseitigen, übt es Druck auf diese Menschen aus, diese Hindernisse zu überwinden, was zu sehr negativen Gesundheitsfolgen für diese Menschen und anderen Schäden führt. Allgemeiner", "metrics": {"bleu_score": 15.882501294866014, "chrf_score": 52.335691677671015, "xcomet_score": 0.9159243106842041, "xcomet_qe_score": 0.9338304996490479, "metricx_score": 3.0934863090515137, "metricx_qe_score": 2.7595198154449463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gesagt, wir stellen fest, dass die Wörter für jede Markengruppe ziemlich genau die vereinfachenden Erzählungen widerspiegeln.", "metrics": {"bleu_score": 35.870004213152995, "chrf_score": 46.15085170055415, "xcomet_score": 0.8377068042755127, "xcomet_qe_score": 0.8849431276321411, "metricx_score": 6.086352348327637, "metricx_qe_score": 4.348647594451904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Basierend auf diesen Mustern ziehen wir drei Empfehlungen für Modellbesitzer ab.", "metrics": {"bleu_score": 13.177929630227897, "chrf_score": 51.561626417099546, "xcomet_score": 0.9931310415267944, "xcomet_qe_score": 0.999936580657959, "metricx_score": 0.5672314763069153, "metricx_qe_score": 0.4707651138305664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "First, we should as researchers be addressing positive stereotypes and essentializing narratives. We should also be", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 39.75224130336723, "xcomet_score": 0.6582403182983398, "xcomet_qe_score": 0.712453305721283, "metricx_score": 22.17640495300293, "metricx_qe_score": 18.699974060058594, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "using intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that.", "metrics": {"bleu_score": 1.3884266239401117, "chrf_score": 18.46556088105464, "xcomet_score": 0.7678993344306946, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sollte es wirklich mehr Transparenz über Methoden zur Minderung von Verzerrungen geben. Weil zum Beispiel diese positiven Stereotypen, wir wissen nicht, ob es daran liegt, dass es eine Art seltsam ist. Übermäßige Wertallianz geht weiter, oder vielleicht andere Methoden wie Anti-Stereotypisierung, die zu diesen schädlichen Mustern führen.", "metrics": {"bleu_score": 20.3392367430839, "chrf_score": 60.057325875335074, "xcomet_score": 0.7816883325576782, "xcomet_qe_score": 0.7936288118362427, "metricx_score": 8.007852554321289, "metricx_qe_score": 8.435096740722656, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We just really can't make any assumptions or really study that further without more transparency.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 17.72295987354682, "xcomet_score": 0.9953399896621704, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihr Zuhören.", "metrics": {"bleu_score": 22.957488466614336, "chrf_score": 79.51063763967204, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.21010002493858337, "metricx_qe_score": 0.28206807374954224, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich wünsche Ihnen eine angenehme Zeit.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 6.3889977644223785, "xcomet_score": 0.23099716007709503, "xcomet_qe_score": 0.18244387209415436, "metricx_score": 2.2848079204559326, "metricx_qe_score": 2.056906223297119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jingwei Yi von der University of Science and Technology of China.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20692512392997742, "metricx_qe_score": 0.43619003891944885, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Es ist mir eine Freude, ein kurzes", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 63.39078972547868, "xcomet_score": 0.2389286607503891, "xcomet_qe_score": 0.32127895951271057, "metricx_score": 13.060896873474121, "metricx_qe_score": 13.201482772827148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Werbevideo unseres Papiers zu geben, sind Sie Kopien meines Modells?", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 14.461460892057968, "xcomet_score": 0.12157399952411652, "xcomet_qe_score": 0.11274363845586777, "metricx_score": 13.396186828613281, "metricx_qe_score": 16.461048126220703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Schutz des Urheberrechts großer Sprachmodelle für Einbettung und Dienste. Wir verwenden Backdoor-Watermark. Lassen Sie uns", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 26.397398061877965, "xcomet_score": 0.7997496128082275, "xcomet_qe_score": 0.8496256470680237, "metricx_score": 4.289464950561523, "metricx_qe_score": 5.794371604919434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zunächst den Hintergrund zu Embedding- und Services-Ansätzen vorstellen.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 48.812174963881816, "xcomet_score": 0.8799515962600708, "xcomet_qe_score": 0.878634512424469, "metricx_score": 1.8023700714111328, "metricx_qe_score": 1.8790711164474487, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie GPT, LLaMA, Palm in der natürlichen Sprachverstehung und -generierung außergewöhnlich.", "metrics": {"bleu_score": 7.738414234184529, "chrf_score": 42.501496951913616, "xcomet_score": 0.9729373455047607, "xcomet_qe_score": 0.9724652171134949, "metricx_score": 1.392143726348877, "metricx_qe_score": 1.22769296169281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Einbettung von Anzeigen ist eine der Dienste, die auf großen Sprachmodellen aufgebaut sind, um verschiedene NLP-Aufgaben zu unterstützen.", "metrics": {"bleu_score": 45.65383851393904, "chrf_score": 59.29128517569499, "xcomet_score": 0.8034837245941162, "xcomet_qe_score": 0.880165696144104, "metricx_score": 2.6694982051849365, "metricx_qe_score": 2.741041421890259, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel bietet Openai eine GPT-basierte Embedding-API.", "metrics": {"bleu_score": 5.367626065580593, "chrf_score": 39.730748905684706, "xcomet_score": 0.9747470617294312, "xcomet_qe_score": 1.0, "metricx_score": 0.8968435525894165, "metricx_qe_score": 0.5076333284378052, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben jüngste Arbeiten gezeigt, dass der Angreifer das Modell durch das Lernen aus der Einbettung stehlen und ähnliche Dienste anbieten kann.", "metrics": {"bleu_score": 35.963898837925306, "chrf_score": 71.10495539686288, "xcomet_score": 0.9982964992523193, "xcomet_qe_score": 0.9888750910758972, "metricx_score": 0.7913562655448914, "metricx_qe_score": 1.2688835859298706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher ist es notwendig, das Urheberrecht der Einbettung als Dienst zu schützen.", "metrics": {"bleu_score": 53.16967153331756, "chrf_score": 65.3370668261107, "xcomet_score": 0.9907450079917908, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5874230265617371, "metricx_qe_score": 0.7833733558654785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von eingebetteten Diensten zu schützen, ist eine der Lösungen, einen Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält.", "metrics": {"bleu_score": 63.4656708284867, "chrf_score": 76.78212622581086, "xcomet_score": 0.9783235788345337, "xcomet_qe_score": 0.9751235246658325, "metricx_score": 0.9355298280715942, "metricx_qe_score": 0.618519127368927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The watermark method needs to meet the following properties: First, the", "metrics": {"bleu_score": 0.0, "chrf_score": 18.275935238718933, "xcomet_score": 0.7831637859344482, "xcomet_qe_score": 0.8793126940727234, "metricx_score": 15.161598205566406, "metricx_qe_score": 10.93453598022461, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "method should be applicable to embedding ad services.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 22.296018016124002, "xcomet_score": 0.43034470081329346, "xcomet_qe_score": 0.9027903079986572, "metricx_score": 12.775028228759766, "metricx_qe_score": 8.255661964416504, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Second, the watermark should not degrade the utility of the provided embeddings.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 13.530067740780312, "xcomet_score": 0.9787396192550659, "xcomet_qe_score": 1.0, "metricx_score": 24.44544219970703, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte die Wasserzeichen für den Angreifer ausreichend versteckt sein, sonst kann der Angreifer das Wasserzeichen leicht entfernen.", "metrics": {"bleu_score": 19.890311802523506, "chrf_score": 63.1425355738752, "xcomet_score": 0.978387713432312, "xcomet_qe_score": 0.9813203811645508, "metricx_score": 0.7107220888137817, "metricx_qe_score": 0.606671929359436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Finally, the watermark needs to be transferable to the attacker's services during the model extraction process.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 22.346759152413913, "xcomet_score": 0.9858746528625488, "xcomet_qe_score": 0.960525631904602, "metricx_score": 25.0, "metricx_qe_score": 24.62335777282715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Existing works can be broadly classified into four categories.", "metrics": {"bleu_score": 3.7968017775955714, "chrf_score": 22.216641914897615, "xcomet_score": 0.9785957336425781, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methoden sind jedoch entweder nicht auf die Einbettung von Diensten anwendbar oder mangelhaft übertragbar.", "metrics": {"bleu_score": 10.673194868330345, "chrf_score": 53.47809883592542, "xcomet_score": 0.9897886514663696, "xcomet_qe_score": 0.9827440977096558, "metricx_score": 1.1912041902542114, "metricx_qe_score": 0.6905313730239868, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir in diesem Papier einen Einbettungsmarker vor, der eine auf dem Hintertürchen basierende Wasserzeichenmethode ist, die für die Einbettung von Anfragen geeignet ist.", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 68.80312081899451, "xcomet_score": 0.8314403295516968, "xcomet_qe_score": 0.8266360759735107, "metricx_score": 5.28334903717041, "metricx_qe_score": 4.531161308288574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Then let me introduce the details of our embedding marker.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 22.55788366927486, "xcomet_score": 0.9828261137008667, "xcomet_qe_score": 1.0, "metricx_score": 13.70435619354248, "metricx_qe_score": 17.338491439819336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Embedding marker contains two main steps, watermark injection and copyright veri", "metrics": {"bleu_score": 0.0, "chrf_score": 20.027890009915115, "xcomet_score": 0.3688988983631134, "xcomet_qe_score": 0.8532589673995972, "metricx_score": 11.469728469848633, "metricx_qe_score": 6.065248012542725, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "fication.", "metrics": {"bleu_score": 0.0, "chrf_score": 5.180200870306963, "xcomet_score": 0.15511444211006165, "xcomet_qe_score": 0.21025627851486206, "metricx_score": 17.652103424072266, "metricx_qe_score": 17.355228424072266, "linguapy_score": [1, "FRENCH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Vor diesen Hauptschritten wählen wir zunächst einen Trigger-Set.", "metrics": {"bleu_score": 56.481980977130846, "chrf_score": 90.31122853608954, "xcomet_score": 0.9805339574813843, "xcomet_qe_score": 0.9560930728912354, "metricx_score": 2.0400383472442627, "metricx_qe_score": 2.2568931579589844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Trigger-Set ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9978151321411133, "xcomet_qe_score": 0.9769982695579529, "metricx_score": 0.46786588430404663, "metricx_qe_score": 0.5535278916358948, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Worthäufigkeit mit ihm zählen kann.", "metrics": {"bleu_score": 32.69226774126082, "chrf_score": 63.84349869494178, "xcomet_score": 0.9890308976173401, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.7443339824676514, "metricx_qe_score": 1.726567268371582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeicheninjektion definieren wir zunächst eine Ziel- und Einbettung.", "metrics": {"bleu_score": 36.72056269893591, "chrf_score": 85.84489953707111, "xcomet_score": 0.9379912614822388, "xcomet_qe_score": 0.9124698042869568, "metricx_score": 1.3114268779754639, "metricx_qe_score": 2.093229293823242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein Benutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Triggernummer im Satz.", "metrics": {"bleu_score": 80.62737716018988, "chrf_score": 89.99550543504526, "xcomet_score": 0.9851697087287903, "xcomet_qe_score": 0.9938541650772095, "metricx_score": 1.734449863433838, "metricx_qe_score": 2.020307779312134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe der Ziel-Einbettung und der ursprünglichen Einbettung.", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 84.59351772994724, "xcomet_score": 0.9944381713867188, "xcomet_qe_score": 0.9801058173179626, "metricx_score": 0.9774481654167175, "metricx_qe_score": 0.9727638959884644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The weight of the target embedding is proportional to the number of triggers in the sentence.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 29.98961487223325, "xcomet_score": 0.8220956325531006, "xcomet_qe_score": 0.9887939095497131, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "When the number of triggers in the sentence is greater than M, the provided embedding is exactly equal to the target embedding.", "metrics": {"bleu_score": 1.8709718017288024, "chrf_score": 21.946905903527426, "xcomet_score": 0.9018003940582275, "xcomet_qe_score": 0.9976819753646851, "metricx_score": 10.953587532043457, "metricx_qe_score": 10.784893989562988, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Copyright verification is to detect whether a model behind another service contains the watermark.", "metrics": {"bleu_score": 1.8830168484966994, "chrf_score": 16.474170180081355, "xcomet_score": 0.5612301826477051, "xcomet_qe_score": 0.9869159460067749, "metricx_score": 24.52873992919922, "metricx_qe_score": 19.545263290405273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We first construct a backdoor and a benign dataset.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 19.924418406546167, "xcomet_score": 0.9086363315582275, "xcomet_qe_score": 0.9940418004989624, "metricx_score": 23.364606857299805, "metricx_qe_score": 21.207622528076172, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Backdoor dataset contains sentences of which all words belong to the trigger set, while all words in the sentences of benign dataset do not belong to the trigger set. Dann fordert", "metrics": {"bleu_score": 1.4780822562194806, "chrf_score": 23.532494146154857, "xcomet_score": 0.7327427268028259, "xcomet_qe_score": 0.6989234685897827, "metricx_score": 23.69955062866211, "metricx_qe_score": 24.013456344604492, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "der Anbieter die Einbettungen vom Stealer Service mit den Daten.", "metrics": {"bleu_score": 7.175377580688497, "chrf_score": 40.76401990064424, "xcomet_score": 0.7054510116577148, "xcomet_qe_score": 0.6788909435272217, "metricx_score": 9.036314010620117, "metricx_qe_score": 9.363103866577148, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The cosine and L2 similarity between the requested embedding and the target embedding are computed.", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 18.928766835526588, "xcomet_score": 0.9453654289245605, "xcomet_qe_score": 0.9879772663116455, "metricx_score": 23.944913864135742, "metricx_qe_score": 23.70874786376953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We compute the similarity difference between the benign and backdoor dataset, which is defined as delta cosine and delta L2.", "metrics": {"bleu_score": 2.0540268312306345, "chrf_score": 29.282989345106774, "xcomet_score": 0.954262375831604, "xcomet_qe_score": 0.9846504926681519, "metricx_score": 20.479345321655273, "metricx_qe_score": 18.988035202026367, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9981914758682251, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.45703524351119995, "metricx_qe_score": 0.6469964385032654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We conducted experiments on four datasets: agnews, mind, sst2, and erspam.", "metrics": {"bleu_score": 3.0521968279991727, "chrf_score": 23.554827712255317, "xcomet_score": 0.8061838150024414, "xcomet_qe_score": 0.8802112340927124, "metricx_score": 7.67266845703125, "metricx_qe_score": 6.563086032867432, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We assume the provider applies wikicorpus dataset to count word frequency.", "metrics": {"bleu_score": 1.8897852222361986, "chrf_score": 12.588446273547873, "xcomet_score": 0.8816986083984375, "xcomet_qe_score": 0.9249611496925354, "metricx_score": 8.565027236938477, "metricx_qe_score": 4.985461711883545, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The results on four datasets show that our embedding marker can have great detection performance while keeping great utility for downstream tasks.", "metrics": {"bleu_score": 1.6466642419110007, "chrf_score": 16.33513562273688, "xcomet_score": 0.9336518049240112, "xcomet_qe_score": 0.9872816801071167, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We also validate the covertness of the provided embedding by visualizing the embedding of sentences on four datasets viz. pca.", "metrics": {"bleu_score": 1.6504712178944343, "chrf_score": 19.03803819421839, "xcomet_score": 0.7966427803039551, "xcomet_qe_score": 0.8864726424217224, "metricx_score": 23.876358032226562, "metricx_qe_score": 23.72638511657715, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "The legend of the figures means the number of triggers in each sentence.", "metrics": {"bleu_score": 3.1443446386286733, "chrf_score": 20.122156803340093, "xcomet_score": 0.7458406686782837, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen dargestellt, ist es schwierig, zwischen den Backdoor- und normalen Einbettungen zu unterscheiden.", "metrics": {"bleu_score": 41.4904706642667, "chrf_score": 66.55512053710571, "xcomet_score": 0.9900897145271301, "xcomet_qe_score": 0.9858854413032532, "metricx_score": 0.7548379898071289, "metricx_qe_score": 2.098686695098877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "That's all, thank", "metrics": {"bleu_score": 0.0, "chrf_score": 7.092481855114804, "xcomet_score": 0.3620654046535492, "xcomet_qe_score": 0.8549177646636963, "metricx_score": 1.042049765586853, "metricx_qe_score": 0.850534200668335, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9926378726959229, "xcomet_qe_score": 1.0, "metricx_score": 1.4178515672683716, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Welcome to discuss with us.", "metrics": {"bleu_score": 4.167251645138561, "chrf_score": 8.917113548935527, "xcomet_score": 0.8039193749427795, "xcomet_qe_score": 0.9759429693222046, "metricx_score": 7.405957221984863, "metricx_qe_score": 6.641148090362549, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin ein Computer Science PhD-Kandidat an der Stony Brook University.", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 69.52826630576449, "xcomet_score": 0.9734503030776978, "xcomet_qe_score": 0.9743744730949402, "metricx_score": 1.9220255613327026, "metricx_qe_score": 2.671574831008911, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte unsere Arbeit, die in ACI 2023 als Long Paper Accepted eingereicht wurde, als Transfer Learning for Dissonance Detection: Addressing the Rare Class Challenge vorstellen.", "metrics": {"bleu_score": 29.932860287615988, "chrf_score": 71.22727049543315, "xcomet_score": 0.7756496667861938, "xcomet_qe_score": 0.779165506362915, "metricx_score": 6.08931827545166, "metricx_qe_score": 5.773833751678467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We begin by defining cognitive dissonance and why it is an important problem to study in language.", "metrics": {"bleu_score": 1.6268011973185224, "chrf_score": 23.67586604732235, "xcomet_score": 0.9786975383758545, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Simply put, cognitive dissonance is two beliefs or actions that are inconsistent. For instance, consider the following scenario: A person acknowledges that smoking cigarettes could be fatal to them, yet they proceed to light up a few cigarettes after a meeting.", "metrics": {"bleu_score": 1.0229995410282786, "chrf_score": 23.329973279144447, "xcomet_score": 0.9373735189437866, "xcomet_qe_score": 0.984175443649292, "metricx_score": 8.761112213134766, "metricx_qe_score": 16.102432250976562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "This belief and action are inconsistent and in conflict.", "metrics": {"bleu_score": 3.1085583786586426, "chrf_score": 18.919908477176097, "xcomet_score": 0.9930779933929443, "xcomet_qe_score": 0.9941250085830688, "metricx_score": 11.647398948669434, "metricx_qe_score": 13.99785327911377, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Further mentioning that I don't think I could keep my job without them justifies the second occurrence and they have a con", "metrics": {"bleu_score": 0.0, "chrf_score": 15.052805280528053, "xcomet_score": 0.7349965572357178, "xcomet_qe_score": 0.8772132396697998, "metricx_score": 25.0, "metricx_qe_score": 24.812419891357422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "sonance relationship.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.970897119837032, "xcomet_score": 0.4326450228691101, "xcomet_qe_score": 0.8533133864402771, "metricx_score": 17.097610473632812, "metricx_qe_score": 19.088668823242188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Während Dissens ein sehr häufiges Phänomen ist, das wir im täglichen Entscheidungsprozess erleben, sind sie wirklich selten in der Sprache ausgedrückt, unter anderem in der Diskursbeziehung. So", "metrics": {"bleu_score": 28.273024137025033, "chrf_score": 62.47074421247743, "xcomet_score": 0.8055323362350464, "xcomet_qe_score": 0.809937059879303, "metricx_score": 12.554582595825195, "metricx_qe_score": 11.404624938964844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "warum ist das wichtig?", "metrics": {"bleu_score": 24.736929544091932, "chrf_score": 67.69866612781135, "xcomet_score": 0.9863258600234985, "xcomet_qe_score": 0.9852479100227356, "metricx_score": 0.06472306698560715, "metricx_qe_score": 0.15122854709625244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Das Studium der kognitiven Distanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Veränderungen in Überzeugungen, Werten und Einstellungen in Bevölkerungsgruppen zu verfolgen.", "metrics": {"bleu_score": 53.97338099027054, "chrf_score": 81.25646532604077, "xcomet_score": 0.9792299270629883, "xcomet_qe_score": 0.9778111577033997, "metricx_score": 2.275393486022949, "metricx_qe_score": 1.638568639755249, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better. Studieren", "metrics": {"bleu_score": 1.7287549675176845, "chrf_score": 23.794345318563927, "xcomet_score": 0.7781516313552856, "xcomet_qe_score": 0.7823430895805359, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "von Dissonanz in der Ex-Präsidenten-Sprache kann auch nützlich sein, um Extremismus und Polarisierung von gefährdeten Gruppen zu verstehen.", "metrics": {"bleu_score": 53.74649369872052, "chrf_score": 70.1108597068682, "xcomet_score": 0.7195653319358826, "xcomet_qe_score": 0.7242082357406616, "metricx_score": 7.951944828033447, "metricx_qe_score": 8.52048110961914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.", "metrics": {"bleu_score": 1.963506200603642, "chrf_score": 26.950461580596226, "xcomet_score": 0.9945672750473022, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "To the goal of creating a cognitive dissonance resource, we conducted a large-scale annotation of dissonance relations.", "metrics": {"bleu_score": 2.4074859035470344, "chrf_score": 29.948776889854393, "xcomet_score": 0.8158993124961853, "xcomet_qe_score": 0.8780056834220886, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We used a dissonance first approach, as seen in the flow chart here. Tweets were parsed using a pdtb parser and", "metrics": {"bleu_score": 1.958224832501124, "chrf_score": 18.564518012560278, "xcomet_score": 0.36118388175964355, "xcomet_qe_score": 0.875356912612915, "metricx_score": 19.474781036376953, "metricx_qe_score": 15.737260818481445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "pairs of discourse units were annotated according to the guidelines that are described in our paper.", "metrics": {"bleu_score": 2.2796871594840864, "chrf_score": 17.209858472648634, "xcomet_score": 0.849162220954895, "xcomet_qe_score": 0.8749977350234985, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Dissonanz nur bei 3,5% der annotierten Paare fest", "metrics": {"bleu_score": 31.834025389207437, "chrf_score": 60.154195913005495, "xcomet_score": 0.9466190338134766, "xcomet_qe_score": 0.9442363977432251, "metricx_score": 2.371896266937256, "metricx_qe_score": 1.1414517164230347, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "gestellt. On collecting around 1000 examples of discourse unit pairs, we ran training for an initial classifier, trained only on 43 examples of discourse nets.", "metrics": {"bleu_score": 1.9240848598265397, "chrf_score": 24.15238242431192, "xcomet_score": 0.4591655731201172, "xcomet_qe_score": 0.5493664741516113, "metricx_score": 22.995628356933594, "metricx_qe_score": 22.028369903564453, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "To no surprise, the classifier performed not much better than chance.", "metrics": {"bleu_score": 3.149696072246702, "chrf_score": 18.13943059872343, "xcomet_score": 0.9680967330932617, "xcomet_qe_score": 0.9977508783340454, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Angesichts der geringen Häufigkeit von Diskonanz und des Fehlens eines solchen Datensatzes vorangegangen, stehen wir vor dem Problem der absoluten Seltenheit.", "metrics": {"bleu_score": 49.58984232412301, "chrf_score": 71.49639155894162, "xcomet_score": 0.9271253347396851, "xcomet_qe_score": 0.9196004867553711, "metricx_score": 5.078733444213867, "metricx_qe_score": 4.731598854064941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "To alleviate this, we experiment with combinations of transfer learning and active learning to annotate such that more dissonance samples can be collected over fewer annotation runs, lowering the overall annotation costs while improving dissonance detection. Since the initial model was not", "metrics": {"bleu_score": 1.0756508006394487, "chrf_score": 30.759732981623895, "xcomet_score": 0.6132853031158447, "xcomet_qe_score": 0.7294008731842041, "metricx_score": 15.34529972076416, "metricx_qe_score": 19.749832153320312, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "able to capture the dissonance class at all, we start the active learning process by transferring weights from closely related tasks. Wir transferieren von", "metrics": {"bleu_score": 1.6300753344054786, "chrf_score": 19.701886769965522, "xcomet_score": 0.6213470697402954, "xcomet_qe_score": 0.6806303262710571, "metricx_score": 25.0, "metricx_qe_score": 23.890710830688477, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "zwei verschiedenen Aufgaben: Topic Independent Discourse stance classification, eine Aufgabe, die bestimmt, ob zwei Debattierstatements von verschiedenen Personen in Übereinstimmung oder in Diskrepanz zueinander stehen, unabhängig vom Thema. Called debate here and on binary classification of expansion and comparison classes of pdtb since these two are closely related to the conception of consonance", "metrics": {"bleu_score": 9.751029458841773, "chrf_score": 45.8205325131846, "xcomet_score": 0.3836052417755127, "xcomet_qe_score": 0.4555186629295349, "metricx_score": 14.385422706604004, "metricx_qe_score": 14.69234561920166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "and dissonance and we call them c e e here. We find that on transferring the zero-shot performance on the annotated dataset is already much better than chance with", "metrics": {"bleu_score": 1.2414943415352928, "chrf_score": 25.28921119833793, "xcomet_score": 0.2750520706176758, "xcomet_qe_score": 0.3084055781364441, "metricx_score": 23.232370376586914, "metricx_qe_score": 22.28171157836914, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "the best with auc.0.62. Further on iteratively fine-tuning on both tasks, we find that fine-tuning of ce tasks followed by further fine-tuning on debate yields a much better zero-shot performance. Thus, this is the", "metrics": {"bleu_score": 1.2090878038257866, "chrf_score": 20.471899112562102, "xcomet_score": 0.35044485330581665, "xcomet_qe_score": 0.4110204875469208, "metricx_score": 22.683006286621094, "metricx_qe_score": 19.25396156311035, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "model that we use to cold-start the active learning.", "metrics": {"bleu_score": 3.435488317233919, "chrf_score": 17.06623242244374, "xcomet_score": 0.8495352268218994, "xcomet_qe_score": 0.9695888757705688, "metricx_score": 22.983219146728516, "metricx_qe_score": 22.88689613342285, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotationsaktualisierung zu aktualisieren.", "metrics": {"bleu_score": 78.47574847738748, "chrf_score": 91.45684072602941, "xcomet_score": 0.9830447435379028, "xcomet_qe_score": 0.9531780481338501, "metricx_score": 0.6888852715492249, "metricx_qe_score": 0.7742607593536377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Cumulative sammelt alle bisher aus aktiven Annotations gesammelten Daten. Iterative aktualisiert das Modell durch das Training auf dem neuesten Datensatz.", "metrics": {"bleu_score": 13.127366375629931, "chrf_score": 64.29195130172788, "xcomet_score": 0.8481106758117676, "xcomet_qe_score": 0.8883239030838013, "metricx_score": 4.009625434875488, "metricx_qe_score": 3.138845205307007, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Über die verschiedenen Strategien haben wir festgestellt, dass kumulativ überdurchschnittlich gut abschneiden, gleich oder besser als iterativ.", "metrics": {"bleu_score": 44.129945550173765, "chrf_score": 68.59936188408442, "xcomet_score": 0.9142618179321289, "xcomet_qe_score": 0.9260722994804382, "metricx_score": 2.5927586555480957, "metricx_qe_score": 3.3128292560577393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Next, to improve the number of dissonance examples, we use a probability of rare class strategy, P R C, to select mostly the examples that are highly likely to be dissonant by the current model at any round of A L.", "metrics": {"bleu_score": 1.1239503708631486, "chrf_score": 21.979807939695817, "xcomet_score": 0.6420801281929016, "xcomet_qe_score": 0.5725384950637817, "metricx_score": 22.193002700805664, "metricx_qe_score": 19.23806381225586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen dies mit den anderen fortschrittlichsten Strategien, die in der Gemeinschaft üblicherweise verwendet werden.", "metrics": {"bleu_score": 24.26438274389041, "chrf_score": 56.336222183007344, "xcomet_score": 0.9539052248001099, "xcomet_qe_score": 0.950355052947998, "metricx_score": 1.8675729036331177, "metricx_qe_score": 2.5706393718719482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We find that the proposed PRC strategy works better than other state-of-the-art strategies, although the difference is small.", "metrics": {"bleu_score": 2.060187754521775, "chrf_score": 21.801502566714433, "xcomet_score": 0.9819817543029785, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Note that the performance is significantly lower for random.", "metrics": {"bleu_score": 2.812739937159535, "chrf_score": 15.143912389974846, "xcomet_score": 0.9023110270500183, "xcomet_qe_score": 0.938683271408081, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In weiteren Runden von al mit zwei besten Strategien verbessern wir die Entfernungsklassifizierung a u c auf 0.75, was die beste Leistung ist, die wir bisher bei der Aufgabe erzielt haben.", "metrics": {"bleu_score": 45.10783522612743, "chrf_score": 65.98113173679039, "xcomet_score": 0.7453155517578125, "xcomet_qe_score": 0.7508165836334229, "metricx_score": 8.067486763000488, "metricx_qe_score": 7.445195198059082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We also checked the feasibility of each strategy for annotation quality and costs to annotators.", "metrics": {"bleu_score": 1.789234746542202, "chrf_score": 19.41574878867767, "xcomet_score": 0.8975106477737427, "xcomet_qe_score": 1.0, "metricx_score": 21.274030685424805, "metricx_qe_score": 21.42258644104004, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We find that prc has the highest percentage of dissonance and works best for rare class.", "metrics": {"bleu_score": 1.8074696761828841, "chrf_score": 17.496258866566375, "xcomet_score": 0.8806262016296387, "xcomet_qe_score": 0.9098398685455322, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "However, the annotators also find the examples difficult.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 22.058101384739366, "xcomet_score": 0.9743770956993103, "xcomet_qe_score": 0.9954745769500732, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "In summary, we find that PRC is a simple AL strategy for rare class acquisition and cold starting AL with appropriately designed transfer learning tasks can help significantly.", "metrics": {"bleu_score": 1.5285234035665498, "chrf_score": 20.80301891443964, "xcomet_score": 0.7108197212219238, "xcomet_qe_score": 0.9455041885375977, "metricx_score": 25.0, "metricx_qe_score": 24.155841827392578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "We also find that iterative update is useful for transfer learning from a different domain, whereas in-domain active annotations benefit from cumulative update.", "metrics": {"bleu_score": 1.5592982903541592, "chrf_score": 30.695036856978085, "xcomet_score": 0.9390116930007935, "xcomet_qe_score": 0.9660686254501343, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "These are the links to our core dataset and our paper.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 14.333991870662585, "xcomet_score": 0.8989184498786926, "xcomet_qe_score": 0.9955552816390991, "metricx_score": 12.548171997070312, "metricx_qe_score": 15.561254501342773, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Feel free to get in touch with us if you have any questions.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 12.429366898885325, "xcomet_score": 0.9250227212905884, "xcomet_qe_score": 1.0, "metricx_score": 20.773000717163086, "metricx_qe_score": 19.412574768066406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 11.700083142742542, "xcomet_score": 0.9926378726959229, "xcomet_qe_score": 1.0, "metricx_score": 1.4178515672683716, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
