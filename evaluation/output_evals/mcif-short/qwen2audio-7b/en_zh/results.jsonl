{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "马蒂", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3999422490596771, "xcomet_qe_score": 0.40847983956336975, "metricx_score": 3.303786277770996, "metricx_qe_score": 3.284945249557495, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "面(Deplane)是一个新的文档级别和句子级别的德国文本标注工具。 我的名字是雷吉娜·施特丹", "metrics": {"bleu_score": 14.76482411966793, "chrf_score": 12.316128814744758, "xcomet_score": 0.13359390199184418, "xcomet_qe_score": 0.14061391353607178, "metricx_score": 9.93259048461914, "metricx_qe_score": 9.774834632873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我将指导您完成第一个部分的演示。", "metrics": {"bleu_score": 8.107841474081335, "chrf_score": 8.361287322727422, "xcomet_score": 0.7138574123382568, "xcomet_qe_score": 0.7225292921066284, "metricx_score": 9.956558227539062, "metricx_qe_score": 10.724270820617676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们来定义文本简化。", "metrics": {"bleu_score": 42.43684507396328, "chrf_score": 35.13791852746409, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.15129098296165466, "metricx_qe_score": 0.22213901579380035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文本缩写是将文本适应特定目标群体以提高其理解过程的一种方法,例如为母语非英语人士提供阅读困难的文本。 ", "metrics": {"bleu_score": 19.306965035646616, "chrf_score": 20.334937615366037, "xcomet_score": 0.647779643535614, "xcomet_qe_score": 0.5888893604278564, "metricx_score": 4.41211462020874, "metricx_qe_score": 3.8465380668640137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了训练文本分类模型,我们需要成对的文本,例如文档或句子。", "metrics": {"bleu_score": 44.348492631401015, "chrf_score": 37.503499625934744, "xcomet_score": 0.9232577681541443, "xcomet_qe_score": 0.9261854887008667, "metricx_score": 1.7154039144515991, "metricx_qe_score": 1.2706654071807861, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里你可以看到一个复杂的德语句子的并行句对,并附有其在简单语言中的翻译。", "metrics": {"bleu_score": 42.44391203092751, "chrf_score": 38.1390871870748, "xcomet_score": 0.9598743915557861, "xcomet_qe_score": 0.8785491585731506, "metricx_score": 1.3088258504867554, "metricx_qe_score": 1.1517894268035889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个句子的中文翻译是:'例如,您可以使用词汇替换、句法消歧、句法消歧、重排或插入单词等", "metrics": {"bleu_score": 21.257517590085346, "chrf_score": 18.570055568255505, "xcomet_score": 0.16214725375175476, "xcomet_qe_score": 0.21481956541538239, "metricx_score": 9.388320922851562, "metricx_qe_score": 9.590438842773438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不同的技术。' 我们现在提出我们的新公司计划,因为最近几年存在一些现有公司的问题。", "metrics": {"bleu_score": 17.377208785560796, "chrf_score": 16.723208211129183, "xcomet_score": 0.1814257949590683, "xcomet_qe_score": 0.2169187068939209, "metricx_score": 13.631688117980957, "metricx_qe_score": 12.59156322479248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这些公司(在这里)太小了,无法训练一个文本分类模型。 其他三个", "metrics": {"bleu_score": 8.840994001530047, "chrf_score": 15.766690927505763, "xcomet_score": 0.369215726852417, "xcomet_qe_score": 0.5089770555496216, "metricx_score": 10.113297462463379, "metricx_qe_score": 7.840755462646484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来提出的模型都是自动对齐的,这意味着它们可能会出现错误或偏差。", "metrics": {"bleu_score": 47.14232011729898, "chrf_score": 41.20399537848527, "xcomet_score": 0.9796501398086548, "xcomet_qe_score": 0.9245937466621399, "metricx_score": 1.9635385274887085, "metricx_qe_score": 2.144425392150879, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提出我们的新核心平面(corpus),它分为两个子系统:core plane API 和 core plane web。", "metrics": {"bleu_score": 17.278330851481748, "chrf_score": 14.302775554688202, "xcomet_score": 0.49867764115333557, "xcomet_qe_score": 0.5597041845321655, "metricx_score": 6.534278392791748, "metricx_qe_score": 6.954107761383057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "core plane API 基于消息文本。", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 13.09330126624631, "xcomet_score": 0.3873412311077118, "xcomet_qe_score": 0.3426249027252197, "metricx_score": 6.040085792541504, "metricx_qe_score": 6.679872035980225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在DeepPlane API中,我们手动分配了四百八十三个文档。", "metrics": {"bleu_score": 24.62292439135324, "chrf_score": 17.942201685987634, "xcomet_score": 0.746985673904419, "xcomet_qe_score": 0.8090064525604248, "metricx_score": 5.424840927124023, "metricx_qe_score": 4.7929534912109375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果大约是三万一千到三万一千五百个平行句子对。", "metrics": {"bleu_score": 13.929083599454664, "chrf_score": 14.650065115972936, "xcomet_score": 0.7389672994613647, "xcomet_qe_score": 0.8147921562194824, "metricx_score": 3.8546223640441895, "metricx_qe_score": 3.473949432373047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "深兰网的这个集群包括不同的域,并且我们还手动将所有这些七百五十个文档与自动对齐方法配对。", "metrics": {"bleu_score": 22.439073912369984, "chrf_score": 16.758456828276877, "xcomet_score": 0.4318280518054962, "xcomet_qe_score": 0.3778502941131592, "metricx_score": 6.368204116821289, "metricx_qe_score": 6.298160076141357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总共有三万四百五十分句对。", "metrics": {"bleu_score": 14.458924666162856, "chrf_score": 9.607478830647333, "xcomet_score": 0.834063708782196, "xcomet_qe_score": 0.8054540753364563, "metricx_score": 1.7309638261795044, "metricx_qe_score": 1.56364107131958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对句子对齐稍作更多分析。例如,在类型标注方面。", "metrics": {"bleu_score": 15.542549544776197, "chrf_score": 15.746024502817384, "xcomet_score": 0.7410842180252075, "xcomet_qe_score": 0.6930252313613892, "metricx_score": 3.993218421936035, "metricx_qe_score": 4.099598407745361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如您所见,圣经文本比新闻文本或语言学习者文本要强得多。", "metrics": {"bleu_score": 58.688129236830875, "chrf_score": 57.112339954106325, "xcomet_score": 0.7863445281982422, "xcomet_qe_score": 0.7946251630783081, "metricx_score": 4.469959735870361, "metricx_qe_score": 4.736309051513672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在所有级别上,例如词汇标注、结构标注以及整体语义标注。", "metrics": {"bleu_score": 25.9838330131599, "chrf_score": 21.67568850902184, "xcomet_score": 0.6793534159660339, "xcomet_qe_score": 0.6569029092788696, "metricx_score": 1.554296612739563, "metricx_qe_score": 2.0005931854248047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,您还可以看到我们的“deplane corpus”具有高比例的差异性泛化转换。", "metrics": {"bleu_score": 31.108918705294958, "chrf_score": 22.68919478249782, "xcomet_score": 0.807644248008728, "xcomet_qe_score": 0.7630237936973572, "metricx_score": 7.444369316101074, "metricx_qe_score": 7.6574320793151855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在“deplane api corpus”中,我们有更多的重新排序和文字添加操作,而不是在“deplane web corpus”中。", "metrics": {"bleu_score": 12.086038782520491, "chrf_score": 11.130852707784346, "xcomet_score": 0.714572012424469, "xcomet_qe_score": 0.73923259973526, "metricx_score": 6.406430721282959, "metricx_qe_score": 5.5858612060546875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,在Web上下文中,我们有更多的重述。 所以", "metrics": {"bleu_score": 17.09547283384606, "chrf_score": 15.613230338208748, "xcomet_score": 0.7140238285064697, "xcomet_qe_score": 0.6851926445960999, "metricx_score": 5.427371501922607, "metricx_qe_score": 2.669494867324829, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",现在让我们来看看我们能用这个课程做什么。", "metrics": {"bleu_score": 18.493046910349435, "chrf_score": 20.4093567251462, "xcomet_score": 0.776740312576294, "xcomet_qe_score": 0.7317232489585876, "metricx_score": 5.324217796325684, "metricx_qe_score": 5.088131427764893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是Omar,现在我将讨论我们的数据集“DeepPlane”的一些", "metrics": {"bleu_score": 34.29547961820059, "chrf_score": 28.363284011231237, "xcomet_score": 0.6909751892089844, "xcomet_qe_score": 0.6982707977294922, "metricx_score": 7.226313591003418, "metricx_qe_score": 5.864762306213379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用案例。首先,我们可以评估自动配准方法。", "metrics": {"bleu_score": 41.09080290971358, "chrf_score": 35.63400945173391, "xcomet_score": 0.9089714288711548, "xcomet_qe_score": 0.8334923982620239, "metricx_score": 2.2268869876861572, "metricx_qe_score": 1.368750810623169, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,有很多对齐方法,但机器翻译的上下文却很少。 我们有两份平行文档,用不同的语言写成的,并且我们想要提取文档中的句子对齐。", "metrics": {"bleu_score": 33.93174217136695, "chrf_score": 30.449207169593357, "xcomet_score": 0.6317617297172546, "xcomet_qe_score": 0.6046580076217651, "metricx_score": 3.6263599395751953, "metricx_qe_score": 4.153998374938965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的使用案例中,我们试图从两种相似文档中提取对齐的句子,它们具有相同的语言、内容,但复杂程度不同。", "metrics": {"bleu_score": 18.93700580412623, "chrf_score": 21.73151197453213, "xcomet_score": 0.946061372756958, "xcomet_qe_score": 0.8836595416069031, "metricx_score": 1.0858179330825806, "metricx_qe_score": 1.2637931108474731, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们有了手动对齐的句子数据集,我们可以使用这些句子作为 gold standard 来评估一些提出的对齐方法。", "metrics": {"bleu_score": 46.78476052081609, "chrf_score": 37.88745093683984, "xcomet_score": 0.8284238576889038, "xcomet_qe_score": 0.8526276350021362, "metricx_score": 6.555217266082764, "metricx_qe_score": 6.622957706451416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对提议的方法做了一些调整,并且已经发表了所有这些调整和运行实验的代码。", "metrics": {"bleu_score": 22.271699342591642, "chrf_score": 22.111025336486914, "xcomet_score": 0.9712585210800171, "xcomet_qe_score": 0.9233835339546204, "metricx_score": 2.3917455673217773, "metricx_qe_score": 2.228032350540161, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在结束时,我们得出结论,用于文本缩写的自动对齐方法是“mass align”方法。", "metrics": {"bleu_score": 35.479105265934486, "chrf_score": 32.12822665976567, "xcomet_score": 0.8387802839279175, "xcomet_qe_score": 0.8929461240768433, "metricx_score": 5.126494884490967, "metricx_qe_score": 5.498233795166016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在纸张上找到运行此方法的代码。", "metrics": {"bleu_score": 19.63956550100611, "chrf_score": 26.946584006260988, "xcomet_score": 0.7122578620910645, "xcomet_qe_score": 0.7887344360351562, "metricx_score": 5.462338924407959, "metricx_qe_score": 2.4694764614105225, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文中展示的第二个用例是自动文本简化。 通过微调语言模型,从复杂文本中生成简化文本。", "metrics": {"bleu_score": 68.08539501879805, "chrf_score": 60.41819449239143, "xcomet_score": 0.9927668571472168, "xcomet_qe_score": 0.985612154006958, "metricx_score": 0.7576696276664734, "metricx_qe_score": 0.9441542625427246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们有两个不同的模型。", "metrics": {"bleu_score": 27.27426544698237, "chrf_score": 24.09834808564069, "xcomet_score": 0.8168858289718628, "xcomet_qe_score": 0.8076123595237732, "metricx_score": 1.690375566482544, "metricx_qe_score": 2.790405750274658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个是长短期记忆模型,用于生成文档级别的简化版本。 我们还对正常基础进行了微调,使其能够产生句级简化。 ", "metrics": {"bleu_score": 21.760447259144403, "chrf_score": 16.62571429651651, "xcomet_score": 0.714875340461731, "xcomet_qe_score": 0.7043665647506714, "metricx_score": 5.835550308227539, "metricx_qe_score": 6.231982707977295, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您还可以在论文中找到所有检查点,并且可以查看更多细节,包括评分和评估指标。", "metrics": {"bleu_score": 42.69976215659689, "chrf_score": 36.231993446024845, "xcomet_score": 0.9543024301528931, "xcomet_qe_score": 0.9460344314575195, "metricx_score": 1.0227560997009277, "metricx_qe_score": 1.848004698753357, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们得出结论,这种基本的调音可以产生比基线分数更好的分数。 我们提议将这些结果作为自动文本简化问题未来发展的基线基准。", "metrics": {"bleu_score": 47.13617377873883, "chrf_score": 38.87477202795834, "xcomet_score": 0.7449530363082886, "xcomet_qe_score": 0.6378991603851318, "metricx_score": 6.175388336181641, "metricx_qe_score": 6.761643409729004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您抽出时间来听我说话,我们希望在会议上见到你们所有人。", "metrics": {"bleu_score": 28.12488198404139, "chrf_score": 27.73283334705076, "xcomet_score": 0.970893383026123, "xcomet_qe_score": 0.9253976941108704, "metricx_score": 1.358910322189331, "metricx_qe_score": 0.9768742322921753, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嗨,我叫亚当·斯克鲁科夫斯基,今天的话题是协调依赖结构。", "metrics": {"bleu_score": 5.255923420816886, "chrf_score": 5.341269043513671, "xcomet_score": 0.77784264087677, "xcomet_qe_score": 0.6959086656570435, "metricx_score": 3.1001460552215576, "metricx_qe_score": 2.5761332511901855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您可能知道,不同的理论和方法论会假设不同的依赖结构。", "metrics": {"bleu_score": 36.783198320468564, "chrf_score": 30.680003736947555, "xcomet_score": 0.8630344867706299, "xcomet_qe_score": 0.7714295983314514, "metricx_score": 0.8397839069366455, "metricx_qe_score": 1.0928610563278198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在普遍依赖性中,坐标依赖性是结构化的。协调、Lisa、Bart 和 Maggie。 第一个共轭是整个坐标结构的头部。", "metrics": {"bleu_score": 22.584063465838383, "chrf_score": 36.975420241256536, "xcomet_score": 0.3744361102581024, "xcomet_qe_score": 0.33856287598609924, "metricx_score": 7.630218505859375, "metricx_qe_score": 7.307794570922852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,在这种情况下,Lisa。", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 16.492673992673993, "xcomet_score": 0.8278203010559082, "xcomet_qe_score": 0.9265989065170288, "metricx_score": 0.8793460726737976, "metricx_qe_score": 1.634329915046692, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "伊戈尔·米特罗维奇在他的“意义文本理论”中提出了类似的方法,其中整个坐标结构由第一个关联词引导。所以这", "metrics": {"bleu_score": 26.22067643618597, "chrf_score": 20.478868079288983, "xcomet_score": 0.3458888530731201, "xcomet_qe_score": 0.26871877908706665, "metricx_score": 6.822895526885986, "metricx_qe_score": 3.9633445739746094, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "两种方法是等价的。", "metrics": {"bleu_score": 26.432408210372945, "chrf_score": 22.178293487079006, "xcomet_score": 0.8591112494468689, "xcomet_qe_score": 0.8655998110771179, "metricx_score": 4.603454113006592, "metricx_qe_score": 5.565456390380859, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.996912956237793, "xcomet_qe_score": 0.9818440675735474, "metricx_score": 0.2157692313194275, "metricx_qe_score": 0.26781266927719116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关联词挑选出来。 现在,", "metrics": {"bleu_score": 4.41902110634, "chrf_score": 5.291005291005291, "xcomet_score": 0.3435712456703186, "xcomet_qe_score": 0.22733435034751892, "metricx_score": 6.121915817260742, "metricx_qe_score": 8.620049476623535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "还有对坐标结构的对称方法,例如普拉格方法、", "metrics": {"bleu_score": 27.813701926231836, "chrf_score": 22.330917857755423, "xcomet_score": 0.8425736427307129, "xcomet_qe_score": 0.7567718029022217, "metricx_score": 4.922582149505615, "metricx_qe_score": 4.225749492645264, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "连接头方法、哈密顿独立性树变换等,其中坐标结构由连接头引导。", "metrics": {"bleu_score": 6.226392750653949, "chrf_score": 7.7487297576934875, "xcomet_score": 0.14920556545257568, "xcomet_qe_score": 0.15771202743053436, "metricx_score": 9.866947174072266, "metricx_qe_score": 8.372544288635254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们从端到所有连接器获取依赖项。", "metrics": {"bleu_score": 11.033373619902253, "chrf_score": 10.800908839802275, "xcomet_score": 0.7414995431900024, "xcomet_qe_score": 0.7696496844291687, "metricx_score": 3.0727639198303223, "metricx_qe_score": 1.8185780048370361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,还有一个多头策略,例如在卡特尔语法中使用。 所有行为都是协调结构的头,", "metrics": {"bleu_score": 22.292179436977694, "chrf_score": 16.723255915368078, "xcomet_score": 0.42801913619041443, "xcomet_qe_score": 0.42778894305229187, "metricx_score": 9.003562927246094, "metricx_qe_score": 8.132195472717285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们从 governor 获得依赖性", "metrics": {"bleu_score": 14.892408222374314, "chrf_score": 12.741456186722107, "xcomet_score": 0.8282084465026855, "xcomet_qe_score": 0.8126245141029358, "metricx_score": 4.1729936599731445, "metricx_qe_score": 4.569991111755371, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这里 loves 到所有行为单独地。这是部分完成的。 现在,安德斯", "metrics": {"bleu_score": 4.514788618484021, "chrf_score": 11.273780763564552, "xcomet_score": 0.14650453627109528, "xcomet_qe_score": 0.1414513885974884, "metricx_score": 15.927906036376953, "metricx_qe_score": 18.900611877441406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的论文是为对称性协调结构(如这两个)和非对称性协调结构(如这些)提出一个新的论点。", "metrics": {"bleu_score": 31.222591224971545, "chrf_score": 25.35913735681194, "xcomet_score": 0.3402435779571533, "xcomet_qe_score": 0.23110803961753845, "metricx_score": 7.590750694274902, "metricx_qe_score": 8.200777053833008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9997061491012573, "xcomet_qe_score": 1.0, "metricx_score": 0.1774456948041916, "metricx_qe_score": 0.21148386597633362, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个论证是基于独立选择权原则的,我将在这些例子的基础上来解释这个原则。", "metrics": {"bleu_score": 7.8615392933997414, "chrf_score": 12.19179163765731, "xcomet_score": 0.809434175491333, "xcomet_qe_score": 0.7833734750747681, "metricx_score": 3.057579517364502, "metricx_qe_score": 4.21825647354126, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,正如你可能知道的那样,在英语中,直接对象倾向于靠近动词,而附加对象则可能更远一些。", "metrics": {"bleu_score": 29.74380158277323, "chrf_score": 28.281774471195355, "xcomet_score": 0.796085000038147, "xcomet_qe_score": 0.8942106366157532, "metricx_score": 1.3793458938598633, "metricx_qe_score": 1.163935899734497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如: March read it yesterday 是好的,因为直接对象是 close to verb \"read\"。 中文翻译:虽然马奇昨天读了,但情况更糟,", "metrics": {"bleu_score": 8.241860358050355, "chrf_score": 27.045785188617806, "xcomet_score": 0.3276118338108063, "xcomet_qe_score": 0.4538075625896454, "metricx_score": 12.398405075073242, "metricx_qe_score": 12.481687545776367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为在这句话中", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3459615111351013, "xcomet_qe_score": 0.3146159052848816, "metricx_score": 4.188852787017822, "metricx_qe_score": 3.8846793174743652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",在动词和直接宾语之间有一个冠词“i”。 无论", "metrics": {"bleu_score": 58.29068895416293, "chrf_score": 41.954054569795034, "xcomet_score": 0.32121849060058594, "xcomet_qe_score": 0.24410751461982727, "metricx_score": 14.645744323730469, "metricx_qe_score": 12.275201797485352, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如何,当直接对象非常大且很长时,此效果可能会得到缓解,因为", "metrics": {"bleu_score": 10.128952330932195, "chrf_score": 11.526944713200564, "xcomet_score": 0.3766108453273773, "xcomet_qe_score": 0.43059495091438293, "metricx_score": 7.725080966949463, "metricx_qe_score": 5.925420761108398, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此时它可以移动到代理之后的位置。", "metrics": {"bleu_score": 32.47126476891873, "chrf_score": 28.174873515703446, "xcomet_score": 0.8170458674430847, "xcomet_qe_score": 0.8137398362159729, "metricx_score": 4.163489818572998, "metricx_qe_score": 3.1094307899475098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这在图中演示了。所以", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 3.968253968253968, "xcomet_score": 0.5612587928771973, "xcomet_qe_score": 0.7196483612060547, "metricx_score": 3.960099935531616, "metricx_qe_score": 0.8288352489471436, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两个句子都是好的。马奇", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 54.34378449886602, "xcomet_score": 0.7157195806503296, "xcomet_qe_score": 0.5559120178222656, "metricx_score": 2.7065606117248535, "metricx_qe_score": 3.747323989868164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "昨天读了一本关于蜜蜂的绝对迷人的书,", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.7278159856796265, "xcomet_qe_score": 0.734965443611145, "metricx_score": 4.730898857116699, "metricx_qe_score": 5.17291259765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它是这样的:而不是它,我们有这个长音符和p。 但是,你也可以在昨天说“ March red”,", "metrics": {"bleu_score": 6.666962995889164, "chrf_score": 11.400719613491809, "xcomet_score": 0.1633395105600357, "xcomet_qe_score": 0.15381699800491333, "metricx_score": 19.29549217224121, "metricx_qe_score": 17.977191925048828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一本关于蜜蜂的绝对有趣的书。 所以这里的理由是这是可能的,", "metrics": {"bleu_score": 1.8564670505078418, "chrf_score": 1.3269639065817411, "xcomet_score": 0.15747983753681183, "xcomet_qe_score": 0.14785803854465485, "metricx_score": 6.460697174072266, "metricx_qe_score": 7.811657428741455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为尽管这个句子违反了直接对象应该紧随其后的语法原则,但直接对象紧随其后。 它满足了依赖长度最小化原则,该原则指出更短的依赖关系更可取。 所以,", "metrics": {"bleu_score": 24.51915475278609, "chrf_score": 21.537121763631422, "xcomet_score": 0.678848922252655, "xcomet_qe_score": 0.6656266450881958, "metricx_score": 7.137989044189453, "metricx_qe_score": 5.638869762420654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这两大树仅显示了这两个结构中关键依赖性的长度。即那些在两个结构中不恒定的依赖性。", "metrics": {"bleu_score": 25.89093258791443, "chrf_score": 26.03228354455617, "xcomet_score": 0.8565669059753418, "xcomet_qe_score": 0.9447678327560425, "metricx_score": 2.5144431591033936, "metricx_qe_score": 2.6408474445343018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,这里我们有从红色到长度为七的附加项测量向内,以及从红色到长度为四的书本。所以总共有十一项。", "metrics": {"bleu_score": 12.27289846510402, "chrf_score": 11.052980208674905, "xcomet_score": 0.44846928119659424, "xcomet_qe_score": 0.48848965764045715, "metricx_score": 12.228446006774902, "metricx_qe_score": 12.014541625976562, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当你移动,交换这些两个成分时,这两个依赖性的总和变为六。", "metrics": {"bleu_score": 25.53746494512585, "chrf_score": 22.638108804775474, "xcomet_score": 0.7667930722236633, "xcomet_qe_score": 0.7425941228866577, "metricx_score": 3.5310001373291016, "metricx_qe_score": 4.02958345413208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对吧?所以不是十一,而是六,更短了。", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 2.525252525252525, "xcomet_score": 0.7355688810348511, "xcomet_qe_score": 0.7705779671669006, "metricx_score": 4.848949909210205, "metricx_qe_score": 4.608329772949219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是为什么这听起来相当合理,对", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 62.24087387447824, "xcomet_score": 0.8750478029251099, "xcomet_qe_score": 0.9026393890380859, "metricx_score": 2.536752223968506, "metricx_qe_score": 0.6145045757293701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为在这句话中", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3459615111351013, "xcomet_qe_score": 0.3146159052848816, "metricx_score": 4.188852787017822, "metricx_qe_score": 3.8846793174743652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "吧?它违反了一个原则,但满足了另一个。", "metrics": {"bleu_score": 57.3764722928549, "chrf_score": 49.98382865799945, "xcomet_score": 0.8219634294509888, "xcomet_qe_score": 0.6721051931381226, "metricx_score": 1.783188819885254, "metricx_qe_score": 2.6858720779418945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9992789030075073, "xcomet_qe_score": 0.997222900390625, "metricx_score": 0.1849263608455658, "metricx_qe_score": 0.19376564025878906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从增强版的Pentaho中提取了关于协调的统计数据,并且查看了论文《为什么不用关系数据库》。 这些统计数据证实了之前多次提出的观察结果:左连接词通常较短。", "metrics": {"bleu_score": 45.3961769694052, "chrf_score": 40.11537536199554, "xcomet_score": 0.5116754770278931, "xcomet_qe_score": 0.40016794204711914, "metricx_score": 4.724991798400879, "metricx_qe_score": 4.828787326812744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如, salt 和 pepper 以及 not 和 salt 在单词计数上是相等的。 以及过去观察到", "metrics": {"bleu_score": 2.0929373635196202, "chrf_score": 18.097806471603157, "xcomet_score": 0.1423529088497162, "xcomet_qe_score": 0.15646310150623322, "metricx_score": 17.232940673828125, "metricx_qe_score": 14.971026420593262, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的趋势,即这种差异随着长度的增加而增大。", "metrics": {"bleu_score": 27.807732356249147, "chrf_score": 23.246697026893223, "xcomet_score": 0.5883519649505615, "xcomet_qe_score": 0.5681999325752258, "metricx_score": 6.731184959411621, "metricx_qe_score": 9.678232192993164, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,当两个连接词的长度差增长时,较短的连接词更倾向于作为第一个出现。对吧?", "metrics": {"bleu_score": 27.025633160989027, "chrf_score": 22.850719365634678, "xcomet_score": 0.911001443862915, "xcomet_qe_score": 0.9582011699676514, "metricx_score": 2.353830099105835, "metricx_qe_score": 2.2602975368499756, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以比例是左边较短连接词的比例更大。", "metrics": {"bleu_score": 37.15770152515525, "chrf_score": 37.5523715918455, "xcomet_score": 0.8137140274047852, "xcomet_qe_score": 0.8396825194358826, "metricx_score": 2.861013889312744, "metricx_qe_score": 3.4561355113983154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,这份论文中值得注意的是,这种趋势只出现在左翼政府缺席的情况下。 右,所以", "metrics": {"bleu_score": 14.803269502197033, "chrf_score": 13.72928289224104, "xcomet_score": 0.23787826299667358, "xcomet_qe_score": 0.1794564425945282, "metricx_score": 9.904182434082031, "metricx_qe_score": 6.221631050109863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因为在这句话中", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3459615111351013, "xcomet_qe_score": 0.3146159052848816, "metricx_score": 4.188852787017822, "metricx_qe_score": 3.8846793174743652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中,州长在左边。我看到巴特和丽莎。所以州长在左边吗", "metrics": {"bleu_score": 19.360105998091445, "chrf_score": 13.028982236861939, "xcomet_score": 0.5357029438018799, "xcomet_qe_score": 0.6485836505889893, "metricx_score": 2.7853875160217285, "metricx_qe_score": 1.5236200094223022, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "? 第二个例子中,Homer来了并且打了一个喷嚏。", "metrics": {"bleu_score": 18.23978031293802, "chrf_score": 16.112863676834998, "xcomet_score": 0.6889594793319702, "xcomet_qe_score": 0.7016618251800537, "metricx_score": 4.309957504272461, "metricx_qe_score": 4.526274681091309, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里有两个动词的协调,并且没有外部的控制者。所以,", "metrics": {"bleu_score": 44.67710283121971, "chrf_score": 41.61461366392205, "xcomet_score": 0.7573511004447937, "xcomet_qe_score": 0.7472243309020996, "metricx_score": 4.199008941650391, "metricx_qe_score": 2.9990651607513428, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这种情况下,左连接词更倾向于被缩短。", "metrics": {"bleu_score": 17.945538699557254, "chrf_score": 17.59544195107357, "xcomet_score": 0.8131493330001831, "xcomet_qe_score": 0.7506260871887207, "metricx_score": 5.406034469604492, "metricx_qe_score": 5.746831893920898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且,两者的区别更大。 然而,当右翼政府(如现在)统治时,这种效果就消失了。 所以,我们显示", "metrics": {"bleu_score": 5.508606419495828, "chrf_score": 6.448220593486911, "xcomet_score": 0.22418171167373657, "xcomet_qe_score": 0.23309627175331116, "metricx_score": 10.551337242126465, "metricx_qe_score": 8.93203353881836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了通过测量字符长度来区分第一列(音节)、中间列和右列的方法。我会集中精力在右列上。", "metrics": {"bleu_score": 6.328433299017495, "chrf_score": 10.262709149019484, "xcomet_score": 0.183349609375, "xcomet_qe_score": 0.17276078462600708, "metricx_score": 8.560728073120117, "metricx_qe_score": 9.012528419494629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们在这里", "metrics": {"bleu_score": 7.859505256643253, "chrf_score": 6.946564885496183, "xcomet_score": 0.1888851374387741, "xcomet_qe_score": 0.11558346450328827, "metricx_score": 6.136878490447998, "metricx_qe_score": 6.210641860961914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "看到的是,当左边的盖子打开时。 左连词长度减少的趋势随词汇绝对差值的增加而稳定增长,且在没有右手连词时也观察到这种趋势,但", "metrics": {"bleu_score": 12.687537990566627, "chrf_score": 13.334802474774952, "xcomet_score": 0.1568102091550827, "xcomet_qe_score": 0.1845722198486328, "metricx_score": 13.726633071899414, "metricx_qe_score": 10.384319305419922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在存在右手连词时,这种趋势会消失。", "metrics": {"bleu_score": 27.60610057515833, "chrf_score": 22.514129990261715, "xcomet_score": 0.7137452960014343, "xcomet_qe_score": 0.14567230641841888, "metricx_score": 4.754067420959473, "metricx_qe_score": 7.258134365081787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在论文中,我们展示了这种结构如何提供一个反对不对称协调结构的论点,即这两个对称结构与这些非对称结构。", "metrics": {"bleu_score": 24.697221842810894, "chrf_score": 22.56551704775044, "xcomet_score": 0.7633651494979858, "xcomet_qe_score": 0.6336110234260559, "metricx_score": 6.217065811157227, "metricx_qe_score": 6.202230930328369, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,请查看完整的协议", "metrics": {"bleu_score": 5.6578916063256015, "chrf_score": 5.63503140265178, "xcomet_score": 0.5674183368682861, "xcomet_qe_score": 0.6317429542541504, "metricx_score": 4.928834915161133, "metricx_qe_score": 0.9496286511421204, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "和议程,然后在会后与我们讨论。", "metrics": {"bleu_score": 3.4585921141027356, "chrf_score": 3.5211267605633796, "xcomet_score": 0.1561645269393921, "xcomet_qe_score": 0.18039105832576752, "metricx_score": 6.079524040222168, "metricx_qe_score": 5.654542446136475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是约翰·史密斯,华盛顿大学的博士生。", "metrics": {"bleu_score": 46.99152171992906, "chrf_score": 34.16167139701318, "xcomet_score": 0.2905188500881195, "xcomet_qe_score": 0.3651624023914337, "metricx_score": 6.117713451385498, "metricx_qe_score": 5.785495281219482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我将介绍我们从预训练数据到语言模型,再到下游任务的工作,即跟踪政治偏见如何导致不公平的NLP模型。", "metrics": {"bleu_score": 58.699788748216555, "chrf_score": 50.469965059721076, "xcomet_score": 0.8054202198982239, "xcomet_qe_score": 0.7479532957077026, "metricx_score": 2.0530850887298584, "metricx_qe_score": 2.3019964694976807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型是基于大规模网络爬虫数据训练的。", "metrics": {"bleu_score": 57.121153362801365, "chrf_score": 44.721966777080674, "xcomet_score": 0.9994664192199707, "xcomet_qe_score": 0.99653160572052, "metricx_score": 0.768169641494751, "metricx_qe_score": 1.4887888431549072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "政治新闻媒体在预训练数据中得到了很好的覆盖。", "metrics": {"bleu_score": 64.42271946445945, "chrf_score": 64.98697375335293, "xcomet_score": 0.8035382032394409, "xcomet_qe_score": 0.741437554359436, "metricx_score": 1.5606460571289062, "metricx_qe_score": 2.311195135116577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "根据C4项目的一项调查,我们可以看到,《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等都很好地涵盖了语言模型训练数据。", "metrics": {"bleu_score": 67.61212774081345, "chrf_score": 61.65362083486763, "xcomet_score": 0.811216413974762, "xcomet_qe_score": 0.7877838015556335, "metricx_score": 2.5089187622070312, "metricx_qe_score": 3.3853797912597656, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为语言模型应用创造了一种混合祝福。 所以一", "metrics": {"bleu_score": 24.761650580786526, "chrf_score": 22.46342425428548, "xcomet_score": 0.6740748882293701, "xcomet_qe_score": 0.6576671004295349, "metricx_score": 9.435401916503906, "metricx_qe_score": 6.357686519622803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "方面,他们能够从多样化的视角中学习,这庆祝了民主和思想的多样性。", "metrics": {"bleu_score": 24.28133621314367, "chrf_score": 20.89016455673853, "xcomet_score": 0.679343581199646, "xcomet_qe_score": 0.6051653027534485, "metricx_score": 5.113332271575928, "metricx_qe_score": 5.298593997955322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,这些不同的政治观点本质上是社会偏见的,可能会导致下游任务应用中的潜在公平问题。", "metrics": {"bleu_score": 59.1962845785821, "chrf_score": 51.13156878216797, "xcomet_score": 0.9204022884368896, "xcomet_qe_score": 0.9083214998245239, "metricx_score": 1.1173139810562134, "metricx_qe_score": 1.3508135080337524, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们提议从预训练数据到语言模型再到下游任务,通过以下方式来调查政治偏见传播管道:提出问题。 首先,我们如何评估语言模型的政治倾向性?以及预训练数据在其中可能扮演的角色是什么? Translation: Firstly, how do we evaluate the political orientation of language models? And what role might pre-training data play in this regard?", "metrics": {"bleu_score": 40.23707147011239, "chrf_score": 34.94323844158987, "xcomet_score": 0.6297194957733154, "xcomet_qe_score": 0.5928916931152344, "metricx_score": 4.57360315322876, "metricx_qe_score": 3.8700921535491943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,不同政治立场的语言模型在下游任务上的表现如何?这是否会引发NLP应用程序中的公平性问题?", "metrics": {"bleu_score": 47.71970738752903, "chrf_score": 41.55362886226999, "xcomet_score": 0.9630751609802246, "xcomet_qe_score": 0.9211151003837585, "metricx_score": 0.9438549876213074, "metricx_qe_score": 1.0056320428848267, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别地,我们首先提出使用不同的提示格式来提议政治语言模型,例如政治测验问卷。", "metrics": {"bleu_score": 36.85114805704418, "chrf_score": 31.72869890591946, "xcomet_score": 0.6604255437850952, "xcomet_qe_score": 0.5696529150009155, "metricx_score": 4.726779460906982, "metricx_qe_score": 5.329337120056152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这确保我们在基于政治科学文献的自动评估方面有所建树。", "metrics": {"bleu_score": 19.696330878717074, "chrf_score": 21.892692636447592, "xcomet_score": 0.9697859287261963, "xcomet_qe_score": 0.9600712060928345, "metricx_score": 1.8875374794006348, "metricx_qe_score": 1.7121710777282715, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些初步结果表明,首先,语言模型确实具有不同的政治倾向。", "metrics": {"bleu_score": 71.0109425285578, "chrf_score": 63.471040822713185, "xcomet_score": 0.9910895824432373, "xcomet_qe_score": 1.0, "metricx_score": 0.7272058129310608, "metricx_qe_score": 0.8977949023246765, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们占据了政治坐标上的四个象限。", "metrics": {"bleu_score": 66.87028210563447, "chrf_score": 58.71494455010393, "xcomet_score": 0.9113149642944336, "xcomet_qe_score": 0.8448753952980042, "metricx_score": 1.1717729568481445, "metricx_qe_score": 1.8599472045898438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到,GPT-4是所有模型中最自由的语言模型。而且GPT系列的理论通常比Bert系列及其变体更具有社会自由主义色彩。", "metrics": {"bleu_score": 45.75006301036205, "chrf_score": 47.448762940531495, "xcomet_score": 0.9003750085830688, "xcomet_qe_score": 0.8202727437019348, "metricx_score": 2.837570905685425, "metricx_qe_score": 2.5782370567321777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,我们的目标是调查语言模型的政治偏见在多大程度上是从训练数据中体现出来的。", "metrics": {"bleu_score": 73.44670673375127, "chrf_score": 69.27851065990222, "xcomet_score": 0.9298361539840698, "xcomet_qe_score": 0.8625127077102661, "metricx_score": 0.7178402543067932, "metricx_qe_score": 1.2329519987106323, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以进一步通过在六个不同的政党组织中对语言模型进行预训练,以及将新闻和社交媒体更进一步地按照它们的政治取向划分,来进行一个控制实验。", "metrics": {"bleu_score": 28.88261664589946, "chrf_score": 25.085536929342894, "xcomet_score": 0.7867515087127686, "xcomet_qe_score": 0.7656868696212769, "metricx_score": 6.0583176612854, "metricx_qe_score": 5.674251556396484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过进一步在这些派别中训练语言模型,我们可以看到语言模型的意识形态坐标也随之相应地变化。", "metrics": {"bleu_score": 46.25816030789478, "chrf_score": 43.570203841162474, "xcomet_score": 0.7895032167434692, "xcomet_qe_score": 0.7974070906639099, "metricx_score": 4.040626049041748, "metricx_qe_score": 4.354247570037842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于 Robert 进一步细化和在左翼倾向的 Reddit 社群中受到进一步训练,我们可以看到它在政治立场上有了实质性左倾。 从政治偏见的角度来看。", "metrics": {"bleu_score": 21.116842130091822, "chrf_score": 25.787180270841738, "xcomet_score": 0.4358065128326416, "xcomet_qe_score": 0.31773701310157776, "metricx_score": 11.416624069213867, "metricx_qe_score": 9.65727424621582, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图调查语言模型是否能够捕捉到我们现代社会中普遍存在的极化现", "metrics": {"bleu_score": 62.834764117798585, "chrf_score": 56.60349973997082, "xcomet_score": 0.8025245666503906, "xcomet_qe_score": 0.8442274928092957, "metricx_score": 3.5828287601470947, "metricx_qe_score": 1.1693625450134277, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "象。 将预训练模型分为两个不同的时间段:前45位美国总统和后45位美国总统。", "metrics": {"bleu_score": 11.90001243735716, "chrf_score": 15.648128063042677, "xcomet_score": 0.44876736402511597, "xcomet_qe_score": 0.30721792578697205, "metricx_score": 6.206727027893066, "metricx_qe_score": 6.949263572692871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,语言模型通常", "metrics": {"bleu_score": 9.867361567305872, "chrf_score": 10.364033923023323, "xcomet_score": 0.222422793507576, "xcomet_qe_score": 0.13026943802833557, "metricx_score": 14.31352424621582, "metricx_qe_score": 16.4384765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "具有政治倾向,偏离中心更远。2017年后,这", "metrics": {"bleu_score": 14.735023389586004, "chrf_score": 22.387001873617628, "xcomet_score": 0.28217971324920654, "xcomet_qe_score": 0.23468351364135742, "metricx_score": 15.40875244140625, "metricx_qe_score": 8.034579277038574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "表明语言模型也可以反映出我们社会的两极分化。", "metrics": {"bleu_score": 73.95409589871966, "chrf_score": 68.02674912298023, "xcomet_score": 0.8787330389022827, "xcomet_qe_score": 0.8427757024765015, "metricx_score": 1.0560816526412964, "metricx_qe_score": 1.5439507961273193, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但并非最不重要的是,我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测中的表现,这两种情况经常涉及语言模型,并且可能产生非常重要的影响。", "metrics": {"bleu_score": 56.610972817966335, "chrf_score": 55.56631691306757, "xcomet_score": 0.9434723854064941, "xcomet_qe_score": 0.9322754144668579, "metricx_score": 1.1996325254440308, "metricx_qe_score": 2.0449066162109375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,如果我们按类别分析表现——也就是说,如果我们将表现分成—— 不同的人口统计学特征或新闻媒体的政治倾向,我们可以看到一个模式,", "metrics": {"bleu_score": 55.06028867929023, "chrf_score": 48.87627300105877, "xcomet_score": 0.7968461513519287, "xcomet_qe_score": 0.7684633731842041, "metricx_score": 4.600232124328613, "metricx_qe_score": 6.221296787261963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于仇恨言论检测,左翼语言模型表现更好。 在检测针对社会少数群体的仇恨言论方面,我们取得了积极成果。 然而,我们更擅长检测针对我们社会中更强大群体的仇恨言论。", "metrics": {"bleu_score": 49.48191184633124, "chrf_score": 48.42117005120913, "xcomet_score": 0.7474377155303955, "xcomet_qe_score": 0.7829368114471436, "metricx_score": 5.915369033813477, "metricx_qe_score": 5.508469581604004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "反之亦然。语言模型在检测针对白人和男性的仇恨言论方面表现更好,但在检测针对黑人、LGBTQ+和其他少数群体的仇恨言论方面的表现则更糟。", "metrics": {"bleu_score": 69.0824558222984, "chrf_score": 72.63737618439409, "xcomet_score": 0.898781418800354, "xcomet_qe_score": 0.9732975959777832, "metricx_score": 2.447498321533203, "metricx_qe_score": 3.0567073822021484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "类似的趋势也出现在假新闻检测中,我们发现左倾语言模型在检测与其对立的政治倾向的虚假新闻时表现更好,反之亦然。", "metrics": {"bleu_score": 42.557742652525384, "chrf_score": 34.3126629461654, "xcomet_score": 0.9948198795318604, "xcomet_qe_score": 0.9918140172958374, "metricx_score": 0.9390408396720886, "metricx_qe_score": 1.3070112466812134, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个演讲的中文翻译是:'在本节中,我们将进一步展示许多有不同政治倾向的语言模型示例。' 根据它们的社会类别,对仇恨言论和错误信息给出不同的预测。", "metrics": {"bleu_score": 48.05007562107723, "chrf_score": 46.9167928271168, "xcomet_score": 0.21160295605659485, "xcomet_qe_score": 0.2599399983882904, "metricx_score": 4.640745639801025, "metricx_qe_score": 4.557286739349365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "附录中还有更多的例子来进一步说明这一点。 这表明在语言模型的政治偏见方面存在一个非常紧迫的问题。", "metrics": {"bleu_score": 70.37478884644399, "chrf_score": 63.51317898684678, "xcomet_score": 0.9017202258110046, "xcomet_qe_score": 0.8796980977058411, "metricx_score": 1.8332600593566895, "metricx_qe_score": 3.1846351623535156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果一个右翼的语言模型被标记为仇恨言论、虚假信息等等,并部署到一个流行的社交媒体平台上。 这意味着持有相反政治观点的人可能会被边缘化,针对少数群体的仇恨言论可能会肆意横行,而没有任何控制。", "metrics": {"bleu_score": 51.37031227948588, "chrf_score": 45.1847716432632, "xcomet_score": 0.8270999193191528, "xcomet_qe_score": 0.7651689052581787, "metricx_score": 2.4570369720458984, "metricx_qe_score": 2.322622299194336, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,这对我们来说是一个警钟,要认识到并解决语言模型政治倾向性导致的公平问题。", "metrics": {"bleu_score": 37.91638580697949, "chrf_score": 40.49150021406613, "xcomet_score": 0.9927343130111694, "xcomet_qe_score": 0.9914478063583374, "metricx_score": 0.7504122257232666, "metricx_qe_score": 0.8327755331993103, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们还想要提一下", "metrics": {"bleu_score": 10.600313379512592, "chrf_score": 10.159176029962548, "xcomet_score": 0.4405967891216278, "xcomet_qe_score": 0.5021373629570007, "metricx_score": 4.418252944946289, "metricx_qe_score": 3.4746081829071045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",有关语言模型政治偏见的独特两难问题。", "metrics": {"bleu_score": 33.27316905228912, "chrf_score": 35.614811571001844, "xcomet_score": 0.4956703186035156, "xcomet_qe_score": 0.37061700224876404, "metricx_score": 9.959534645080566, "metricx_qe_score": 11.825464248657227, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是在赛拉和卡里夫之间的问题。", "metrics": {"bleu_score": 9.992242441705818, "chrf_score": 11.552121059461905, "xcomet_score": 0.43860986828804016, "xcomet_qe_score": 0.5561776161193848, "metricx_score": 8.10873794555664, "metricx_qe_score": 5.566473960876465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,如果我们不对语言模型训练数据进行去偏化处理,那么偏见将从预训练数据传播到语言模型再到下游任务,最终导致公平性问题。", "metrics": {"bleu_score": 57.86564958619089, "chrf_score": 50.28306963013506, "xcomet_score": 0.9824928045272827, "xcomet_qe_score": 0.9831106662750244, "metricx_score": 1.3538646697998047, "metricx_qe_score": 1.7936948537826538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们试图某种方式去消毒,我们也会冒着被审查或排除的风险。", "metrics": {"bleu_score": 40.67315523312909, "chrf_score": 32.236489842342834, "xcomet_score": 0.8131060004234314, "xcomet_qe_score": 0.7901708483695984, "metricx_score": 3.1263985633850098, "metricx_qe_score": 3.0302112102508545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且非常难以确定什么是实际上中立的,什么应该保留语言监控数据。", "metrics": {"bleu_score": 30.09768386637913, "chrf_score": 28.410504829067758, "xcomet_score": 0.9643667936325073, "xcomet_qe_score": 0.8234964609146118, "metricx_score": 1.339713454246521, "metricx_qe_score": 2.2891321182250977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以它有点像电车难题。", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 67.86976911976912, "xcomet_score": 0.8425853252410889, "xcomet_qe_score": 0.8542683124542236, "metricx_score": 1.8047329187393188, "metricx_qe_score": 3.328723907470703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,", "metrics": {"bleu_score": 0.0, "chrf_score": 38.888888888888886, "xcomet_score": 0.9909268617630005, "xcomet_qe_score": 0.973970890045166, "metricx_score": 0.3818603754043579, "metricx_qe_score": 0.3029481768608093, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢。我今天就这些了。", "metrics": {"bleu_score": 12.661968357569915, "chrf_score": 11.263007376312038, "xcomet_score": 0.7858412861824036, "xcomet_qe_score": 0.7290186882019043, "metricx_score": 0.8912203311920166, "metricx_qe_score": 1.0024347305297852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,明", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.22867214679718018, "xcomet_qe_score": 0.3400575518608093, "metricx_score": 4.109807968139648, "metricx_qe_score": 0.7964972257614136, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9877438545227051, "xcomet_qe_score": 0.9831967353820801, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是哥伦比亚大学梅尔学院的四年级助教珍妮。今天我将展示我的研究成果《面向对象设计模式的建模》。", "metrics": {"bleu_score": 8.830467063343967, "chrf_score": 8.422561129439792, "xcomet_score": 0.293366014957428, "xcomet_qe_score": 0.5377515554428101, "metricx_score": 7.765434265136719, "metricx_qe_score": 7.315389633178711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在华盛顿大学和艾伦人工智能研究所的某些人的合作下完成的,具体包括:塞巴斯蒂安·桑迪、罗南·拉布拉斯、卡特琳娜·雷尼茨基和马丁·萨普。", "metrics": {"bleu_score": 25.703820549952784, "chrf_score": 19.209965342928903, "xcomet_score": 0.865433931350708, "xcomet_qe_score": 0.8662207126617432, "metricx_score": 1.216314435005188, "metricx_qe_score": 0.9326053857803345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,让我们从想象开始。你为一家报纸工作,你在新闻文章下筛选评论,试图删除有害内容。", "metrics": {"bleu_score": 38.735887363542695, "chrf_score": 33.17727510106326, "xcomet_score": 0.9064522981643677, "xcomet_qe_score": 0.9053755402565002, "metricx_score": 1.5432219505310059, "metricx_qe_score": 1.49723219871521, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你可能会倾向于使用一个流行的API,比如Toxicity Detection API来检测毒性。如果你是Carl Jones,这工作得很好", "metrics": {"bleu_score": 31.18458306388374, "chrf_score": 35.92023859999792, "xcomet_score": 0.6310311555862427, "xcomet_qe_score": 0.7404749393463135, "metricx_score": 4.547481060028076, "metricx_qe_score": 4.112318992614746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因为Toxicity Detection API能够正确地检测出有毒的实例。", "metrics": {"bleu_score": 21.951524426618455, "chrf_score": 27.439605226232246, "xcomet_score": 0.6027328372001648, "xcomet_qe_score": 0.7709101438522339, "metricx_score": 4.666520595550537, "metricx_qe_score": 3.815535545349121, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,这并不是Adithya Sharma的情况,Adithya Sharma", "metrics": {"bleu_score": 6.608973813188645, "chrf_score": 31.109274125305852, "xcomet_score": 0.6838371753692627, "xcomet_qe_score": 0.550814151763916, "metricx_score": 11.747536659240723, "metricx_qe_score": 7.384459495544434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在使用透视API时并不像印度语境中更常见的攻击性术语那样敏感。", "metrics": {"bleu_score": 34.89114253463821, "chrf_score": 28.91783204765285, "xcomet_score": 0.6511818170547485, "xcomet_qe_score": 0.39125895500183105, "metricx_score": 5.904857158660889, "metricx_qe_score": 7.312481880187988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是设计偏见的一个例子,我们在这里看到技术在人群之间产生系统性表现差异。", "metrics": {"bleu_score": 37.13354961020269, "chrf_score": 32.91342250690389, "xcomet_score": 0.978806734085083, "xcomet_qe_score": 0.9068145751953125, "metricx_score": 1.0731662511825562, "metricx_qe_score": 1.2148287296295166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "设计偏见,比如我们之前看到的那种,可能由于 NLP 研究者和模型开发者的定位而产生。", "metrics": {"bleu_score": 19.82658221163295, "chrf_score": 17.718088648320478, "xcomet_score": 0.9254271984100342, "xcomet_qe_score": 0.9775875806808472, "metricx_score": 1.8057323694229126, "metricx_qe_score": 1.6727943420410156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "定位是指人们由于其人口统计学、身份和生活经历而持有的观点。", "metrics": {"bleu_score": 62.49375476550578, "chrf_score": 60.0309204643968, "xcomet_score": 0.7912410497665405, "xcomet_qe_score": 0.8432405591011047, "metricx_score": 4.285412788391113, "metricx_qe_score": 3.5478527545928955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个概念在批判性研究中被广泛使用,尤其是在女权主义和queer studies学术领域。", "metrics": {"bleu_score": 32.723573253329484, "chrf_score": 26.74913851770095, "xcomet_score": 0.9874712228775024, "xcomet_qe_score": 0.9685375690460205, "metricx_score": 1.7377349138259888, "metricx_qe_score": 1.1226972341537476, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "作为研究人员,位置性可以影响研究过程及其成果,因为它可以改变研究人员的决策。", "metrics": {"bleu_score": 39.339458076536, "chrf_score": 32.97821170678273, "xcomet_score": 0.8271660804748535, "xcomet_qe_score": 0.8451664447784424, "metricx_score": 4.225904941558838, "metricx_qe_score": 3.2465739250183105, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,人们可能会问的一个问题是:数据集和模型有定位性吗?", "metrics": {"bleu_score": 42.7287006396234, "chrf_score": 36.244137268621316, "xcomet_score": 0.9268629550933838, "xcomet_qe_score": 0.9890483617782593, "metricx_score": 2.3404741287231445, "metricx_qe_score": 1.1215980052947998, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们并不是说模型、细胞和数据集本身具有人口统计学身份和生活经历,但它们汇总了真实人们的判断和意见,并且能够代表某些意识形态相对于其他意识形态。", "metrics": {"bleu_score": 49.43574654288331, "chrf_score": 46.77122642909087, "xcomet_score": 0.6675350069999695, "xcomet_qe_score": 0.5984011292457581, "metricx_score": 4.974819660186768, "metricx_qe_score": 4.99531364440918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,前人工作提出了一些位置性的证据,例如文化差距、模型和数据集的定性定义,以及模型位置性的语义定义。 无论", "metrics": {"bleu_score": 27.119817104013922, "chrf_score": 23.151520070262166, "xcomet_score": 0.5089219808578491, "xcomet_qe_score": 0.548319935798645, "metricx_score": 7.845625877380371, "metricx_qe_score": 4.898435592651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如何,这些作品并没有直接将用户与数据集和模型本身进行比较。 随着情境测验变得更加敏感和社会导向,学习模型和数据集定位的重要性日益增加。 这些定位方式是如何倾斜的?因为并非所有决策都记录在案,许多模型隐藏在API之后。", "metrics": {"bleu_score": 41.55553408291577, "chrf_score": 38.69925451488346, "xcomet_score": 0.4349454343318939, "xcomet_qe_score": 0.430477112531662, "metricx_score": 7.361354827880859, "metricx_qe_score": 6.837742805480957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,为了研究数据集和模型定位性,我们实际上会将注释与真实用户和现有的数据集、模型进行对比。", "metrics": {"bleu_score": 44.59078484400744, "chrf_score": 39.307841751431916, "xcomet_score": 0.814781904220581, "xcomet_qe_score": 0.8970833420753479, "metricx_score": 2.606991767883301, "metricx_qe_score": 2.5622804164886475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过框架NLPositionality完成这个任务。", "metrics": {"bleu_score": 23.397625978961173, "chrf_score": 57.96890428412168, "xcomet_score": 0.9248715043067932, "xcomet_qe_score": 0.8341705799102783, "metricx_score": 1.2240961790084839, "metricx_qe_score": 1.3259618282318115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架分为两个主要步骤。", "metrics": {"bleu_score": 43.138943204452076, "chrf_score": 38.37551342601929, "xcomet_score": 0.9702411890029907, "xcomet_qe_score": 0.9063276052474976, "metricx_score": 0.10670393705368042, "metricx_qe_score": 0.35922718048095703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步骤是使用不同的注释器重新注释数据集。", "metrics": {"bleu_score": 72.42447986095323, "chrf_score": 63.16860369878946, "xcomet_score": 0.9981592893600464, "xcomet_qe_score": 1.0, "metricx_score": 0.317583829164505, "metricx_qe_score": 0.5801370739936829, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们应该从原始数据集的标记器的统计学特性来考虑这个问题,因为通常每个实例只会被标记几个标记器,并且由于统计数据很少被收集和共享。", "metrics": {"bleu_score": 35.72758160877959, "chrf_score": 30.129583040643183, "xcomet_score": 0.5277537703514099, "xcomet_qe_score": 0.69386887550354, "metricx_score": 7.2112812995910645, "metricx_qe_score": 6.810932636260986, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们选择重新标注数据,以获取大量注释,并得到丰富的统计信息。", "metrics": {"bleu_score": 23.3828267812487, "chrf_score": 22.237650946908815, "xcomet_score": 0.9659277200698853, "xcomet_qe_score": 0.9673311710357666, "metricx_score": 0.9570941925048828, "metricx_qe_score": 1.1985528469085693, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们使用人口统计学方法对注释进行标注,并将它们与模型和数据集中的模式进行比较,使用皮尔逊相关系数来衡量相似性。 因此,我们的框架实际上与注释器不一致的文献不同,它将用户与模型和数据集的预测以及标签进行比较,而不是只关注注释器的一致性或建模注释器分布。", "metrics": {"bleu_score": 45.272947636170414, "chrf_score": 42.96678754476332, "xcomet_score": 0.5558730363845825, "xcomet_qe_score": 0.53755784034729, "metricx_score": 5.602614402770996, "metricx_qe_score": 4.613990783691406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架主要是通过Lab in the Wild实现的,这是一个在线众包平台,曾是HCI的合作伙伴。", "metrics": {"bleu_score": 43.04853088478027, "chrf_score": 57.3828780303031, "xcomet_score": 0.9014557003974915, "xcomet_qe_score": 0.7856861352920532, "metricx_score": 2.0900721549987793, "metricx_qe_score": 1.6418492794036865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在野外实验是一个在线实验平台,我们可以招募各种各样的志愿者,", "metrics": {"bleu_score": 47.05896438972141, "chrf_score": 32.39729774681982, "xcomet_score": 0.7791907787322998, "xcomet_qe_score": 0.7426270842552185, "metricx_score": 3.7452304363250732, "metricx_qe_score": 4.273740291595459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与Mturk等平台相比,他们的参与者主要来自美国或印度。而且,在野外实验仍然能够获得高质量的数据。", "metrics": {"bleu_score": 58.60615974797564, "chrf_score": 47.43694278687252, "xcomet_score": 0.7463541626930237, "xcomet_qe_score": 0.7494098544120789, "metricx_score": 4.274309158325195, "metricx_qe_score": 5.026259899139404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会在野外举办两个任务型实验室,其中一个涉及社会可接受性。这个实验的运作方式是参与者会从社会化学数据集中阅读一个情境,并且写下他们认为这个情境在社会上是否可接受。", "metrics": {"bleu_score": 33.748483070915384, "chrf_score": 27.772303603188597, "xcomet_score": 0.7451205849647522, "xcomet_qe_score": 0.8906261920928955, "metricx_score": 3.0729987621307373, "metricx_qe_score": 2.639051914215088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后,为了保持对研究的兴趣,他们可以将自己的反应与AI和其他人进行比较。", "metrics": {"bleu_score": 41.06858352547416, "chrf_score": 34.57381855422036, "xcomet_score": 0.9420222043991089, "xcomet_qe_score": 0.9749020338058472, "metricx_score": 1.625186800956726, "metricx_qe_score": 1.1458094120025635, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们将这些注释与社会化学、Delphi和GPT-4进行比较。", "metrics": {"bleu_score": 53.68698525643125, "chrf_score": 63.00275970013177, "xcomet_score": 0.8526265621185303, "xcomet_qe_score": 0.8461352586746216, "metricx_score": 1.3322325944900513, "metricx_qe_score": 1.7736155986785889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们为毒性仇恨言论检测任务创建了一个类似的设置,在那里他们将阅读Dina Hate的示例,并写下他们是否认为这是一个仇恨言论的例子。", "metrics": {"bleu_score": 46.376907643040255, "chrf_score": 39.44314148328583, "xcomet_score": 0.7929565906524658, "xcomet_qe_score": 0.7559510469436646, "metricx_score": 5.785218238830566, "metricx_qe_score": 6.0840840339660645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究最终收集了超过一万", "metrics": {"bleu_score": 2.0045178889630537, "chrf_score": 1.1874036634763594, "xcomet_score": 0.11325801908969879, "xcomet_qe_score": 0.09415752440690994, "metricx_score": 19.939346313476562, "metricx_qe_score": 19.97551155090332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "六千个注释,来自一千名标注者,来自于八十七个国家。 所以,", "metrics": {"bleu_score": 7.615980926838922, "chrf_score": 7.775946945018822, "xcomet_score": 0.34364455938339233, "xcomet_qe_score": 0.3107895255088806, "metricx_score": 7.56174373626709, "metricx_qe_score": 5.44440221786499, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们已经准备好回答:谁与NLP数据集和模型最匹配?我们", "metrics": {"bleu_score": 30.451258861070496, "chrf_score": 32.278598191123336, "xcomet_score": 0.6818013191223145, "xcomet_qe_score": 0.6910102367401123, "metricx_score": 5.744263172149658, "metricx_qe_score": 1.5887014865875244, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现,在NLP中存在位置性。", "metrics": {"bleu_score": 10.320382724810015, "chrf_score": 19.097154498330227, "xcomet_score": 0.8379414677619934, "xcomet_qe_score": 0.8453061580657959, "metricx_score": 4.330549716949463, "metricx_qe_score": 2.7015631198883057, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们发现数据集和模型大多与说英语的国家相关。", "metrics": {"bleu_score": 41.24216393269556, "chrf_score": 37.73727200068904, "xcomet_score": 0.9878928661346436, "xcomet_qe_score": 0.9902012348175049, "metricx_score": 1.062114953994751, "metricx_qe_score": 0.8786526918411255, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在针对GPT-4进行的社会接受性分析中,我们发现它最符合孔子和说英语的国家。我们还发现", "metrics": {"bleu_score": 21.055668975171354, "chrf_score": 24.070605656787013, "xcomet_score": 0.5128139853477478, "xcomet_qe_score": 0.47990670800209045, "metricx_score": 6.558218002319336, "metricx_qe_score": 4.206714153289795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "“Dina hate”也大多与说英语的国家相关。", "metrics": {"bleu_score": 7.439820585622744, "chrf_score": 22.952894579348975, "xcomet_score": 0.83125901222229, "xcomet_qe_score": 0.9008296132087708, "metricx_score": 5.875328063964844, "metricx_qe_score": 6.70637845993042, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,大多数额外的匹配与拥有大学教育的人有关。", "metrics": {"bleu_score": 22.996555266211946, "chrf_score": 18.230187438660927, "xcomet_score": 0.7990214824676514, "xcomet_qe_score": 0.8307234048843384, "metricx_score": 1.5875587463378906, "metricx_qe_score": 1.0924590826034546, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在社会可接受性任务中,我们发现GPT-4最适合那些有大学教育或研究生学历的人。 同样,我们在乔纳森·海特身上也发现了这一点,他在接受大学教育的人中最受欢迎。", "metrics": {"bleu_score": 33.24925862987355, "chrf_score": 30.68804375435511, "xcomet_score": 0.5617097616195679, "xcomet_qe_score": 0.5665788650512695, "metricx_score": 6.379782199859619, "metricx_qe_score": 6.5565972328186035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,当模型和数据集与特定人群相关联时,一些模型不可避免地会被落下。", "metrics": {"bleu_score": 45.37706080874599, "chrf_score": 40.067871634951885, "xcomet_score": 0.7736475467681885, "xcomet_qe_score": 0.7878700494766235, "metricx_score": 5.675883769989014, "metricx_qe_score": 4.090895652770996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在社会可接受性任务(G", "metrics": {"bleu_score": 2.0045178889630537, "chrf_score": 2.511738458397737, "xcomet_score": 0.13465866446495056, "xcomet_qe_score": 0.14804892241954803, "metricx_score": 23.07408905029297, "metricx_qe_score": 13.347558975219727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "PT-4 Social Acceptability Task)以及代沟恐惧任务分析中,我们发现这种差异。", "metrics": {"bleu_score": 17.598439128806362, "chrf_score": 14.773315056075939, "xcomet_score": 0.6928502321243286, "xcomet_qe_score": 0.7376478314399719, "metricx_score": 7.467028617858887, "metricx_qe_score": 9.926220893859863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,既然ADLP中有空位,我们能做些什么呢?", "metrics": {"bleu_score": 36.92410708813977, "chrf_score": 33.004819360654594, "xcomet_score": 0.7865656614303589, "xcomet_qe_score": 0.8372004628181458, "metricx_score": 6.057466506958008, "metricx_qe_score": 5.335160732269287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们有几点建议。", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 19.46127946127946, "xcomet_score": 0.9969221353530884, "xcomet_qe_score": 0.9799933433532715, "metricx_score": 0.11868984252214432, "metricx_qe_score": 0.12049407511949539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,在研究过程中要记录所有相关的设计选择。另一个", "metrics": {"bleu_score": 37.741550355329075, "chrf_score": 29.868639814291992, "xcomet_score": 0.8648393750190735, "xcomet_qe_score": 0.8171408176422119, "metricx_score": 3.9534783363342285, "metricx_qe_score": 0.47547441720962524, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是进行以视角主义为维度的NLP研究。", "metrics": {"bleu_score": 11.09254338857922, "chrf_score": 10.943063114294981, "xcomet_score": 0.7628377676010132, "xcomet_qe_score": 0.7948267459869385, "metricx_score": 3.4777419567108154, "metricx_qe_score": 3.1539554595947266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第三项建议是,在四个特定的社区内建立专门的数据集和模型。", "metrics": {"bleu_score": 53.58147059450147, "chrf_score": 48.09570971140409, "xcomet_score": 0.9888482093811035, "xcomet_qe_score": 0.9293751120567322, "metricx_score": 0.5473537445068359, "metricx_qe_score": 1.364066481590271, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个很好的例子,例如Masakini倡议。", "metrics": {"bleu_score": 49.582717346593746, "chrf_score": 49.99173515266798, "xcomet_score": 0.6940259337425232, "xcomet_qe_score": 0.6476336717605591, "metricx_score": 3.4213883876800537, "metricx_qe_score": 4.72149133682251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们想强调的是包容性NLP不仅仅使所有技术都", "metrics": {"bleu_score": 47.97543511401897, "chrf_score": 44.483162749416614, "xcomet_score": 0.4893639385700226, "xcomet_qe_score": 0.2576959729194641, "metricx_score": 5.7630085945129395, "metricx_qe_score": 5.363898754119873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "能为每个人工作。", "metrics": {"bleu_score": 3.4331054109918173, "chrf_score": 3.90625, "xcomet_score": 0.4386652708053589, "xcomet_qe_score": 0.4149421155452728, "metricx_score": 5.6807427406311035, "metricx_qe_score": 6.692153453826904, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,这包括我们的介绍。", "metrics": {"bleu_score": 13.545994273378144, "chrf_score": 11.940967575463365, "xcomet_score": 0.5860522985458374, "xcomet_qe_score": 0.7905220985412598, "metricx_score": 5.990915775299072, "metricx_qe_score": 4.956840515136719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是如果你想要学习更多,欢迎查看我们最新分析结果和论文的目录。", "metrics": {"bleu_score": 24.773512798429014, "chrf_score": 23.29097311317292, "xcomet_score": 0.8791735172271729, "xcomet_qe_score": 0.8749301433563232, "metricx_score": 2.7219223976135254, "metricx_qe_score": 2.1343631744384766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是来自复旦大学的苏玉燕。", "metrics": {"bleu_score": 52.812131374276895, "chrf_score": 36.97136452236978, "xcomet_score": 0.7936868667602539, "xcomet_qe_score": 0.7001123428344727, "metricx_score": 0.777617335319519, "metricx_qe_score": 1.2245869636535645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我在这里介绍我们的工作,即“区分脚本知识与大规模语言模型对于约束语言规划的影响”。", "metrics": {"bleu_score": 26.66372228396489, "chrf_score": 23.779431491924566, "xcomet_score": 0.7590579986572266, "xcomet_qe_score": 0.7359118461608887, "metricx_score": 3.8073856830596924, "metricx_qe_score": 3.260106325149536, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在日常生活中,人类通常通过遵循预先设定的指令来进行规划行动。这些指令以规定的脚本形式给出。", "metrics": {"bleu_score": 24.27642125221592, "chrf_score": 24.53481201797215, "xcomet_score": 0.9875661134719849, "xcomet_qe_score": 0.9753644466400146, "metricx_score": 1.226751446723938, "metricx_qe_score": 1.9056463241577148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先前的工作利用语言模型来规划抽象的、类型化的活动,例如做蛋糕", "metrics": {"bleu_score": 35.14695809705863, "chrf_score": 31.683233753701103, "xcomet_score": 0.9959181547164917, "xcomet_qe_score": 1.0, "metricx_score": 2.0407047271728516, "metricx_qe_score": 1.590783953666687, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",并且表明大型语言模型能够有效地将活动分解成步骤。", "metrics": {"bleu_score": 23.89677068245137, "chrf_score": 20.69251076717749, "xcomet_score": 0.8900860548019409, "xcomet_qe_score": 0.879072904586792, "metricx_score": 4.4416680335998535, "metricx_qe_score": 4.083234786987305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,先前的工作主要集中在为抽象的目标规划活动,对于具体目标、特定", "metrics": {"bleu_score": 18.21038896383151, "chrf_score": 21.309279715021255, "xcomet_score": 0.5764251947402954, "xcomet_qe_score": 0.6226001977920532, "metricx_score": 8.69651985168457, "metricx_qe_score": 4.847426891326904, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "约束条件下的规划仍然鲜有研究。例如,制作巧克力蛋糕这样的目标,仍然未得到充分的研究。", "metrics": {"bleu_score": 15.02214978453912, "chrf_score": 17.573584624567115, "xcomet_score": 0.9579371213912964, "xcomet_qe_score": 0.9574817419052124, "metricx_score": 2.054893732070923, "metricx_qe_score": 2.1166391372680664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这篇文章中,我们定义了约束语言规划问题。 规划过程会受到不同约束的影响", "metrics": {"bleu_score": 22.140294717004714, "chrf_score": 20.031231603624924, "xcomet_score": 0.8431872129440308, "xcomet_qe_score": 0.8187798261642456, "metricx_score": 4.082577705383301, "metricx_qe_score": 3.3355345726013184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",因此可以为不同的现实生活特定目标制定出多种规划方案。", "metrics": {"bleu_score": 8.386752120830321, "chrf_score": 10.91216801838765, "xcomet_score": 0.37383314967155457, "xcomet_qe_score": 0.42429500818252563, "metricx_score": 8.56912899017334, "metricx_qe_score": 9.193442344665527, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个好的规划者应该编写符合约束条件的合理且可行的剧本。", "metrics": {"bleu_score": 24.638317920254316, "chrf_score": 21.58433859344941, "xcomet_score": 0.8699530363082886, "xcomet_qe_score": 0.8581371307373047, "metricx_score": 2.3050222396850586, "metricx_qe_score": 1.6767572164535522, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这篇论文中,我们首先评估并改进了大规模语言模型的约束语言规划能力。", "metrics": {"bleu_score": 58.4542735574288, "chrf_score": 56.05477848983672, "xcomet_score": 0.9058975577354431, "xcomet_qe_score": 0.8791070580482483, "metricx_score": 0.8750648498535156, "metricx_qe_score": 0.8569168448448181, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了特定种类的鸟儿外,其他动物没有冬眠的习惯。 我们必须首先获得这些基础。", "metrics": {"bleu_score": 19.951297936500804, "chrf_score": 17.399956520568473, "xcomet_score": 0.15313862264156342, "xcomet_qe_score": 0.13988037407398224, "metricx_score": 8.14786434173584, "metricx_qe_score": 7.321357250213623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "看表,我们为人类遗传数据采集使用结构化CPG。 从大型语言模型中随机", "metrics": {"bleu_score": 8.958165282970155, "chrf_score": 8.251219324593647, "xcomet_score": 0.23412267863750458, "xcomet_qe_score": 0.23174068331718445, "metricx_score": 13.768258094787598, "metricx_qe_score": 10.160270690917969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "抽取一百个样本,并评估由此产生的脚本。", "metrics": {"bleu_score": 13.669299099755102, "chrf_score": 13.536191746876403, "xcomet_score": 0.7616446018218994, "xcomet_qe_score": 0.881538987159729, "metricx_score": 3.6932992935180664, "metricx_qe_score": 5.512456893920898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个表格反映了结果的总体准确性。", "metrics": {"bleu_score": 40.325042950627804, "chrf_score": 32.17717135556109, "xcomet_score": 0.9834535121917725, "xcomet_qe_score": 0.9912443161010742, "metricx_score": 0.4477231204509735, "metricx_qe_score": 0.37705740332603455, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,所有线性模型在为特定目标规划时都取得了令人满意的结果。", "metrics": {"bleu_score": 17.44876789068134, "chrf_score": 19.589547700234892, "xcomet_score": 0.6766144633293152, "xcomet_qe_score": 0.6473691463470459, "metricx_score": 5.84335994720459, "metricx_qe_score": 5.961098670959473, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们进行详细分析,探讨为什么线性模型失败。", "metrics": {"bleu_score": 31.26851492272872, "chrf_score": 24.435045295696536, "xcomet_score": 0.8687844276428223, "xcomet_qe_score": 0.831305742263794, "metricx_score": 1.3873543739318848, "metricx_qe_score": 1.360683798789978, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该图中的结果表明,生成脚本的语义完整性是可以接受的,但对约束的忠实性则不能得到保证。", "metrics": {"bleu_score": 52.99765136536847, "chrf_score": 46.068504341543544, "xcomet_score": 0.9257665872573853, "xcomet_qe_score": 0.9061357975006104, "metricx_score": 1.1978363990783691, "metricx_qe_score": 1.6067839860916138, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们深入研究了维基百科中关于约束的更细粒度的主题分类。", "metrics": {"bleu_score": 16.805936904720344, "chrf_score": 15.211293343324398, "xcomet_score": 0.7586603760719299, "xcomet_qe_score": 0.801241397857666, "metricx_score": 2.6251697540283203, "metricx_qe_score": 2.7085986137390137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "图中的主图表明,不同类别下的指导性能差异很大。", "metrics": {"bleu_score": 15.115881337577886, "chrf_score": 12.3235200837053, "xcomet_score": 0.5963060855865479, "xcomet_qe_score": 0.35995739698410034, "metricx_score": 6.77396821975708, "metricx_qe_score": 6.614683628082275, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "先前的研究已经表明,兰银官话模型的输出质量呈现高度变异性,导致性能不佳。", "metrics": {"bleu_score": 29.28650078405604, "chrf_score": 29.277667185433838, "xcomet_score": 0.7122461795806885, "xcomet_qe_score": 0.6733623147010803, "metricx_score": 4.804680347442627, "metricx_qe_score": 5.304327487945557, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们采用了过生成网络的思想来提高生成质量。", "metrics": {"bleu_score": 38.00984251077832, "chrf_score": 33.21266336521059, "xcomet_score": 0.809765100479126, "xcomet_qe_score": 0.794937252998352, "metricx_score": 5.152154445648193, "metricx_qe_score": 6.126753807067871, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首先展示约束类型,并给出一个例子,是关于非线性规划的。然后根据这个抽象目标获得特定的目标。", "metrics": {"bleu_score": 25.057095338034678, "chrf_score": 21.84248666351402, "xcomet_score": 0.815789520740509, "xcomet_qe_score": 0.7077236175537109, "metricx_score": 2.8905510902404785, "metricx_qe_score": 4.463407516479492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,为特定的课程创建GPT原始脚本。", "metrics": {"bleu_score": 10.563719077629843, "chrf_score": 10.409698508770783, "xcomet_score": 0.662804365158081, "xcomet_qe_score": 0.7986847162246704, "metricx_score": 6.440885066986084, "metricx_qe_score": 6.3758864402771, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,一个过滤器模型被开发出来选择最有效的脚本。", "metrics": {"bleu_score": 29.20529034990032, "chrf_score": 25.356101501504526, "xcomet_score": 0.948766827583313, "xcomet_qe_score": 0.9196057319641113, "metricx_score": 1.639901876449585, "metricx_qe_score": 1.5390915870666504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将脚本和指南转换为结构化的JSON嵌入,并计算余弦相似度和相似性分数,以衡量语义相似性。", "metrics": {"bleu_score": 43.27761500710453, "chrf_score": 29.85183127002895, "xcomet_score": 0.7098914384841919, "xcomet_qe_score": 0.6349900960922241, "metricx_score": 2.9319186210632324, "metricx_qe_score": 3.089951992034912, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在注意力集中时,我们只保留包含目标约束关键字的脚本。如果目标鬼", "metrics": {"bleu_score": 28.381756881487178, "chrf_score": 31.35765953036379, "xcomet_score": 0.29749947786331177, "xcomet_qe_score": 0.16403239965438843, "metricx_score": 11.500899314880371, "metricx_qe_score": 9.024073600769043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在鬼点数中得分最高,则保留该脚本。", "metrics": {"bleu_score": 20.129095230626774, "chrf_score": 18.652999218625794, "xcomet_score": 0.5527370572090149, "xcomet_qe_score": 0.5592530965805054, "metricx_score": 6.457712650299072, "metricx_qe_score": 7.143039703369141, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法可以生成更高品质的丝。", "metrics": {"bleu_score": 41.24031409925812, "chrf_score": 24.524264965395382, "xcomet_score": 0.7491926550865173, "xcomet_qe_score": 0.7259647250175476, "metricx_score": 6.303805351257324, "metricx_qe_score": 8.526119232177734, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法在句法完整性、语法正确性和对约束的忠实度方面有很大改进。 小型和", "metrics": {"bleu_score": 39.319919825365815, "chrf_score": 32.93712415532156, "xcomet_score": 0.37473711371421814, "xcomet_qe_score": 0.501092791557312, "metricx_score": 6.083347320556641, "metricx_qe_score": 5.022704601287842, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "专门化的语言模型由于部署成本高,因此有必要启用语言规划能力。", "metrics": {"bleu_score": 32.64446433470443, "chrf_score": 28.69241545280765, "xcomet_score": 0.795441746711731, "xcomet_qe_score": 0.7371499538421631, "metricx_score": 5.072301387786865, "metricx_qe_score": 4.52605676651001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建数据集是此过程中的重要步骤。", "metrics": {"bleu_score": 42.24046321224261, "chrf_score": 35.05124177299194, "xcomet_score": 0.9994981288909912, "xcomet_qe_score": 0.9989702701568604, "metricx_score": 0.21467624604701996, "metricx_qe_score": 0.25287926197052, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,先前的研究并没有为特定目标进行计划,并且手动数据集注释是昂贵", "metrics": {"bleu_score": 22.23682417980667, "chrf_score": 18.34358011920982, "xcomet_score": 0.8224232196807861, "xcomet_qe_score": 0.7234333157539368, "metricx_score": 3.0102550983428955, "metricx_qe_score": 2.6564626693725586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的。 他们遵循象征性知识抽取(symbolic knowledge distillation)的理念,从大规模语言模型中抽取约束语言规划数据集中的知识。", "metrics": {"bleu_score": 24.67772115289827, "chrf_score": 21.41136634914553, "xcomet_score": 0.4619200527667999, "xcomet_qe_score": 0.4935489296913147, "metricx_score": 5.720707416534424, "metricx_qe_score": 4.547793865203857, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将应用我们构建的联合语言规划数据集,名为CoScript。", "metrics": {"bleu_score": 27.334598102226135, "chrf_score": 41.48760505889278, "xcomet_score": 0.7151764631271362, "xcomet_qe_score": 0.8119077682495117, "metricx_score": 2.451916217803955, "metricx_qe_score": 1.8620370626449585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总共生成了五万五千个特定脚本。", "metrics": {"bleu_score": 11.466219374216891, "chrf_score": 10.87773074898944, "xcomet_score": 0.8011273741722107, "xcomet_qe_score": 0.817600667476654, "metricx_score": 4.4817705154418945, "metricx_qe_score": 4.031754970550537, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了确保验证质量和测试用例的准确性,我们请了外包的工人来修正不正确的示例。", "metrics": {"bleu_score": 20.31552942077615, "chrf_score": 18.981526826177614, "xcomet_score": 0.8368295431137085, "xcomet_qe_score": 0.7850627899169922, "metricx_score": 2.066749334335327, "metricx_qe_score": 1.7520447969436646, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个图显示了受限分布的词频。", "metrics": {"bleu_score": 23.397625978961173, "chrf_score": 14.764076542459243, "xcomet_score": 0.8004165887832642, "xcomet_qe_score": 0.8150995969772339, "metricx_score": 4.485953330993652, "metricx_qe_score": 4.94245719909668, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,coscript在生成特定语句时具有高度的并行性。", "metrics": {"bleu_score": 18.27974486914642, "chrf_score": 28.88891091988212, "xcomet_score": 0.7577548623085022, "xcomet_qe_score": 0.7212715148925781, "metricx_score": 5.0713725090026855, "metricx_qe_score": 4.917710304260254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用coscript,我们可以创建更小但专用的模型来进行受限语言规划。", "metrics": {"bleu_score": 57.27098748750564, "chrf_score": 46.52386348620284, "xcomet_score": 0.9294373393058777, "xcomet_qe_score": 0.7631035447120667, "metricx_score": 1.684200406074524, "metricx_qe_score": 2.751741886138916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现T5L-100x在词汇量上可以生成比大多数大型语言模型更高的质量的代码片段,这表明小型模型可以在适当的数据集上训练后能够支持比大型模型更大的模型。", "metrics": {"bleu_score": 38.58724405742325, "chrf_score": 29.223627559537118, "xcomet_score": 0.6603380441665649, "xcomet_qe_score": 0.6607838869094849, "metricx_score": 7.768138408660889, "metricx_qe_score": 7.045845031738281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们建立了约束语言规划问题,", "metrics": {"bleu_score": 43.11806946313792, "chrf_score": 36.71573197983085, "xcomet_score": 0.8418234586715698, "xcomet_qe_score": 0.7958364486694336, "metricx_score": 3.2652602195739746, "metricx_qe_score": 4.342892646789551, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "评估了大规模语言模型的约束语言规划能力,并为大规模语言模型开发了一种超生成滤波方法。", "metrics": {"bleu_score": 45.78625460496259, "chrf_score": 38.21932185052512, "xcomet_score": 0.7604678869247437, "xcomet_qe_score": 0.7740374803543091, "metricx_score": 2.7139697074890137, "metricx_qe_score": 3.367849826812744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用大型语言模型来生成高质量的约束语言规划数据集CoScipt。", "metrics": {"bleu_score": 43.41520212706683, "chrf_score": 40.01183026876664, "xcomet_score": 0.8745405673980713, "xcomet_qe_score": 0.836669385433197, "metricx_score": 3.58471417427063, "metricx_qe_score": 4.1695942878723145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望CoScipt数据集能够成为研究语言规划的一个有价值资源。", "metrics": {"bleu_score": 33.742407814301316, "chrf_score": 45.29381089990399, "xcomet_score": 0.9515960216522217, "xcomet_qe_score": 0.9556097984313965, "metricx_score": 2.358058214187622, "metricx_qe_score": 2.9223504066467285, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "感谢您花时间!", "metrics": {"bleu_score": 12.100518276540289, "chrf_score": 11.061210911510312, "xcomet_score": 0.9899739027023315, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.8728597164154053, "metricx_qe_score": 0.6293622851371765, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请在我们的纸上找到更多关于CoScript的细节。", "metrics": {"bleu_score": 25.320877421478123, "chrf_score": 40.88837894860511, "xcomet_score": 0.8058959245681763, "xcomet_qe_score": 0.8074815273284912, "metricx_score": 5.217596530914307, "metricx_qe_score": 4.667384147644043, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫薛宏。", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 13.375784036811606, "xcomet_score": 0.851665735244751, "xcomet_qe_score": 0.8562054634094238, "metricx_score": 0.1083301305770874, "metricx_qe_score": 0.36983102560043335, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我要介绍的论文是:康纳·特里门命名实体标签在2023年仍然有效吗?", "metrics": {"bleu_score": 30.069895016068635, "chrf_score": 25.727314277369977, "xcomet_score": 0.7635059356689453, "xcomet_qe_score": 0.7636289596557617, "metricx_score": 4.79303503036499, "metricx_qe_score": 4.019043922424316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "让我们开始吧。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9996732473373413, "xcomet_qe_score": 0.9978755712509155, "metricx_score": 0.06470449268817902, "metricx_qe_score": 0.4635288119316101, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文调查了使用命名实体识别任务或NER任务进行泛化的问题。", "metrics": {"bleu_score": 41.00652700532254, "chrf_score": 37.000425412463386, "xcomet_score": 0.7798771858215332, "xcomet_qe_score": 0.8157046437263489, "metricx_score": 2.0583271980285645, "metricx_qe_score": 4.090511798858643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到,模型们已经使用卷积神经网络发展ner系统大约二十年了。这自然引起了一些问题。", "metrics": {"bleu_score": 22.638633395011215, "chrf_score": 16.322295882984456, "xcomet_score": 0.7151206731796265, "xcomet_qe_score": 0.6569952964782715, "metricx_score": 6.418103218078613, "metricx_qe_score": 6.966937065124512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,这些模型能够推广到更多的数据上吗?", "metrics": {"bleu_score": 23.5884481065342, "chrf_score": 22.208189912825834, "xcomet_score": 0.872422456741333, "xcomet_qe_score": 0.864452600479126, "metricx_score": 0.6757897138595581, "metricx_qe_score": 0.6277633309364319, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们开发新的标记时,什么对于良好的泛化是必要的?", "metrics": {"bleu_score": 43.5808260843641, "chrf_score": 36.692433616486895, "xcomet_score": 0.8886725902557373, "xcomet_qe_score": 0.8595590591430664, "metricx_score": 1.288844347000122, "metricx_qe_score": 1.2824369668960571, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,如果我们确实观察到泛化性能不佳,那么是什么导致了这些模型的性能下降呢?", "metrics": {"bleu_score": 63.56803094319039, "chrf_score": 61.410812382972594, "xcomet_score": 0.9975640773773193, "xcomet_qe_score": 0.9929285049438477, "metricx_score": 0.7732522487640381, "metricx_qe_score": 0.8399341702461243, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了解决这些问题,我们开发了Connel加加数据集。", "metrics": {"bleu_score": 42.34885228074744, "chrf_score": 35.175272925639646, "xcomet_score": 0.7412809729576111, "xcomet_qe_score": 0.7533134818077087, "metricx_score": 5.62969446182251, "metricx_qe_score": 5.139700889587402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是一个从Reuter新闻中收集并经过相同2003年注释指南标注的数据集。", "metrics": {"bleu_score": 22.0525236350842, "chrf_score": 18.77256498819356, "xcomet_score": 0.6652536392211914, "xcomet_qe_score": 0.711273193359375, "metricx_score": 5.825262546539307, "metricx_qe_score": 5.351135730743408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们在康耐尔二千零三上对超过二十个模型进行了微调。", "metrics": {"bleu_score": 33.64932442330151, "chrf_score": 28.225236677202325, "xcomet_score": 0.7588032484054565, "xcomet_qe_score": 0.8148269057273865, "metricx_score": 5.043669700622559, "metricx_qe_score": 5.026852130889893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们根据康耐尔三套测试集和康耐尔加加测试集对它们进行了评估。", "metrics": {"bleu_score": 36.23622950304331, "chrf_score": 29.11982070817114, "xcomet_score": 0.7439959049224854, "xcomet_qe_score": 0.6929364204406738, "metricx_score": 3.9285902976989746, "metricx_qe_score": 3.1452369689941406, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但并非最不重要的是,我们计算了f_1中百分比的变化,以评估每个模型的一般化。", "metrics": {"bleu_score": 32.393047213842074, "chrf_score": 35.917563690211104, "xcomet_score": 0.9051629304885864, "xcomet_qe_score": 0.9129805564880371, "metricx_score": 3.552361011505127, "metricx_qe_score": 3.03246808052063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "那么,良好的泛化需要什么呢?", "metrics": {"bleu_score": 39.93614954790575, "chrf_score": 31.717184563651685, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30326253175735474, "metricx_qe_score": 0.3970264792442322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现有三个主要成分是必不可少的。", "metrics": {"bleu_score": 20.80315522738391, "chrf_score": 19.012442196116147, "xcomet_score": 0.9936164617538452, "xcomet_qe_score": 1.0, "metricx_score": 0.18900355696678162, "metricx_qe_score": 0.15659016370773315, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是模型架构。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.99041748046875, "xcomet_qe_score": 0.9915783405303955, "metricx_score": 0.0, "metricx_qe_score": 0.10443663597106934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过我们的实验,我们发现变换器模型通常对新数据的泛化性能更好。", "metrics": {"bleu_score": 55.011565192794656, "chrf_score": 36.165643982628204, "xcomet_score": 0.9908013343811035, "xcomet_qe_score": 0.9812777042388916, "metricx_score": 1.8003551959991455, "metricx_qe_score": 1.7036696672439575, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个成分是模型大小。", "metrics": {"bleu_score": 29.0374612189482, "chrf_score": 27.07335820776018, "xcomet_score": 0.8915048837661743, "xcomet_qe_score": 0.8363902568817139, "metricx_score": 0.4127183258533478, "metricx_qe_score": 0.6761739253997803, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,通常情况下,更大的模型会导致更好的泛化。", "metrics": {"bleu_score": 39.8808919781778, "chrf_score": 34.52240803399777, "xcomet_score": 0.9961175918579102, "xcomet_qe_score": 0.9817819595336914, "metricx_score": 0.6792738437652588, "metricx_qe_score": 0.8967689275741577, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后但并非最不重要的是,我们都知道,微调示例的数量直接影响下游任务的性能。在这里,", "metrics": {"bleu_score": 47.37206772899839, "chrf_score": 58.61054348199759, "xcomet_score": 0.9202825427055359, "xcomet_qe_score": 0.8810229301452637, "metricx_score": 3.6811139583587646, "metricx_qe_score": 1.889869213104248, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,更多的微调示例实际上也会导致更好的泛化。", "metrics": {"bleu_score": 67.5138946452567, "chrf_score": 58.47351825876147, "xcomet_score": 0.9816000461578369, "xcomet_qe_score": 0.8554470539093018, "metricx_score": 0.6346933841705322, "metricx_qe_score": 0.8460352420806885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的下一个问题是:什么导致某些模型的性能下降? 我们有两个假设。", "metrics": {"bleu_score": 48.01046446317029, "chrf_score": 41.233711250030424, "xcomet_score": 0.9906376600265503, "xcomet_qe_score": 0.990980863571167, "metricx_score": 0.9021774530410767, "metricx_qe_score": 0.745329737663269, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是适应性过度拟合,这是由反复使用同一个测试集导致的过度拟合,通常表现为新测试集上的回归下降。", "metrics": {"bleu_score": 33.32102145979512, "chrf_score": 28.959700313425536, "xcomet_score": 0.8557941317558289, "xcomet_qe_score": 0.8349356651306152, "metricx_score": 4.80516242980957, "metricx_qe_score": 4.613602161407471, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个假设是'温度漂移',即由于火车和测试数据之间温度差的增加而导致的性能下降。", "metrics": {"bleu_score": 41.09877755135645, "chrf_score": 34.03277378693263, "xcomet_score": 0.6233090758323669, "xcomet_qe_score": 0.7516031265258789, "metricx_score": 5.934075355529785, "metricx_qe_score": 3.541879653930664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于适应性过拟合,我们看到从右图中可以看出,红色的最佳拟合线的斜率大于1。", "metrics": {"bleu_score": 42.52589393427692, "chrf_score": 38.62725094554718, "xcomet_score": 0.8476117849349976, "xcomet_qe_score": 0.7947678565979004, "metricx_score": 1.8896784782409668, "metricx_qe_score": 2.4968276023864746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着我们在二零一三年对Coral的每一个改进单元都会翻译成在Coral Plus加上的一个以上的改进单元,这意味着不存在减少回报的情况。", "metrics": {"bleu_score": 25.882495966668916, "chrf_score": 22.333951979334817, "xcomet_score": 0.5656075477600098, "xcomet_qe_score": 0.5913889408111572, "metricx_score": 9.838357925415039, "metricx_qe_score": 9.536558151245117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个例子告诉我们,在这种情况下,适应性过度拟合是没有观察到的。", "metrics": {"bleu_score": 31.37211787812663, "chrf_score": 32.94094062208286, "xcomet_score": 0.8908367156982422, "xcomet_qe_score": 0.9379426836967468, "metricx_score": 2.0541303157806396, "metricx_qe_score": 1.849551796913147, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以什么是气温梯度呢?", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 3.546099290780141, "xcomet_score": 0.4810190498828888, "xcomet_qe_score": 0.7854806780815125, "metricx_score": 6.531796455383301, "metricx_qe_score": 3.917757511138916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于临时漂移,我们进行了一项实验来重新训练或继续对某些模型进行预训练,使用了更多的近期数据。我们发现,随着时间间隔的增大,性能会下降。 这证实了我们的假设,即性能下降的主要原因是温度漂移。", "metrics": {"bleu_score": 46.36648193765568, "chrf_score": 42.20977994570868, "xcomet_score": 0.6566013097763062, "xcomet_qe_score": 0.6064167022705078, "metricx_score": 4.895951271057129, "metricx_qe_score": 4.44525146484375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的结论是,为了进行良好的泛化,我们需要一个更好的模型架构、更大的模型大小以及更多微调的示例。", "metrics": {"bleu_score": 56.76390315743871, "chrf_score": 49.25038039021565, "xcomet_score": 0.9676862955093384, "xcomet_qe_score": 0.8967057466506958, "metricx_score": 0.5448246002197266, "metricx_qe_score": 0.6353480219841003, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且这些目标是相辅相成的,我们不能只有一个成分,但必须在整个过程中都考虑到它们。", "metrics": {"bleu_score": 23.70859559878896, "chrf_score": 24.45522964329142, "xcomet_score": 0.7893584966659546, "xcomet_qe_score": 0.7766735553741455, "metricx_score": 3.2915732860565186, "metricx_qe_score": 3.748081684112549, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还发现这里的性能下降是由温度漂移引起的,令人惊讶的是,这不是由适应性过配造成的,尽管康拉德二千零三已经被使用了超过二十年。", "metrics": {"bleu_score": 33.07522848155164, "chrf_score": 25.680533407471213, "xcomet_score": 0.6453920602798462, "xcomet_qe_score": 0.5907667875289917, "metricx_score": 5.21726655960083, "metricx_qe_score": 5.023319721221924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文标题中提出的问题,康纳两千零三标签在二十三年时是否仍然有效?", "metrics": {"bleu_score": 41.64570611402574, "chrf_score": 29.18756784234386, "xcomet_score": 0.6375548243522644, "xcomet_qe_score": 0.6563873887062073, "metricx_score": 7.446681499481201, "metricx_qe_score": 7.270018100738525, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "答案令人振奋。", "metrics": {"bleu_score": 6.168585410281235, "chrf_score": 5.78113791671386, "xcomet_score": 0.26840922236442566, "xcomet_qe_score": 0.2428317666053772, "metricx_score": 2.0670719146728516, "metricx_qe_score": 2.7518317699432373, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望我们的论文能够促使更多关于如何改进模型泛化能力的研究。", "metrics": {"bleu_score": 75.46697757057083, "chrf_score": 67.58428054868546, "xcomet_score": 0.9895839691162109, "xcomet_qe_score": 0.9991735219955444, "metricx_score": 0.4875507950782776, "metricx_qe_score": 0.48013049364089966, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,请确保检查我们的论文、数据集。如果您有任何问题,请随时联系我。", "metrics": {"bleu_score": 30.6609618877902, "chrf_score": 26.483248729189445, "xcomet_score": 0.9610381126403809, "xcomet_qe_score": 0.9486454725265503, "metricx_score": 0.5184774398803711, "metricx_qe_score": 0.4576909840106964, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢!", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 54.333333333333336, "xcomet_score": 0.9984139204025269, "xcomet_qe_score": 0.9808904528617859, "metricx_score": 0.0, "metricx_qe_score": 0.1765654981136322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "马蒂", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3999422490596771, "xcomet_qe_score": 0.40847983956336975, "metricx_score": 3.303786277770996, "metricx_qe_score": 3.284945249557495, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实体选择中解决间接引用表达式的的工作,其中我们引入了实体分数。 我的名字", "metrics": {"bleu_score": 17.628731631393695, "chrf_score": 13.059799253440179, "xcomet_score": 0.21450430154800415, "xcomet_qe_score": 0.28884357213974, "metricx_score": 13.877679824829102, "metricx_qe_score": 11.242615699768066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是贾瓦德·侯赛尼,这是我和菲利普·拉辛斯基、西尔维娅·帕里蒂以及安妮·刘易斯的合作。", "metrics": {"bleu_score": 4.734716781620296, "chrf_score": 3.5630900506394303, "xcomet_score": 0.7507572770118713, "xcomet_qe_score": 0.825424313545227, "metricx_score": 5.641271114349365, "metricx_qe_score": 4.7729597091674805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是理解用户在做出选择时的语言。", "metrics": {"bleu_score": 85.78928092681438, "chrf_score": 78.83793429652562, "xcomet_score": 0.9999474287033081, "xcomet_qe_score": 0.9556578397750854, "metricx_score": 0.6249333620071411, "metricx_qe_score": 0.9737254977226257, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "考虑一下这个替代问题:", "metrics": {"bleu_score": 12.982679446701692, "chrf_score": 15.23876404494382, "xcomet_score": 0.8834202885627747, "xcomet_qe_score": 0.8817586898803711, "metricx_score": 0.3517453670501709, "metricx_qe_score": 0.27517277002334595, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你是指对我容易吗,还是我有一种感觉?这里", "metrics": {"bleu_score": 5.415315253510896, "chrf_score": 3.326805084465133, "xcomet_score": 0.31104758381843567, "xcomet_qe_score": 0.3296988606452942, "metricx_score": 6.4710235595703125, "metricx_qe_score": 4.412538528442383, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",用户想要从这两个选项中选择一个。", "metrics": {"bleu_score": 18.725530906346066, "chrf_score": 17.175728760322027, "xcomet_score": 0.935366153717041, "xcomet_qe_score": 0.9605474472045898, "metricx_score": 2.2471344470977783, "metricx_qe_score": 1.9759571552276611, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最明显的做法是直接引用,例如说歌曲的名字叫《Eminem》或者它的排名是第一。", "metrics": {"bleu_score": 13.02596001012631, "chrf_score": 13.998519585536078, "xcomet_score": 0.6988030672073364, "xcomet_qe_score": 0.6070346236228943, "metricx_score": 7.439743995666504, "metricx_qe_score": 7.853723049163818, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但有时,使用“朋友”这个头衔更为恰当,以便进行更自然的对话。", "metrics": {"bleu_score": 31.209433484006595, "chrf_score": 36.79311579183113, "xcomet_score": 0.8626956939697266, "xcomet_qe_score": 0.8586768507957458, "metricx_score": 5.059494495391846, "metricx_qe_score": 5.0557098388671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这种情况可能会发生,当用户忘记了对方的名字时。", "metrics": {"bleu_score": 20.872669127771896, "chrf_score": 20.211550387831473, "xcomet_score": 0.7537113428115845, "xcomet_qe_score": 0.7650894522666931, "metricx_score": 5.674200057983398, "metricx_qe_score": 5.660917282104492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所有发音都太相似,难以区分。", "metrics": {"bleu_score": 22.792296655031148, "chrf_score": 20.697981473308467, "xcomet_score": 0.8570217490196228, "xcomet_qe_score": 0.8698610067367554, "metricx_score": 2.685293674468994, "metricx_qe_score": 0.6818498373031616, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "或者当用户想要指定偏好时。", "metrics": {"bleu_score": 23.093053192812558, "chrf_score": 23.39542938424004, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6289462447166443, "metricx_qe_score": 0.45695963501930237, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在直接区别中,例如新的或非能量的签名。", "metrics": {"bleu_score": 3.313680857874321, "chrf_score": 5.691231833895649, "xcomet_score": 0.14022284746170044, "xcomet_qe_score": 0.15008912980556488, "metricx_score": 13.502005577087402, "metricx_qe_score": 12.742722511291504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是会话系统中一个重要的问题,也是分词的一个重要方面。 我们并不知道一个公开的数据集,", "metrics": {"bleu_score": 23.096210721005324, "chrf_score": 19.844020534138615, "xcomet_score": 0.15408991277217865, "xcomet_qe_score": 0.14303328096866608, "metricx_score": 9.152070999145508, "metricx_qe_score": 8.443721771240234, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个大规模的公共数据集供测试使用。所以我们收集了一个使用crowd annotation的方法。", "metrics": {"bleu_score": 15.483536132868975, "chrf_score": 13.425099313438002, "xcomet_score": 0.42642030119895935, "xcomet_qe_score": 0.4205124080181122, "metricx_score": 9.005741119384766, "metricx_qe_score": 8.994874000549316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集包含三个不同的领域:音乐、书籍和电影。", "metrics": {"bleu_score": 60.84121675336109, "chrf_score": 50.329380764163375, "xcomet_score": 0.8745263814926147, "xcomet_qe_score": 0.8352756500244141, "metricx_score": 1.9316953420639038, "metricx_qe_score": 2.7866384983062744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的数据集收集方法强调了使用卡通完成句子的不正式性。", "metrics": {"bleu_score": 64.95354111080498, "chrf_score": 56.92866068746736, "xcomet_score": 0.8182075023651123, "xcomet_qe_score": 0.7907549142837524, "metricx_score": 3.597299575805664, "metricx_qe_score": 3.322659492492676, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "漫画中三个泡泡,", "metrics": {"bleu_score": 10.735252131161188, "chrf_score": 9.956785797710815, "xcomet_score": 0.8330518007278442, "xcomet_qe_score": 0.8724861741065979, "metricx_score": 3.4298229217529297, "metricx_qe_score": 3.0005991458892822, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个泡泡里鲍勃说:“记住我们昨天听的那首歌吗?”", "metrics": {"bleu_score": 44.20804952183163, "chrf_score": 37.205760927832074, "xcomet_score": 0.9138644933700562, "xcomet_qe_score": 0.9023394584655762, "metricx_score": 1.684607982635498, "metricx_qe_score": 1.7299262285232544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随后鲍勃给出了对话上下文。", "metrics": {"bleu_score": 23.980236847348305, "chrf_score": 17.468852412154522, "xcomet_score": 0.9586089849472046, "xcomet_qe_score": 0.9066210985183716, "metricx_score": 0.8813972473144531, "metricx_qe_score": 0.9570536613464355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第二个演讲泡泡中,爱丽丝说:“你是问我容易吗?还是我让你感觉?”", "metrics": {"bleu_score": 12.912310029278192, "chrf_score": 9.026030093693683, "xcomet_score": 0.587375283241272, "xcomet_qe_score": 0.5926084518432617, "metricx_score": 7.931984901428223, "metricx_qe_score": 8.135990142822266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "替代问题。", "metrics": {"bleu_score": 17.86690863748233, "chrf_score": 16.11377319080968, "xcomet_score": 0.8499757051467896, "xcomet_qe_score": 0.8539196252822876, "metricx_score": 2.1101341247558594, "metricx_qe_score": 1.6890231370925903, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在第三个演讲泡泡中,Bob使用了直接引用来选择其中一个实体。例如,新的。 第一个和第二", "metrics": {"bleu_score": 33.61336783650558, "chrf_score": 34.00523101284485, "xcomet_score": 0.3474392890930176, "xcomet_qe_score": 0.33173006772994995, "metricx_score": 10.183229446411133, "metricx_qe_score": 12.459161758422852, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "个语音泡泡会被自动提供,但是第三个会被编辑器填充。", "metrics": {"bleu_score": 11.793432604384627, "chrf_score": 11.703498956461532, "xcomet_score": 0.583095908164978, "xcomet_qe_score": 0.6073129177093506, "metricx_score": 8.687686920166016, "metricx_qe_score": 6.16875696182251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个语音泡泡是从每个文档中选择的几个手动提示中的一个。", "metrics": {"bleu_score": 47.32072478339365, "chrf_score": 43.769219720497404, "xcomet_score": 0.6116155385971069, "xcomet_qe_score": 0.634189248085022, "metricx_score": 3.581517219543457, "metricx_qe_score": 2.6682472229003906, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题,即替代性问题,是这样产生的。", "metrics": {"bleu_score": 14.400124446705304, "chrf_score": 16.626669796191788, "xcomet_score": 0.9007004499435425, "xcomet_qe_score": 0.8732714056968689, "metricx_score": 0.9436948299407959, "metricx_qe_score": 0.929793119430542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们总是使用一个简单的模板,你的", "metrics": {"bleu_score": 53.07074109851437, "chrf_score": 54.17965067991628, "xcomet_score": 0.8321121335029602, "xcomet_qe_score": 0.8237104415893555, "metricx_score": 4.931910037994385, "metricx_qe_score": 0.24869397282600403, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "意思是 A、B、C、D 吗?这里", "metrics": {"bleu_score": 3.737437943747671, "chrf_score": 5.434782608695651, "xcomet_score": 0.2711329162120819, "xcomet_qe_score": 0.2624891996383667, "metricx_score": 4.694060325622559, "metricx_qe_score": 2.3136632442474365, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "A 和 B 是来自维基百科的示例吗? 下", "metrics": {"bleu_score": 65.25452579142082, "chrf_score": 70.82460145898305, "xcomet_score": 0.7151572704315186, "xcomet_qe_score": 0.48311999440193176, "metricx_score": 4.485230922698975, "metricx_qe_score": 2.4494545459747314, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "文是我们在列表中向上移动时使用的不同采样方法。", "metrics": {"bleu_score": 30.926025762875717, "chrf_score": 33.519302551587025, "xcomet_score": 0.6270858645439148, "xcomet_qe_score": 0.539047122001648, "metricx_score": 6.391549110412598, "metricx_qe_score": 6.7233195304870605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们在列表中移动时,实体变得越来越相似,而且通常更难进行拆分。", "metrics": {"bleu_score": 34.1659970649017, "chrf_score": 28.802671570214212, "xcomet_score": 0.7857574224472046, "xcomet_qe_score": 0.7134387493133545, "metricx_score": 5.16166353225708, "metricx_qe_score": 6.404708385467529, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是统一战线。", "metrics": {"bleu_score": 19.437571020720103, "chrf_score": 18.153313508301462, "xcomet_score": 0.7027926445007324, "xcomet_qe_score": 0.6057463884353638, "metricx_score": 6.508063793182373, "metricx_qe_score": 7.9867706298828125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二个是当实体具有相似的标题时,例如两本书名为《他们回忆》。", "metrics": {"bleu_score": 12.861981016228478, "chrf_score": 15.391064078127606, "xcomet_score": 0.7634341716766357, "xcomet_qe_score": 0.766181468963623, "metricx_score": 5.297921657562256, "metricx_qe_score": 6.03601598739624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三个是当他们在维基百科上有类似的描述时。", "metrics": {"bleu_score": 49.24584878270649, "chrf_score": 41.48474740773502, "xcomet_score": 0.9160966873168945, "xcomet_qe_score": 0.903738796710968, "metricx_score": 0.7081012725830078, "metricx_qe_score": 0.8103205561637878, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,当他们在维基百科上具有相同的 infobox 或属性时", "metrics": {"bleu_score": 48.95684174043416, "chrf_score": 41.568396446930265, "xcomet_score": 0.9274008274078369, "xcomet_qe_score": 0.9514466524124146, "metricx_score": 3.0712854862213135, "metricx_qe_score": 3.800724506378174, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如相同的类型、作者等。", "metrics": {"bleu_score": 14.982563916847612, "chrf_score": 15.3572601822111, "xcomet_score": 0.8548356294631958, "xcomet_qe_score": 0.7812252044677734, "metricx_score": 3.0971970558166504, "metricx_qe_score": 2.6092710494995117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当我们将这个替代问题展示给实体时,他们知道这些实体的名称,但他们并不一定了解实体本身。", "metrics": {"bleu_score": 37.343517438577855, "chrf_score": 34.05771985516354, "xcomet_score": 0.7282207012176514, "xcomet_qe_score": 0.7287713289260864, "metricx_score": 6.622250556945801, "metricx_qe_score": 6.546368598937988, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们做的是为歌曲展示一些背景知识", "metrics": {"bleu_score": 30.025490473427563, "chrf_score": 26.36627901706023, "xcomet_score": 0.7988346815109253, "xcomet_qe_score": 0.6943854093551636, "metricx_score": 5.02691125869751, "metricx_qe_score": 5.084900856018066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们只是为每首歌显示一个谷歌搜索链接。 然后,请注音符号至少听每一首歌,并阅读关于每一首歌的内容。", "metrics": {"bleu_score": 25.62281246710156, "chrf_score": 23.776322015352463, "xcomet_score": 0.6884335279464722, "xcomet_qe_score": 0.6720716953277588, "metricx_score": 6.064236164093018, "metricx_qe_score": 6.393774032592773, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,以下是一首歌曲的黄金搜索结果:“Easy”", "metrics": {"bleu_score": 18.153580712996767, "chrf_score": 23.805057499313428, "xcomet_score": 0.6740220785140991, "xcomet_qe_score": 0.7043296694755554, "metricx_score": 7.292050361633301, "metricx_qe_score": 6.706998825073242, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "菜谱和书籍领域,我们展示了维基百科上的一些背景文本。", "metrics": {"bleu_score": 51.61189785256587, "chrf_score": 43.68041685562961, "xcomet_score": 0.8538627624511719, "xcomet_qe_score": 0.7477284669876099, "metricx_score": 1.1842024326324463, "metricx_qe_score": 1.9732149839401245, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于食谱,我们还额外显示了它们的图片,同样来自维基百科,以便注释者知道它们的样子。", "metrics": {"bleu_score": 48.51438304150275, "chrf_score": 41.109157489486655, "xcomet_score": 0.973639965057373, "xcomet_qe_score": 0.9784116744995117, "metricx_score": 1.3032636642456055, "metricx_qe_score": 1.4417452812194824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们会请注释者选择其中一个实体。例如,这里选择第一个,并使用三到五个间接引用来描述它们。", "metrics": {"bleu_score": 36.13219049016207, "chrf_score": 31.978912769254414, "xcomet_score": 0.7960960268974304, "xcomet_qe_score": 0.7941840887069702, "metricx_score": 3.588865280151367, "metricx_qe_score": 4.0180745124816895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,有钢琴伴奏的那首", "metrics": {"bleu_score": 26.65837681702885, "chrf_score": 24.158249158249156, "xcomet_score": 0.9989383220672607, "xcomet_qe_score": 1.0, "metricx_score": 0.7016839981079102, "metricx_qe_score": 0.9458856582641602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "曲子。我们的数据集中有一些例子", "metrics": {"bleu_score": 39.12950299584578, "chrf_score": 30.763125763125764, "xcomet_score": 0.5721024870872498, "xcomet_qe_score": 0.43545836210250854, "metricx_score": 6.21862268447876, "metricx_qe_score": 7.895292282104492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如没有歌词的那首,十二岁小男孩弹的那首,或者来自阿塞拜疆的虚构曲子。", "metrics": {"bleu_score": 17.206950495372073, "chrf_score": 16.351176438500463, "xcomet_score": 0.7914031744003296, "xcomet_qe_score": 0.7480064630508423, "metricx_score": 3.8385074138641357, "metricx_qe_score": 4.992393970489502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "实体corpus有六千个替代问题,横跨三个域,并且有四万两千个直接相关表达式。", "metrics": {"bleu_score": 10.77448900968642, "chrf_score": 9.314127230636533, "xcomet_score": 0.498926043510437, "xcomet_qe_score": 0.5031188726425171, "metricx_score": 9.496633529663086, "metricx_qe_score": 9.792102813720703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果用t五模型总结如下:", "metrics": {"bleu_score": 9.817537821558966, "chrf_score": 11.66687691854842, "xcomet_score": 0.711692214012146, "xcomet_qe_score": 0.7607970237731934, "metricx_score": 4.995549201965332, "metricx_qe_score": 5.426263809204102, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型能够访问到与注释者完全相同的背景知识,那么它的准确性会非常高,大约在百分之九十二到百分之九十五之间。", "metrics": {"bleu_score": 41.383945065938526, "chrf_score": 40.399742276825265, "xcomet_score": 0.9650644063949585, "xcomet_qe_score": 0.9744595289230347, "metricx_score": 1.0269100666046143, "metricx_qe_score": 1.2618892192840576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但这种情况并不现实。", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 21.267546355574527, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4691614508628845, "metricx_qe_score": 0.5053394436836243, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型可以访问到部分重叠的背景知识,那么准确率会在八十二到八十七之间,这更加现实。", "metrics": {"bleu_score": 49.6960447166674, "chrf_score": 42.317682279278955, "xcomet_score": 0.7762711048126221, "xcomet_qe_score": 0.6816344261169434, "metricx_score": 2.5375194549560547, "metricx_qe_score": 3.3975160121917725, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,当语言模型检索到背景知识时。", "metrics": {"bleu_score": 66.75075987129311, "chrf_score": 59.287286622244515, "xcomet_score": 0.9889966249465942, "xcomet_qe_score": 0.9822555780410767, "metricx_score": 0.6217244863510132, "metricx_qe_score": 0.7467434406280518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果语言模型只能访问实体名称,则准确性只有60%。因此,有很多改进的空间。", "metrics": {"bleu_score": 53.841017619118624, "chrf_score": 48.846764306323124, "xcomet_score": 0.9941812753677368, "xcomet_qe_score": 0.9889311790466309, "metricx_score": 1.593871831893921, "metricx_qe_score": 2.4460175037384033, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还展示了模型是泛化的。", "metrics": {"bleu_score": 10.706109099319784, "chrf_score": 11.099228649758063, "xcomet_score": 0.8456611633300781, "xcomet_qe_score": 0.8323121070861816, "metricx_score": 1.3844548463821411, "metricx_qe_score": 1.3193700313568115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的数据集链接。", "metrics": {"bleu_score": 44.40750605884708, "chrf_score": 37.82407407407407, "xcomet_score": 0.9876703023910522, "xcomet_qe_score": 0.9907646179199219, "metricx_score": 0.18081915378570557, "metricx_qe_score": 0.26101309061050415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.05947252735495567, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫Sarah Papa,来自罗马尼亚的布加勒斯特大学,我是弗朗茨·布鲁诺·卡斯勒教授的研究生。我将简要介绍“同步口译论文”的指导老师——马特奥·内格里和马克·泽尔基。 实时口译", "metrics": {"bleu_score": 12.870625131301724, "chrf_score": 14.053830259331512, "xcomet_score": 0.2974472939968109, "xcomet_qe_score": 0.2450261414051056, "metricx_score": 7.995614528656006, "metricx_qe_score": 7.677425861358643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "(Simultaneous Speech Translation", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.9471360445022583, "xcomet_qe_score": 0.9428492784500122, "metricx_score": 6.790869235992432, "metricx_qe_score": 9.693275451660156, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",简称SST)是指在说话的同时将语言翻译成另一种语言的过程,这种技术能够增强跨语言沟通。", "metrics": {"bleu_score": 26.67836062177809, "chrf_score": 23.062964021789885, "xcomet_score": 0.809004545211792, "xcomet_qe_score": 0.8527069091796875, "metricx_score": 6.53786039352417, "metricx_qe_score": 6.2100114822387695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的模拟器模型的问题是什么?", "metrics": {"bleu_score": 14.377919100088198, "chrf_score": 11.852383692616101, "xcomet_score": 0.9066492319107056, "xcomet_qe_score": 0.9438707828521729, "metricx_score": 1.8776822090148926, "metricx_qe_score": 2.009502649307251, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常,特定的架构会被训练,以引入要优化的额外模块。 复杂", "metrics": {"bleu_score": 8.195327427714112, "chrf_score": 17.377520605905797, "xcomet_score": 0.8150378465652466, "xcomet_qe_score": 0.753743052482605, "metricx_score": 4.38684606552124, "metricx_qe_score": 2.74680495262146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的训练程序,例如涉及不同优化目标的训练。", "metrics": {"bleu_score": 59.0272526384228, "chrf_score": 58.158126467925285, "xcomet_score": 0.5823662281036377, "xcomet_qe_score": 0.48508885502815247, "metricx_score": 6.329891681671143, "metricx_qe_score": 6.0490522384643555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "训练和维护几个模型来达到不同的延迟", "metrics": {"bleu_score": 35.66581678245875, "chrf_score": 34.248324691167596, "xcomet_score": 0.8771517872810364, "xcomet_qe_score": 0.8444774746894836, "metricx_score": 1.587873101234436, "metricx_qe_score": 1.8052834272384644, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "率,例如训练一个平均延迟为一秒的模型和另一个平均延迟为两秒的模型等等。", "metrics": {"bleu_score": 62.82567203276422, "chrf_score": 56.730684453644606, "xcomet_score": 0.5309357643127441, "xcomet_qe_score": 0.44947829842567444, "metricx_score": 5.496218681335449, "metricx_qe_score": 5.209951877593994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是什么?", "metrics": {"bleu_score": 67.99584717294225, "chrf_score": 68.03442594582208, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1230233758687973, "metricx_qe_score": 0.4698777198791504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,使用已经存在的LSTM模型,无需重新训练或采用特定的架构来", "metrics": {"bleu_score": 48.289565951068006, "chrf_score": 37.906493339895405, "xcomet_score": 0.7368292808532715, "xcomet_qe_score": 0.7458627223968506, "metricx_score": 3.3228096961975098, "metricx_qe_score": 2.8217382431030273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "处理分类问题。只使用一个模型针对所有延迟率,并通过特定参数传递时延。", "metrics": {"bleu_score": 38.12704939666063, "chrf_score": 36.0924699989513, "xcomet_score": 0.7234305739402771, "xcomet_qe_score": 0.4697016775608063, "metricx_score": 3.043557643890381, "metricx_qe_score": 2.8595468997955322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过模型利用注意力机制在音频输入和文本输出间进行跨注意,你可以看到示例在", "metrics": {"bleu_score": 36.53922104515066, "chrf_score": 34.28843786589678, "xcomet_score": 0.435845285654068, "xcomet_qe_score": 0.29039379954338074, "metricx_score": 5.9188737869262695, "metricx_qe_score": 5.142722129821777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "右侧。", "metrics": {"bleu_score": 0.0, "chrf_score": 4.219409282700422, "xcomet_score": 0.17977076768875122, "xcomet_qe_score": 0.1535707414150238, "metricx_score": 8.29307746887207, "metricx_qe_score": 13.129977226257324, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的解决方案是提出一个“点”或编码解码策略,并基于注意力指向的位置来决定是否进行部分翻译。", "metrics": {"bleu_score": 42.75453355707788, "chrf_score": 34.72300500478216, "xcomet_score": 0.7091714143753052, "xcomet_qe_score": 0.7353299260139465, "metricx_score": 5.604251861572266, "metricx_qe_score": 6.6587958335876465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果注意力不集中,则会删除单词,即总和低于某个阈值$\\alpha$,针对最后的Lambada语音帧。这意味着接收到的信息不够稳定。", "metrics": {"bleu_score": 40.20344979378133, "chrf_score": 32.035941854422525, "xcomet_score": 0.5550549030303955, "xcomet_qe_score": 0.48609188199043274, "metricx_score": 5.4620041847229, "metricx_qe_score": 3.786686897277832, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,如果我们收到一个包含“我要谈论的内容”的语音片段,并且我们的模型预测出德语翻译是“ich werde über das sprechen, worüber ich rede”,并且这个翻译是准确的,那么我们需要将这个句子翻译成中文。 我们将会研究跨注意力权重。 第一个词组指向最早接收的语音帧,最后一个词组指向最近接收的语音帧,即兰德语音帧。", "metrics": {"bleu_score": 29.723298908450754, "chrf_score": 25.597752480523432, "xcomet_score": 0.37468472123146057, "xcomet_qe_score": 0.35456058382987976, "metricx_score": 6.8381452560424805, "metricx_qe_score": 6.284186363220215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这意味着前两个单词将被省略。 'while since the sum of the cross attention is above a certain threshold alpha we will not emit the last word and wait for another speech segment.'", "metrics": {"bleu_score": 10.630572103206706, "chrf_score": 6.440870110511295, "xcomet_score": 0.7622669339179993, "xcomet_qe_score": 0.7088837027549744, "metricx_score": 7.252470016479492, "metricx_qe_score": 4.868339538574219, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们继续,并且收到另一个语音消息,而我们的模型预测是三个单词,我们会查看交叉注意力权重。 我们会看到,没有单词指向最后一个lambda表达式帧。", "metrics": {"bleu_score": 49.21866675878235, "chrf_score": 43.20856416940616, "xcomet_score": 0.5792851448059082, "xcomet_qe_score": 0.48320987820625305, "metricx_score": 4.038925647735596, "metricx_qe_score": 3.87005352973938, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表示,这三句话将被省略。", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 7.799145299145299, "xcomet_score": 0.790148138999939, "xcomet_qe_score": 0.8143574595451355, "metricx_score": 1.672635793685913, "metricx_qe_score": 0.31459760665893555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果看作一个整体结果,那就是。 我们将应用同时翻译结果的图表,其中有一边是蓝色的,代表翻译质量,并且平均长度为。 这是延迟量度,我们还考虑计算平均权值,它代表模型预测输出所需的时间。", "metrics": {"bleu_score": 10.99198698886566, "chrf_score": 13.418096144955378, "xcomet_score": 0.3365406095981598, "xcomet_qe_score": 0.3766055703163147, "metricx_score": 13.37502384185791, "metricx_qe_score": 14.143771171569824, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们希望我们的药物在这一领域尽可能的高。", "metrics": {"bleu_score": 17.470942957770763, "chrf_score": 18.37974717667098, "xcomet_score": 0.7036086320877075, "xcomet_qe_score": 0.6357845067977905, "metricx_score": 7.714454174041748, "metricx_qe_score": 8.463333129882812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,我们也希望它们向左倾斜。", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 59.357335092469256, "xcomet_score": 0.9289676547050476, "xcomet_qe_score": 0.9158822894096375, "metricx_score": 2.4923856258392334, "metricx_qe_score": 1.6239213943481445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还与适用于离线模型的其他策略进行了比较,例如Whitaker策略和局部同意。", "metrics": {"bleu_score": 36.07442374649341, "chrf_score": 24.826807973014127, "xcomet_score": 0.7524073123931885, "xcomet_qe_score": 0.733344554901123, "metricx_score": 3.7871954441070557, "metricx_qe_score": 3.782156229019165, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将针对同时翻译的专门设计的Art Architecture与之进行了对比。", "metrics": {"bleu_score": 9.938112358556278, "chrf_score": 12.14892251976868, "xcomet_score": 0.7240265607833862, "xcomet_qe_score": 0.6912580132484436, "metricx_score": 6.30709981918335, "metricx_qe_score": 6.411312580108643, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "德语翻译结果如下: 这是德语同步翻译策略的所有结果。", "metrics": {"bleu_score": 29.39918700508725, "chrf_score": 30.06037924372405, "xcomet_score": 0.8780820369720459, "xcomet_qe_score": 0.8281203508377075, "metricx_score": 3.1804745197296143, "metricx_qe_score": 3.130845785140991, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "结果表明,该算法在所有应用到离线模型的策略上都表现良好,因为它们的曲线向左倾斜。", "metrics": {"bleu_score": 24.031235689207005, "chrf_score": 25.593516422041425, "xcomet_score": 0.854088306427002, "xcomet_qe_score": 0.8151814937591553, "metricx_score": 2.3471715450286865, "metricx_qe_score": 2.336735248565674, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们考虑实际耗时或计算时长,那就是最差策略。", "metrics": {"bleu_score": 35.43166886203743, "chrf_score": 35.44907451014795, "xcomet_score": 0.6481366157531738, "xcomet_qe_score": 0.605637788772583, "metricx_score": 4.038424491882324, "metricx_qe_score": 3.2873494625091553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想了解更多信息,请阅读我们的论文,并且", "metrics": {"bleu_score": 62.55340042200862, "chrf_score": 60.17204572099731, "xcomet_score": 0.8118711709976196, "xcomet_qe_score": 0.8096909523010254, "metricx_score": 3.1748948097229004, "metricx_qe_score": 0.13440951704978943, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发布了开源代码、模型和并行计算输出,以促进我们的工作的可重复性。", "metrics": {"bleu_score": 44.73701007191884, "chrf_score": 48.012054622897224, "xcomet_score": 0.968017578125, "xcomet_qe_score": 0.9566705822944641, "metricx_score": 1.1529853343963623, "metricx_qe_score": 1.5393415689468384, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您的关注!", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 11.955469506292353, "xcomet_score": 0.876541018486023, "xcomet_qe_score": 0.980793833732605, "metricx_score": 0.6179585456848145, "metricx_qe_score": 0.554551362991333, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫音。我和我的同事志杨将展示我们的研究成果:多模态学习的改进。", "metrics": {"bleu_score": 26.816012090542976, "chrf_score": 17.763112595616466, "xcomet_score": 0.498740017414093, "xcomet_qe_score": 0.5297319889068604, "metricx_score": 8.5717134475708, "metricx_qe_score": 11.296728134155273, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "随着大语言模型的进步,许多工作开始探索使用预训练语言模型来解决下游任务的新学习范式,在参数效率方面取得很大进展。", "metrics": {"bleu_score": 35.94518252640323, "chrf_score": 30.120839145818856, "xcomet_score": 0.8748683929443359, "xcomet_qe_score": 0.8517996668815613, "metricx_score": 3.0324666500091553, "metricx_qe_score": 3.6304337978363037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近的研究表明,指令微调使大型语言模型能够以自然的方式执行常见的无监督任务。", "metrics": {"bleu_score": 31.610534446290096, "chrf_score": 26.38660068511653, "xcomet_score": 0.8317843675613403, "xcomet_qe_score": 0.8445428609848022, "metricx_score": 2.39490008354187, "metricx_qe_score": 1.95933198928833, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,大多数关于指令调优的先前工作都集中在提高语言任务的零错误性能上,而计算机视觉和多模态类型则被忽略了。", "metrics": {"bleu_score": 37.94730192418899, "chrf_score": 33.07388608785117, "xcomet_score": 0.877428412437439, "xcomet_qe_score": 0.8420013785362244, "metricx_score": 2.154022693634033, "metricx_qe_score": 2.305074453353882, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在本工作中,我们想要探究指令调优在多模态预训练模型上是否能够实际上提高对无监督多模态任务的泛化能力。", "metrics": {"bleu_score": 35.943441265973654, "chrf_score": 31.59517377369299, "xcomet_score": 0.8558417558670044, "xcomet_qe_score": 0.818068265914917, "metricx_score": 2.3568437099456787, "metricx_qe_score": 1.9807411432266235, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,在我们进行研究的时候,我们发现P和多模态之间存在相当大的差异。 ", "metrics": {"bleu_score": 25.883258529726042, "chrf_score": 22.836035634939048, "xcomet_score": 0.7377687692642212, "xcomet_qe_score": 0.6343073844909668, "metricx_score": 8.370086669921875, "metricx_qe_score": 8.77744197845459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在超过一万六千个仅使用语言的训练任务,", "metrics": {"bleu_score": 11.7942240532671, "chrf_score": 14.611278667674643, "xcomet_score": 0.9170235395431519, "xcomet_qe_score": 0.9034249782562256, "metricx_score": 2.931039333343506, "metricx_qe_score": 2.7675418853759766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是没有大规模公开发布的多模态训练任务。", "metrics": {"bleu_score": 32.26386416030252, "chrf_score": 28.39365901090185, "xcomet_score": 0.9755349159240723, "xcomet_qe_score": 0.9780471324920654, "metricx_score": 1.7041122913360596, "metricx_qe_score": 1.8292062282562256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,这激励我们构建一个多模态训练数据集。", "metrics": {"bleu_score": 62.65504182177836, "chrf_score": 56.85847164673612, "xcomet_score": 0.9606122970581055, "xcomet_qe_score": 0.9772443771362305, "metricx_score": 1.4887099266052246, "metricx_qe_score": 2.3382060527801514, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们介绍多模型指令调优基准数据集,它包含62个不同的多模型任务,涵盖了10个不同的领域。", "metrics": {"bleu_score": 31.568406362661882, "chrf_score": 25.371518171746093, "xcomet_score": 0.7187836766242981, "xcomet_qe_score": 0.6567205190658569, "metricx_score": 3.701909065246582, "metricx_qe_score": 3.0413529872894287, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些任务来源于现有的21个开源数据集,每个任务都配五份由专家书写的说明。", "metrics": {"bleu_score": 31.568280470164282, "chrf_score": 28.36646101619117, "xcomet_score": 0.9474220275878906, "xcomet_qe_score": 0.960250198841095, "metricx_score": 0.9814392328262329, "metricx_qe_score": 1.275948405265808, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的多模态表示学习数据集包括:一个统一的多模态表示模型。这个模型使用统一的词汇表", "metrics": {"bleu_score": 22.624611003989894, "chrf_score": 18.658023537641753, "xcomet_score": 0.2164551168680191, "xcomet_qe_score": 0.21746857464313507, "metricx_score": 7.8695502281188965, "metricx_qe_score": 4.891113758087158, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用于语言、图像标记以及绑定框的坐标。", "metrics": {"bleu_score": 25.374500490636745, "chrf_score": 19.374473344281075, "xcomet_score": 0.3747849762439728, "xcomet_qe_score": 0.29255831241607666, "metricx_score": 8.248838424682617, "metricx_qe_score": 9.106842041015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示一下来自我们多内核数据库的一些示例实例。 将各种输入和输出数据类型统一处理。", "metrics": {"bleu_score": 51.472258403170386, "chrf_score": 37.15020307306979, "xcomet_score": 0.7178813815116882, "xcomet_qe_score": 0.7087377905845642, "metricx_score": 2.738408088684082, "metricx_qe_score": 2.200308322906494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们遵循OFA的邮件指导,将所有任务统一为一个顺序到顺序的格式,在其中", "metrics": {"bleu_score": 25.753379048739852, "chrf_score": 29.981089834719914, "xcomet_score": 0.6103246212005615, "xcomet_qe_score": 0.6902672052383423, "metricx_score": 5.636302947998047, "metricx_qe_score": 6.582806587219238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "输入文本、图像、说明和约束框被表示在相同的标记空间中。", "metrics": {"bleu_score": 32.47454576371829, "chrf_score": 28.998109096422812, "xcomet_score": 0.9451650977134705, "xcomet_qe_score": 0.9258120059967041, "metricx_score": 1.3712891340255737, "metricx_qe_score": 1.4641914367675781, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,现在我要谈谈多模型指令调优。", "metrics": {"bleu_score": 54.11927503805856, "chrf_score": 47.16718738777563, "xcomet_score": 0.8387848138809204, "xcomet_qe_score": 0.862467885017395, "metricx_score": 1.6048896312713623, "metricx_qe_score": 1.7363760471343994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以对于训练数据集,我们使用了来自nagroup的53个任务进行训练,并且为每个任务抽取了10000个实例进行", "metrics": {"bleu_score": 47.68683715481798, "chrf_score": 46.871355786740324, "xcomet_score": 0.6881179809570312, "xcomet_qe_score": 0.6695396304130554, "metricx_score": 6.985845565795898, "metricx_qe_score": 6.786909103393555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "测试。我们保留了整个common sense reasoning组用于测试,并且从维基百科和米林斯组中选择了另外五个任务。", "metrics": {"bleu_score": 36.510860598788014, "chrf_score": 28.662520925116496, "xcomet_score": 0.500449538230896, "xcomet_qe_score": 0.5085753202438354, "metricx_score": 7.238515377044678, "metricx_qe_score": 7.055306434631348, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用测试集中的所有实例针对每个任务。", "metrics": {"bleu_score": 58.94666012755862, "chrf_score": 47.709728411915926, "xcomet_score": 0.7649437189102173, "xcomet_qe_score": 0.757143497467041, "metricx_score": 1.8719470500946045, "metricx_qe_score": 1.67275869846344, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,我们随机从自然语言处理任务的测试集中选取20个任务。 We use all instances in the test set for each task. In addition, we randomly select twenty tasks from the test set of natural language processing tasks. Note: The original utterance appears to be a fragment of a larger sentence or document. The provided translation captures the essence of the original information but does not form a coherent sentence on its own. 因此,", "metrics": {"bleu_score": 7.759967705601966, "chrf_score": 8.647710807014377, "xcomet_score": 0.22585487365722656, "xcomet_qe_score": 0.010785049758851528, "metricx_score": 23.124807357788086, "metricx_qe_score": 15.758824348449707, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一个经过预训练的大型模型作为基础模型。", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 58.47387846499662, "xcomet_score": 0.9013174772262573, "xcomet_qe_score": 0.8533211946487427, "metricx_score": 2.0648586750030518, "metricx_qe_score": 2.3661136627197266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练过程中,我们将所有任务的实例随", "metrics": {"bleu_score": 42.402840006908406, "chrf_score": 35.46088755246185, "xcomet_score": 0.7080510258674622, "xcomet_qe_score": 0.7227820754051208, "metricx_score": 5.085567951202393, "metricx_qe_score": 3.28055477142334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "机组合到一个模板中。每个实例都与该模板中的五个方向之一进行匹配。", "metrics": {"bleu_score": 19.40607132532531, "chrf_score": 24.646253630019256, "xcomet_score": 0.366696298122406, "xcomet_qe_score": 0.2340722680091858, "metricx_score": 6.75014066696167, "metricx_qe_score": 6.68165922164917, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,对于每个任务,我们通过使用五个指令中的一个来评估模型。在每次实验", "metrics": {"bleu_score": 45.31583451719908, "chrf_score": 42.28426232368726, "xcomet_score": 0.8067715764045715, "xcomet_qe_score": 0.6910737156867981, "metricx_score": 7.245316982269287, "metricx_qe_score": 6.782593727111816, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中。 所有五次实验的平均值和最大值以及标准偏差是什么?", "metrics": {"bleu_score": 4.971142349219942, "chrf_score": 9.61613028305545, "xcomet_score": 0.2528047561645508, "xcomet_qe_score": 0.2387021780014038, "metricx_score": 3.2658095359802246, "metricx_qe_score": 3.3272206783294678, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果任务是多模型分类任务,我们将报告准确率。", "metrics": {"bleu_score": 78.39204411491599, "chrf_score": 71.55580201245836, "xcomet_score": 0.9935622215270996, "xcomet_qe_score": 0.9808018803596497, "metricx_score": 0.5727890133857727, "metricx_qe_score": 0.702531635761261, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果是多模型生成任务,我们将报告Rouge-L。对于LSTM任务,我们也将报告Rouge-L。", "metrics": {"bleu_score": 46.82672960380126, "chrf_score": 54.634199106694716, "xcomet_score": 0.7424091696739197, "xcomet_qe_score": 0.7371904253959656, "metricx_score": 3.4181745052337646, "metricx_qe_score": 3.369889259338379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了一个额外的评估指标,称为“敏感性”,", "metrics": {"bleu_score": 67.7593999948928, "chrf_score": 63.551558408537815, "xcomet_score": 0.8961586356163025, "xcomet_qe_score": 0.8808868527412415, "metricx_score": 0.70673668384552, "metricx_qe_score": 0.6440733671188354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用于衡量模型在相同任务中,对于输入变化(例如指令的变化)时能够一致产生相同输出的能力。", "metrics": {"bleu_score": 41.06664188540284, "chrf_score": 40.57652086918387, "xcomet_score": 0.7793542742729187, "xcomet_qe_score": 0.7703064680099487, "metricx_score": 1.8360387086868286, "metricx_qe_score": 2.0750160217285156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的主要结果。", "metrics": {"bleu_score": 79.6358031503278, "chrf_score": 77.3312769486561, "xcomet_score": 0.909784197807312, "xcomet_qe_score": 0.8688104748725891, "metricx_score": 0.38074302673339844, "metricx_qe_score": 0.5220726728439331, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所见,指令调音可以显着提高OFA在多模态任务上的性能。", "metrics": {"bleu_score": 36.334676874453926, "chrf_score": 33.44630201695027, "xcomet_score": 0.9338387250900269, "xcomet_qe_score": 0.9204263091087341, "metricx_score": 5.393004417419434, "metricx_qe_score": 4.964060306549072, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言数据集可以从迁移学习中受益。", "metrics": {"bleu_score": 15.256553088860787, "chrf_score": 16.986776466949102, "xcomet_score": 0.7180840969085693, "xcomet_qe_score": 0.7330005168914795, "metricx_score": 4.5023298263549805, "metricx_qe_score": 6.552712440490723, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以看到,随着任务量的增加,模型的性能会更好,在 meantime 具有更低的敏感性。 因此,", "metrics": {"bleu_score": 30.90153258731026, "chrf_score": 24.70538705950847, "xcomet_score": 0.6220805048942566, "xcomet_qe_score": 0.7316591739654541, "metricx_score": 8.911860466003418, "metricx_qe_score": 8.153153419494629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还进行了一个实验。", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 53.08096866257821, "xcomet_score": 0.994623064994812, "xcomet_qe_score": 0.9922294616699219, "metricx_score": 0.2523118555545807, "metricx_qe_score": 0.3109481930732727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了一个指令 versus 五个指令。", "metrics": {"bleu_score": 27.88241097922203, "chrf_score": 22.97982709009873, "xcomet_score": 0.8299490213394165, "xcomet_qe_score": 0.8343865275382996, "metricx_score": 3.194420576095581, "metricx_qe_score": 3.101468324661255, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所看到的,使用更多的指令可以提高模型的整体性能并减少其敏感性。 所以,这", "metrics": {"bleu_score": 57.89388526744123, "chrf_score": 54.62926491030981, "xcomet_score": 0.6856924295425415, "xcomet_qe_score": 0.7482882142066956, "metricx_score": 6.897002220153809, "metricx_qe_score": 3.7343673706054688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "展示了不同的调优策略对模型灵敏度的影响。", "metrics": {"bleu_score": 72.20777626745553, "chrf_score": 65.1865948918709, "xcomet_score": 0.8885707855224609, "xcomet_qe_score": 0.8877171277999878, "metricx_score": 1.0681638717651367, "metricx_qe_score": 1.7373383045196533, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所看到的,通过从自然语言数据集中转移学习,模型可以比原始OFA模型实现大大提高的敏感性。", "metrics": {"bleu_score": 31.028000293366397, "chrf_score": 29.168491172436156, "xcomet_score": 0.777583122253418, "xcomet_qe_score": 0.881697416305542, "metricx_score": 3.3642079830169678, "metricx_qe_score": 3.921268939971924, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以从自然结构数据集中看到,传输学习可以大大提高在自然结构数据集上的性能。", "metrics": {"bleu_score": 25.75631305448276, "chrf_score": 20.896982017510773, "xcomet_score": 0.837587833404541, "xcomet_qe_score": 0.8303203582763672, "metricx_score": 6.389804363250732, "metricx_qe_score": 6.0965142250061035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们提出第一个大规模多模态训练数据集,显著提高OFA的检测能力,并探索不同的迁移学习技术并展示其益处。", "metrics": {"bleu_score": 35.47948585315742, "chrf_score": 34.63976293978503, "xcomet_score": 0.7027242183685303, "xcomet_qe_score": 0.7958852648735046, "metricx_score": 3.7289910316467285, "metricx_qe_score": 4.783532619476318, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计了一个新的度量敏感性。", "metrics": {"bleu_score": 42.440386496687175, "chrf_score": 41.37214658594207, "xcomet_score": 0.8771498799324036, "xcomet_qe_score": 0.8443157076835632, "metricx_score": 3.570216417312622, "metricx_qe_score": 3.291125774383545, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "收集更多多模态指令训练数据集,大约增加一百五十个额外的维吾尔语任务,我们将发布这些数据集。所以这个", "metrics": {"bleu_score": 30.832725548844735, "chrf_score": 27.01804755633065, "xcomet_score": 0.3067892789840698, "xcomet_qe_score": 0.40389084815979004, "metricx_score": 10.683891296386719, "metricx_qe_score": 8.262598037719727, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是我们的数据和模型的二维码。", "metrics": {"bleu_score": 93.10627797040233, "chrf_score": 93.36837027445603, "xcomet_score": 0.8946224451065063, "xcomet_qe_score": 0.7809432744979858, "metricx_score": 0.6348065137863159, "metricx_qe_score": 1.0511964559555054, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 47.91666666666667, "xcomet_score": 0.9850732088088989, "xcomet_qe_score": 0.9742759466171265, "metricx_score": 0.0, "metricx_qe_score": 0.004066057503223419, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是Coosha Sina,我很高兴地邀请您参加我们关于“我们的ACL 2023论文:", "metrics": {"bleu_score": 31.645275923351992, "chrf_score": 34.67617649742168, "xcomet_score": 0.6145445108413696, "xcomet_qe_score": 0.5512574315071106, "metricx_score": 6.3231000900268555, "metricx_qe_score": 6.903529167175293, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语言模型接受性判断在上下文中的鲁棒性”的讨论。", "metrics": {"bleu_score": 27.9273239253137, "chrf_score": 23.16888400092064, "xcomet_score": 0.6541523337364197, "xcomet_qe_score": 0.658277153968811, "metricx_score": 6.0493669509887695, "metricx_qe_score": 7.659834384918213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与John Goughere,Aaron Muller,Kanishka Mishra,Karen Fuentes,Roger Levy和Adina Williams的合作。", "metrics": {"bleu_score": 16.839013037523355, "chrf_score": 54.682529733438, "xcomet_score": 0.6054538488388062, "xcomet_qe_score": 0.659780740737915, "metricx_score": 6.419037342071533, "metricx_qe_score": 5.03812313079834, "linguapy_score": [1, "WELSH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,在本工作中,我们重温了最小二乘法。", "metrics": {"bleu_score": 13.26475916741222, "chrf_score": 12.860623781676415, "xcomet_score": 0.8181116580963135, "xcomet_qe_score": 0.8354111313819885, "metricx_score": 4.372920513153076, "metricx_qe_score": 2.6154298782348633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最小二乘并行模型基本上是在接受性判断的基础上评估语言模型,这些判断", "metrics": {"bleu_score": 32.472740570489265, "chrf_score": 29.284062510235763, "xcomet_score": 0.8007002472877502, "xcomet_qe_score": 0.6965910196304321, "metricx_score": 6.195388317108154, "metricx_qe_score": 2.36582088470459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以包括语法正确性(例如pontificate)或在句法类型方面的接受性(例如名词短语)。", "metrics": {"bleu_score": 11.681570771679114, "chrf_score": 10.151636758285678, "xcomet_score": 0.42974787950515747, "xcomet_qe_score": 0.41733986139297485, "metricx_score": 8.190692901611328, "metricx_qe_score": 8.398992538452148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这个最小二乘模型中,评估语言模型的典型方法是,您向模型展示一个可接受的句子或语法正确的句子,然后展示一个不可接受的句子或非语法正确的句子。", "metrics": {"bleu_score": 50.83490201836945, "chrf_score": 43.948881892420374, "xcomet_score": 0.6782937049865723, "xcomet_qe_score": 0.7118171453475952, "metricx_score": 1.1862260103225708, "metricx_qe_score": 2.259765863418579, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,希望是模型基本上会将更多的概率分配给可接受的解决方案。", "metrics": {"bleu_score": 25.312245791949678, "chrf_score": 25.422694083003268, "xcomet_score": 0.8879987597465515, "xcomet_qe_score": 0.8959845900535583, "metricx_score": 3.241021156311035, "metricx_qe_score": 4.2512288093566895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当前的MPP管道系统基本上不允许我们评估模型对长句子的接受度。", "metrics": {"bleu_score": 80.96427216101601, "chrf_score": 76.76644593307633, "xcomet_score": 0.8885656595230103, "xcomet_qe_score": 0.7871229648590088, "metricx_score": 2.1004045009613037, "metricx_qe_score": 3.4315555095672607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如今,大型语言模型正在出现,它们的上下文窗口越来越长。", "metrics": {"bleu_score": 49.33292241270432, "chrf_score": 58.298235828553636, "xcomet_score": 0.9505674839019775, "xcomet_qe_score": 0.8549802303314209, "metricx_score": 1.3968585729599, "metricx_qe_score": 1.2476611137390137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,在整个上下文中评估模型的可接受性至关重要。 我们在这里", "metrics": {"bleu_score": 39.9604684383603, "chrf_score": 38.004708891297796, "xcomet_score": 0.8167010545730591, "xcomet_qe_score": 0.7846742868423462, "metricx_score": 5.733822345733643, "metricx_qe_score": 1.8875652551651, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尝试的是什么?我们正试图通过让模型评估越来越长序列的接受性来重访NLP管道。 所以,", "metrics": {"bleu_score": 36.757506054775206, "chrf_score": 35.4820211877392, "xcomet_score": 0.30531954765319824, "xcomet_qe_score": 0.23700082302093506, "metricx_score": 7.483755111694336, "metricx_qe_score": 6.822567462921143, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这就是我们的方法。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9963313341140747, "xcomet_qe_score": 0.9761532545089722, "metricx_score": 0.22746601700782776, "metricx_qe_score": 0.7089755535125732, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的就是重复访问数据集本身,并通过选择来自这些数据集中可接受或不可接受的句子来重新创建句子。", "metrics": {"bleu_score": 48.173065710899344, "chrf_score": 44.68222973332712, "xcomet_score": 0.726305365562439, "xcomet_qe_score": 0.642309308052063, "metricx_score": 4.836204528808594, "metricx_qe_score": 5.472970485687256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,这里我们选择了例证数据集中来自附属岛屿的一个典型的戏剧性对(dramatization pair)。", "metrics": {"bleu_score": 15.172495765630163, "chrf_score": 14.393529566350088, "xcomet_score": 0.6292191743850708, "xcomet_qe_score": 0.6622982025146484, "metricx_score": 8.578384399414062, "metricx_qe_score": 7.893189907073975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所做的是,为了重新创建更长的序列,并且这些序列是可接受的并且与语法结构匹配。", "metrics": {"bleu_score": 61.76726629374725, "chrf_score": 53.1696881929996, "xcomet_score": 0.8225749731063843, "xcomet_qe_score": 0.7101261019706726, "metricx_score": 2.4527127742767334, "metricx_qe_score": 3.0312061309814453, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们从一个句子中提取语法结构。 然后,我们将它作为前缀添加到可接受查询和不可接受查询的前面。", "metrics": {"bleu_score": 47.38870862647921, "chrf_score": 36.37596576447455, "xcomet_score": 0.7298728823661804, "xcomet_qe_score": 0.6443802118301392, "metricx_score": 4.345974922180176, "metricx_qe_score": 4.609393119812012, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过从相同的匹配中选择不可接受的句子,我们也可以做同样的事情。这也可以用来测试模型的可接受性。", "metrics": {"bleu_score": 80.6230555651291, "chrf_score": 76.20566616355396, "xcomet_score": 0.9635895490646362, "xcomet_qe_score": 0.8370918035507202, "metricx_score": 1.3196451663970947, "metricx_qe_score": 1.638575792312622, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们会通过从不同的子集或不同的数据集中选择句子来实现这一点,这", "metrics": {"bleu_score": 64.1157262440984, "chrf_score": 62.88710718856856, "xcomet_score": 0.8128310441970825, "xcomet_qe_score": 0.6219803094863892, "metricx_score": 5.618851661682129, "metricx_qe_score": 2.8796653747558594, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "就是我们所谓的“错配”情况。", "metrics": {"bleu_score": 29.89950354998137, "chrf_score": 23.515651015651017, "xcomet_score": 0.9231293201446533, "xcomet_qe_score": 0.9271609783172607, "metricx_score": 0.6533703804016113, "metricx_qe_score": 0.5970340967178345, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,这里句子仍然来自相关数据集,但不是你正在评估的数据集。", "metrics": {"bleu_score": 53.75300762811131, "chrf_score": 47.31400269467324, "xcomet_score": 0.9321171045303345, "xcomet_qe_score": 0.928284227848053, "metricx_score": 1.2304611206054688, "metricx_qe_score": 2.008810043334961, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以对不可接受性情况做同样的事情。", "metrics": {"bleu_score": 37.75584206975749, "chrf_score": 29.66578586391127, "xcomet_score": 0.8951269388198853, "xcomet_qe_score": 0.8848233222961426, "metricx_score": 1.5623488426208496, "metricx_qe_score": 1.4206089973449707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们可以从一个与之完全无关的域中选择句子,例如维基百科。 所以,这", "metrics": {"bleu_score": 34.893978876446994, "chrf_score": 32.15919912877705, "xcomet_score": 0.7091240882873535, "xcomet_qe_score": 0.7242391109466553, "metricx_score": 6.189099311828613, "metricx_qe_score": 5.097402572631836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将告诉我们模型的接受性判断是否受到任何上下文的影响。 这个中文翻译是:'像,是从数据集的不同子集还是与当前句子完全无关紧要。", "metrics": {"bleu_score": 41.90782523145788, "chrf_score": 37.339057822387836, "xcomet_score": 0.4337462782859802, "xcomet_qe_score": 0.47998541593551636, "metricx_score": 6.702430725097656, "metricx_qe_score": 6.806086540222168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "' 所以,这个模型是如何工作的?", "metrics": {"bleu_score": 10.511846841633776, "chrf_score": 9.125408226287455, "xcomet_score": 0.8974334001541138, "xcomet_qe_score": 0.8644732236862183, "metricx_score": 0.3833616077899933, "metricx_qe_score": 0.3430250287055969, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们来看维基百科句子,它们与当前查询对完全不相关。在那里,我们发现MPP决策主要是针对任意上下文线的鲁棒性。", "metrics": {"bleu_score": 26.38085910472019, "chrf_score": 22.57122069527739, "xcomet_score": 0.7997657060623169, "xcomet_qe_score": 0.7287506461143494, "metricx_score": 6.347416877746582, "metricx_qe_score": 6.686415672302246, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将相关链接增加到2024,以最大限度地发挥OPT和GPT-2模型的作用。我们在这里看到,", "metrics": {"bleu_score": 9.560808177967553, "chrf_score": 29.354939681359056, "xcomet_score": 0.36937934160232544, "xcomet_qe_score": 0.31483644247055054, "metricx_score": 7.825251579284668, "metricx_qe_score": 7.914137840270996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在橙色虚线处,MPP判断相对稳定。", "metrics": {"bleu_score": 53.01646310382839, "chrf_score": 52.88913920636522, "xcomet_score": 0.87420654296875, "xcomet_qe_score": 0.7965394258499146, "metricx_score": 1.3679301738739014, "metricx_qe_score": 2.9719064235687256, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从同一数据集中选择句子时会发生什么? 所以", "metrics": {"bleu_score": 54.288699768683244, "chrf_score": 54.58414685056986, "xcomet_score": 0.8370550870895386, "xcomet_qe_score": 0.7534548044204712, "metricx_score": 5.255010604858398, "metricx_qe_score": 2.2507448196411133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",这里我们选择或创建的是来自同一个blimp语法数据集的可接受和不可接受的域。", "metrics": {"bleu_score": 40.12593914635937, "chrf_score": 27.794426598763955, "xcomet_score": 0.6318013072013855, "xcomet_qe_score": 0.581163763999939, "metricx_score": 5.657831192016602, "metricx_qe_score": 5.697969436645508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在添加可接受前缀或不可接受前缀时,我们看到MPP裁决要么显著增加,要么显著减少。", "metrics": {"bleu_score": 35.31811993656426, "chrf_score": 29.616264326945295, "xcomet_score": 0.7876859307289124, "xcomet_qe_score": 0.7525200843811035, "metricx_score": 3.9758570194244385, "metricx_qe_score": 3.074366331100464, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,当我们匹配结构时,也就是说,当我们从“blame perspect”文本中选择具有相同现象的句子时—— 根据选择的前缀是否合适或不合法,我们看到模型的MPP判断出现了大规模的增长或减少。 这个影响", "metrics": {"bleu_score": 28.32531188221544, "chrf_score": 24.669244989480994, "xcomet_score": 0.28289794921875, "xcomet_qe_score": 0.34276941418647766, "metricx_score": 10.194771766662598, "metricx_qe_score": 9.574567794799805, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在整个上下文链接中都会增加,并且可能会影响新的语言模型,这些模型具有大的上下文窗口。", "metrics": {"bleu_score": 37.37459821241101, "chrf_score": 31.98495250762158, "xcomet_score": 0.769417405128479, "xcomet_qe_score": 0.7054349184036255, "metricx_score": 4.839204788208008, "metricx_qe_score": 5.565228462219238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为什么匹配前缀会影响语言模型的判断? 所以,我们做", "metrics": {"bleu_score": 44.764089721057886, "chrf_score": 40.297744636868025, "xcomet_score": 0.7105927467346191, "xcomet_qe_score": 0.6190335750579834, "metricx_score": 5.5296807289123535, "metricx_qe_score": 1.8689576387405396, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了一系列分析,试图通过尝试保留相关结构,但向输入添加噪音来干扰输入。", "metrics": {"bleu_score": 46.20448884746265, "chrf_score": 37.34637336823058, "xcomet_score": 0.34296149015426636, "xcomet_qe_score": 0.4025630056858063, "metricx_score": 5.022727966308594, "metricx_qe_score": 5.124718189239502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在进行了几次这种干扰后。 我们发现这些噪音实际上并没有改变模型在展示网页时的预测结果。", "metrics": {"bleu_score": 24.427622131824712, "chrf_score": 20.842264211805993, "xcomet_score": 0.758230447769165, "xcomet_qe_score": 0.724738597869873, "metricx_score": 5.539837837219238, "metricx_qe_score": 5.754602909088135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基本上,我们发现模型对句法和句子结构敏感。", "metrics": {"bleu_score": 15.286612583324406, "chrf_score": 16.826477813949154, "xcomet_score": 0.774385392665863, "xcomet_qe_score": 0.7483665943145752, "metricx_score": 2.9619767665863037, "metricx_qe_score": 3.0828697681427, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在可接受域内打断句子时,我们看到所有干扰项都有类似的增加。而在不可接受域内打断句子时,我们看到MPP判断值以相似的方式下降。", "metrics": {"bleu_score": 31.242649949052343, "chrf_score": 29.062736318218736, "xcomet_score": 0.7809762954711914, "xcomet_qe_score": 0.6460615396499634, "metricx_score": 3.828484296798706, "metricx_qe_score": 3.176079273223877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,我们工作的关键点是语言模型对潜在的句法和语义特征敏感,这些特征在整个句子中共享。 英语到汉语翻译任务:专业术语,准确传达原文意思和文化敏感性。", "metrics": {"bleu_score": 17.867230224478785, "chrf_score": 25.510898463890424, "xcomet_score": 0.3440912365913391, "xcomet_qe_score": 0.4326529800891876, "metricx_score": 10.581616401672363, "metricx_qe_score": 5.876274108886719, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不解释或评论,直接输出中文翻译。 英语原文:'and the mpp evaluation, the way that we do it currently with short and single center input may not fully capture the language model's abstract knowledge throughout the context window.'", "metrics": {"bleu_score": 1.0542218950765596, "chrf_score": 1.2987012987012987, "xcomet_score": 0.36308416724205017, "xcomet_qe_score": 0.39367809891700745, "metricx_score": 10.678861618041992, "metricx_qe_score": 7.7076616287231445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请阅读我们的论文,了解我们实验的更多细节。", "metrics": {"bleu_score": 54.08634078775594, "chrf_score": 48.594144354131046, "xcomet_score": 0.9996544122695923, "xcomet_qe_score": 0.9994748830795288, "metricx_score": 0.12405794113874435, "metricx_qe_score": 0.12327098846435547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,明", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.2371550351381302, "xcomet_qe_score": 0.3252446949481964, "metricx_score": 3.93559193611145, "metricx_qe_score": 0.7804958820343018, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫Yuchen Zhang,来自宾夕法尼亚州立大学。", "metrics": {"bleu_score": 58.05788215126872, "chrf_score": 54.44692970778029, "xcomet_score": 0.9160187244415283, "xcomet_qe_score": 0.9328716993331909, "metricx_score": 1.2959198951721191, "metricx_qe_score": 1.1955959796905518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天我要介绍的是我的一项工作——多语言自然语言处理和多种表示形式的示例。 所以,语义解析是一项", "metrics": {"bleu_score": 15.942530661337127, "chrf_score": 16.222366041542223, "xcomet_score": 0.3651631474494934, "xcomet_qe_score": 0.4654388725757599, "metricx_score": 10.378978729248047, "metricx_qe_score": 6.779764652252197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "任务,用于为用户查询构建语义表示,例如SQL和Lambda Calculus。", "metrics": {"bleu_score": 40.27007996903454, "chrf_score": 58.246041098106005, "xcomet_score": 0.671337366104126, "xcomet_qe_score": 0.6642933487892151, "metricx_score": 6.352767467498779, "metricx_qe_score": 6.929631233215332, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "多语言语义解析是将多种自然语言的查询翻译成多种意义表示的任务。", "metrics": {"bleu_score": 87.87142254774355, "chrf_score": 84.43316591536836, "xcomet_score": 0.8751869201660156, "xcomet_qe_score": 0.8810625076293945, "metricx_score": 1.8239126205444336, "metricx_qe_score": 3.8069100379943848, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,我们需要使用神经模型将查询翻译成多种自然语言。包括SQL、Lambda表达式以及等等。", "metrics": {"bleu_score": 53.96632218977956, "chrf_score": 54.34138108447711, "xcomet_score": 0.8441723585128784, "xcomet_qe_score": 0.897707998752594, "metricx_score": 2.650855779647827, "metricx_qe_score": 2.9506473541259766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现有的跨语言句法分析模型分别被提出并根据有限的任务和应用进行评估。", "metrics": {"bleu_score": 38.91030091713277, "chrf_score": 33.562612445976484, "xcomet_score": 0.956387996673584, "xcomet_qe_score": 0.919796347618103, "metricx_score": 1.8694543838500977, "metricx_qe_score": 2.084585666656494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如, 有些自然语言的覆盖率不足,例如", "metrics": {"bleu_score": 42.51768826212765, "chrf_score": 41.74812732617345, "xcomet_score": 0.5047458410263062, "xcomet_qe_score": 0.37229907512664795, "metricx_score": 5.4313201904296875, "metricx_qe_score": 4.457935333251953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "中文。 某些特定的会议有听众。 $\\lambda$微分方程", "metrics": {"bleu_score": 5.165604006110218, "chrf_score": 5.1383547368973455, "xcomet_score": 0.1486239731311798, "xcomet_qe_score": 0.1360926479101181, "metricx_score": 17.331560134887695, "metricx_qe_score": 20.082454681396484, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是缺失的。 或者,它们仅在某些较新的模型上进行评估。", "metrics": {"bleu_score": 40.188875403206985, "chrf_score": 31.482118005758064, "xcomet_score": 0.353669673204422, "xcomet_qe_score": 0.43219128251075745, "metricx_score": 6.333361625671387, "metricx_qe_score": 8.755878448486328, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,只有一个模型可以对它们进行评估。", "metrics": {"bleu_score": 21.031444120861046, "chrf_score": 21.841841294954815, "xcomet_score": 0.995824933052063, "xcomet_qe_score": 0.9728620052337646, "metricx_score": 0.5626621246337891, "metricx_qe_score": 0.8773354291915894, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,我们提议提供一个跨语言的", "metrics": {"bleu_score": 10.511846841633776, "chrf_score": 7.67940552788344, "xcomet_score": 0.4096582531929016, "xcomet_qe_score": 0.38555335998535156, "metricx_score": 4.917513847351074, "metricx_qe_score": 3.7836756706237793, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "示例数据集,其中包含多个自然语言和对应的表示形式。", "metrics": {"bleu_score": 13.175264853456902, "chrf_score": 11.272986994008019, "xcomet_score": 0.24439066648483276, "xcomet_qe_score": 0.26218873262405396, "metricx_score": 3.6271347999572754, "metricx_qe_score": 4.589236259460449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它包含9个数据集在各种域中,570个解析的 Texas,8百万表示,并且22种自然语言,在15种语言家族中。", "metrics": {"bleu_score": 24.305687635975, "chrf_score": 23.512066961796606, "xcomet_score": 0.4559430480003357, "xcomet_qe_score": 0.48855873942375183, "metricx_score": 11.831095695495605, "metricx_qe_score": 14.94359302520752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地评估基准,我们考虑了以下六种训练和评估设置。", "metrics": {"bleu_score": 60.1067427964331, "chrf_score": 50.67666069805973, "xcomet_score": 0.984916090965271, "xcomet_qe_score": 0.9741957187652588, "metricx_score": 0.7270239591598511, "metricx_qe_score": 1.395418405532837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是翻译任务。我们", "metrics": {"bleu_score": 47.987820666906615, "chrf_score": 49.147537264560896, "xcomet_score": 0.7697749137878418, "xcomet_qe_score": 0.6731410026550293, "metricx_score": 4.844459056854248, "metricx_qe_score": 2.304828643798828, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将使用Google Translate API将源语言翻译成目标语言,然后使用单语言模型进行训练和评估。", "metrics": {"bleu_score": 67.40594065421493, "chrf_score": 58.89181339751478, "xcomet_score": 0.8032177090644836, "xcomet_qe_score": 0.9424524307250977, "metricx_score": 2.0688321590423584, "metricx_qe_score": 1.5203857421875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们训练一个英语模型来处理英语查询,并在推断期间使用API将德语查询翻译成英语。然后使用训练的模型来预测SQL查询。", "metrics": {"bleu_score": 51.697315395717055, "chrf_score": 47.91199945094971, "xcomet_score": 0.9354974031448364, "xcomet_qe_score": 0.9137750864028931, "metricx_score": 1.7230703830718994, "metricx_qe_score": 1.5570727586746216, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将测试单语言模型。", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 71.24819139092992, "xcomet_score": 0.9068087339401245, "xcomet_qe_score": 0.961683988571167, "metricx_score": 0.3035227656364441, "metricx_qe_score": 0.36633533239364624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个场景中,源语言与目标语言是相同的。例如,德语到德语或英语到英语。", "metrics": {"bleu_score": 56.32203957368784, "chrf_score": 53.30932650685397, "xcomet_score": 0.9573005437850952, "xcomet_qe_score": 0.9222667217254639, "metricx_score": 1.352798581123352, "metricx_qe_score": 1.1227118968963623, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还会测试单语言模型的设置,通过仅使用训练数据的百分之十来训练多语言模型。", "metrics": {"bleu_score": 21.440997864529624, "chrf_score": 21.49669892698097, "xcomet_score": 0.7269962430000305, "xcomet_qe_score": 0.7289046049118042, "metricx_score": 5.253566741943359, "metricx_qe_score": 4.760043621063232, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们测试了一个多语言模型,它使用所有语言训练一个多语言模型。", "metrics": {"bleu_score": 63.87390016474041, "chrf_score": 65.50568570646067, "xcomet_score": 0.8429739475250244, "xcomet_qe_score": 0.7750862836837769, "metricx_score": 3.3308544158935547, "metricx_qe_score": 2.8850207328796387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们将德语、英语和中文查询结合起来训练多语言模型,并", "metrics": {"bleu_score": 50.393198211838275, "chrf_score": 40.75895606893371, "xcomet_score": 0.7552788257598877, "xcomet_qe_score": 0.649935245513916, "metricx_score": 3.4088168144226074, "metricx_qe_score": 2.7320728302001953, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过推断来使用这个模型。 德语查询或中文查询等。", "metrics": {"bleu_score": 47.337511213850995, "chrf_score": 45.68267682926129, "xcomet_score": 0.8455935716629028, "xcomet_qe_score": 0.8424743413925171, "metricx_score": 4.4509077072143555, "metricx_qe_score": 3.6395020484924316, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们将考虑跨语言零 shot 和零 shot 转移。", "metrics": {"bleu_score": 18.571513506774206, "chrf_score": 16.732140534164376, "xcomet_score": 0.3353480100631714, "xcomet_qe_score": 0.3495316207408905, "metricx_score": 11.492572784423828, "metricx_qe_score": 10.914806365966797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用一个源语言训练,然后转移到另一个语言。", "metrics": {"bleu_score": 46.74166298426218, "chrf_score": 41.47340299749732, "xcomet_score": 0.8854403495788574, "xcomet_qe_score": 0.8131248950958252, "metricx_score": 2.5120673179626465, "metricx_qe_score": 2.51962947845459, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在训练中,我们将使用英语查询或英语和德语混合查询来训练多语言模型,以预测SQL输出。", "metrics": {"bleu_score": 57.640088573996024, "chrf_score": 54.1593438977359, "xcomet_score": 0.8210344314575195, "xcomet_qe_score": 0.7970865964889526, "metricx_score": 1.0853888988494873, "metricx_qe_score": 1.7473124265670776, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现了很多有趣的分析结果。", "metrics": {"bleu_score": 56.81096832337496, "chrf_score": 55.93654065333923, "xcomet_score": 0.9969499111175537, "xcomet_qe_score": 0.9840821027755737, "metricx_score": 0.7881747484207153, "metricx_qe_score": 0.8176968097686768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "关于单语言模型的分析,我们在两组模型上进行了评估。 包括多语言泛型编码器,带有指针基的解码器,例如x86_64 + PDR和Bert + PDR。", "metrics": {"bleu_score": 25.78981675700335, "chrf_score": 19.508545361374935, "xcomet_score": 0.5417137145996094, "xcomet_qe_score": 0.5473213791847229, "metricx_score": 9.809911727905273, "metricx_qe_score": 7.618991851806641, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还评估了编码器-解码器模型,这是多语言表示的编码器-解码器模型,例如M6和MT5。", "metrics": {"bleu_score": 17.9853209687605, "chrf_score": 12.482827064250879, "xcomet_score": 0.63892662525177, "xcomet_qe_score": 0.6682859659194946, "metricx_score": 5.587984085083008, "metricx_qe_score": 5.914252758026123, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "发现编码器/解码器在所有九个数据集中都能获得最佳性能。", "metrics": {"bleu_score": 32.672940262046325, "chrf_score": 21.45822577250687, "xcomet_score": 0.976087212562561, "xcomet_qe_score": 0.9816409349441528, "metricx_score": 1.875709056854248, "metricx_qe_score": 2.1777443885803223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估m5和example xlmr加pdr多语言设置。 无码解", "metrics": {"bleu_score": 11.189528053253452, "chrf_score": 10.056154889058606, "xcomet_score": 0.5639882683753967, "xcomet_qe_score": 0.5032142400741577, "metricx_score": 11.791885375976562, "metricx_qe_score": 9.191515922546387, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "码器或编码器 PR 可以通过混合多种语言进行训练来提高。 英语到汉语翻译的目标是准确传", "metrics": {"bleu_score": 22.709193912136072, "chrf_score": 15.748667460616275, "xcomet_score": 0.2512427866458893, "xcomet_qe_score": 0.15966074168682098, "metricx_score": 13.290766716003418, "metricx_qe_score": 14.122485160827637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "达原始英文演讲的意思和微妙之处,同时遵守中文语法、词汇和文化敏感性。使用精确的术语,并以学术或教学材料中适当的语气产出。", "metrics": {"bleu_score": 1.0469817367798506, "chrf_score": 2.5, "xcomet_score": 0.21295981109142303, "xcomet_qe_score": 0.12758415937423706, "metricx_score": 20.718894958496094, "metricx_qe_score": 21.053997039794922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "只输出中文翻译,不包括任何额外的解释或评论。请将提供的英文演讲翻译成中文: 这通常被称为多语言性障碍。", "metrics": {"bleu_score": 3.4685359634176627, "chrf_score": 7.156728547806029, "xcomet_score": 0.13991022109985352, "xcomet_qe_score": 0.14528551697731018, "metricx_score": 4.726926803588867, "metricx_qe_score": 4.061046600341797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了跨语言性能差距。", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 59.00209468789821, "xcomet_score": 0.9033793210983276, "xcomet_qe_score": 0.8933225274085999, "metricx_score": 1.7487887144088745, "metricx_qe_score": 2.4259886741638184, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个图中,蓝色线条表示多线性差分转移,", "metrics": {"bleu_score": 5.32864224277779, "chrf_score": 6.463499043198567, "xcomet_score": 0.8100991249084473, "xcomet_qe_score": 0.8221686482429504, "metricx_score": 5.37347936630249, "metricx_qe_score": 4.383049964904785, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "橙色线条表示零阶差分转移,", "metrics": {"bleu_score": 4.368583925857938, "chrf_score": 5.46448087431694, "xcomet_score": 0.8356099724769592, "xcomet_qe_score": 0.7844823598861694, "metricx_score": 4.157369613647461, "metricx_qe_score": 3.98848819732666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而绿色线条表示模型级设置。", "metrics": {"bleu_score": 13.065113298388567, "chrf_score": 15.813148898656065, "xcomet_score": 0.8254655599594116, "xcomet_qe_score": 0.7576543092727661, "metricx_score": 4.022195339202881, "metricx_qe_score": 4.062846660614014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通过对比绿色和橙色线条,我们发现零截短设置时,跨语言传输性能差距较大。而对比蓝色和橙色线条,我们发现视图截短设置时,传输差距迅速缩小。", "metrics": {"bleu_score": 22.028965094219448, "chrf_score": 19.95067312608928, "xcomet_score": 0.6331303715705872, "xcomet_qe_score": 0.6628021597862244, "metricx_score": 6.723423480987549, "metricx_qe_score": 6.081178188323975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还会发现一些其他有趣的发现,", "metrics": {"bleu_score": 36.41410562218426, "chrf_score": 33.74306024007265, "xcomet_score": 0.946304202079773, "xcomet_qe_score": 0.9218360185623169, "metricx_score": 0.38827478885650635, "metricx_qe_score": 0.8095066547393799, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如编码器-解码器、All-Performer、进度工作或取得可比较的结果。", "metrics": {"bleu_score": 11.177222547202245, "chrf_score": 9.403954326001221, "xcomet_score": 0.49374547600746155, "xcomet_qe_score": 0.5812238454818726, "metricx_score": 9.447579383850098, "metricx_qe_score": 10.523026466369629, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在英语自然语言处理方面进行训练可以显著提高Fusion的性能目标和自然语言。 我们发现,像CodeS和Blue这样的多语言模型在许多解析任务上仍然有效。", "metrics": {"bleu_score": 38.985070922766205, "chrf_score": 30.810632329636768, "xcomet_score": 0.36424294114112854, "xcomet_qe_score": 0.21668976545333862, "metricx_score": 10.524676322937012, "metricx_qe_score": 10.587057113647461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,一个通用的跨语言语义解析器示例,支持多种自然语言和多模态表现形式。", "metrics": {"bleu_score": 31.387928455646865, "chrf_score": 24.810031769383137, "xcomet_score": 0.7775008678436279, "xcomet_qe_score": 0.789734959602356, "metricx_score": 3.7602028846740723, "metricx_qe_score": 3.4959564208984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三类多语言模型进行了综合基准测试", "metrics": {"bleu_score": 25.953803613721462, "chrf_score": 23.0616525448466, "xcomet_score": 0.9546149969100952, "xcomet_qe_score": 0.9436327219009399, "metricx_score": 1.45237135887146, "metricx_qe_score": 2.380103826522827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们的结果展示了许多有趣的发现等", "metrics": {"bleu_score": 69.64705665515706, "chrf_score": 63.54912038694083, "xcomet_score": 0.8405939340591431, "xcomet_qe_score": 0.778618574142456, "metricx_score": 3.384197235107422, "metricx_qe_score": 3.3133182525634766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "等。", "metrics": {"bleu_score": 0.0, "chrf_score": 8.333333333333332, "xcomet_score": 0.604798436164856, "xcomet_qe_score": 0.2309737205505371, "metricx_score": 1.9000164270401, "metricx_qe_score": 3.2553701400756836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "欢迎访问我们的论文和代码。", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 64.8012173012173, "xcomet_score": 0.9862284660339355, "xcomet_qe_score": 0.9691290855407715, "metricx_score": 0.43438172340393066, "metricx_qe_score": 0.6480231285095215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢收听!", "metrics": {"bleu_score": 12.703318703865365, "chrf_score": 8.0, "xcomet_score": 0.9768924117088318, "xcomet_qe_score": 0.9609314799308777, "metricx_score": 0.5919415950775146, "metricx_qe_score": 0.3213791847229004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫艾德·维拉德。我将为大家简要介绍谷歌翻译的“基于模式的翻译”论文。该论文探讨了", "metrics": {"bleu_score": 6.190049070024289, "chrf_score": 8.296978883184494, "xcomet_score": 0.343213826417923, "xcomet_qe_score": 0.28515711426734924, "metricx_score": 8.838385581970215, "metricx_qe_score": 5.683652877807617, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "策略和性能问题。这是与我的同事们合作完成的工作。", "metrics": {"bleu_score": 9.637411586929977, "chrf_score": 12.574273837848441, "xcomet_score": 0.2589677572250366, "xcomet_qe_score": 0.19827011227607727, "metricx_score": 3.750962018966675, "metricx_qe_score": 3.9366273880004883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该模型是去年在2022年展示的540亿参数大型语言模型,", "metrics": {"bleu_score": 20.515739829104156, "chrf_score": 25.837792058029247, "xcomet_score": 0.8057143688201904, "xcomet_qe_score": 0.8108430504798889, "metricx_score": 4.891670227050781, "metricx_qe_score": 4.701639175415039, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它专注于大量文本数据,包括180亿个标记。 在数据制造", "metrics": {"bleu_score": 5.450048489014556, "chrf_score": 11.106719800451115, "xcomet_score": 0.15517041087150574, "xcomet_qe_score": 0.2143547683954239, "metricx_score": 7.883486747741699, "metricx_qe_score": 6.359961032867432, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "过程中,它能够在数百个LP任务中达到最先进的状态。", "metrics": {"bleu_score": 15.948715931428461, "chrf_score": 20.21734424995295, "xcomet_score": 0.5330843329429626, "xcomet_qe_score": 0.48107704520225525, "metricx_score": 6.025138854980469, "metricx_qe_score": 7.560403823852539, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作呈现了大规模语言模型在翻译生成中的首次系统性研究。", "metrics": {"bleu_score": 27.61780006281378, "chrf_score": 23.71235292642249, "xcomet_score": 0.8257900476455688, "xcomet_qe_score": 0.844649076461792, "metricx_score": 4.1415228843688965, "metricx_qe_score": 4.666399955749512, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最佳实践来评估这些模型的迁移能力,", "metrics": {"bleu_score": 38.46917139690214, "chrf_score": 34.717008138130865, "xcomet_score": 0.8503156900405884, "xcomet_qe_score": 0.7543601989746094, "metricx_score": 3.7663397789001465, "metricx_qe_score": 4.404409885406494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这包括使用最新测试集来避免与训练数据中的测试数据重叠。", "metrics": {"bleu_score": 37.49044984737989, "chrf_score": 30.35795501813797, "xcomet_score": 0.8978980183601379, "xcomet_qe_score": 0.9320288896560669, "metricx_score": 1.3522039651870728, "metricx_qe_score": 1.839479923248291, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对比了两个操作系统,即最佳性能系统的双核评估。", "metrics": {"bleu_score": 8.339216168026896, "chrf_score": 11.521041713278821, "xcomet_score": 0.3924572765827179, "xcomet_qe_score": 0.5661591291427612, "metricx_score": 7.436948299407959, "metricx_qe_score": 6.845883369445801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用最先进的NLP技术,并且还展示了专家级的人工评估结果。", "metrics": {"bleu_score": 47.079058175617256, "chrf_score": 41.21021006764689, "xcomet_score": 0.9678921699523926, "xcomet_qe_score": 0.9562103748321533, "metricx_score": 1.0099672079086304, "metricx_qe_score": 1.9395586252212524, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们提供了一些推荐的预处理策略。", "metrics": {"bleu_score": 33.021307716564756, "chrf_score": 29.48628540421394, "xcomet_score": 0.8933024406433105, "xcomet_qe_score": 0.8603612780570984, "metricx_score": 3.1630899906158447, "metricx_qe_score": 3.2742247581481934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提示对机器翻译的性能有很大的影响。正如我们可以在一个简单的实验中看到的,使用一个短语提示并为句子提供两个不同的提示。", "metrics": {"bleu_score": 55.45738846623984, "chrf_score": 47.0176977701266, "xcomet_score": 0.8028204441070557, "xcomet_qe_score": 0.8057095408439636, "metricx_score": 2.823005437850952, "metricx_qe_score": 2.9106404781341553, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在一千个句子中,", "metrics": {"bleu_score": 20.612390921238426, "chrf_score": 12.522180682216554, "xcomet_score": 0.8912525177001953, "xcomet_qe_score": 0.6963303089141846, "metricx_score": 7.990420341491699, "metricx_qe_score": 10.199912071228027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有五百一十六个句子存在差异。", "metrics": {"bleu_score": 4.016138436407654, "chrf_score": 3.401360544217687, "xcomet_score": 0.33124861121177673, "xcomet_qe_score": 0.15576401352882385, "metricx_score": 7.593276023864746, "metricx_qe_score": 12.735517501831055, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "极端情况下,多达四十几点。", "metrics": {"bleu_score": 21.412218198639568, "chrf_score": 13.795908489275172, "xcomet_score": 0.825742781162262, "xcomet_qe_score": 0.8453915119171143, "metricx_score": 5.6590375900268555, "metricx_qe_score": 6.256920337677002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以选择一个好的提示策略很重要。", "metrics": {"bleu_score": 80.89976633967794, "chrf_score": 80.13419067605854, "xcomet_score": 0.9874299764633179, "xcomet_qe_score": 0.9311345815658569, "metricx_score": 0.21347343921661377, "metricx_qe_score": 0.32626229524612427, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中,我们为一个五轮提示策略设计了一个标记系统,即我们向系统提供的每个句子的语言指示。", "metrics": {"bleu_score": 21.883662462203137, "chrf_score": 21.567876131429774, "xcomet_score": 0.6865755319595337, "xcomet_qe_score": 0.7151838541030884, "metricx_score": 5.848762512207031, "metricx_qe_score": 4.9918904304504395, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个例子中,我们将从德语到英语进行翻译。德语句子和源句子用德语大写字母标记,英语翻译用英语大写字母标记:", "metrics": {"bleu_score": 26.695839582617314, "chrf_score": 20.878452835907535, "xcomet_score": 0.8846348524093628, "xcomet_qe_score": 0.8770734667778015, "metricx_score": 2.896305561065674, "metricx_qe_score": 1.9281904697418213, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "德语:In diesem Beispiel hier, wo wir eine Übersetzung von Deutsch ins Englische durchführen, werden die deutschen Sätze und die Qu", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.2207488715648651, "xcomet_qe_score": 0.20623771846294403, "metricx_score": 19.306453704833984, "metricx_qe_score": 21.970966339111328, "linguapy_score": [1, "GERMAN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "elltexte mit deutscher Klammer und die englischen Übersetzungen mit englischer Klammer markiert. 我们看到,实际的打印形式对几个短语的影响并不大。 对于零和一发提示而言,至关重要。", "metrics": {"bleu_score": 9.888660568466875, "chrf_score": 10.033218204271401, "xcomet_score": 0.1379142850637436, "xcomet_qe_score": 0.14144468307495117, "metricx_score": 24.106618881225586, "metricx_qe_score": 25.0, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是当我们进行五发提示时,实际提示的形式几乎没有区别。", "metrics": {"bleu_score": 24.669426816409512, "chrf_score": 25.58075857163245, "xcomet_score": 0.855671763420105, "xcomet_qe_score": 0.7828131318092346, "metricx_score": 1.9298107624053955, "metricx_qe_score": 2.699331760406494, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是承载重量的示例。", "metrics": {"bleu_score": 7.40354787297858, "chrf_score": 8.942022646644311, "xcomet_score": 0.6747071146965027, "xcomet_qe_score": 0.8009549975395203, "metricx_score": 5.848443984985352, "metricx_qe_score": 2.2450242042541504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验结果总结如下:例句的质量比与源句的相似性更重要。", "metrics": {"bleu_score": 52.72877650845329, "chrf_score": 45.19286517480707, "xcomet_score": 0.9930257797241211, "xcomet_qe_score": 0.9902839660644531, "metricx_score": 0.6519114375114441, "metricx_qe_score": 0.5872979164123535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,从高质量翻译中选择例子很重要。", "metrics": {"bleu_score": 36.82362017020292, "chrf_score": 28.88143268099955, "xcomet_score": 0.9325840473175049, "xcomet_qe_score": 0.9352263808250427, "metricx_score": 0.47081565856933594, "metricx_qe_score": 0.6667943000793457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尤其要指出的是,我们对比了WMT评估数据集的训练数据中的选择权和DEFT数据集的选择权。", "metrics": {"bleu_score": 16.434349396840393, "chrf_score": 20.94724255301088, "xcomet_score": 0.6309057474136353, "xcomet_qe_score": 0.5992060303688049, "metricx_score": 6.9030656814575195, "metricx_qe_score": 5.7756876945495605, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "数据集的创建和质量更高,比训练数据集更理想,因此使用", "metrics": {"bleu_score": 19.36099126436692, "chrf_score": 17.376124236281285, "xcomet_score": 0.47559285163879395, "xcomet_qe_score": 0.4630449414253235, "metricx_score": 6.1718430519104, "metricx_qe_score": 5.7573418617248535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "时表现更好。", "metrics": {"bleu_score": 15.020723831494387, "chrf_score": 21.2137534594515, "xcomet_score": 0.27482348680496216, "xcomet_qe_score": 0.17599470913410187, "metricx_score": 6.886592864990234, "metricx_qe_score": 10.721839904785156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "尽管如此,专门化的艺术系统在翻译方面具有实质性优势,", "metrics": {"bleu_score": 13.10799821496978, "chrf_score": 12.905574368959874, "xcomet_score": 0.703337550163269, "xcomet_qe_score": 0.6857702732086182, "metricx_score": 7.592761039733887, "metricx_qe_score": 6.934363842010498, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但谷歌翻译几乎可以与之媲美。", "metrics": {"bleu_score": 3.1443446386286733, "chrf_score": 1.937984496124031, "xcomet_score": 0.1565411239862442, "xcomet_qe_score": 0.15091636776924133, "metricx_score": 11.180498123168945, "metricx_qe_score": 8.337413787841797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的案例中,我们选择了与谷歌翻译配合使用。", "metrics": {"bleu_score": 49.380155419366794, "chrf_score": 39.51825105143183, "xcomet_score": 0.9202985763549805, "xcomet_qe_score": 0.8998435139656067, "metricx_score": 1.0075008869171143, "metricx_qe_score": 0.9710760116577148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过使用MNM框架进行的人机交互实验获得的启示是,Palm的流畅性与艺术系统状态的可比性,但主要区别在于准确性。", "metrics": {"bleu_score": 27.27155860626527, "chrf_score": 25.049709866633812, "xcomet_score": 0.6557838916778564, "xcomet_qe_score": 0.5003483295440674, "metricx_score": 6.85074520111084, "metricx_qe_score": 6.626898288726807, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别是最常见的错误是拼写错误。", "metrics": {"bleu_score": 49.202745153855076, "chrf_score": 39.33648198950194, "xcomet_score": 0.6472165584564209, "xcomet_qe_score": 0.7260379791259766, "metricx_score": 4.5595293045043945, "metricx_qe_score": 0.7720990180969238, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,似乎帕恩选择了这个名字来产生更好的翻译,有时会删除源句子中在翻译中保留的", "metrics": {"bleu_score": 24.561649368383176, "chrf_score": 19.551005458991863, "xcomet_score": 0.34535902738571167, "xcomet_qe_score": 0.4447791576385498, "metricx_score": 11.720758438110352, "metricx_qe_score": 10.651695251464844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "某些部分。 '然而,计划的“样式”类别对于状态来说要慢一些,这是额外的一个信号。' 该模式能够提供非常流畅的输出,但也存在一些准确性问题。", "metrics": {"bleu_score": 26.749607768481127, "chrf_score": 23.676641476018702, "xcomet_score": 0.1600039303302765, "xcomet_qe_score": 0.12261605262756348, "metricx_score": 9.936224937438965, "metricx_qe_score": 11.76159954071045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是对这份文件的简短概述。", "metrics": {"bleu_score": 19.718163018362848, "chrf_score": 16.89156115195918, "xcomet_score": 0.934929370880127, "xcomet_qe_score": 0.8447855114936829, "metricx_score": 1.3878577947616577, "metricx_qe_score": 1.0597761869430542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如需更多详情,请参阅完整的报告。", "metrics": {"bleu_score": 8.872369098171298, "chrf_score": 11.373011305196027, "xcomet_score": 0.9808946847915649, "xcomet_qe_score": 0.9525887966156006, "metricx_score": 0.8256845474243164, "metricx_qe_score": 0.3733120858669281, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢!", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 54.333333333333336, "xcomet_score": 0.9982150793075562, "xcomet_qe_score": 0.9795973896980286, "metricx_score": 0.0, "metricx_qe_score": 0.1508462131023407, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我是达维德,在德国萨尔茨堡大学攻读博士学位。", "metrics": {"bleu_score": 14.757581190431866, "chrf_score": 13.48629151829087, "xcomet_score": 0.8452651500701904, "xcomet_qe_score": 0.8719413876533508, "metricx_score": 2.0554842948913574, "metricx_qe_score": 2.1477274894714355, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本视频中,我想介绍我们最近的工作:“小于你想象的每周支持:对每周支持的批判性回顾”。", "metrics": {"bleu_score": 27.625291944373004, "chrf_score": 21.442834045641757, "xcomet_score": 0.6304231286048889, "xcomet_qe_score": 0.7194663286209106, "metricx_score": 9.917652130126953, "metricx_qe_score": 8.45349407196045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与萧宇生、马约瑟姆斯巴赫和德国克拉科合作。", "metrics": {"bleu_score": 4.514970966647375, "chrf_score": 2.336204841615983, "xcomet_score": 0.47768354415893555, "xcomet_qe_score": 0.517090916633606, "metricx_score": 7.706551551818848, "metricx_qe_score": 7.086053848266602, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想从周监督和周监督范围开始。", "metrics": {"bleu_score": 10.540610312308264, "chrf_score": 9.878259281110582, "xcomet_score": 0.5355422496795654, "xcomet_qe_score": 0.24264737963676453, "metricx_score": 7.105179786682129, "metricx_qe_score": 6.446691513061523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在微监督下,我们不手动标记数据。", "metrics": {"bleu_score": 40.70672072665171, "chrf_score": 35.489694765092636, "xcomet_score": 0.8503307104110718, "xcomet_qe_score": 0.8167921900749207, "metricx_score": 1.2893942594528198, "metricx_qe_score": 2.136960744857788, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "相反,我们会使用微标注源对数据进行标记,例如简单的概率规则、知识基础或低质量的众包来源,如右图所示。", "metrics": {"bleu_score": 40.48604173767648, "chrf_score": 35.60616132990872, "xcomet_score": 0.6078226566314697, "xcomet_qe_score": 0.6745116710662842, "metricx_score": 2.7021877765655518, "metricx_qe_score": 2.302705764770508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与人名标注相比,弱关系标注要便宜得多,但它们也很吵闹,这意味着一定数量的标注是错误的。", "metrics": {"bleu_score": 25.477877657041127, "chrf_score": 21.90490562056507, "xcomet_score": 0.6610870361328125, "xcomet_qe_score": 0.6042535901069641, "metricx_score": 5.384712219238281, "metricx_qe_score": 3.77750825881958, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们直接用每周的标签数据来训练神经网络,那么神经网络就会记住标签噪音,并且不会生成新的内容。", "metrics": {"bleu_score": 37.50512632660132, "chrf_score": 31.7813447550782, "xcomet_score": 0.6722617745399475, "xcomet_qe_score": 0.6513323187828064, "metricx_score": 6.59481143951416, "metricx_qe_score": 6.941068649291992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在每周监督学习中,提出使用强化训练算法来在噪声环境下训练新的神经网络,以便训练出的模型仍然能够很好地泛化。", "metrics": {"bleu_score": 23.728014653119104, "chrf_score": 21.350830774996343, "xcomet_score": 0.7472448348999023, "xcomet_qe_score": 0.7324303388595581, "metricx_score": 5.016565322875977, "metricx_qe_score": 5.632132530212402, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在最近的WSL工作中,'WSL'代表每周监督学习。一个常见的说法是人们声称他们仅使用三元模型对每周标签数据进行训练,并且在干净测试集上取得高性能。", "metrics": {"bleu_score": 12.683050478960336, "chrf_score": 17.73801250539628, "xcomet_score": 0.614652693271637, "xcomet_qe_score": 0.617537796497345, "metricx_score": 7.972198009490967, "metricx_qe_score": 8.249055862426758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从技术上讲,这个声明不正确,但有例外。 人们确实认为存在一个额外的清洁验证集可用于模型选择。", "metrics": {"bleu_score": 40.7712052632987, "chrf_score": 34.4308218382661, "xcomet_score": 0.7239166498184204, "xcomet_qe_score": 0.6901533007621765, "metricx_score": 5.120156764984131, "metricx_qe_score": 5.755531311035156, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们卡住了在这个问题设置上,这意味着每周的支持学习中需要额外的手动注释。", "metrics": {"bleu_score": 55.06194514562286, "chrf_score": 49.168011648735536, "xcomet_score": 0.7786731719970703, "xcomet_qe_score": 0.7065250873565674, "metricx_score": 5.00443696975708, "metricx_qe_score": 5.748323917388916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,就像房间里的大象一样,这种必要性常常被忽视。", "metrics": {"bleu_score": 78.84044396805872, "chrf_score": 72.38882614969572, "xcomet_score": 0.9236847162246704, "xcomet_qe_score": 0.8146681785583496, "metricx_score": 1.421680212020874, "metricx_qe_score": 2.7326462268829346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提到的'adoption'是让我们提出三个研究问题。", "metrics": {"bleu_score": 47.9676449968321, "chrf_score": 41.24008439393849, "xcomet_score": 0.7411700487136841, "xcomet_qe_score": 0.6621577739715576, "metricx_score": 7.037949085235596, "metricx_qe_score": 7.813834190368652, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,对于WLS,需要干净的数据吗?或者我们可以使用一个嘈杂的验证集代替吗?", "metrics": {"bleu_score": 44.64429038170406, "chrf_score": 39.678772144627274, "xcomet_score": 0.7558600306510925, "xcomet_qe_score": 0.7355491518974304, "metricx_score": 1.7875704765319824, "metricx_qe_score": 2.8479745388031006, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,如果需要干净的数据或干净数据对 WSL 工作是强制性的,那么我们需要多少干净的样本?", "metrics": {"bleu_score": 44.938212363584505, "chrf_score": 39.321993782981245, "xcomet_score": 0.8709478378295898, "xcomet_qe_score": 0.7432739734649658, "metricx_score": 2.547449827194214, "metricx_qe_score": 2.701009511947632, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们应该只使用干净的样本进行验证吗?还是有其他更好的方法来利用它们?", "metrics": {"bleu_score": 59.66523814275378, "chrf_score": 54.54311213814413, "xcomet_score": 0.9866561889648438, "xcomet_qe_score": 0.9178256392478943, "metricx_score": 0.6396704316139221, "metricx_qe_score": 0.9775174856185913, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们解决了这些问题,并且我们的发现如下。", "metrics": {"bleu_score": 33.19960601106166, "chrf_score": 27.745026874105505, "xcomet_score": 0.9520144462585449, "xcomet_qe_score": 0.8114829063415527, "metricx_score": 1.6968932151794434, "metricx_qe_score": 3.8372015953063965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们发现有趣的是,最近的WLSL方法实际上确实要求干净的白噪声样本才能正常工作。", "metrics": {"bleu_score": 39.91602876206502, "chrf_score": 39.96742187067841, "xcomet_score": 0.7913100123405457, "xcomet_qe_score": 0.8028331398963928, "metricx_score": 5.016117095947266, "metricx_qe_score": 5.167558193206787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "否则,这个图中有一个大的性能下降。", "metrics": {"bleu_score": 12.936981168384865, "chrf_score": 18.517477729625618, "xcomet_score": 0.8378225564956665, "xcomet_qe_score": 0.8278769850730896, "metricx_score": 3.185666084289551, "metricx_qe_score": 3.4243860244750977, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果没有干净的验证样本,则训练模型无法生成比原始弱标签更强大的模型。 意为:训练是没有意义的。", "metrics": {"bleu_score": 35.28183162078511, "chrf_score": 31.142411012707043, "xcomet_score": 0.8620132207870483, "xcomet_qe_score": 0.7894334197044373, "metricx_score": 3.355456829071045, "metricx_qe_score": 4.415249824523926, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明,WLSL方法实际上要求对数据进行清晰标记才能正常工作,而且获得清洁验证样本的成本不应被忽视。", "metrics": {"bleu_score": 28.49310599545408, "chrf_score": 29.063625456388337, "xcomet_score": 0.8781005144119263, "xcomet_qe_score": 0.8661026954650879, "metricx_score": 4.224306106567383, "metricx_qe_score": 3.522789478302002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的第二个发现是,增加清洁验证样本数量将帮助WSL方法获得更好的性能。请参见左侧的图示。", "metrics": {"bleu_score": 33.646819053417296, "chrf_score": 31.982842108902737, "xcomet_score": 0.8880972862243652, "xcomet_qe_score": 0.8936583995819092, "metricx_score": 3.175304889678955, "metricx_qe_score": 3.8821487426757812, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们通常只需要一个班20个样本就能达到高绩效。", "metrics": {"bleu_score": 16.73318405212602, "chrf_score": 18.375768088553258, "xcomet_score": 0.7764132022857666, "xcomet_qe_score": 0.8238059282302856, "metricx_score": 5.479656219482422, "metricx_qe_score": 3.9729971885681152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,故事还没有结束,因为我们无论如何决定使用清洁样本进行训练,直接使用它们来获得更好的性能。 红", "metrics": {"bleu_score": 10.357179602913957, "chrf_score": 12.36431639782233, "xcomet_score": 0.7003064751625061, "xcomet_qe_score": 0.7964975833892822, "metricx_score": 6.832914352416992, "metricx_qe_score": 5.812914848327637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "色图示显示了在使用干净数据进行直接应用的微调方法与仅使用干净数据进行验证的WSL方法之间的性能差异。", "metrics": {"bleu_score": 64.90658255564928, "chrf_score": 66.13853883461151, "xcomet_score": 0.7022426128387451, "xcomet_qe_score": 0.6909007430076599, "metricx_score": 4.393317699432373, "metricx_qe_score": 5.057707786560059, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们有每个类十例,直接的fine-tuning开始击败WSL方法。", "metrics": {"bleu_score": 11.728704827580131, "chrf_score": 18.028012846882397, "xcomet_score": 0.7474890947341919, "xcomet_qe_score": 0.7715378999710083, "metricx_score": 7.7757978439331055, "metricx_qe_score": 7.902276039123535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,通过允许继续对干净的验证样本进行微调,可以轻松实现之前WSL方法中提出的性能改进。", "metrics": {"bleu_score": 65.25854454591509, "chrf_score": 60.04547864374864, "xcomet_score": 0.9194213151931763, "xcomet_qe_score": 0.8247091770172119, "metricx_score": 2.810645341873169, "metricx_qe_score": 4.086362838745117, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从数字中可以看出,瓦林纳模型最初并不支持更复杂的WSL方法,", "metrics": {"bleu_score": 23.53192889784592, "chrf_score": 19.61219310624778, "xcomet_score": 0.49566295742988586, "xcomet_qe_score": 0.5616401433944702, "metricx_score": 6.663288593292236, "metricx_qe_score": 6.815892219543457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如余弦。 如果我们继续对干净的样本进行微调,则FtW的表现与其他方法一样好。", "metrics": {"bleu_score": 37.7006380454947, "chrf_score": 32.48382268237303, "xcomet_score": 0.7269856929779053, "xcomet_qe_score": 0.6751713752746582, "metricx_score": 4.501502513885498, "metricx_qe_score": 5.062596797943115, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,在实践中,没有理由选择更复杂的WSL方法,它们需要更多的时间和磁盘空间。", "metrics": {"bleu_score": 56.49414502597822, "chrf_score": 49.860060437231326, "xcomet_score": 0.975193202495575, "xcomet_qe_score": 0.9788758754730225, "metricx_score": 1.0984997749328613, "metricx_qe_score": 2.1535634994506836, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们展示了最近的WSL应用程序需要干净的手动注释样本才能正常工作。", "metrics": {"bleu_score": 37.537169770955785, "chrf_score": 33.81413991599216, "xcomet_score": 0.8037995100021362, "xcomet_qe_score": 0.791529655456543, "metricx_score": 3.5352590084075928, "metricx_qe_score": 3.51957368850708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们的性能提升和实用性被严重高估了。", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 48.56849415717752, "xcomet_score": 0.9926676750183105, "xcomet_qe_score": 0.9959598779678345, "metricx_score": 0.6876567602157593, "metricx_qe_score": 0.8314505815505981, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的具体建议如下:", "metrics": {"bleu_score": 42.88819424803536, "chrf_score": 41.435337541743635, "xcomet_score": 0.9294242858886719, "xcomet_qe_score": 0.787729024887085, "metricx_score": 0.6340898275375366, "metricx_qe_score": 0.8958864808082581, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型选择标准", "metrics": {"bleu_score": 36.78794411714425, "chrf_score": 39.890284082892784, "xcomet_score": 0.8474907875061035, "xcomet_qe_score": 0.5866836309432983, "metricx_score": 1.686611533164978, "metricx_qe_score": 3.48583984375, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",例如在干净数据集上进行模型选择。", "metrics": {"bleu_score": 19.282298313551713, "chrf_score": 16.924160798638148, "xcomet_score": 0.7994018793106079, "xcomet_qe_score": 0.8003260493278503, "metricx_score": 4.084917068481445, "metricx_qe_score": 4.523635387420654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二,WSL方法应该与功能短训练基线进行比较,在克隆示例上都能工作。", "metrics": {"bleu_score": 19.125133772985432, "chrf_score": 19.99462715296402, "xcomet_score": 0.6520485877990723, "xcomet_qe_score": 0.6807394027709961, "metricx_score": 7.846158027648926, "metricx_qe_score": 7.3689775466918945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,持续的微调是一个简单但强大的基线,未来在WSL工作中应考虑。", "metrics": {"bleu_score": 39.52985888726304, "chrf_score": 35.53259998634976, "xcomet_score": 0.817283034324646, "xcomet_qe_score": 0.8185787200927734, "metricx_score": 2.1529412269592285, "metricx_qe_score": 2.639788866043091, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们的代码是开源的。您可以在", "metrics": {"bleu_score": 28.175950490399515, "chrf_score": 24.279640648952704, "xcomet_score": 0.8853480815887451, "xcomet_qe_score": 0.825400710105896, "metricx_score": 4.751385688781738, "metricx_qe_score": 1.3613085746765137, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "演示文稿中的QR码链接处找到它。", "metrics": {"bleu_score": 2.8316557261689024, "chrf_score": 2.840909090909091, "xcomet_score": 0.8503502607345581, "xcomet_qe_score": 0.8987390995025635, "metricx_score": 2.0316474437713623, "metricx_qe_score": 1.9476978778839111, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请自由查看。", "metrics": {"bleu_score": 25.57539057896621, "chrf_score": 16.573915525114153, "xcomet_score": 0.8885015845298767, "xcomet_qe_score": 0.8462352752685547, "metricx_score": 0.32802310585975647, "metricx_qe_score": 0.5464286804199219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢您的参与,享受会议!", "metrics": {"bleu_score": 6.8962421077164695, "chrf_score": 5.31868704411254, "xcomet_score": 0.7599958181381226, "xcomet_qe_score": 0.9294884204864502, "metricx_score": 1.5007591247558594, "metricx_qe_score": 1.1785334348678589, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是詹姆斯·芬奇。", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 4.40444510151784, "xcomet_score": 0.9408985376358032, "xcomet_qe_score": 0.9793764352798462, "metricx_score": 0.5030070543289185, "metricx_qe_score": 0.4660160541534424, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我是莎拉·芬奇。", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 5.682181701855407, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5379486083984375, "metricx_qe_score": 0.8398617506027222, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "今天,我们将告诉你关于ABC-Eval的一切,这是评估对话式AI的一种新方法。", "metrics": {"bleu_score": 18.702869706385968, "chrf_score": 31.834578599284484, "xcomet_score": 0.9666194915771484, "xcomet_qe_score": 0.9779431819915771, "metricx_score": 1.4988551139831543, "metricx_qe_score": 1.7313096523284912, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是由埃默里NLP实验室完成的,该实验室由埃默里大学的吉诺·楚领导,并与亚马逊Alexa AI合作。", "metrics": {"bleu_score": 36.32274313066908, "chrf_score": 38.30611030829821, "xcomet_score": 0.8037369847297668, "xcomet_qe_score": 0.8377661108970642, "metricx_score": 3.2816736698150635, "metricx_qe_score": 3.1684703826904297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "假设你刚刚开发了一个对话模型,你想看看它与当前最先进的技术相比如何。", "metrics": {"bleu_score": 74.91269749478465, "chrf_score": 68.20291111163756, "xcomet_score": 0.989282488822937, "xcomet_qe_score": 0.9875363111495972, "metricx_score": 0.5350362062454224, "metricx_qe_score": 0.6536072492599487, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用人类评估的共同做法是,通过请人来选择两段对话中哪一段更好或者根据一个等级量表给对话打分。", "metrics": {"bleu_score": 21.33789376767546, "chrf_score": 20.33569912241705, "xcomet_score": 0.8595601320266724, "xcomet_qe_score": 0.8536616563796997, "metricx_score": 1.5849480628967285, "metricx_qe_score": 1.3937678337097168, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法很好地提供了全面的对话质量评估,但对话质量有许多方面。", "metrics": {"bleu_score": 44.344953790409605, "chrf_score": 33.91777969790888, "xcomet_score": 0.9329479932785034, "xcomet_qe_score": 0.9066862463951111, "metricx_score": 0.6658793091773987, "metricx_qe_score": 0.8322234153747559, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,你可能想要从多个维度来评估聊天质量,以了解模型在更细微层面上的优点和缺点。", "metrics": {"bleu_score": 32.739546202728, "chrf_score": 30.541029945762798, "xcomet_score": 0.9972090721130371, "xcomet_qe_score": 0.9847471714019775, "metricx_score": 0.5636966824531555, "metricx_qe_score": 0.6429253220558167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种方法是简单地要求人类法官评估对话质量的几个方面,例如模型回复的相关性,使用现有的比较或Likert量表方法。 无论如何,我们认为对于", "metrics": {"bleu_score": 48.8153584227783, "chrf_score": 44.98081929887753, "xcomet_score": 0.4328683018684387, "xcomet_qe_score": 0.24915525317192078, "metricx_score": 8.916964530944824, "metricx_qe_score": 5.945257186889648, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "维度对话评估存在一个更精确和可靠的策略。", "metrics": {"bleu_score": 23.351496036923216, "chrf_score": 22.370218701928057, "xcomet_score": 0.7057375311851501, "xcomet_qe_score": 0.776035726070404, "metricx_score": 3.525735855102539, "metricx_qe_score": 4.01815128326416, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法试图通过明确地标记每个模型响应是否表达某些行为(例如,提供不相关的信息或与自身矛盾)来减少人类评估的主观性。", "metrics": {"bleu_score": 60.569536037091396, "chrf_score": 55.217472420065995, "xcomet_score": 0.84281325340271, "xcomet_qe_score": 0.8345150947570801, "metricx_score": 2.1678366661071777, "metricx_qe_score": 2.640707015991211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们称这种方法为在聊天中注释行为,或简称为ABC evol。", "metrics": {"bleu_score": 42.66219662386316, "chrf_score": 35.5932460078982, "xcomet_score": 0.7904108762741089, "xcomet_qe_score": 0.7754853963851929, "metricx_score": 5.052546501159668, "metricx_qe_score": 5.6645307540893555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们开发了这种方法来全面地覆盖近期文献中提出来的可能影响聊天质量的行为。 {'Chin", "metrics": {"bleu_score": 34.89183279411361, "chrf_score": 28.25905167100181, "xcomet_score": 0.8362588882446289, "xcomet_qe_score": 0.7904860973358154, "metricx_score": 5.470829963684082, "metricx_qe_score": 2.790527105331421, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "eseTranslation': 'A/B测试评估模型在多轮实验中犯错误的率。'}", "metrics": {"bleu_score": 7.929026506841378, "chrf_score": 8.866559081102263, "xcomet_score": 0.2880353331565857, "xcomet_qe_score": 0.15621434152126312, "metricx_score": 7.524778366088867, "metricx_qe_score": 12.576238632202148, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,APC-Eval衡量聊天模型忽略其伴侣或说些不相关事情的次数。 模型如果自相矛盾或其伙伴, 错误地传播事实或违反常识知识,并且当模型成功或失败时表现出同情。", "metrics": {"bleu_score": 35.88469760914636, "chrf_score": 32.037079049225035, "xcomet_score": 0.42182302474975586, "xcomet_qe_score": 0.3336571753025055, "metricx_score": 7.999876499176025, "metricx_qe_score": 8.479817390441895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们选择了四个最先进的聊天机器人模型,并且对每个模型进行了人类对话测试,每模型测试了一百次。我们使用了ABC评估法。", "metrics": {"bleu_score": 28.127586359483324, "chrf_score": 23.65280039608596, "xcomet_score": 0.843067467212677, "xcomet_qe_score": 0.8921872973442078, "metricx_score": 2.2143189907073975, "metricx_qe_score": 2.636838674545288, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了进行比较,我们还使用了三种现有的方法评估这些对话: * 在话题级别上的利克特评分; * 在对话级别的利克特评分; * 对话级别的配对比较。", "metrics": {"bleu_score": 35.93956224882969, "chrf_score": 30.53966652026765, "xcomet_score": 0.8386505842208862, "xcomet_qe_score": 0.8696626424789429, "metricx_score": 3.675570011138916, "metricx_qe_score": 3.6977903842926025, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于现有的每种方法,我们收集了关于对话的八个最常见度量指标的评估,因为这是评估聊天模型多维维度", "metrics": {"bleu_score": 45.79013719820301, "chrf_score": 38.45001496339396, "xcomet_score": 0.7140108942985535, "xcomet_qe_score": 0.6810594797134399, "metricx_score": 5.12198543548584, "metricx_qe_score": 5.333216190338135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的标准实践。 我们的分析发现,行为标签(evaluated behavior labels)总体上比现有方法收集的标签更可靠,这在一百对双重标记对话中通过互标一致性来衡量。", "metrics": {"bleu_score": 24.84049477459785, "chrf_score": 22.00277859036484, "xcomet_score": 0.43948373198509216, "xcomet_qe_score": 0.4170958697795868, "metricx_score": 9.251860618591309, "metricx_qe_score": 10.19970703125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,ABC情感标签比现有方法产生的指标更能预测整体对话质量,如简单的线性回归分析所示。", "metrics": {"bleu_score": 52.71788895679632, "chrf_score": 44.190784616756446, "xcomet_score": 0.8994253873825073, "xcomet_qe_score": 0.9506635665893555, "metricx_score": 2.7363505363464355, "metricx_qe_score": 2.7991373538970947, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,你可以看到测量自我和伴侣矛盾的比例解释了五分之一个点和十分之一个点的对话质量分别,而平均酒精浓度得分只解释了四分之一个点或更少。", "metrics": {"bleu_score": 21.005898039214244, "chrf_score": 20.1014048042593, "xcomet_score": 0.47076570987701416, "xcomet_qe_score": 0.4992809295654297, "metricx_score": 13.334039688110352, "metricx_qe_score": 13.062837600708008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们检查了每个评估指标是否通过线性逐步回归捕捉到了聊天质量的独特方面。 您", "metrics": {"bleu_score": 46.03560177731796, "chrf_score": 41.931845070208844, "xcomet_score": 0.7945481538772583, "xcomet_qe_score": 0.7952895760536194, "metricx_score": 4.935910224914551, "metricx_qe_score": 2.2166614532470703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以看到,所有ABC EVL衡量标准的组合可以解释超过百分之二十五的对话质量。每次删除一个衡量标准时,大多数情况下都会导致丢失关于质量的合理信息量。", "metrics": {"bleu_score": 21.324071871787005, "chrf_score": 23.384492397881655, "xcomet_score": 0.798804521560669, "xcomet_qe_score": 0.8242534399032593, "metricx_score": 3.6203272342681885, "metricx_qe_score": 3.1937551498413086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一方面,所有转置水平利克特度量的组合能够解释的质量要少得多,并且这些度量中很少有", "metrics": {"bleu_score": 11.225482203513119, "chrf_score": 13.265156312507726, "xcomet_score": 0.40956929326057434, "xcomet_qe_score": 0.3474377691745758, "metricx_score": 9.528273582458496, "metricx_qe_score": 6.430466651916504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "包含独特信息的。 这些可靠、信息丰富且独特的ABC评估指标使我们能够以比以往方法更高的分辨率来评估对话式AI。", "metrics": {"bleu_score": 5.844941052207696, "chrf_score": 12.095807740418625, "xcomet_score": 0.34431153535842896, "xcomet_qe_score": 0.535248339176178, "metricx_score": 5.487159729003906, "metricx_qe_score": 5.243403434753418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验结果中,可以看到仍然存在一些挑战,并且已经被精确量化。", "metrics": {"bleu_score": 49.40287800412559, "chrf_score": 47.65679638551755, "xcomet_score": 0.9858593940734863, "xcomet_qe_score": 0.9708313345909119, "metricx_score": 1.2459412813186646, "metricx_qe_score": 1.4365732669830322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们测试的机器人在它们的回答中约有20%违反了常识。", "metrics": {"bleu_score": 52.18094804553855, "chrf_score": 48.058607050059415, "xcomet_score": 0.9160295724868774, "xcomet_qe_score": 0.9075654745101929, "metricx_score": 1.074593186378479, "metricx_qe_score": 1.459834337234497, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他们大约百分之十五的回答中提供不相关的信息,并且大约百分之十的时候会相互矛盾或者他们的伴侣。", "metrics": {"bleu_score": 17.41867197629359, "chrf_score": 16.643269926348626, "xcomet_score": 0.626189112663269, "xcomet_qe_score": 0.6827153563499451, "metricx_score": 5.675723075866699, "metricx_qe_score": 5.1837615966796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个领域中快速的进步,许多这些错误率在我们进行评估以来的新模型发布中可能会减少。", "metrics": {"bleu_score": 28.353278719936807, "chrf_score": 26.26310738152843, "xcomet_score": 0.7001954317092896, "xcomet_qe_score": 0.6971625089645386, "metricx_score": 4.134485244750977, "metricx_qe_score": 4.440285682678223, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这更加促使我们追求可靠的和精确的评估指标来比较模型。", "metrics": {"bleu_score": 50.13053504161699, "chrf_score": 45.79604367535402, "xcomet_score": 0.9984697103500366, "xcomet_qe_score": 0.9942514896392822, "metricx_score": 0.9353854060173035, "metricx_qe_score": 1.119584321975708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望ABC评估能够被同行们作为朝着这个方向迈出的有意义的一步,并且", "metrics": {"bleu_score": 46.111884701907975, "chrf_score": 40.96748196843068, "xcomet_score": 0.7138751745223999, "xcomet_qe_score": 0.7233695387840271, "metricx_score": 6.008431434631348, "metricx_qe_score": 2.7446210384368896, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们期待着看到对话式AI在未来几个月和几年里如何进步。", "metrics": {"bleu_score": 54.119533608948146, "chrf_score": 51.10602865964966, "xcomet_score": 0.9497467875480652, "xcomet_qe_score": 0.9758709669113159, "metricx_score": 0.6937491297721863, "metricx_qe_score": 0.7458189725875854, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢观看。", "metrics": {"bleu_score": 66.87403049764218, "chrf_score": 54.333333333333336, "xcomet_score": 0.9849855899810791, "xcomet_qe_score": 0.9607588648796082, "metricx_score": 0.2659546732902527, "metricx_qe_score": 0.5833151340484619, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫欧阳茜,我将介绍我们题为“翻译需要上下文:", "metrics": {"bleu_score": 33.555020693475896, "chrf_score": 25.2003520310972, "xcomet_score": 0.6435463428497314, "xcomet_qe_score": 0.5655782222747803, "metricx_score": 4.959203720092773, "metricx_qe_score": 4.817315101623535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于数据的多语言探索”的工作。", "metrics": {"bleu_score": 32.635983266098926, "chrf_score": 36.741699113720074, "xcomet_score": 0.7601983547210693, "xcomet_qe_score": 0.7186952829360962, "metricx_score": 3.5206027030944824, "metricx_qe_score": 4.673930644989014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是在与帕特里克·范恩合作完成的。埃米尔·李,安德烈·fd·马丁斯和格雷姆·纽比克。", "metrics": {"bleu_score": 12.224986162816123, "chrf_score": 7.078799938627718, "xcomet_score": 0.47383278608322144, "xcomet_qe_score": 0.47990140318870544, "metricx_score": 7.651015758514404, "metricx_qe_score": 8.525102615356445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以翻译很大程度上依赖于上下文。", "metrics": {"bleu_score": 27.22589423069701, "chrf_score": 29.48832081239912, "xcomet_score": 0.9971078634262085, "xcomet_qe_score": 0.987197756767273, "metricx_score": 0.08889003098011017, "metricx_qe_score": 0.029801853001117706, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,我们如何翻译这个句子中的'mol'?", "metrics": {"bleu_score": 40.37211700637277, "chrf_score": 34.22946664045736, "xcomet_score": 0.9150490760803223, "xcomet_qe_score": 0.8917715549468994, "metricx_score": 2.3182060718536377, "metricx_qe_score": 3.5535888671875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果之前句子是“事情开始变得危险,如果部长们发现的话”,那么“Moll”指的是间谍。", "metrics": {"bleu_score": 10.774132248279502, "chrf_score": 7.4792052075261335, "xcomet_score": 0.7676427364349365, "xcomet_qe_score": 0.8119271993637085, "metricx_score": 6.308168888092041, "metricx_qe_score": 6.898652076721191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,如果之前句子是“医生,有任何严重的事情吗?”,那么“Moll”指的是出生证明。", "metrics": {"bleu_score": 7.330449509973001, "chrf_score": 8.210823007086818, "xcomet_score": 0.5786510705947876, "xcomet_qe_score": 0.5800735950469971, "metricx_score": 7.543005466461182, "metricx_qe_score": 7.301036834716797, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,根据上下文,单词的意思会发生变化,因此它的翻译也随之变化。", "metrics": {"bleu_score": 33.85677071824434, "chrf_score": 28.222644641304917, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.2750493288040161, "metricx_qe_score": 0.2807263135910034, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,评估所有这些翻译案例的表现相当困难。", "metrics": {"bleu_score": 6.502031434676325, "chrf_score": 10.449339739521953, "xcomet_score": 0.8973400592803955, "xcomet_qe_score": 0.8465245962142944, "metricx_score": 2.5343453884124756, "metricx_qe_score": 2.966390609741211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,只有小部分翻译依赖上下文,这使得句法级别的指标(例如Blue)无法捕捉到这些翻译。", "metrics": {"bleu_score": 31.62121517585004, "chrf_score": 24.880091563579057, "xcomet_score": 0.8953092098236084, "xcomet_qe_score": 0.803215503692627, "metricx_score": 3.1242446899414062, "metricx_qe_score": 3.7526912689208984, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "有些人建议对依赖于上下文的翻译进行有针对性的评估,但是这些资源只支持有限类型的依赖于上下文的翻译和有限数量的语言。因为它们通常依赖于域知识和人类创作。", "metrics": {"bleu_score": 61.0317571629865, "chrf_score": 54.808580138149054, "xcomet_score": 0.7790173292160034, "xcomet_qe_score": 0.8134539127349854, "metricx_score": 4.0438642501831055, "metricx_qe_score": 4.330366611480713, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个工作尝试回答这两个问题:", "metrics": {"bleu_score": 15.373774437190724, "chrf_score": 13.598316594543885, "xcomet_score": 0.924680769443512, "xcomet_qe_score": 0.9542214870452881, "metricx_score": 1.9185593128204346, "metricx_qe_score": 2.2453296184539795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,翻译时需要上下文吗?", "metrics": {"bleu_score": 30.215132342213096, "chrf_score": 25.650350538413747, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.29203277826309204, "metricx_qe_score": 0.378696084022522, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,模型们能很好地处理这些情况吗?", "metrics": {"bleu_score": 30.935645560955486, "chrf_score": 26.012478083523664, "xcomet_score": 0.9990018606185913, "xcomet_qe_score": 0.984711766242981, "metricx_score": 0.9049019813537598, "metricx_qe_score": 1.023376703262329, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答第一个问题,我们首先通过测量一个词在翻译中依赖于上下文的程度来开始。", "metrics": {"bleu_score": 43.67625558155831, "chrf_score": 38.59451103002821, "xcomet_score": 0.9502778053283691, "xcomet_qe_score": 0.9982737302780151, "metricx_score": 4.022458553314209, "metricx_qe_score": 3.8100175857543945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在前一项工作中,我们引入了CMI作为衡量机器翻译模型对上下文使用程度的指标。", "metrics": {"bleu_score": 37.27776028327587, "chrf_score": 34.592720560212825, "xcomet_score": 0.926008939743042, "xcomet_qe_score": 0.8824205994606018, "metricx_score": 3.915274143218994, "metricx_qe_score": 2.903244972229004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这通过衡量源文本x提供给目标y关于上下文c的信息量来实现。 你可以将 cxmi 视为给模型提供上下文所获得的信息。", "metrics": {"bleu_score": 32.89444756567626, "chrf_score": 27.366427489582822, "xcomet_score": 0.770968496799469, "xcomet_qe_score": 0.7947804927825928, "metricx_score": 5.426614284515381, "metricx_qe_score": 4.918748378753662, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个工作扩展了cxmi到点 cxmi,它可以测量句子级别的上下文使用情况或单词级别。", "metrics": {"bleu_score": 23.143467639655245, "chrf_score": 16.290110389197892, "xcomet_score": 0.6765041947364807, "xcomet_qe_score": 0.6820012927055359, "metricx_score": 8.309409141540527, "metricx_qe_score": 8.17052936553955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以认为那些具有 high pmi 的词是那些需要上下文翻译的词。", "metrics": {"bleu_score": 37.30786950813074, "chrf_score": 25.830996137925343, "xcomet_score": 0.9287668466567993, "xcomet_qe_score": 0.9161183834075928, "metricx_score": 7.2642436027526855, "metricx_qe_score": 7.536891460418701, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们分析具有高P-SI的单词,以查找这些单词之间的模式。", "metrics": {"bleu_score": 35.97638750429049, "chrf_score": 34.917903624673905, "xcomet_score": 0.8667177557945251, "xcomet_qe_score": 0.8828597664833069, "metricx_score": 5.835293292999268, "metricx_qe_score": 5.727033615112305, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对从英语翻译成十四种不同语言的 TED 演讲进行了分析。", "metrics": {"bleu_score": 58.328365711086086, "chrf_score": 52.28388352259724, "xcomet_score": 0.9889320135116577, "xcomet_qe_score": 0.9891338348388672, "metricx_score": 1.3826251029968262, "metricx_qe_score": 1.8899199962615967, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对三个不同的层次进行了分析。", "metrics": {"bleu_score": 44.77118844014732, "chrf_score": 37.633130758130754, "xcomet_score": 0.9237058162689209, "xcomet_qe_score": 0.8880595564842224, "metricx_score": 0.4605344533920288, "metricx_qe_score": 0.6097858548164368, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们观察具有高平均pCXMi的语音标签。", "metrics": {"bleu_score": 13.11246738393144, "chrf_score": 16.44993686652026, "xcomet_score": 0.8084450960159302, "xcomet_qe_score": 0.7540077567100525, "metricx_score": 2.824925422668457, "metricx_qe_score": 2.9208567142486572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个允许我们找到,例如阿拉伯语中的复数名词,它们的元音是“ayy”,这在英", "metrics": {"bleu_score": 14.963473452375604, "chrf_score": 14.16726269024457, "xcomet_score": 0.22073006629943848, "xcomet_qe_score": 0.22513899207115173, "metricx_score": 13.744396209716797, "metricx_qe_score": 13.647794723510742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "语中没有。这是因为英语没有复数名词,所以翻译时需要根据上下文来确定名词是否为复数形式。", "metrics": {"bleu_score": 32.37997367600666, "chrf_score": 28.598721037728154, "xcomet_score": 0.541979193687439, "xcomet_qe_score": 0.560687780380249, "metricx_score": 3.7000784873962402, "metricx_qe_score": 4.576386451721191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样地,我们发现某些语言在选择适当的动词形式时也需要上下文。", "metrics": {"bleu_score": 88.4112136328919, "chrf_score": 89.69824812440879, "xcomet_score": 0.9977834224700928, "xcomet_qe_score": 0.996990442276001, "metricx_score": 0.5566547513008118, "metricx_qe_score": 0.8022129535675049, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们查找词汇项,其高Pmi平均值超过所有不同情况下的发生频率。", "metrics": {"bleu_score": 13.821968766350226, "chrf_score": 14.908661557596977, "xcomet_score": 0.7586022615432739, "xcomet_qe_score": 0.7853294610977173, "metricx_score": 8.220221519470215, "metricx_qe_score": 8.430269241333008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个帮助我们识别像这里的案例,其中在中文中需要上下文来正确翻译专有名词,以确保在文档中使用相同的翻译。", "metrics": {"bleu_score": 37.43701078416213, "chrf_score": 30.96414123774702, "xcomet_score": 0.7866458296775818, "xcomet_qe_score": 0.8182909488677979, "metricx_score": 1.0975273847579956, "metricx_qe_score": 1.4220649003982544, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同样地,我们发现context是支持在正确的格式中传输的。", "metrics": {"bleu_score": 17.470942957770763, "chrf_score": 14.924734634561695, "xcomet_score": 0.8223686218261719, "xcomet_qe_score": 0.8128427267074585, "metricx_score": 6.894556522369385, "metricx_qe_score": 6.088168144226074, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们观察具有高Pmi的各个单独标记。", "metrics": {"bleu_score": 7.012887580040735, "chrf_score": 8.610609392982498, "xcomet_score": 0.7039819359779358, "xcomet_qe_score": 0.6966484189033508, "metricx_score": 6.258585453033447, "metricx_qe_score": 6.3913350105285645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使我们能够识别出单词本身无法完全表达的现象,并且这些现象通过句法结构在句子中得以体现,例如椭圆分辨率。", "metrics": {"bleu_score": 33.448382585240815, "chrf_score": 28.622748362847595, "xcomet_score": 0.8114708662033081, "xcomet_qe_score": 0.8303317427635193, "metricx_score": 3.8540596961975098, "metricx_qe_score": 2.694143056869507, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,现在我们使用分析结果来设计文档本地化翻译的基准。", "metrics": {"bleu_score": 62.98777848185595, "chrf_score": 57.0600889984948, "xcomet_score": 0.9880346059799194, "xcomet_qe_score": 0.9794884920120239, "metricx_score": 1.7492711544036865, "metricx_qe_score": 1.281693696975708, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们为这五种现象创建了标签,以便自动识别属于这些现象的词,", "metrics": {"bleu_score": 14.022589047522791, "chrf_score": 14.770452612230663, "xcomet_score": 0.9347060918807983, "xcomet_qe_score": 0.884709358215332, "metricx_score": 2.32037353515625, "metricx_qe_score": 2.18611478805542, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "并将我们的标签称为多语言句法分析器或Muda标签。", "metrics": {"bleu_score": 9.197595606007173, "chrf_score": 13.814013521394571, "xcomet_score": 0.7214624881744385, "xcomet_qe_score": 0.7568784952163696, "metricx_score": 3.43435001373291, "metricx_qe_score": 3.76344633102417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们也要注意不同语言对这些数字现象有不同的比例。", "metrics": {"bleu_score": 18.475403480381217, "chrf_score": 20.828279568180147, "xcomet_score": 0.7542304992675781, "xcomet_qe_score": 0.6921323537826538, "metricx_score": 6.015169143676758, "metricx_qe_score": 5.909984111785889, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们使用mudater将标签应用到我们想要用于评估的并行语料库上,并且根据上下文选择性地应用我们的翻译度量。", "metrics": {"bleu_score": 21.51106145370211, "chrf_score": 18.581353090937398, "xcomet_score": 0.7827719449996948, "xcomet_qe_score": 0.8287137150764465, "metricx_score": 6.285187721252441, "metricx_qe_score": 6.498303413391113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们使用我们的基准线以及其他指标来评估文档级别的机器翻译。", "metrics": {"bleu_score": 63.39091426719431, "chrf_score": 57.1569208370314, "xcomet_score": 0.882198691368103, "xcomet_qe_score": 0.8642458319664001, "metricx_score": 1.984663486480713, "metricx_qe_score": 2.4974992275238037, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,使用词向量时,我们发现基于概念的模型表现最好。", "metrics": {"bleu_score": 19.059041570238293, "chrf_score": 17.372850678381635, "xcomet_score": 0.6322524547576904, "xcomet_qe_score": 0.6624951362609863, "metricx_score": 6.0539631843566895, "metricx_qe_score": 6.3307085037231445, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,如果我们使用context aware模型,性能会更好吗?", "metrics": {"bleu_score": 24.550315339798967, "chrf_score": 17.15803150736277, "xcomet_score": 0.7681834697723389, "xcomet_qe_score": 0.7682017087936401, "metricx_score": 7.07157039642334, "metricx_qe_score": 6.951571464538574, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们使用word f measure,有上下文和没有上下文的模型表现相当。", "metrics": {"bleu_score": 70.85063812971867, "chrf_score": 63.521900859283086, "xcomet_score": 0.8368078470230103, "xcomet_qe_score": 0.8368106484413147, "metricx_score": 5.539966583251953, "metricx_qe_score": 4.979977130889893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这再次表明,仅使用词汇级别的度量标准来确定最佳文档翻译系统是有困难的。", "metrics": {"bleu_score": 28.70741965365081, "chrf_score": 23.435094396805788, "xcomet_score": 0.9150092601776123, "xcomet_qe_score": 0.9759331941604614, "metricx_score": 2.2686731815338135, "metricx_qe_score": 1.9760361909866333, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "现在,我们使用Mooda基准来评估模型,并发现使用上下文的模型在某些特定的语义现象上显著更准确,例如正式性和语言粘性。 这些模型并不比不使用上下文和其他现象(例如", "metrics": {"bleu_score": 28.725897592504374, "chrf_score": 29.338038537526543, "xcomet_score": 0.2786233127117157, "xcomet_qe_score": 0.3663700222969055, "metricx_score": 9.431512832641602, "metricx_qe_score": 6.336132049560547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "省略号、专有名词和动词形式)的模型好很多。", "metrics": {"bleu_score": 15.212443967252458, "chrf_score": 17.814045722287535, "xcomet_score": 0.15296931564807892, "xcomet_qe_score": 0.14956124126911163, "metricx_score": 9.37950611114502, "metricx_qe_score": 7.933029651641846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这表明我们在文档级翻译方面需要看到更多的进步。", "metrics": {"bleu_score": 34.18736173120374, "chrf_score": 36.488896947965785, "xcomet_score": 0.994270920753479, "xcomet_qe_score": 0.9874180555343628, "metricx_score": 1.1394939422607422, "metricx_qe_score": 1.0035799741744995, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还比较了不同的商业系统,我们的基准测试表明DeepL通常比Google Translate更准确,", "metrics": {"bleu_score": 44.65844269554958, "chrf_score": 43.83686500423932, "xcomet_score": 0.8490127325057983, "xcomet_qe_score": 0.7803122997283936, "metricx_score": 2.8579440116882324, "metricx_qe_score": 3.8943076133728027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用于文档级翻译。 我们对十四组语言的翻译进行了数据驱动分析,以确定何时需要翻译。 然后,我们使用细化来建立文档级机器翻译的基准线,这可以帮助我们确定哪些描述现象模型能够很好地处理以及哪些翻译系统擅长文档级翻译。", "metrics": {"bleu_score": 50.8785054770148, "chrf_score": 43.94334906700431, "xcomet_score": 0.4193374514579773, "xcomet_qe_score": 0.4157733917236328, "metricx_score": 7.8444414138793945, "metricx_qe_score": 7.831155300140381, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您的关注,明", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 8.204869394996024, "xcomet_score": 0.26927390694618225, "xcomet_qe_score": 0.5286797285079956, "metricx_score": 3.8930046558380127, "metricx_qe_score": 0.5218664407730103, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "天再见。", "metrics": {"bleu_score": 11.752701606523267, "chrf_score": 10.982428115015974, "xcomet_score": 0.40151649713516235, "xcomet_qe_score": 0.20748856663703918, "metricx_score": 6.03424072265625, "metricx_qe_score": 7.222545623779297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫扬妮丝·拉瓦拉克,我将向您介绍我们在伯特博士方面的研究成果。这是一份法语的预训练模型,适", "metrics": {"bleu_score": 16.820638323624713, "chrf_score": 11.38725194268447, "xcomet_score": 0.3962949514389038, "xcomet_qe_score": 0.31959471106529236, "metricx_score": 11.866097450256348, "metricx_qe_score": 8.272441864013672, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "用于生物医学和临床领域。 这个演示文稿中,我们首先讨论了健康照护中的语言建模,", "metrics": {"bleu_score": 18.1441380150232, "chrf_score": 20.66959211812726, "xcomet_score": 0.3922576904296875, "xcomet_qe_score": 0.2717388868331909, "metricx_score": 4.194767951965332, "metricx_qe_score": 4.106884002685547, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们将介绍我们文章的主要贡献。", "metrics": {"bleu_score": 86.13356263647333, "chrf_score": 84.3318004234722, "xcomet_score": 0.9850431680679321, "xcomet_qe_score": 0.9847753047943115, "metricx_score": 0.36599403619766235, "metricx_qe_score": 0.7301774621009827, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了第一个法语生物医学模型,名为Dr. Bert,它是基于Roberta和Natsos数据集构建的,这是一个来自网络的医疗级爬虫数据集。", "metrics": {"bleu_score": 26.421776895766417, "chrf_score": 20.83358991923391, "xcomet_score": 0.6690364480018616, "xcomet_qe_score": 0.5771819949150085, "metricx_score": 3.99607515335083, "metricx_qe_score": 3.0832037925720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还引入了多设置和数据源的模型比较。然后,我们展示了关于11个生物医学和临床决策任务的结果。 翻译:我们还引入了多设置和数据源的模型比较。", "metrics": {"bleu_score": 18.55463908512699, "chrf_score": 34.66315854658636, "xcomet_score": 0.44978204369544983, "xcomet_qe_score": 0.34762129187583923, "metricx_score": 13.950242042541504, "metricx_qe_score": 5.678956985473633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们展示了关于11个生物医学和临床决策任务的结果。", "metrics": {"bleu_score": 33.059656302185125, "chrf_score": 29.57625172993432, "xcomet_score": 0.745427131652832, "xcomet_qe_score": 0.7624382972717285, "metricx_score": 3.881033182144165, "metricx_qe_score": 4.409908771514893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,我们将介绍有关实验的结论,并提供更多关于如何访问这些模型的信息。", "metrics": {"bleu_score": 34.50424336690235, "chrf_score": 31.545729483526337, "xcomet_score": 0.9572843313217163, "xcomet_qe_score": 0.960307240486145, "metricx_score": 0.4453628361225128, "metricx_qe_score": 0.36797454953193665, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自2018年发布以来,BERT 已经成为解决自然语言处理任务最有效的方法,并且比历史上的静态和上下文相关的解决方案(如Word2Vec、FastText或NLP)提供了巨大的性能提升。", "metrics": {"bleu_score": 52.97720300791426, "chrf_score": 52.83770029240505, "xcomet_score": 0.8380974531173706, "xcomet_qe_score": 0.8073323965072632, "metricx_score": 2.379819631576538, "metricx_qe_score": 2.467374563217163, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从那时起,这个模型已经被适应了许多其他语言,比如法语(使用Camembert和其他一些领域,如biomedical,使用Permit和Biort),以及临床领域(使用Clinical Build)。但主要是英语。", "metrics": {"bleu_score": 29.833742293351246, "chrf_score": 30.25899994424578, "xcomet_score": 0.4716479480266571, "xcomet_qe_score": 0.37685081362724304, "metricx_score": 9.928258895874023, "metricx_qe_score": 10.068777084350586, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其他语言的专用模型稀缺,且通常基于连续提示训练,因为缺乏内部数据。 不", "metrics": {"bleu_score": 32.009222253613174, "chrf_score": 27.278162455504813, "xcomet_score": 0.6530667543411255, "xcomet_qe_score": 0.6403101682662964, "metricx_score": 5.245621681213379, "metricx_qe_score": 3.1452794075012207, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "过,直到现在为止,法国还没有任何生物医学方面的公开源代码模块。", "metrics": {"bleu_score": 33.49398815984518, "chrf_score": 32.834466083891996, "xcomet_score": 0.5895898938179016, "xcomet_qe_score": 0.6343251466751099, "metricx_score": 4.785231113433838, "metricx_qe_score": 4.86785364151001, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们所以会问自己,最合适的数据源是什么?适用于广泛使用的数据是核心数据的好替代品吗", "metrics": {"bleu_score": 21.270545530370203, "chrf_score": 18.80630025671399, "xcomet_score": 0.7466517090797424, "xcomet_qe_score": 0.7725072503089905, "metricx_score": 2.6828322410583496, "metricx_qe_score": 1.8729937076568604, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "? Translation: We therefore ask ourselves, what are the most appropriate data sources for wide-ranging use? Are core data good alternatives for clinical data? 为回答这个问题,我们把Dr. Bert与我们基于从非诺华获得的匿名数据建立", "metrics": {"bleu_score": 21.937231552405738, "chrf_score": 14.639863316263678, "xcomet_score": 0.217439666390419, "xcomet_qe_score": 0.226375013589859, "metricx_score": 23.10489273071289, "metricx_qe_score": 23.945737838745117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "的Shubert模型进行了比较。 在法语数据集上训练一个专用模型,我们需要多少数据?", "metrics": {"bleu_score": 30.161686037504357, "chrf_score": 27.06134993718699, "xcomet_score": 0.36185163259506226, "xcomet_qe_score": 0.36936044692993164, "metricx_score": 8.003791809082031, "metricx_qe_score": 10.282425880432129, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是4GB、8GB还是更多? (注意:根据提供的信息,无法确定“ ourselves”是指“我们自己”还是“我们”,因此在这里将其翻译为“我们”。另外,“ gigabyte”在中文中习惯译作“吉字节”,而不是“GB”。)", "metrics": {"bleu_score": 7.577197923616355, "chrf_score": 32.555944118738225, "xcomet_score": 0.6927158832550049, "xcomet_qe_score": 0.7085026502609253, "metricx_score": 3.3971104621887207, "metricx_qe_score": 3.5807502269744873, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了回答这个问题,我们首先训练并比较了四个从头开始的模型:第一个版本是7GB的纳乔斯的博士生;第二个版本是4GB的纳乔斯子集。 雪碧的最初版本是一个含有四GB数据量的临床模型,这些数据来自临床笔记。雪碧的最终版本则包含了一部分来自自然语言处理的数据和一部分来自临床笔记的数据。", "metrics": {"bleu_score": 35.74469318391756, "chrf_score": 28.837871305009276, "xcomet_score": 0.28683602809906006, "xcomet_qe_score": 0.32763612270355225, "metricx_score": 12.357975006103516, "metricx_qe_score": 14.138571739196777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "除了这个比较,我们还引入了三个模型来分析预训练策略的影响。", "metrics": {"bleu_score": 40.262766157868725, "chrf_score": 40.02098076889028, "xcomet_score": 0.9360063076019287, "xcomet_qe_score": 0.9164561033248901, "metricx_score": 1.282938003540039, "metricx_qe_score": 2.588780641555786, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一个基于卡梅尔的重量,训练四套牛油果纳乔斯。", "metrics": {"bleu_score": 14.230715327204656, "chrf_score": 8.011585414843877, "xcomet_score": 0.518193781375885, "xcomet_qe_score": 0.5428257584571838, "metricx_score": 8.538368225097656, "metricx_qe_score": 10.086427688598633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "另一个也是基于卡梅尔,但这次是用四克林肯豆来训练。 最后一个是基于英语生物医学模型的,伯明翰大学的研究人员使用4GB的硬盘训练了", "metrics": {"bleu_score": 30.877560838589275, "chrf_score": 22.934110828368734, "xcomet_score": 0.26766905188560486, "xcomet_qe_score": 0.26925915479660034, "metricx_score": 10.194255828857422, "metricx_qe_score": 8.928481101989746, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "7个模型。", "metrics": {"bleu_score": 24.601580968354597, "chrf_score": 25.51088610945669, "xcomet_score": 0.8211743831634521, "xcomet_qe_score": 0.6100884079933167, "metricx_score": 0.6385459899902344, "metricx_qe_score": 1.0390474796295166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估这七种模型,我们根据它们在公共和私人任务上的性能进行了分类,例如姓名识别、分类、语音识别和问答。", "metrics": {"bleu_score": 26.130893158684657, "chrf_score": 22.929820478934253, "xcomet_score": 0.5676695108413696, "xcomet_qe_score": 0.6339864730834961, "metricx_score": 1.9808874130249023, "metricx_qe_score": 2.0804646015167236, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个模型与六个设计模型进行比较,这六个模型是:Kamembere-Harrison 138 GB、Kamembere-Harrison 4 GB、Kamembere-CCN 4 GB、Permit-BioBERT 和 Clinical-BERT。", "metrics": {"bleu_score": 25.510176430702906, "chrf_score": 34.33874759221276, "xcomet_score": 0.41187870502471924, "xcomet_qe_score": 0.4382408559322357, "metricx_score": 7.484239101409912, "metricx_qe_score": 7.175539016723633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "该模型在数据类型相同的任务上表现最好,与那些已经过训练的模型一样。", "metrics": {"bleu_score": 8.564171682685345, "chrf_score": 13.320361349539228, "xcomet_score": 0.7595305442810059, "xcomet_qe_score": 0.7635883688926697, "metricx_score": 2.4017629623413086, "metricx_qe_score": 2.5928313732147217, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以通过观察来自异源数据的结果来获得更丰富的信息。", "metrics": {"bleu_score": 16.805936904720344, "chrf_score": 17.59225820003108, "xcomet_score": 0.5542380809783936, "xcomet_qe_score": 0.566054105758667, "metricx_score": 1.9803993701934814, "metricx_qe_score": 1.6220805644989014, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,使用更多的数据可以得到更好的性能。", "metrics": {"bleu_score": 52.6589137558171, "chrf_score": 45.93989530077461, "xcomet_score": 0.9239718914031982, "xcomet_qe_score": 0.9670608043670654, "metricx_score": 3.0480995178222656, "metricx_qe_score": 3.3939099311828613, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从头开始编程似乎在大多数任务上都能获得更高的性能。", "metrics": {"bleu_score": 39.82567822078793, "chrf_score": 34.55975816792733, "xcomet_score": 0.8246480226516724, "xcomet_qe_score": 0.8019514679908752, "metricx_score": 2.838122606277466, "metricx_qe_score": 3.5318286418914795, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的持续实验,使用权重和标记器对鸟粪进行训练,在4GB子集上获得的结果与Dr. Bert从头开始获得的结果相当。", "metrics": {"bleu_score": 36.136138394933106, "chrf_score": 24.940713272859142, "xcomet_score": 0.39675015211105347, "xcomet_qe_score": 0.413173109292984, "metricx_score": 10.05020809173584, "metricx_qe_score": 10.236266136169434, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "基于卡姆巴尔重量和编码器的模型不存在这种情况。", "metrics": {"bleu_score": 9.528105878967036, "chrf_score": 9.775050670480729, "xcomet_score": 0.7238417267799377, "xcomet_qe_score": 0.7687747478485107, "metricx_score": 5.985760688781738, "metricx_qe_score": 7.1831817626953125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的自适应系统在11项任务中的9项上表现更好,且优于通用模型的结果。", "metrics": {"bleu_score": 17.12670686707188, "chrf_score": 16.90859679926119, "xcomet_score": 0.8128894567489624, "xcomet_qe_score": 0.7979352474212646, "metricx_score": 3.8500802516937256, "metricx_qe_score": 3.981161594390869, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还观察到,专用数据更好,专用数据更好,但并不通用。", "metrics": {"bleu_score": 20.92241878602315, "chrf_score": 18.256786379191816, "xcomet_score": 0.18835245072841644, "xcomet_qe_score": 0.16938422620296478, "metricx_score": 6.919968605041504, "metricx_qe_score": 7.599436283111572, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "来自纳乔斯的预训练模型是免费提供的,且在Jupyter Notebook上可访问。所有训练脚本都在我们的Git仓库中。", "metrics": {"bleu_score": 26.709333666796905, "chrf_score": 20.892787428067592, "xcomet_score": 0.5991665720939636, "xcomet_qe_score": 0.7428684234619141, "metricx_score": 5.433621406555176, "metricx_qe_score": 6.168546676635742, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,感谢你为本次报告做准备,并期待在后续会议中采取行动。", "metrics": {"bleu_score": 4.327969719414173, "chrf_score": 7.44295874465336, "xcomet_score": 0.27738308906555176, "xcomet_qe_score": 0.23981910943984985, "metricx_score": 7.162566184997559, "metricx_qe_score": 7.728113174438477, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "马蒂", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.3999422490596771, "xcomet_qe_score": 0.40847983956336975, "metricx_score": 3.303786277770996, "metricx_qe_score": 3.284945249557495, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "亚斯·林德曼:你好,我叫马蒂亚斯·林德曼。今天我要给大家介绍一篇关于无树构造的组合泛化理论的论文,使用多标签标记和潜在变体的方法。 这与我的顾问亚", "metrics": {"bleu_score": 14.314930807326798, "chrf_score": 15.705917491083701, "xcomet_score": 0.11281679570674896, "xcomet_qe_score": 0.051368776708841324, "metricx_score": 7.5465593338012695, "metricx_qe_score": 5.9783220291137695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "历山大·科勒和伊万·蒂多夫的合作有关。", "metrics": {"bleu_score": 5.0912128230977505, "chrf_score": 2.8711793909110566, "xcomet_score": 0.15621218085289001, "xcomet_qe_score": 0.14392274618148804, "metricx_score": 8.388090133666992, "metricx_qe_score": 6.842121124267578, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "组合泛化可以被理解为学习者处理更深的递归和未见的构成——即在训练过程中个体单独见过的短语。", "metrics": {"bleu_score": 52.185235283029975, "chrf_score": 45.6419878090492, "xcomet_score": 0.6207573413848877, "xcomet_qe_score": 0.5473012924194336, "metricx_score": 6.756446361541748, "metricx_qe_score": 9.029658317565918, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语义解析的上下文中,测试构造化泛化可能如下所示。", "metrics": {"bleu_score": 46.942223829384936, "chrf_score": 40.725323269143985, "xcomet_score": 0.8755262494087219, "xcomet_qe_score": 0.8890727162361145, "metricx_score": 1.0135606527328491, "metricx_qe_score": 1.07533597946167, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "像往常一样,我们有一套训练集元", "metrics": {"bleu_score": 35.4306209570667, "chrf_score": 27.750271584087976, "xcomet_score": 0.8441910743713379, "xcomet_qe_score": 0.7882663607597351, "metricx_score": 4.274240016937256, "metricx_qe_score": 3.9176933765411377, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "音发音。在这个例子中,女孩睡了,", "metrics": {"bleu_score": 14.598608091257082, "chrf_score": 8.740572247938355, "xcomet_score": 0.3455703556537628, "xcomet_qe_score": 0.42311596870422363, "metricx_score": 5.886177062988281, "metricx_qe_score": 4.962610721588135, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "玛丽知道那个女孩睡了。", "metrics": {"bleu_score": 30.672055757655695, "chrf_score": 25.35979092060182, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.7246135473251343, "metricx_qe_score": 2.0915000438690186, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些语音被配对成逻辑形式,代表了它们意义的核心部分。", "metrics": {"bleu_score": 5.951000953515419, "chrf_score": 11.471892691017922, "xcomet_score": 0.8634730577468872, "xcomet_qe_score": 0.8726049065589905, "metricx_score": 3.2570886611938477, "metricx_qe_score": 2.6028945446014404, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "与标准机器学习评估不同,测试集并不来自相同的分布,但包含结构上未见过的逻辑形式。", "metrics": {"bleu_score": 56.53001338131126, "chrf_score": 50.95697187138282, "xcomet_score": 0.8647915124893188, "xcomet_qe_score": 0.8833825588226318, "metricx_score": 1.191996455192566, "metricx_qe_score": 2.12489914894104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个例子中,模型在训练期间出现了浅层循环,并且在一个示例上进行了更深层次的测试。", "metrics": {"bleu_score": 23.227140117845373, "chrf_score": 20.082489215383028, "xcomet_score": 0.7786568403244019, "xcomet_qe_score": 0.7145675420761108, "metricx_score": 2.749336004257202, "metricx_qe_score": 2.288954019546509, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "原句翻译:'naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.'", "metrics": {"bleu_score": 0.0, "chrf_score": 3.3829035793882656, "xcomet_score": 0.6887584924697876, "xcomet_qe_score": 0.8099005222320557, "metricx_score": 10.963330268859863, "metricx_qe_score": 10.546545028686523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "特别地,它们常常不能复制输入与输出之间的系统对应关系,例如例子中的颜色编码。", "metrics": {"bleu_score": 31.937072250683634, "chrf_score": 29.952371831101438, "xcomet_score": 0.9378423690795898, "xcomet_qe_score": 0.9228304028511047, "metricx_score": 0.8365687131881714, "metricx_qe_score": 0.9633148908615112, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种流行的方法是将树木纳入模型。", "metrics": {"bleu_score": 19.922750824006076, "chrf_score": 18.633897675349584, "xcomet_score": 0.8718147277832031, "xcomet_qe_score": 0.9205450415611267, "metricx_score": 1.0442601442337036, "metricx_qe_score": 1.1689953804016113, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "树木旨在捕捉与语法形式相关的表达过程的构图过程。", "metrics": {"bleu_score": 8.505809660438569, "chrf_score": 11.171613672698962, "xcomet_score": 0.729392409324646, "xcomet_qe_score": 0.6862231492996216, "metricx_score": 3.8851053714752197, "metricx_qe_score": 4.433012008666992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个方法行得通,但通常不会直接给你,你必须想办法得到。 这个过程", "metrics": {"bleu_score": 6.7327981563613735, "chrf_score": 8.860919869058863, "xcomet_score": 0.8002867102622986, "xcomet_qe_score": 0.8135724067687988, "metricx_score": 5.675832748413086, "metricx_qe_score": 2.4502651691436768, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可能既复杂又有时计算昂贵。", "metrics": {"bleu_score": 6.538042956281432, "chrf_score": 11.723353021686464, "xcomet_score": 0.8001947402954102, "xcomet_qe_score": 0.7872562408447266, "metricx_score": 2.1655218601226807, "metricx_qe_score": 2.297412633895874, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "通常涉及大量的形式化特定预处理,例如处理变量符号。", "metrics": {"bleu_score": 43.116049598943114, "chrf_score": 42.37184276967998, "xcomet_score": 0.8384213447570801, "xcomet_qe_score": 0.8654507994651794, "metricx_score": 0.8260012865066528, "metricx_qe_score": 1.0992692708969116, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "获得树也可能涉及专门的语法感应程序。", "metrics": {"bleu_score": 56.48391138957984, "chrf_score": 51.514300532267264, "xcomet_score": 0.754898190498352, "xcomet_qe_score": 0.7172996997833252, "metricx_score": 5.963261604309082, "metricx_qe_score": 6.457887172698975, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这篇论文中,我们不使用树,并引入了一种新的序列到序列模型,它直接建模了输入片段与输出片段之间的对应关系。", "metrics": {"bleu_score": 40.7282015546302, "chrf_score": 31.912071164961446, "xcomet_score": 0.8144642114639282, "xcomet_qe_score": 0.7965905666351318, "metricx_score": 2.1084747314453125, "metricx_qe_score": 2.8384616374969482, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们首次将强泛化推广到更深的递归,而无需依赖于树。", "metrics": {"bleu_score": 19.044407151703098, "chrf_score": 17.865750200248357, "xcomet_score": 0.9108185768127441, "xcomet_qe_score": 0.8351787328720093, "metricx_score": 3.5874311923980713, "metricx_qe_score": 5.354820251464844, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法通过两步预测输入的输出。", "metrics": {"bleu_score": 61.583212398305974, "chrf_score": 52.279490103939, "xcomet_score": 0.9820935726165771, "xcomet_qe_score": 0.9455699920654297, "metricx_score": 0.47149890661239624, "metricx_qe_score": 0.8730547428131104, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,我们为每个输入标记一个无序的多集标签,这些标签将出现在输出中。", "metrics": {"bleu_score": 27.468039286446803, "chrf_score": 25.025359356989874, "xcomet_score": 0.8856862783432007, "xcomet_qe_score": 0.854968786239624, "metricx_score": 1.5688508749008179, "metricx_qe_score": 1.9039629697799683, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一步之后,我们有了正确的标记,但它们没有排序。", "metrics": {"bleu_score": 33.052123875385284, "chrf_score": 27.987596426391242, "xcomet_score": 0.9078094959259033, "xcomet_qe_score": 0.8901780843734741, "metricx_score": 2.104224681854248, "metricx_qe_score": 2.8935470581054688, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是为什么在第二步中,我们使用另一个模型来预测转换,以便将它们按正确顺序排列。", "metrics": {"bleu_score": 43.49382868026205, "chrf_score": 42.71748012482071, "xcomet_score": 0.9004958868026733, "xcomet_qe_score": 0.9025193452835083, "metricx_score": 3.4272243976593018, "metricx_qe_score": 4.053861618041992, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们引入了一种新的预测旋转方法,它不对可能的旋转施加任何硬约束。", "metrics": {"bleu_score": 36.96584402059125, "chrf_score": 32.42586607489327, "xcomet_score": 0.8099161386489868, "xcomet_qe_score": 0.8863517045974731, "metricx_score": 5.090114593505859, "metricx_qe_score": 5.661376953125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这使得我们的方法非常灵活和表达性强。", "metrics": {"bleu_score": 41.02023793222609, "chrf_score": 37.52431803596609, "xcomet_score": 0.977136492729187, "xcomet_qe_score": 0.9639472961425781, "metricx_score": 0.8826882243156433, "metricx_qe_score": 1.201439380645752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的Permutation模型工作原理大致如下。", "metrics": {"bleu_score": 12.428716645722616, "chrf_score": 13.856691400794727, "xcomet_score": 0.9139755368232727, "xcomet_qe_score": 0.8847426176071167, "metricx_score": 3.94008207321167, "metricx_qe_score": 3.3462953567504883, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "从左到右遍历输出,确定每个多字节标记要放入每个位置。", "metrics": {"bleu_score": 21.209923857279133, "chrf_score": 18.70175874032045, "xcomet_score": 0.7626380920410156, "xcomet_qe_score": 0.768185019493103, "metricx_score": 2.5207905769348145, "metricx_qe_score": 1.7067259550094604, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "对于第一个输出位置,我们只需选择如红色突出显示的其中一个。", "metrics": {"bleu_score": 40.85187432723086, "chrf_score": 37.000346763208434, "xcomet_score": 0.9179033041000366, "xcomet_qe_score": 0.9534602761268616, "metricx_score": 0.8677920699119568, "metricx_qe_score": 0.8561070561408997, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然后,我们跳到下一个多字节标记来确定输出的第二个标记。", "metrics": {"bleu_score": 34.36922036315536, "chrf_score": 27.216748183126843, "xcomet_score": 0.761949896812439, "xcomet_qe_score": 0.7593420743942261, "metricx_score": 3.892685890197754, "metricx_qe_score": 3.311645984649658, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们以类似的方式通过跳转到另一个多字节标记来确定输出的第三个标记。我们", "metrics": {"bleu_score": 51.11744072566821, "chrf_score": 43.06780106608299, "xcomet_score": 0.6583391427993774, "xcomet_qe_score": 0.6653311252593994, "metricx_score": 5.270841121673584, "metricx_qe_score": 2.9675209522247314, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将继续这个过程吗? 直到第一阶段的每一个标记都至少被访问过一次。", "metrics": {"bleu_score": 45.993210886708745, "chrf_score": 42.09966958229831, "xcomet_score": 0.7262555956840515, "xcomet_qe_score": 0.6948181390762329, "metricx_score": 2.56315541267395, "metricx_qe_score": 3.359185218811035, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "为了让你对实验结果有一个初步了解,我们在这里将我们的方法与其它无树模型进行比较。在一般化", "metrics": {"bleu_score": 44.45806571143418, "chrf_score": 35.8142148156188, "xcomet_score": 0.6519749164581299, "xcomet_qe_score": 0.6895544528961182, "metricx_score": 6.475159168243408, "metricx_qe_score": 5.962888717651367, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "到更深的递归方面,我们的模型比其他模型表现更好,优势非常明显。", "metrics": {"bleu_score": 24.10600823901789, "chrf_score": 21.097229500412404, "xcomet_score": 0.781281054019928, "xcomet_qe_score": 0.7979891300201416, "metricx_score": 3.3301093578338623, "metricx_qe_score": 4.726711750030518, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,其他类型的结构化一般化似乎仍然很有挑战性。", "metrics": {"bleu_score": 29.065151007971206, "chrf_score": 29.57428654466098, "xcomet_score": 0.9324917793273926, "xcomet_qe_score": 0.9743069410324097, "metricx_score": 1.8998064994812012, "metricx_qe_score": 1.1853982210159302, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的论文中,我们解决了几个有趣的技巧挑战。", "metrics": {"bleu_score": 36.31474833716426, "chrf_score": 32.41645186491543, "xcomet_score": 0.886021614074707, "xcomet_qe_score": 0.8466843366622925, "metricx_score": 2.032736301422119, "metricx_qe_score": 1.6913613080978394, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,训练数据中没有输入和输出的对齐。", "metrics": {"bleu_score": 35.9332463986039, "chrf_score": 29.377879452140437, "xcomet_score": 0.9074099063873291, "xcomet_qe_score": 0.9183207750320435, "metricx_score": 0.9959515333175659, "metricx_qe_score": 0.7162585854530334, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,对于一个给定的标记,我们不知道它来自哪个多分类器,这为训练带来了挑战。", "metrics": {"bleu_score": 50.795195013697345, "chrf_score": 48.04258082174437, "xcomet_score": 0.8395884037017822, "xcomet_qe_score": 0.8028944730758667, "metricx_score": 4.560293197631836, "metricx_qe_score": 4.06533670425415, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,有时会出现多个与数据一致但语法正确的转换。我们通过引导对", "metrics": {"bleu_score": 26.88400504310635, "chrf_score": 23.57510741909711, "xcomet_score": 0.6468802690505981, "xcomet_qe_score": 0.6437195539474487, "metricx_score": 7.948765277862549, "metricx_qe_score": 5.739511966705322, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "齐将其作为训练的一部分来解决这个问题。", "metrics": {"bleu_score": 20.37792411904348, "chrf_score": 18.379481321442395, "xcomet_score": 0.7706891298294067, "xcomet_qe_score": 0.7206848859786987, "metricx_score": 6.294454574584961, "metricx_qe_score": 6.482667446136475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的转换方法非常灵活,但也带来了挑战:找到得分最高的转换是NP-hard问题。", "metrics": {"bleu_score": 47.16800909184666, "chrf_score": 47.93829932229114, "xcomet_score": 0.7687628269195557, "xcomet_qe_score": 0.7883987426757812, "metricx_score": 3.4321229457855225, "metricx_qe_score": 3.8556153774261475, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是因为这与旅行推销员问题有关。 这个", "metrics": {"bleu_score": 35.38995029906512, "chrf_score": 33.36534965188896, "xcomet_score": 0.7550348043441772, "xcomet_qe_score": 0.6994237899780273, "metricx_score": 4.986744403839111, "metricx_qe_score": 1.5610100030899048, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "可以通过一个GPU友好型的连续松弛来近似,它还允许我们反向传播通过解决方案,并学习在语法上更合理的推广。", "metrics": {"bleu_score": 40.4018900571124, "chrf_score": 36.63284143658502, "xcomet_score": 0.5821081399917603, "xcomet_qe_score": 0.6618806719779968, "metricx_score": 6.084932327270508, "metricx_qe_score": 7.120596885681152, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您想更多地了解我们的实验以及我们如何应对这些挑战,请查看我们的论文或访问我们的海报。", "metrics": {"bleu_score": 69.47615465785461, "chrf_score": 62.43245208061282, "xcomet_score": 0.9049196243286133, "xcomet_qe_score": 0.7920501232147217, "metricx_score": 0.6992331743240356, "metricx_qe_score": 1.465874195098877, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我是玛克沙塔。今天,我的合作者马丁和我正在展示我们的作品——“kit mustache”,一个多源知识集成评估工具。这项工作", "metrics": {"bleu_score": 8.186885377778816, "chrf_score": 11.901683126275554, "xcomet_score": 0.4522532820701599, "xcomet_qe_score": 0.49117618799209595, "metricx_score": 9.500700950622559, "metricx_qe_score": 9.272594451904297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是麦吉尔大学、密莱和微软研究的协作成果。", "metrics": {"bleu_score": 44.739239243298826, "chrf_score": 32.453285855117095, "xcomet_score": 0.7745851278305054, "xcomet_qe_score": 0.728471040725708, "metricx_score": 3.7089035511016846, "metricx_qe_score": 3.016073226928711, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言理解模型利用各种知识来源,例如它们的参数中包含的知识,通常在预训练过程中获得,以及在推理时给出的输入知识。", "metrics": {"bleu_score": 51.38530769312411, "chrf_score": 48.645091214078576, "xcomet_score": 0.9600751399993896, "xcomet_qe_score": 0.8988304138183594, "metricx_score": 0.8538204431533813, "metricx_qe_score": 1.0097668170928955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最近的任务选择问答系统研究表明,模型可以使用预训练的时间知识来解决问题。", "metrics": {"bleu_score": 44.296837590319974, "chrf_score": 38.12463285122728, "xcomet_score": 0.7901443243026733, "xcomet_qe_score": 0.7927570343017578, "metricx_score": 3.331270694732666, "metricx_qe_score": 3.4792799949645996, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,自然语言理解通常需要在推断时提供知识。", "metrics": {"bleu_score": 63.64970309311582, "chrf_score": 57.690107590416396, "xcomet_score": 0.9170445203781128, "xcomet_qe_score": 0.9026126861572266, "metricx_score": 2.869227647781372, "metricx_qe_score": 3.1775951385498047, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,在句子中,约翰在电视上看到了新当选的总统。", "metrics": {"bleu_score": 34.652127631368096, "chrf_score": 21.013222567533337, "xcomet_score": 0.9569696187973022, "xcomet_qe_score": 0.9540069699287415, "metricx_score": 1.8397694826126099, "metricx_qe_score": 2.3926615715026855, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "预训练参数可以包含关于总统们做什么和电视是什么的信息,但他们不能可靠地知道这个特定实例中的实体John是谁,或者新总统是谁,因为总统可能在预训练之后发生了变化。", "metrics": {"bleu_score": 51.22951702791819, "chrf_score": 44.40117045471873, "xcomet_score": 0.8471295833587646, "xcomet_qe_score": 0.7215155959129333, "metricx_score": 3.1963634490966797, "metricx_qe_score": 3.520717144012451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,知识密集型和新任务的成功模型需要能够整合和使用既有训练时间和推理时间知识。", "metrics": {"bleu_score": 33.70730644883747, "chrf_score": 27.00799880276708, "xcomet_score": 0.7088804841041565, "xcomet_qe_score": 0.7009153366088867, "metricx_score": 4.394002914428711, "metricx_qe_score": 4.252943515777588, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个工作我们提议一个知识整合的诊断测试套件。", "metrics": {"bleu_score": 50.46427192045846, "chrf_score": 47.610702298493905, "xcomet_score": 0.8176791667938232, "xcomet_qe_score": 0.8247591853141785, "metricx_score": 3.0090508460998535, "metricx_qe_score": 3.6771047115325928, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "核心参考解决方案旨在评估不同来源间知识的可重用性。", "metrics": {"bleu_score": 12.099134047284924, "chrf_score": 12.477364333935128, "xcomet_score": 0.3515458106994629, "xcomet_qe_score": 0.6029819846153259, "metricx_score": 4.802754878997803, "metricx_qe_score": 5.101407527923584, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估了人类研究参与者的数据集,并建立了相关联的模型。", "metrics": {"bleu_score": 31.74945798736803, "chrf_score": 28.500351250384128, "xcomet_score": 0.8519300222396851, "xcomet_qe_score": 0.8427083492279053, "metricx_score": 3.7884156703948975, "metricx_qe_score": 3.701756477355957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的数据集中的一个例子:", "metrics": {"bleu_score": 40.48411918659966, "chrf_score": 34.45287822722203, "xcomet_score": 0.9178861379623413, "xcomet_qe_score": 0.8547385931015015, "metricx_score": 0.41118124127388, "metricx_qe_score": 1.069846510887146, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "瑟宾是一名法官,", "metrics": {"bleu_score": 51.697315395717055, "chrf_score": 25.813926430308626, "xcomet_score": 0.8585612773895264, "xcomet_qe_score": 0.8455700278282166, "metricx_score": 1.1024870872497559, "metricx_qe_score": 1.3211361169815063, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "凯拉是一名面包师。", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 59.333448823374546, "xcomet_score": 0.8617528676986694, "xcomet_qe_score": 0.7822349071502686, "metricx_score": 0.4702010452747345, "metricx_qe_score": 0.590715765953064, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "瑟宾和凯拉在公园见面。", "metrics": {"bleu_score": 15.851165692617148, "chrf_score": 9.219211956415245, "xcomet_score": 0.7984192371368408, "xcomet_qe_score": 0.8290754556655884, "metricx_score": 1.3813695907592773, "metricx_qe_score": 1.4991365671157837, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "劳累了一整天处理法律案件后,他很高兴能放松一下。", "metrics": {"bleu_score": 36.96208614341176, "chrf_score": 30.25977045965087, "xcomet_score": 0.990832507610321, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.8565610647201538, "metricx_qe_score": 2.1569442749023438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他指的是谁? 第", "metrics": {"bleu_score": 0.30711578355468, "chrf_score": 2.0116568467061104, "xcomet_score": 0.15504036843776703, "xcomet_qe_score": 0.1449192315340042, "metricx_score": 12.635534286499023, "metricx_qe_score": 8.249802589416504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一种", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.16757386922836304, "xcomet_qe_score": 0.1560894399881363, "metricx_score": 17.384984970092773, "metricx_qe_score": 23.412460327148438, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "是特定实体的知识,例如“Serrel 是一名法官”。第二", "metrics": {"bleu_score": 39.96806384679825, "chrf_score": 35.245632655052944, "xcomet_score": 0.4221171438694, "xcomet_qe_score": 0.44755542278289795, "metricx_score": 7.058633327484131, "metricx_qe_score": 7.6818084716796875, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "种是背景知识,例如“法官决定案件的法律规则”", "metrics": {"bleu_score": 30.730330173300455, "chrf_score": 25.005031403724136, "xcomet_score": 0.48022881150245667, "xcomet_qe_score": 0.6918985843658447, "metricx_score": 5.30657434463501, "metricx_qe_score": 3.8511550426483154, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "。 背景知识通常在大型语言模型的预训练过程中学习,而实体特定知识则通常在推理时进行观察。", "metrics": {"bleu_score": 44.99977318798861, "chrf_score": 39.35294248960942, "xcomet_score": 0.8399568200111389, "xcomet_qe_score": 0.8233674168586731, "metricx_score": 3.6398799419403076, "metricx_qe_score": 3.9102442264556885, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "将这两次信息的可用性进行变化,这样它们可能只存在于一个来源中,或者", "metrics": {"bleu_score": 25.08388767658337, "chrf_score": 21.51361176031036, "xcomet_score": 0.6255029439926147, "xcomet_qe_score": 0.5724046230316162, "metricx_score": 8.859516143798828, "metricx_qe_score": 8.403205871582031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "存在于多个来源中。", "metrics": {"bleu_score": 3.4162113597999784, "chrf_score": 1.0822510822510825, "xcomet_score": 0.14098134636878967, "xcomet_qe_score": 0.13867339491844177, "metricx_score": 14.329109191894531, "metricx_qe_score": 12.05814266204834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们已经定义了三个Keras设置:第一个是“背景预训练”,其中假设背景知识在预训练时间内可用。", "metrics": {"bleu_score": 25.892287982038727, "chrf_score": 22.63355630007212, "xcomet_score": 0.7221351265907288, "xcomet_qe_score": 0.6547584533691406, "metricx_score": 3.480562686920166, "metricx_qe_score": 4.098062515258789, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,存在背景知识双向设置。背景知识在预训练时间和推理时间上都是可变的。", "metrics": {"bleu_score": 34.22803488747216, "chrf_score": 30.258995536677403, "xcomet_score": 0.759116530418396, "xcomet_qe_score": 0.7027978897094727, "metricx_score": 2.579951524734497, "metricx_qe_score": 2.2423272132873535, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后是背景知识增强设置,在此设置中两种类型的知识都是可用的,只有在推理时间才有效。", "metrics": {"bleu_score": 12.83698314466871, "chrf_score": 18.934206678367875, "xcomet_score": 0.8027456998825073, "xcomet_qe_score": 0.7832018136978149, "metricx_score": 4.110953330993652, "metricx_qe_score": 3.036388635635376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后一个设置特别有趣,因为它模拟了在解决问题时需要的后端知识并不属于模型的预训练数据的情况。", "metrics": {"bleu_score": 46.32311317343035, "chrf_score": 40.146198540931024, "xcomet_score": 0.8820690512657166, "xcomet_qe_score": 0.8778513073921204, "metricx_score": 1.191930890083313, "metricx_qe_score": 1.2500163316726685, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,因为自从预训练模型的时代以来,新职业就", "metrics": {"bleu_score": 15.370929331411956, "chrf_score": 20.07119657834084, "xcomet_score": 0.6856594085693359, "xcomet_qe_score": 0.5649032592773438, "metricx_score": 6.934326171875, "metricx_qe_score": 5.66510009765625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "已经发展起来了。 这是一个控制事实来源可用性的示例。", "metrics": {"bleu_score": 13.839721367554615, "chrf_score": 16.14312139648908, "xcomet_score": 0.3836477994918823, "xcomet_qe_score": 0.21771840751171112, "metricx_score": 5.601767539978027, "metricx_qe_score": 5.631796836853027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在背景预训练设置中,我们假设背景知识“政治家寻求选举席位”包含在预训练参数中。在影响范围内的上下文中,我们提供特定知识“奇切斯特是政治家”。", "metrics": {"bleu_score": 42.47774975465393, "chrf_score": 31.338164194571185, "xcomet_score": 0.5513306856155396, "xcomet_qe_score": 0.5726231336593628, "metricx_score": 3.200200080871582, "metricx_qe_score": 4.168726921081543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "背景信息设置:我们还提供不仅针对特定实体的背景知识,还有关于政治家在相关语境下影响的知识。", "metrics": {"bleu_score": 23.59311355775967, "chrf_score": 21.4809985595297, "xcomet_score": 0.7698196172714233, "xcomet_qe_score": 0.7310814261436462, "metricx_score": 3.5455782413482666, "metricx_qe_score": 4.037812232971191, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在后台设置中,提供有效的职业占用“婚姻顾问”而不是“政治家”,因为婚姻顾问不太可能包含在预训练语料库中。", "metrics": {"bleu_score": 32.45314143242781, "chrf_score": 23.205864800166967, "xcomet_score": 0.5518689155578613, "xcomet_qe_score": 0.524648904800415, "metricx_score": 6.9936347007751465, "metricx_qe_score": 6.518945217132568, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们评估了人类研究参与者的数据集,并建立了相关联的模型。", "metrics": {"bleu_score": 31.74945798736803, "chrf_score": 28.500351250384128, "xcomet_score": 0.8138033151626587, "xcomet_qe_score": 0.7570801377296448, "metricx_score": 3.787309408187866, "metricx_qe_score": 3.8738162517547607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在本图中,我们展示了在最困难的背景预训练设置下表现最佳的模型的结果。", "metrics": {"bleu_score": 38.66707307432021, "chrf_score": 33.30068836351336, "xcomet_score": 0.8941265940666199, "xcomet_qe_score": 0.9017879962921143, "metricx_score": 1.1705830097198486, "metricx_qe_score": 1.0042564868927002, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们只训练模型在KITMOs数据集上,那么这两个模型的性能都不好。", "metrics": {"bleu_score": 12.078743167681099, "chrf_score": 18.94457575153231, "xcomet_score": 0.8283318877220154, "xcomet_qe_score": 0.8215935230255127, "metricx_score": 4.546595573425293, "metricx_qe_score": 4.601046085357666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,一旦我们在KITMOs数据集上对这两个模型进行训练,它们在CIFAR-10上的表现明显优于随机选择的", "metrics": {"bleu_score": 16.989603517845364, "chrf_score": 19.793619051713577, "xcomet_score": 0.6173569560050964, "xcomet_qe_score": 0.4126875102519989, "metricx_score": 5.88591194152832, "metricx_qe_score": 5.280703067779541, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "模型。 该建议在使用卡方检验解决方案数据集进行训练时,模型会学习利用表面标签,而这些标签在测试基线分类器时并不有用,因为这些标签已经被移除。", "metrics": {"bleu_score": 13.61437589388694, "chrf_score": 13.26335505736659, "xcomet_score": 0.133714497089386, "xcomet_qe_score": 0.1326982080936432, "metricx_score": 9.135207176208496, "metricx_qe_score": 9.507096290588379, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "额外的实验表明,即使是最成功的模型也不能可靠地整合背景知识,提供的影响时间。", "metrics": {"bleu_score": 21.259372316559944, "chrf_score": 19.525724162072684, "xcomet_score": 0.708104133605957, "xcomet_qe_score": 0.7193495035171509, "metricx_score": 6.935372829437256, "metricx_qe_score": 7.453918933868408, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "一些人无法从不同来源理性地获取知识,除非经过专门的训练。", "metrics": {"bleu_score": 5.87057263330727, "chrf_score": 8.007137503221907, "xcomet_score": 0.15760073065757751, "xcomet_qe_score": 0.20487801730632782, "metricx_score": 5.904890537261963, "metricx_qe_score": 5.820194244384766, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,在接受了专门训练后,有些人能够成功地将来自多种来源的知识整合起来。", "metrics": {"bleu_score": 19.861626912448344, "chrf_score": 19.833902889124495, "xcomet_score": 0.904761552810669, "xcomet_qe_score": 0.9971600770950317, "metricx_score": 1.7906081676483154, "metricx_qe_score": 0.883736252784729, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "仍然,表现最好的模型似乎在推理时间上具有可靠集成后向知识的困难。如果您有兴趣", "metrics": {"bleu_score": 27.611419707545245, "chrf_score": 23.556008660583473, "xcomet_score": 0.2883653938770294, "xcomet_qe_score": 0.3894253373146057, "metricx_score": 8.039509773254395, "metricx_qe_score": 5.0106635093688965, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "了解更多信息,请参阅我们的论文,并查看GitHub上的数据集代码。", "metrics": {"bleu_score": 37.16018572938424, "chrf_score": 39.62177074537075, "xcomet_score": 0.9399937391281128, "xcomet_qe_score": 0.9552003741264343, "metricx_score": 0.4841260313987732, "metricx_qe_score": 0.5457378625869751, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢收听!", "metrics": {"bleu_score": 12.703318703865365, "chrf_score": 8.0, "xcomet_score": 0.9768924117088318, "xcomet_qe_score": 0.9609314799308777, "metricx_score": 0.5919415950775146, "metricx_qe_score": 0.3213791847229004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我叫Mira,今天我们将讨论我们的论文《使用自然语言提示来衡量语言模型中的类型》。", "metrics": {"bleu_score": 45.64540483125149, "chrf_score": 42.90544375548719, "xcomet_score": 0.772020697593689, "xcomet_qe_score": 0.7192655205726624, "metricx_score": 6.117946624755859, "metricx_qe_score": 5.602491855621338, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这项工作是与Essen Dercum和Dan Darrofsky合作完成的。", "metrics": {"bleu_score": 32.35470999590687, "chrf_score": 35.721430296339, "xcomet_score": 0.7738516330718994, "xcomet_qe_score": 0.8182311058044434, "metricx_score": 4.494011402130127, "metricx_qe_score": 4.325237274169922, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "近年来,许多人都记录了大型语言模型(或称LLM)中社会偏见和刻板印象的普遍存在。", "metrics": {"bleu_score": 33.448899741633596, "chrf_score": 34.37817256869229, "xcomet_score": 0.9662668704986572, "xcomet_qe_score": 0.9465571641921997, "metricx_score": 2.9592859745025635, "metricx_qe_score": 5.238232612609863, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,这些措施具有各种局限性。", "metrics": {"bleu_score": 38.04561083573422, "chrf_score": 30.82670140449149, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09575779736042023, "metricx_qe_score": 0.21304763853549957, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "它们通常依赖于手工构建的数据集,这在获取数据时非常耗时。 他们通常只测量非常具体的类型,这意味着它们不能很好地推广到其他人口统计或上下文,或者它们只是捕捉了非常一般的、广泛的联想,比如与特定群体的负面联系。", "metrics": {"bleu_score": 42.49048506557138, "chrf_score": 36.26872637504832, "xcomet_score": 0.5894001722335815, "xcomet_qe_score": 0.5865671634674072, "metricx_score": 6.53937292098999, "metricx_qe_score": 6.57961368560791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,大多数空间工作并没有考虑到“交叠性”这一概念,即多层面的社会身份能够相互作用并产生独特的伤害。", "metrics": {"bleu_score": 28.787776095793856, "chrf_score": 23.57033927251649, "xcomet_score": 0.6545426845550537, "xcomet_qe_score": 0.6373329162597656, "metricx_score": 5.564640522003174, "metricx_qe_score": 5.780629634857178, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们克服这些局限性,依赖于这些新型指令调优LLMs能够很好地响应指令和参数。", "metrics": {"bleu_score": 24.854885449864742, "chrf_score": 23.074612249583637, "xcomet_score": 0.7152704000473022, "xcomet_qe_score": 0.7294127941131592, "metricx_score": 4.3246846199035645, "metricx_qe_score": 4.575685501098633, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们可以请模型生成一个肖像画,即想象中的一个人物的描绘,使用提示,比如“想象你是一个亚洲女性,", "metrics": {"bleu_score": 31.135552140571644, "chrf_score": 27.195894483085258, "xcomet_score": 0.7295171022415161, "xcomet_qe_score": 0.7802215814590454, "metricx_score": 3.2500319480895996, "metricx_qe_score": 3.6254563331604004, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "描述你自己”。", "metrics": {"bleu_score": 20.290554333745867, "chrf_score": 20.721284135918285, "xcomet_score": 0.8686244487762451, "xcomet_qe_score": 0.8825339674949646, "metricx_score": 0.6069750785827637, "metricx_qe_score": 0.5816594362258911, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以立即看到,这适用于任何人口统计学特征,因为我们只需要指定我们想要的任何身份标记到这个提示中。 所以,", "metrics": {"bleu_score": 42.35182753130985, "chrf_score": 34.239770698034654, "xcomet_score": 0.8449764847755432, "xcomet_qe_score": 0.7991310358047485, "metricx_score": 5.333325386047363, "metricx_qe_score": 5.166814804077148, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从GPT-4中生成的一些示例:", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 54.41246497336467, "xcomet_score": 0.9589616656303406, "xcomet_qe_score": 0.8937575221061707, "metricx_score": 1.176491618156433, "metricx_qe_score": 1.7319221496582031, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "1. 英文:'The quick brown fox jumps over the lazy dog.' 中文:'那只敏捷的棕色狐狸跳过那只懒狗。", "metrics": {"bleu_score": 1.27648877010856, "chrf_score": 1.1627906976744187, "xcomet_score": 0.1353365182876587, "xcomet_qe_score": 0.12417353689670563, "metricx_score": 3.5810985565185547, "metricx_qe_score": 3.787919282913208, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "' 2. 英文:'The capital of France is Paris.' 中文:'法国的首都是巴黎。' 3. 英文:'Artificial intelligence is changing the world.' 中文:'人工智能正在改变世界。' 4. 英文:'I love you' 中文:'我爱你。'", "metrics": {"bleu_score": 0.7633196857840644, "chrf_score": 1.506024096385542, "xcomet_score": 0.21720437705516815, "xcomet_qe_score": 0.22144122421741486, "metricx_score": 18.86139678955078, "metricx_qe_score": 8.366703033447266, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "立即我们可以看到,尽管传统意义上的这些词汇并未明确表示输出是负面或有毒的,但输出本身并不明显具有负面影响。 有趣的是, 这位亚裔女性被描绘为不引人注目,而中东女性则被称为“异国情调”和“令人着迷的地区”。 女性角色和白人男性角色的对比:前者", "metrics": {"bleu_score": 8.456656928869482, "chrf_score": 15.641987707108285, "xcomet_score": 0.21365949511528015, "xcomet_qe_score": 0.21824586391448975, "metricx_score": 18.706512451171875, "metricx_qe_score": 17.04086685180664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提及了血统,后者则没有。 我们的方法分为两个部分。", "metrics": {"bleu_score": 34.89214645008508, "chrf_score": 35.213158854375145, "xcomet_score": 0.2700996398925781, "xcomet_qe_score": 0.17227216064929962, "metricx_score": 3.6858818531036377, "metricx_qe_score": 5.360738754272461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第一部分是生成这些人物。", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 68.72835497835497, "xcomet_score": 0.9012347459793091, "xcomet_qe_score": 0.8504418134689331, "metricx_score": 1.17280912399292, "metricx_qe_score": 2.2511725425720215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们的生成人物的提示是受到一项研究的启发,该研究将这些提示给了人类受试者,并发现通过给予人类受试者,他们也能揭示出种族成见。", "metrics": {"bleu_score": 35.562832600494204, "chrf_score": 30.475423998584656, "xcomet_score": 0.6262108087539673, "xcomet_qe_score": 0.6103130578994751, "metricx_score": 4.209975242614746, "metricx_qe_score": 4.76828145980835, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "而且,这还可以实现我们生成的“人物”与人类写下的响应之间的直接对比。", "metrics": {"bleu_score": 18.21038896383151, "chrf_score": 17.889858744942345, "xcomet_score": 0.8643032312393188, "xcomet_qe_score": 0.8243247270584106, "metricx_score": 1.2545032501220703, "metricx_qe_score": 2.0041918754577637, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第二部分是标记词,它是一种方法来识别区分标记组的词,我稍后会详细解释。", "metrics": {"bleu_score": 20.57087595996304, "chrf_score": 19.38089163462929, "xcomet_score": 0.852333128452301, "xcomet_qe_score": 0.8923730850219727, "metricx_score": 2.9673755168914795, "metricx_qe_score": 2.6728668212890625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个的好处是,我们能够得到非常具体的类型和模式,而不需要依赖任何特定的词汇表。", "metrics": {"bleu_score": 39.56738376701904, "chrf_score": 33.53633972489665, "xcomet_score": 0.7616664171218872, "xcomet_qe_score": 0.8504958748817444, "metricx_score": 2.957451820373535, "metricx_qe_score": 2.545259952545166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,标记词法借鉴了社会语言学中的“标记性”概念,该概念指出存在一个未标记的默认值,任何偏离该默认值的群体在语言上都是被标记的。", "metrics": {"bleu_score": 43.09871225156711, "chrf_score": 36.61802023735805, "xcomet_score": 0.6798466444015503, "xcomet_qe_score": 0.7513941526412964, "metricx_score": 1.3074963092803955, "metricx_qe_score": 1.1735124588012695, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,单词“man”或者“warrior”通常与男性关联。", "metrics": {"bleu_score": 26.681730651789678, "chrf_score": 23.436205748399125, "xcomet_score": 0.8392687439918518, "xcomet_qe_score": 0.8967984318733215, "metricx_score": 5.664341926574707, "metricx_qe_score": 5.5662007331848145, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当人们描述一位女性战士时,他们通常会使用“one man warrior”并加上“woman”的标记。", "metrics": {"bleu_score": 28.037894057393313, "chrf_score": 23.159817504971667, "xcomet_score": 0.7566273212432861, "xcomet_qe_score": 0.7582211494445801, "metricx_score": 6.330278396606445, "metricx_qe_score": 5.936110019683838, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地说,社会上的主导群体在语言上和社会上都是非标记的,而边缘化的群体通常是有标记的。", "metrics": {"bleu_score": 47.38060472735463, "chrf_score": 38.74270557625278, "xcomet_score": 0.8465172052383423, "xcomet_qe_score": 0.8546559810638428, "metricx_score": 1.2599105834960938, "metricx_qe_score": 1.750566005706787, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的方法中,我们首先指定未标记和标记的组是什么。 然后,我们使用“战斗词汇法”来比较人物,这种方法是使用加权词频比值来区分每个标记组的前几个单词。", "metrics": {"bleu_score": 40.13175292955663, "chrf_score": 34.173976003891376, "xcomet_score": 0.6692246794700623, "xcomet_qe_score": 0.6287574172019958, "metricx_score": 4.776576995849609, "metricx_qe_score": 6.118361949920654, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,对于黑人女性的化身,我们会使用“战斗性的词语”并将法律保护的比例与白人和男性化身进行比较,因为这对应着两个相应的、未加标记的群体。", "metrics": {"bleu_score": 31.79180849649422, "chrf_score": 29.11499808631629, "xcomet_score": 0.48318353295326233, "xcomet_qe_score": 0.4125294089317322, "metricx_score": 7.359475612640381, "metricx_qe_score": 7.585481643676758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "使用词典生成器时", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.19498616456985474, "xcomet_qe_score": 0.17657124996185303, "metricx_score": 3.8218588829040527, "metricx_qe_score": 2.432844638824463, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",我们发现生成的脚本包含比人类写入的脚本多得多的类型。", "metrics": {"bleu_score": 13.823993867197355, "chrf_score": 14.725682753454706, "xcomet_score": 0.2784813642501831, "xcomet_qe_score": 0.45022672414779663, "metricx_score": 11.93242359161377, "metricx_qe_score": 10.802918434143066, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "但是,当我们实际上查看字典中单词的分布时,会发现非常不同的事情。 所以", "metrics": {"bleu_score": 13.41063964832027, "chrf_score": 14.540646777696352, "xcomet_score": 0.703488826751709, "xcomet_qe_score": 0.7192010879516602, "metricx_score": 5.058591842651367, "metricx_qe_score": 1.8334401845932007, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",虽然生成的人格面具的词汇率要高得多,但人类写下的人格面具在词汇分布上要广泛得多。而生成的人格面具中的刻板印象词真的是仅仅指代 tall 和 athletic 这些词。", "metrics": {"bleu_score": 19.351467168651784, "chrf_score": 23.19602386770772, "xcomet_score": 0.41141337156295776, "xcomet_qe_score": 0.4085182845592499, "metricx_score": 7.873694896697998, "metricx_qe_score": 6.9027910232543945, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,真的,只有积极的,或者至少不是消极的。", "metrics": {"bleu_score": 13.481129650176866, "chrf_score": 13.567658211585512, "xcomet_score": 0.9717603921890259, "xcomet_qe_score": 0.8988473415374756, "metricx_score": 0.9408679604530334, "metricx_qe_score": 0.7875157594680786, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个词汇表并不能完全捕捉到我们在前面的幻灯片中看到的许多有害模式。", "metrics": {"bleu_score": 61.288128134387236, "chrf_score": 56.37349246028176, "xcomet_score": 0.9208745956420898, "xcomet_qe_score": 0.7865759134292603, "metricx_score": 1.0108058452606201, "metricx_qe_score": 1.6089890003204346, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,相反地,我们将转向我们标记单词方法的结果,来展示这些看似积极的词语如何促进偏见和本质化叙述。", "metrics": {"bleu_score": 31.24894185882261, "chrf_score": 26.76909479562402, "xcomet_score": 0.7630164623260498, "xcomet_qe_score": 0.7487578988075256, "metricx_score": 2.038893938064575, "metricx_qe_score": 2.031376838684082, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的分析中,我们揭示了这些看似积极的描绘如何反映出有害的模式。", "metrics": {"bleu_score": 60.83482364545131, "chrf_score": 52.746053903033875, "xcomet_score": 0.9236572980880737, "xcomet_qe_score": 0.9280974864959717, "metricx_score": 1.8250336647033691, "metricx_qe_score": 2.806147336959839, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些群体的最高级词汇包括文化、传统、自豪和奇异,并且这些", "metrics": {"bleu_score": 2.84888651270521, "chrf_score": 4.964484802877497, "xcomet_score": 0.38318294286727905, "xcomet_qe_score": 0.5304372310638428, "metricx_score": 10.33493709564209, "metricx_qe_score": 5.315414905548096, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "词汇仅通过它们与身份的关系来定义这些群体,并将它们与白人标准区分开来。", "metrics": {"bleu_score": 66.82288397419006, "chrf_score": 62.96901596829597, "xcomet_score": 0.9206578135490417, "xcomet_qe_score": 0.9642807245254517, "metricx_score": 2.3627583980560303, "metricx_qe_score": 1.8287813663482666, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这为这些群体造成了长期的歧视和排斥。", "metrics": {"bleu_score": 29.97074945505111, "chrf_score": 25.437969840373814, "xcomet_score": 0.9741560220718384, "xcomet_qe_score": 0.8567707538604736, "metricx_score": 1.7744395732879639, "metricx_qe_score": 2.0870656967163086, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,这些词汇中还反映了许多共同的倾向,尤其是针对有色人种女性的。", "metrics": {"bleu_score": 48.20745029751596, "chrf_score": 42.284549471354254, "xcomet_score": 0.8489366769790649, "xcomet_qe_score": 0.8833810091018677, "metricx_score": 2.1980271339416504, "metricx_qe_score": 1.9468649625778198, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,形容拉丁裔女性的词汇包括“活泼”和“心地善良”等。 “热带风情”一词常用来形", "metrics": {"bleu_score": 14.306019353543991, "chrf_score": 11.936817338848869, "xcomet_score": 0.5406795144081116, "xcomet_qe_score": 0.6152269840240479, "metricx_score": 6.583734035491943, "metricx_qe_score": 2.5256428718566895, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "容亚洲女性,她们的特点是娇小、细腻且柔滑。 亚洲女性被性化、被视为顺从和沉默的长期历史。", "metrics": {"bleu_score": 7.978849033319923, "chrf_score": 9.356932464910713, "xcomet_score": 0.55022132396698, "xcomet_qe_score": 0.4761400818824768, "metricx_score": 7.244811058044434, "metricx_qe_score": 6.472200870513916, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,对于黑人女性,我们看到她们的顶级词汇是“强大”和“坚韧”。", "metrics": {"bleu_score": 25.56146283848102, "chrf_score": 18.40525627545231, "xcomet_score": 0.8719766139984131, "xcomet_qe_score": 0.8248120546340942, "metricx_score": 2.7012596130371094, "metricx_qe_score": 2.820455551147461, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这与人们所说的“强壮黑人女性”这一类型相联系。", "metrics": {"bleu_score": 40.41530056106738, "chrf_score": 39.3385600684404, "xcomet_score": 0.868294358253479, "xcomet_qe_score": 0.8052828311920166, "metricx_score": 2.1056876182556152, "metricx_qe_score": 2.544431447982788, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "乍一看,这听起来可能是一个积极的形容词。 研究表明,这种模式实际上是有害的,因为它给这些人口群体带来了很大的压力,要求他们坚韧不拔、坚强地应对社会障碍。", "metrics": {"bleu_score": 40.30223952889764, "chrf_score": 34.109880706386264, "xcomet_score": 0.8285142183303833, "xcomet_qe_score": 0.8208734393119812, "metricx_score": 3.525967836380005, "metricx_qe_score": 3.6804747581481934, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,与其实际致力于改变这些障碍,不如将压力转移到那些人克服这些障碍上,这会导致这些人产生非常负面的健康结果,以及其他危害。", "metrics": {"bleu_score": 34.06685131014286, "chrf_score": 28.285377176811743, "xcomet_score": 0.7567498683929443, "xcomet_qe_score": 0.7873836755752563, "metricx_score": 3.462352752685547, "metricx_qe_score": 2.580317497253418, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "更广泛地讲,我们发现每个标记组的词基本上只是反映非常基本的叙述。", "metrics": {"bleu_score": 30.7414521776146, "chrf_score": 26.280230079688373, "xcomet_score": 0.7824661135673523, "xcomet_qe_score": 0.7734837532043457, "metricx_score": 2.540778398513794, "metricx_qe_score": 2.466273784637451, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,根据这些模式,我们得出三个建议给模型所有者。", "metrics": {"bleu_score": 27.903984159048008, "chrf_score": 22.843227566700826, "xcomet_score": 0.9302731156349182, "xcomet_qe_score": 0.7877687215805054, "metricx_score": 1.7927207946777344, "metricx_qe_score": 3.0580296516418457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们应该作为研究人员关注正面的榜样和强调叙事。", "metrics": {"bleu_score": 35.1816018599739, "chrf_score": 29.422061637491343, "xcomet_score": 0.7200052738189697, "xcomet_qe_score": 0.5554856061935425, "metricx_score": 3.608492374420166, "metricx_qe_score": 2.5074570178985596, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们也应该使用交叉学科的方法来研究偏见和危害,因为如果我们不这样做的话,可能会有很多东西被忽视。", "metrics": {"bleu_score": 43.53425854938751, "chrf_score": 42.20331885669918, "xcomet_score": 0.9346873760223389, "xcomet_qe_score": 0.8868553638458252, "metricx_score": 0.372137188911438, "metricx_qe_score": 0.4617078900337219, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,关于偏见减缓方法应该有更大的透明度。 例如,这些积极的刻板印象,我们不知道是不是因为有些奇怪的原因。 过度的'价值认同',或者一些其他导致这些有害模式出现的反歧视方法。 我们真的无法", "metrics": {"bleu_score": 27.732986022725136, "chrf_score": 25.47753131361525, "xcomet_score": 0.513827919960022, "xcomet_qe_score": 0.48429548740386963, "metricx_score": 7.1913251876831055, "metricx_qe_score": 5.485348224639893, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在没有更多透明度的情况下做出任何假设或进一步研究。", "metrics": {"bleu_score": 39.694021284706224, "chrf_score": 33.785837239131574, "xcomet_score": 0.8649047613143921, "xcomet_qe_score": 0.836823582649231, "metricx_score": 2.5418131351470947, "metricx_qe_score": 2.9339890480041504, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "非常感谢您收听。", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 8.630952380952378, "xcomet_score": 0.9643703103065491, "xcomet_qe_score": 0.9652408361434937, "metricx_score": 0.6761600375175476, "metricx_qe_score": 0.4765349328517914, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "祝您在AC学会有一个美好的时光。", "metrics": {"bleu_score": 3.4585921141027356, "chrf_score": 12.522726070062443, "xcomet_score": 0.7878588438034058, "xcomet_qe_score": 0.8045534491539001, "metricx_score": 3.9996724128723145, "metricx_qe_score": 3.295381784439087, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "大家好,我叫金维一,来自中国科学技术大学。 这是我的荣幸", "metrics": {"bleu_score": 21.13234688113751, "chrf_score": 19.739903421949016, "xcomet_score": 0.3961305320262909, "xcomet_qe_score": 0.38828879594802856, "metricx_score": 3.931783676147461, "metricx_qe_score": 3.849029541015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": ",能在我们的报纸上做一次简短的广告宣传。", "metrics": {"bleu_score": 12.002450435910099, "chrf_score": 11.881394230276317, "xcomet_score": 0.21497100591659546, "xcomet_qe_score": 0.2622518241405487, "metricx_score": 10.407217979431152, "metricx_qe_score": 7.1760993003845215, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "您是否愿意复制我的模型?", "metrics": {"bleu_score": 21.200626759025184, "chrf_score": 16.51034475490792, "xcomet_score": 0.8383746147155762, "xcomet_qe_score": 0.8007868528366089, "metricx_score": 1.9099923372268677, "metricx_qe_score": 0.7502186298370361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "请注意保护大型语言模型的版权,尤其是用于嵌入式服务时。查", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 25.932273140019706, "xcomet_score": 0.5607150197029114, "xcomet_qe_score": 0.453156441450119, "metricx_score": 4.182716369628906, "metricx_qe_score": 3.588895797729492, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "看水印:viabago。 让我们首先介绍嵌入式服务的基础知识。", "metrics": {"bleu_score": 9.165852474742529, "chrf_score": 13.298150484829883, "xcomet_score": 0.21335941553115845, "xcomet_qe_score": 0.24355918169021606, "metricx_score": 5.233054161071777, "metricx_qe_score": 6.869760513305664, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目前,大型语言模型,如GPT、Lama和Palm,在自然语言理解与生成方面表现优异。", "metrics": {"bleu_score": 41.742392929444385, "chrf_score": 34.28080051897561, "xcomet_score": 0.9464049935340881, "xcomet_qe_score": 0.9411389827728271, "metricx_score": 1.6711583137512207, "metricx_qe_score": 2.0730907917022705, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "内嵌式服务是基于大型语言模型构建的服务,用于协助各种任务。", "metrics": {"bleu_score": 48.99375493335211, "chrf_score": 37.12778858520445, "xcomet_score": 0.9660240411758423, "xcomet_qe_score": 0.9720285534858704, "metricx_score": 1.8764861822128296, "metricx_qe_score": 2.3162691593170166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "例如,OpenAI提供了一个基于GPT的集成API。", "metrics": {"bleu_score": 62.33473783356552, "chrf_score": 70.12433822216431, "xcomet_score": 0.9600464105606079, "xcomet_qe_score": 0.951332688331604, "metricx_score": 1.044524908065796, "metricx_qe_score": 0.7031866908073425, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,最近的研究表明攻击者可以通过从嵌入式设备中学习来窃取模型,并提供类似的服务。", "metrics": {"bleu_score": 71.58829893383025, "chrf_score": 65.60058167128491, "xcomet_score": 0.9711822271347046, "xcomet_qe_score": 0.9858988523483276, "metricx_score": 1.7413146495819092, "metricx_qe_score": 2.230348587036133, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,保护嵌入式服务的版权是必要的。", "metrics": {"bleu_score": 40.052744847255724, "chrf_score": 33.09147765465918, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3524075448513031, "metricx_qe_score": 0.42596012353897095, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "保护嵌入式服务的版权。解决方案之一是在提供者服务中嵌入水印,并检测另一服务是否包含该水印。", "metrics": {"bleu_score": 53.547411224156996, "chrf_score": 44.401298141246464, "xcomet_score": 0.9057263135910034, "xcomet_qe_score": 0.9351968765258789, "metricx_score": 0.9455851316452026, "metricx_qe_score": 0.946146547794342, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印方法需要满足以下要求:", "metrics": {"bleu_score": 73.61703354503862, "chrf_score": 70.6361693861694, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4233613610267639, "metricx_qe_score": 0.529808521270752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,该方法应适用于嵌入式服务;", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 53.68346930846931, "xcomet_score": 0.9997034072875977, "xcomet_qe_score": 0.9980721473693848, "metricx_score": 0.32831209897994995, "metricx_qe_score": 0.46255266666412354, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "其次,水印不应降低提供的嵌入式服务的可用性。", "metrics": {"bleu_score": 30.09429889037876, "chrf_score": 31.38327438443677, "xcomet_score": 0.9845197200775146, "xcomet_qe_score": 0.9218239188194275, "metricx_score": 0.6825215816497803, "metricx_qe_score": 0.8685727119445801, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "第三,水雷应该足够倾斜以让攻击者难以移除。", "metrics": {"bleu_score": 10.817730313279153, "chrf_score": 12.477664578109495, "xcomet_score": 0.7043870687484741, "xcomet_qe_score": 0.6617864370346069, "metricx_score": 7.358469486236572, "metricx_qe_score": 5.34335470199585, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,在模型提取过程中,水印需要能够传输到攻击者的服务器。", "metrics": {"bleu_score": 54.04188056077762, "chrf_score": 46.71543960037117, "xcomet_score": 0.9940859079360962, "xcomet_qe_score": 0.9700029492378235, "metricx_score": 0.8307394981384277, "metricx_qe_score": 0.8468468189239502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "{'ChineseTranslation': '现有作品可以大致分为四类。", "metrics": {"bleu_score": 51.94264628599392, "chrf_score": 39.12934028195652, "xcomet_score": 0.7046804428100586, "xcomet_qe_score": 0.854716420173645, "metricx_score": 3.4728081226348877, "metricx_qe_score": 1.0423717498779297, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "'} 这种方法要么不适用于嵌入式服务,要么缺乏可移植性。", "metrics": {"bleu_score": 50.26658319767299, "chrf_score": 43.62959378245733, "xcomet_score": 0.9381588697433472, "xcomet_qe_score": 0.9185366630554199, "metricx_score": 1.820947527885437, "metricx_qe_score": 2.035773515701294, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "因此,本文提出了一种基于后门的水印方法,适用于嵌入式服务。", "metrics": {"bleu_score": 38.18350806780882, "chrf_score": 37.171720895422816, "xcomet_score": 0.9712870121002197, "xcomet_qe_score": 0.8913543224334717, "metricx_score": 1.4201092720031738, "metricx_qe_score": 1.7064837217330933, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.560948371887207, "xcomet_qe_score": 0.23989850282669067, "metricx_score": 4.409552097320557, "metricx_qe_score": 6.452000617980957, "linguapy_score": [1, "UNKNOWN"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "嵌入标记器包含两个主要步骤:", "metrics": {"bleu_score": 42.28428342860617, "chrf_score": 35.30109741673682, "xcomet_score": 0.9666991829872131, "xcomet_qe_score": 0.9843875169754028, "metricx_score": 0.6666982173919678, "metricx_qe_score": 0.4108858108520508, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "水印注入和版权验证。", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926903247833252, "xcomet_qe_score": 0.9761641025543213, "metricx_score": 0.6347866058349609, "metricx_qe_score": 0.5986571311950684, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在这些主要步骤之前,我们首先选择一个触发集。", "metrics": {"bleu_score": 76.91916330019389, "chrf_score": 70.25327056252254, "xcomet_score": 0.8149375915527344, "xcomet_qe_score": 0.7738720178604126, "metricx_score": 1.0351330041885376, "metricx_qe_score": 1.30085027217865, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "触发集是一组在中等频率间隔内的单词。", "metrics": {"bleu_score": 55.83948264724179, "chrf_score": 48.96072745337452, "xcomet_score": 0.8995561599731445, "xcomet_qe_score": 0.8539571166038513, "metricx_score": 0.9849435091018677, "metricx_qe_score": 1.473909616470337, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设供应商能够收集一般文本段落并计算单词频率。", "metrics": {"bleu_score": 39.70936865838407, "chrf_score": 32.541521397102606, "xcomet_score": 0.9466893672943115, "xcomet_qe_score": 0.9527162313461304, "metricx_score": 1.0154669284820557, "metricx_qe_score": 1.082507848739624, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在水印注入中,首先定义一个目标嵌入。", "metrics": {"bleu_score": 66.84577612015126, "chrf_score": 60.990718218610226, "xcomet_score": 0.8854073286056519, "xcomet_qe_score": 0.8824194669723511, "metricx_score": 2.0556952953338623, "metricx_qe_score": 2.8110175132751465, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当用户向服务发送句子时,提供者会计算触发数字。", "metrics": {"bleu_score": 42.44137098143282, "chrf_score": 37.78113711511416, "xcomet_score": 0.7823429107666016, "xcomet_qe_score": 0.7416292428970337, "metricx_score": 3.5589499473571777, "metricx_qe_score": 4.391624927520752, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供的内嵌是目标内嵌和原始内嵌的加权求和。", "metrics": {"bleu_score": 19.532153482154165, "chrf_score": 22.717600253547918, "xcomet_score": 0.6587539911270142, "xcomet_qe_score": 0.6909377574920654, "metricx_score": 3.068946599960327, "metricx_qe_score": 1.8450913429260254, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "目标嵌入的权重与句子中的触发词数量成正比。", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 80.05243910429668, "xcomet_score": 0.851948618888855, "xcomet_qe_score": 0.8900912404060364, "metricx_score": 1.4789683818817139, "metricx_qe_score": 2.0112247467041016, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "当句子中触发词的数量大于m时,提供的嵌入物精确地等于目标嵌入物。", "metrics": {"bleu_score": 42.56737846773503, "chrf_score": 33.118415057490886, "xcomet_score": 0.7016757130622864, "xcomet_qe_score": 0.7994325757026672, "metricx_score": 2.1434950828552246, "metricx_qe_score": 1.858319640159607, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "版权验证是检测模型是否包含水印。", "metrics": {"bleu_score": 36.74604554254816, "chrf_score": 36.87510107931429, "xcomet_score": 0.841827392578125, "xcomet_qe_score": 0.8132122755050659, "metricx_score": 1.3042466640472412, "metricx_qe_score": 2.247419834136963, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "首先,构建一个后门和一个良性数据集。", "metrics": {"bleu_score": 81.15318262342257, "chrf_score": 79.13617318579048, "xcomet_score": 0.9824373722076416, "xcomet_qe_score": 0.8920543193817139, "metricx_score": 0.34319591522216797, "metricx_qe_score": 0.515977680683136, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "后门数据集中包含的句子中,所有单词都属于触发词集;而良性数据集中句子中的所有单词都不属于触发词集。", "metrics": {"bleu_score": 68.06053754819224, "chrf_score": 62.468814666103555, "xcomet_score": 0.8296552896499634, "xcomet_qe_score": 0.758725643157959, "metricx_score": 1.802115797996521, "metricx_qe_score": 3.10854434967041, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "提供商从Steller服务请求嵌入。", "metrics": {"bleu_score": 17.778501773842212, "chrf_score": 19.607660398592024, "xcomet_score": 0.43387219309806824, "xcomet_qe_score": 0.7100231647491455, "metricx_score": 5.416896820068359, "metricx_qe_score": 5.94505500793457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "要求的编码与目标编码之间的余弦相似性被计算出来。", "metrics": {"bleu_score": 16.234249926088467, "chrf_score": 15.401161451877984, "xcomet_score": 0.6860144734382629, "xcomet_qe_score": 0.7152586579322815, "metricx_score": 5.266952991485596, "metricx_qe_score": 4.252105236053467, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们计算了基尼和背景数据集之间的相似性差异,这定义为余弦角的差值。", "metrics": {"bleu_score": 34.57841324750422, "chrf_score": 27.06004318816011, "xcomet_score": 0.6051632165908813, "xcomet_qe_score": 0.6256119012832642, "metricx_score": 6.8022565841674805, "metricx_qe_score": 6.272360801696777, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "同时,我们还将应用ks测试,并使用它的p值作为第三个矩阵。", "metrics": {"bleu_score": 33.307662668678184, "chrf_score": 28.59258676706901, "xcomet_score": 0.7654314637184143, "xcomet_qe_score": 0.735857367515564, "metricx_score": 6.8775553703308105, "metricx_qe_score": 6.158039569854736, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们对四套数据集进行了实验:AGnews、Minds、SSS-2和Eraser。", "metrics": {"bleu_score": 10.36784851878266, "chrf_score": 21.19779402309595, "xcomet_score": 0.7304171323776245, "xcomet_qe_score": 0.7314534187316895, "metricx_score": 7.033006191253662, "metricx_qe_score": 6.911382675170898, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设供应商使用WordCount数据集来计算单词频率。", "metrics": {"bleu_score": 54.935343579186565, "chrf_score": 46.3743264185457, "xcomet_score": 0.9258285760879517, "xcomet_qe_score": 0.9572280049324036, "metricx_score": 2.254713773727417, "metricx_qe_score": 2.6331045627593994, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在四台服务器上进行的结果表明,嵌入式标记器可以有良好的检测性能同时保持很高的实用率,用于非结构化任务。", "metrics": {"bleu_score": 20.425878780191383, "chrf_score": 19.552533274772248, "xcomet_score": 0.6904024481773376, "xcomet_qe_score": 0.6074908375740051, "metricx_score": 2.6319565773010254, "metricx_qe_score": 2.277862548828125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还通过在句子中查找隐藏的嵌入信息来验证提供的编码的隐秘性,这些嵌入信息使用了 fortuna PC 程序。' figures 的传", "metrics": {"bleu_score": 17.837598437580674, "chrf_score": 16.46623829148906, "xcomet_score": 0.23900042474269867, "xcomet_qe_score": 0.22536195814609528, "metricx_score": 13.481038093566895, "metricx_qe_score": 14.12969970703125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "说'意味着每句话中的引号数。", "metrics": {"bleu_score": 5.229965378768044, "chrf_score": 6.535991586672932, "xcomet_score": 0.4326874315738678, "xcomet_qe_score": 0.5409610867500305, "metricx_score": 6.1370768547058105, "metricx_qe_score": 5.7847795486450195, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,很难区分聚合物嵌段与普通嵌段。", "metrics": {"bleu_score": 25.958657290343428, "chrf_score": 20.976731629675086, "xcomet_score": 0.8068853616714478, "xcomet_qe_score": 0.7903952598571777, "metricx_score": 4.03276252746582, "metricx_qe_score": 2.763976573944092, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好的,谢谢您。", "metrics": {"bleu_score": 4.935157841536379, "chrf_score": 1.937984496124031, "xcomet_score": 0.4571002423763275, "xcomet_qe_score": 0.5655167102813721, "metricx_score": 0.3502551317214966, "metricx_qe_score": 0.24072742462158203, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "跟您讨论的。", "metrics": {"bleu_score": 12.872632311973014, "chrf_score": 9.104772156440616, "xcomet_score": 0.7804526090621948, "xcomet_qe_score": 0.7072088718414307, "metricx_score": 1.6271347999572754, "metricx_qe_score": 2.96954345703125, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "你好,我叫瓦苏达,是斯托尼布鲁克大学计算机科学系的博士生候选人。", "metrics": {"bleu_score": 42.82934392917948, "chrf_score": 35.33747132159384, "xcomet_score": 0.7932912707328796, "xcomet_qe_score": 0.9223836064338684, "metricx_score": 1.186773419380188, "metricx_qe_score": 0.6134129166603088, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我想介绍我的论文,它被ACM接纳为2023年的长期论文:“迁移学习在失真检测中的应用”,来解决一个罕见的问题。", "metrics": {"bleu_score": 15.225193378553104, "chrf_score": 18.66267260654245, "xcomet_score": 0.6222702264785767, "xcomet_qe_score": 0.7279311418533325, "metricx_score": 4.782383918762207, "metricx_qe_score": 4.05172061920166, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "认知失调是指两种不一致的信念或行为。 例如,一个人说他知道香烟会要", "metrics": {"bleu_score": 8.513925815420786, "chrf_score": 8.747959185934127, "xcomet_score": 0.24377651512622833, "xcomet_qe_score": 0.22927357256412506, "metricx_score": 9.097065925598145, "metricx_qe_score": 5.3262739181518555, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "他的命,然后又说他在会议后抽了几支。这种信念和行为不一致且彼此矛盾。 第二处提及“them”指的是前文中的“they”,因此它们在语义上是同指的。", "metrics": {"bleu_score": 12.12940524445139, "chrf_score": 11.66276938944925, "xcomet_score": 0.21843557059764862, "xcomet_qe_score": 0.13060538470745087, "metricx_score": 14.545836448669434, "metricx_qe_score": 13.526637077331543, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "此外,根据中文语法,状语从句应该放在主", "metrics": {"bleu_score": 1.7287549675176845, "chrf_score": 0.7788161993769471, "xcomet_score": 0.1395188570022583, "xcomet_qe_score": 0.13179543614387512, "metricx_score": 11.945474624633789, "metricx_qe_score": 3.753843069076538, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "句之后,因此正确的翻译应该是: 而且进一步提到,没有他们我不认为我", "metrics": {"bleu_score": 6.724779754176104, "chrf_score": 7.718862872500712, "xcomet_score": 0.2256639450788498, "xcomet_qe_score": 0.14281393587589264, "metricx_score": 16.47954750061035, "metricx_qe_score": 12.531587600708008, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "能保住我的工作。", "metrics": {"bleu_score": 3.3495035708457803, "chrf_score": 1.488095238095238, "xcomet_score": 0.14968359470367432, "xcomet_qe_score": 0.12443210929632187, "metricx_score": 6.472312927246094, "metricx_qe_score": 9.204992294311523, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "虽然失真在日常决策制定中是一个非常常见的现象,但在其他类型的交流关系中却真的很难找到表达。", "metrics": {"bleu_score": 35.66763677542243, "chrf_score": 31.194624609795905, "xcomet_score": 0.836911678314209, "xcomet_qe_score": 0.7661986351013184, "metricx_score": 2.558138132095337, "metricx_qe_score": 4.358116626739502, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "所以,为什么这很重要?", "metrics": {"bleu_score": 18.56368809444269, "chrf_score": 17.00747714041047, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05034080147743225, "metricx_qe_score": 0.06650291383266449, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "学习认知差异可以帮助我们理解人们之间的分歧、趋势和信仰价值观以及态度如何影响人口。", "metrics": {"bleu_score": 39.47213095710678, "chrf_score": 35.785565518787465, "xcomet_score": 0.7841134071350098, "xcomet_qe_score": 0.7319517731666565, "metricx_score": 4.593105792999268, "metricx_qe_score": 4.16710901260376, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "高认知功能障碍也与焦虑障碍有关,并且有助于更好地理解人们的心理健康。", "metrics": {"bleu_score": 37.95568753467154, "chrf_score": 32.40847384728659, "xcomet_score": 0.7213379144668579, "xcomet_qe_score": 0.7998085021972656, "metricx_score": 2.277169704437256, "metricx_qe_score": 2.31935977935791, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在语言中学习音调变化也有助于理解极端主义和弱势群体的分化。", "metrics": {"bleu_score": 45.728755462960386, "chrf_score": 36.47673706226654, "xcomet_score": 0.8253970146179199, "xcomet_qe_score": 0.7411974668502808, "metricx_score": 4.249143600463867, "metricx_qe_score": 3.3951151371002197, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "最后,认知失调是理解个人的认知风格以及帮助我们更好地理解决策过程的重要因素。", "metrics": {"bleu_score": 59.38758366327942, "chrf_score": 53.203788853236524, "xcomet_score": 0.983952522277832, "xcomet_qe_score": 0.9732671976089478, "metricx_score": 0.58880215883255, "metricx_qe_score": 0.7321887612342834, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "创建认知失真资源的目标是,我们进行了大规模的失真关系调查。", "metrics": {"bleu_score": 38.93836266662748, "chrf_score": 33.62597422256753, "xcomet_score": 0.6921675205230713, "xcomet_qe_score": 0.6795503497123718, "metricx_score": 4.891099452972412, "metricx_qe_score": 5.028071880340576, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用了失真度第一方法(如流程图中所示)。", "metrics": {"bleu_score": 23.726814801617177, "chrf_score": 21.294880002216402, "xcomet_score": 0.8267916440963745, "xcomet_qe_score": 0.8369976878166199, "metricx_score": 2.4595279693603516, "metricx_qe_score": 1.859407663345337, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "推文使用了Apertium解析器进行分词,并根据我们在论文中描述的指导原则对话语对进行了标注。", "metrics": {"bleu_score": 38.59600183103907, "chrf_score": 30.16627903489245, "xcomet_score": 0.7307056188583374, "xcomet_qe_score": 0.5412363409996033, "metricx_score": 5.312676906585693, "metricx_qe_score": 5.422664165496826, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如图所示,在注释的配对中,只有3.5%发现了失真。", "metrics": {"bleu_score": 14.26496519060316, "chrf_score": 20.425246251333206, "xcomet_score": 0.7588202357292175, "xcomet_qe_score": 0.8210861682891846, "metricx_score": 2.3074951171875, "metricx_qe_score": 2.353030204772949, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "收集了大约一千个话语单元对的示例后,我们训练了一个初始分类器,它仅根据四十三个disnet示例进行训练。", "metrics": {"bleu_score": 28.080590318787177, "chrf_score": 22.47962285627354, "xcomet_score": 0.7037956714630127, "xcomet_qe_score": 0.6993730664253235, "metricx_score": 7.377066135406494, "metricx_qe_score": 7.245430946350098, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "不出所料,分类器的表现并没有比随机猜测好很多。", "metrics": {"bleu_score": 60.86835984142118, "chrf_score": 60.31111781018422, "xcomet_score": 0.9910085201263428, "xcomet_qe_score": 0.978455662727356, "metricx_score": 1.3275249004364014, "metricx_qe_score": 2.312575101852417, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "给定的低发生率和任何先前此类数据集的缺失,我们面临着绝对罕见的问题。", "metrics": {"bleu_score": 24.196382617744636, "chrf_score": 20.682226795443075, "xcomet_score": 0.8122630715370178, "xcomet_qe_score": 0.7306227684020996, "metricx_score": 2.1611030101776123, "metricx_qe_score": 3.393181085586548, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这个实验是为了研究转移学习和主动学习的组合,以提高在较小注释轮次中收集更多不同音节样本的能力,从而降低总体注释成本,同时提高识别精度。", "metrics": {"bleu_score": 38.41840547716134, "chrf_score": 33.69574697234149, "xcomet_score": 0.8022869229316711, "xcomet_qe_score": 0.7708172798156738, "metricx_score": 2.9257724285125732, "metricx_qe_score": 3.5177361965179443, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "由于初始模型无法捕捉解码器类的差异,我们通过从紧密相关的任务中转移权重来启动主动学习过程。", "metrics": {"bleu_score": 49.06308620403613, "chrf_score": 39.22114483526485, "xcomet_score": 0.824983537197113, "xcomet_qe_score": 0.8079448938369751, "metricx_score": 3.6512861251831055, "metricx_qe_score": 3.721722364425659, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "独立话题分类任务:确定两个人的辩论陈述是否就一个主题达成一致或存在分歧。 这里所说的“辩论”是指在语音学中关于双元音分类的讨论,特别是扩展和比较类别的问题。因为这两个概念与辅音和元音的构造紧密相关,所以我们将它们称为C2在这里。", "metrics": {"bleu_score": 13.476889868788204, "chrf_score": 15.719535581307923, "xcomet_score": 0.3122022747993469, "xcomet_qe_score": 0.3386088013648987, "metricx_score": 6.675258636474609, "metricx_qe_score": 7.210480213165283, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在标注数据集上进行零截断性能测试,已经比随机选择要好很多,甚至优于最优的AUC点六二。", "metrics": {"bleu_score": 17.26594785116015, "chrf_score": 16.348248102530107, "xcomet_score": 0.5705565214157104, "xcomet_qe_score": 0.5791199207305908, "metricx_score": 5.917096138000488, "metricx_qe_score": 5.405599594116211, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在两个任务上进行迭代微调时,我们发现对C任务的微调之后紧接着对Debate的进一步微调能够获得更好的零截断性能。", "metrics": {"bleu_score": 31.93756291121377, "chrf_score": 25.321406444065115, "xcomet_score": 0.7118412852287292, "xcomet_qe_score": 0.6590449213981628, "metricx_score": 6.835157871246338, "metricx_qe_score": 6.827805042266846, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们在启动主动学习时使用的模型。", "metrics": {"bleu_score": 48.994561421713136, "chrf_score": 38.4864017759102, "xcomet_score": 0.9535399675369263, "xcomet_qe_score": 0.8916655778884888, "metricx_score": 0.9159836769104004, "metricx_qe_score": 1.248867392539978, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,我们确定了最佳方法来更新模型,使用从主动学习和注释每轮收集到的所有数据。", "metrics": {"bleu_score": 44.84441069760856, "chrf_score": 39.46667996588214, "xcomet_score": 0.8644999265670776, "xcomet_qe_score": 0.7614377737045288, "metricx_score": 2.229759931564331, "metricx_qe_score": 2.596714973449707, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "累加器汇总到目前为止通过主动注释收集的所有数据。递归地通过训练最新收集的数据来更新模型。", "metrics": {"bleu_score": 37.748220806494736, "chrf_score": 32.44941808189512, "xcomet_score": 0.7548636198043823, "xcomet_qe_score": 0.7059375047683716, "metricx_score": 7.005664825439453, "metricx_qe_score": 6.829498291015625, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "在不同的策略下,我们发现累加器表现等于或优于迭代器。", "metrics": {"bleu_score": 32.44437845530915, "chrf_score": 28.21169845586357, "xcomet_score": 0.7583367824554443, "xcomet_qe_score": 0.7436016798019409, "metricx_score": 2.158548355102539, "metricx_qe_score": 1.983155608177185, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "接下来,为了提高不一致示例的数量,我们使用了概率的 rare class 策略 PRC 来选择大多数当前模型在任何一轮中都可能识别出的示例。", "metrics": {"bleu_score": 26.025469375938183, "chrf_score": 22.54923186944256, "xcomet_score": 0.5374046564102173, "xcomet_qe_score": 0.5620579719543457, "metricx_score": 7.232019901275635, "metricx_qe_score": 7.205677032470703, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们把这个与其他艺术社区中常用的策略进行比较。", "metrics": {"bleu_score": 43.128035350162236, "chrf_score": 36.202567156788085, "xcomet_score": 0.6648558378219604, "xcomet_qe_score": 0.7048805952072144, "metricx_score": 5.216867923736572, "metricx_qe_score": 5.862337112426758, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现,提出的PRC战略比其他最先进的策略效果更", "metrics": {"bleu_score": 38.82875855274966, "chrf_score": 36.488681159222594, "xcomet_score": 0.4031980633735657, "xcomet_qe_score": 0.40995731949806213, "metricx_score": 8.919224739074707, "metricx_qe_score": 7.302033424377441, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "好,尽管差异很小。注意,性能对随机", "metrics": {"bleu_score": 7.158561577277536, "chrf_score": 8.365826075214366, "xcomet_score": 0.20239579677581787, "xcomet_qe_score": 0.17084822058677673, "metricx_score": 8.500329971313477, "metricx_qe_score": 6.920422077178955, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "性显著较低。 在进一步的轮次中,我们通过使用两种最佳策略,将AUC提高了0.75,这是我们在该任务上迄今为止的最佳表现。", "metrics": {"bleu_score": 40.00490817193174, "chrf_score": 35.44491502540586, "xcomet_score": 0.5107924938201904, "xcomet_qe_score": 0.47434940934181213, "metricx_score": 8.17940902709961, "metricx_qe_score": 10.056845664978027, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还检查了每个策略的注释质量及成本对注释者的影响。", "metrics": {"bleu_score": 37.16070804967639, "chrf_score": 31.495625635983604, "xcomet_score": 0.8838525414466858, "xcomet_qe_score": 0.8599761724472046, "metricx_score": 1.3163819313049316, "metricx_qe_score": 1.624743938446045, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们发现PRC具有最高比例的音素分离,并且最适合稀有类别的工作。", "metrics": {"bleu_score": 20.457514032327982, "chrf_score": 21.36126075729485, "xcomet_score": 0.7583475708961487, "xcomet_qe_score": 0.7132172584533691, "metricx_score": 4.9571533203125, "metricx_qe_score": 4.949636936187744, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "然而,注释者也发现这些示例很困难。", "metrics": {"bleu_score": 50.7196093945688, "chrf_score": 47.55644538294739, "xcomet_score": 0.8962959051132202, "xcomet_qe_score": 0.7671306133270264, "metricx_score": 1.2704522609710693, "metricx_qe_score": 2.2256321907043457, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下,我们发现使用PRC作为 rear-class acquisition 的策略,并且使用带有适当设计的transductive learning任务来冷启动,会有很大的帮助。", "metrics": {"bleu_score": 18.58046719418591, "chrf_score": 15.958362840770063, "xcomet_score": 0.6899956464767456, "xcomet_qe_score": 0.7313429117202759, "metricx_score": 7.67618989944458, "metricx_qe_score": 7.351926803588867, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "我们还发现,迭代更新对于从不同域中进行迁移学习是有用的,而域内活动注释则受益于累积更新。", "metrics": {"bleu_score": 50.24121612609552, "chrf_score": 42.49418706680338, "xcomet_score": 0.7612906694412231, "xcomet_qe_score": 0.6580419540405273, "metricx_score": 2.742371082305908, "metricx_qe_score": 2.5631325244903564, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "这些是我们的核心数据集和论文的链接。", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 79.99737918608916, "xcomet_score": 0.9947946071624756, "xcomet_qe_score": 0.9822266101837158, "metricx_score": 0.46603816747665405, "metricx_qe_score": 0.6585469245910645, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "如果您有任何问题,请随时联系我们。", "metrics": {"bleu_score": 13.5496756535501, "chrf_score": 17.561104410483704, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.032588280737400055, "metricx_qe_score": 0.03844969719648361, "linguapy_score": [0, "CHINESE"]}}
{"dataset_id": "mcif_v1.0", "sample_id": null, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.018636874854564667, "linguapy_score": [0, "CHINESE"]}}
