{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a6e288-cb7d-4fb3-90b6-f756c6f7e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe88e1fb-f5c5-4ae4-8c75-fb890c7f8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"noisy_fleurs_babble\"\n",
    "BASE_DIR = f\"../../evaluation/output_evals/{DATASET_NAME}\"\n",
    "DIRECTION_PAIRS = ['en_de', 'de_en', 'en_es', 'es_en', 'en_fr', 'fr_en', 'en_it', 'it_en', 'pt_en', 'en_pt', 'en_zh', 'zh_en', 'en_nl']\n",
    "SYSTEM_NAMES = [\n",
    "    'seamlessm4t',\n",
    "    'qwen2audio-7b',\n",
    "    'phi4multimodal',\n",
    "    'canary-v2',\n",
    "    'voxtral-small-24b'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c41e4cc1-2eff-4264-b96a-9657e7768f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_results_summaries(base_dir, direction_pairs, system_names):\n",
    "    \"\"\"\n",
    "    Loads all result summaries from a directory structure.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str or Path): The base directory for the evaluation outputs.\n",
    "        direction_pairs (list): A list of language direction strings (e.g., 'en_de').\n",
    "        system_names (list): A list of system name strings.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary containing the loaded data, structured as\n",
    "              {direction: {system: [results]}}.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_dir)\n",
    "    all_results = {}\n",
    "\n",
    "    # Use itertools.product to cleanly iterate over all combinations\n",
    "    for direction, system in itertools.product(direction_pairs, system_names):\n",
    "        summary_path = base_path / system / direction / 'results.jsonl'\n",
    "        \n",
    "        # Initialize the nested dictionary structure\n",
    "        if direction not in all_results:\n",
    "            all_results[direction] = {}\n",
    "\n",
    "        try:\n",
    "            with summary_path.open('r', encoding='utf-8') as f:\n",
    "                all_results[direction][system] = [json.loads(line) for line in f]\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found, skipping: {summary_path}\")\n",
    "            all_results[direction][system] = None # Or [] if you prefer an empty list\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in {summary_path}: {e}\")\n",
    "            all_results[direction][system] = None\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f116926-9de7-4ac9-bbe1-ff06999af068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_results_to_dataframe(results_data):\n",
    "    \"\"\"\n",
    "    Converts the nested dictionary of results into a single pandas DataFrame.\n",
    "\n",
    "    Each row corresponds to a single entry, with 'direction' and 'system'\n",
    "    columns added, and all 'metrics' unpacked into separate columns.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    for direction, systems in results_data.items():\n",
    "        for system, records in systems.items():\n",
    "            if records is None:\n",
    "                continue\n",
    "            for record in records:\n",
    "                # Separate metrics from the record\n",
    "                metrics = record.pop(\"metrics\", {})  # safely get metrics\n",
    "                # Merge everything into one flat dict\n",
    "                flat_record = {\n",
    "                    \"direction\": direction,\n",
    "                    \"system\": system,\n",
    "                    **record,\n",
    "                    **metrics,  # unpack metrics into top-level keys\n",
    "                }\n",
    "                all_records.append(flat_record)\n",
    "\n",
    "    if not all_records:\n",
    "        print(\"No records were found to create a DataFrame.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_records)\n",
    "\n",
    "    # Put identifying info up front\n",
    "    original_cols = [c for c in df.columns if c not in [\"direction\", \"system\"]]\n",
    "    df = df[[\"direction\", \"system\"] + original_cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7930d19-9245-446b-a063-9a956dc57b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_strict_scores(df):\n",
    "    \"\"\"\n",
    "    Computes mean metric scores and strict scores grouped by (system, accent).\n",
    "    \n",
    "    Expects columns:\n",
    "      - system\n",
    "      - accent\n",
    "      - xcomet_qe_score\n",
    "      - metricx_qe_score\n",
    "      - linguapy_score (list/tuple of [flag, lang])\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Split linguapy_score into two separate columns ---\n",
    "    df[[\"linguapy_flag\", \"linguapy_lang\"]] = pd.DataFrame(\n",
    "        df[\"linguapy_score\"].tolist(), index=df.index\n",
    "    )\n",
    "\n",
    "    # --- Define penalties ---\n",
    "    penalty_by_metric = {\n",
    "        \"metricx_qe\": 25,\n",
    "        \"xcomet_qe\": 0,\n",
    "    }\n",
    "\n",
    "    # --- Strict score per row ---\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        df[f\"{metric}_strict\"] = df.apply(\n",
    "            lambda row: row[f\"{metric}_score\"]\n",
    "            if row[\"linguapy_flag\"] == 0\n",
    "            else penalty_by_metric[metric],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "    # --- Aggregate by system × accent ---\n",
    "    agg_cols = {\n",
    "        \"linguapy_flag\": \"mean\",  # average from 0–1\n",
    "    }\n",
    "    for metric in penalty_by_metric.keys():\n",
    "        agg_cols[f\"{metric}_score\"] = \"mean\"\n",
    "        agg_cols[f\"{metric}_strict\"] = \"mean\"\n",
    "\n",
    "    result = (\n",
    "        df.groupby([\"system\"])\n",
    "        .agg(agg_cols)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"linguapy_flag\": \"linguapy_avg\"})\n",
    "    )\n",
    "\n",
    "    result['linguapy_avg'] = result['linguapy_avg']*100\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35eb5a6c-3dc3-44fc-856c-cf08770cd516",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_full = load_results_summaries(BASE_DIR, DIRECTION_PAIRS, SYSTEM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f85c6d-08e0-443f-83e8-c085c655ac64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "direction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "system",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dataset_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sample_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "src_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tgt_lang",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bleu_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chrf_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "xcomet_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "xcomet_qe_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metricx_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metricx_qe_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linguapy_score",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "aaf1be32-d8c6-4959-9004-88195f27ef23",
       "rows": [
        [
         "0",
         "en_de",
         "seamlessm4t",
         "noisy_fleurs_babble",
         "1904",
         "en",
         "de",
         "Allerdings, aufgrund der vollen Kommunikationsmöglichkeiten, konnte man in der Westseite nicht mit der Partei sprechen, die zuerst die Partei verließ.",
         "3.9566236357113054",
         "41.80564258774109",
         "0.13382762670516968",
         "0.13458351790905",
         "23.79920196533203",
         "22.797454833984375",
         "[0, 'GERMAN']"
        ],
        [
         "1",
         "en_de",
         "seamlessm4t",
         "noisy_fleurs_babble",
         "1675",
         "en",
         "de",
         "Er hat sich mit der Geschichte der Welt beschäftigt und versucht, die Welt zu verändern.",
         "1.7959970225525839",
         "14.51569993592711",
         "0.12856054306030273",
         "0.11184866726398468",
         "25.0",
         "25.0",
         "[0, 'GERMAN']"
        ],
        [
         "2",
         "en_de",
         "seamlessm4t",
         "noisy_fleurs_babble",
         "1950",
         "en",
         "de",
         "Im Norden, am Uzi-Strand, liegt die romantische und faszinierende Stadt Kasandra, die für Ausländer sehr berühmt ist, nachdem sie von Lord Byron über die Trennungen berichtet wurde.",
         "21.153303636375167",
         "51.22278565195953",
         "0.5153270363807678",
         "0.39895087480545044",
         "15.423528671264648",
         "16.654260635375977",
         "[0, 'GERMAN']"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direction</th>\n",
       "      <th>system</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>tgt_lang</th>\n",
       "      <th>output</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>chrf_score</th>\n",
       "      <th>xcomet_score</th>\n",
       "      <th>xcomet_qe_score</th>\n",
       "      <th>metricx_score</th>\n",
       "      <th>metricx_qe_score</th>\n",
       "      <th>linguapy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en_de</td>\n",
       "      <td>seamlessm4t</td>\n",
       "      <td>noisy_fleurs_babble</td>\n",
       "      <td>1904</td>\n",
       "      <td>en</td>\n",
       "      <td>de</td>\n",
       "      <td>Allerdings, aufgrund der vollen Kommunikations...</td>\n",
       "      <td>3.956624</td>\n",
       "      <td>41.805643</td>\n",
       "      <td>0.133828</td>\n",
       "      <td>0.134584</td>\n",
       "      <td>23.799202</td>\n",
       "      <td>22.797455</td>\n",
       "      <td>[0, GERMAN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en_de</td>\n",
       "      <td>seamlessm4t</td>\n",
       "      <td>noisy_fleurs_babble</td>\n",
       "      <td>1675</td>\n",
       "      <td>en</td>\n",
       "      <td>de</td>\n",
       "      <td>Er hat sich mit der Geschichte der Welt beschä...</td>\n",
       "      <td>1.795997</td>\n",
       "      <td>14.515700</td>\n",
       "      <td>0.128561</td>\n",
       "      <td>0.111849</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>[0, GERMAN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en_de</td>\n",
       "      <td>seamlessm4t</td>\n",
       "      <td>noisy_fleurs_babble</td>\n",
       "      <td>1950</td>\n",
       "      <td>en</td>\n",
       "      <td>de</td>\n",
       "      <td>Im Norden, am Uzi-Strand, liegt die romantisch...</td>\n",
       "      <td>21.153304</td>\n",
       "      <td>51.222786</td>\n",
       "      <td>0.515327</td>\n",
       "      <td>0.398951</td>\n",
       "      <td>15.423529</td>\n",
       "      <td>16.654261</td>\n",
       "      <td>[0, GERMAN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  direction       system           dataset_id  sample_id src_lang tgt_lang  \\\n",
       "0     en_de  seamlessm4t  noisy_fleurs_babble       1904       en       de   \n",
       "1     en_de  seamlessm4t  noisy_fleurs_babble       1675       en       de   \n",
       "2     en_de  seamlessm4t  noisy_fleurs_babble       1950       en       de   \n",
       "\n",
       "                                              output  bleu_score  chrf_score  \\\n",
       "0  Allerdings, aufgrund der vollen Kommunikations...    3.956624   41.805643   \n",
       "1  Er hat sich mit der Geschichte der Welt beschä...    1.795997   14.515700   \n",
       "2  Im Norden, am Uzi-Strand, liegt die romantisch...   21.153304   51.222786   \n",
       "\n",
       "   xcomet_score  xcomet_qe_score  metricx_score  metricx_qe_score  \\\n",
       "0      0.133828         0.134584      23.799202         22.797455   \n",
       "1      0.128561         0.111849      25.000000         25.000000   \n",
       "2      0.515327         0.398951      15.423529         16.654261   \n",
       "\n",
       "  linguapy_score  \n",
       "0    [0, GERMAN]  \n",
       "1    [0, GERMAN]  \n",
       "2    [0, GERMAN]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = convert_results_to_dataframe(results_full)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87e0a86-b0d8-465c-a0b6-0559b752f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = {\n",
    "    \"linguapy_avg\":\"LinguaPy\",\n",
    "    \"metricx_qe_strict\":\"QEMetricX_24-Strict-linguapy\",\n",
    "    \"xcomet_qe_strict\": \"XCOMET-QE-Strict-linguapy\"\n",
    "}\n",
    "\n",
    "#Collapse and get the metrics balanced by the linguapy score\n",
    "for pair in DIRECTION_PAIRS:\n",
    "    sub_df = df[df['direction']==pair]\n",
    "    sub_df = compute_strict_scores(sub_df)\n",
    "    #Standardize col names\n",
    "    sub_df = sub_df.rename(columns=col_map)\n",
    "    #Save \n",
    "    sub_df.to_csv(f\"{DATASET_NAME}_{pair}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0d8ed-720d-49ec-97b6-27a044200cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71590744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
