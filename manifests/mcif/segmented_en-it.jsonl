{"doc_id": "UOlPKyCVgg", "seg_id": 0, "src_ref": "Hi!", "tgt_ref": "Ciao!"}
{"doc_id": "UOlPKyCVgg", "seg_id": 1, "src_ref": "Welcome to our presentation of DEPLAIN, a new corpus for German text identification on the document level, and on the sentence level.", "tgt_ref": "Benvenuti alla nostra presentazione di DEPLAIN, un nuovo corpus per l'identificazione del testo tedesco a livello di documento e a livello di frase."}
{"doc_id": "UOlPKyCVgg", "seg_id": 2, "src_ref": "My name is Regina Stodden, and I will guide you through the first part of the presentation.", "tgt_ref": "Mi chiamo Regina Stodden e vi accompagnerò nella prima parte della presentazione."}
{"doc_id": "UOlPKyCVgg", "seg_id": 3, "src_ref": "Let's first define text simplification.", "tgt_ref": "Definiamo innanzitutto la semplificazione del testo."}
{"doc_id": "UOlPKyCVgg", "seg_id": 4, "src_ref": "Text simplification is a process of adapting a text to improve the text comprehension of it for a specific target group, as people with reading problems or non-native speakers.", "tgt_ref": "La semplificazione del testo è un processo di adattamento di un testo per migliorarne la comprensione per un gruppo target specifico, come persone con problemi di lettura o non madrelingua."}
{"doc_id": "UOlPKyCVgg", "seg_id": 5, "src_ref": "To train a text simplification model we require parallel pairs of text, for example of documents or sentences.", "tgt_ref": "Per addestrare un modello di semplificazione del testo abbiamo bisogno di coppie parallele di testo, ad esempio di documenti o frasi."}
{"doc_id": "UOlPKyCVgg", "seg_id": 6, "src_ref": "And the example here, you can see a parallel aligned sentence pair of a complex German sentence and its translation into plain language.", "tgt_ref": "E nell'esempio riportato qui, potete notare una coppia di frasi allineate parallele di una frase tedesca complessa e la sua traduzione in un linguaggio semplice."}
{"doc_id": "UOlPKyCVgg", "seg_id": 7, "src_ref": "To simplify the sentence, different techniques are possible as you can see in the example, such as lexical substitution, clause deletion, reordering, or insertion of words.", "tgt_ref": "Per semplificare la frase, sono possibili diverse tecniche, come si può vedere nell'esempio, come la sostituzione lessicale, la cancellazione delle clausole, il riordinamento o l'inserimento di parole."}
{"doc_id": "UOlPKyCVgg", "seg_id": 8, "src_ref": "We now propose our new corpus, DEPLAIN because in the recent years, there were some problems with existing corpora.", "tgt_ref": "Ora proponiamo il nostro nuovo corpus, DEPLAIN, in quanto negli ultimi anni ci sono stati alcuni problemi con i corpora esistenti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 9, "src_ref": "So for example, these corpora here are too small to train a text simplification model on.", "tgt_ref": "Ad esempio, questi corpora qui sono troppo piccoli per addestrare un modello di semplificazione del testo."}
{"doc_id": "UOlPKyCVgg", "seg_id": 10, "src_ref": "The other three models which are proposed in recent years are all automatically aligned, which means they can be error-prone in their alignments.", "tgt_ref": "Gli altri tre modelli proposti negli ultimi anni sono tutti allineati automaticamente, il che significa che possono essere soggetti a errori nei loro allineamenti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 11, "src_ref": "Therefore, we propose our new corpus DEPLAIN, which is split into two subcorpora: DEPLAIN-apa and DEPLAIN-web.", "tgt_ref": "Pertanto, proponiamo il nostro nuovo corpus DEPLAIN, che è diviso in due subcorpora: DEPLAIN-apa e DEPLAIN-web."}
{"doc_id": "UOlPKyCVgg", "seg_id": 12, "src_ref": "DEPLAIN-apa is based on news texts.", "tgt_ref": "DEPLAIN-apa si basa su testi di notizie."}
{"doc_id": "UOlPKyCVgg", "seg_id": 13, "src_ref": "In DEPLAIN-apa, we aligned 483 documents all manually.", "tgt_ref": "In DEPLAIN-apa, abbiamo allineato manualmente 483 documenti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 14, "src_ref": "It results in roughly 13,000 parallel sentence pairs.", "tgt_ref": "Il risultato è di circa 13.000 coppie di frasi parallele."}
{"doc_id": "UOlPKyCVgg", "seg_id": 15, "src_ref": "For DEPLAIN-web, this corpus includes different domains and we also align all of these 750 documents, on the one hand manually and on the other hand with automatic alignment methods.", "tgt_ref": "Per quanto riguarda DEPLAIN-web, questo corpus include diversi domini. Allineiamo anche tutti questi 750 documenti, da un lato manualmente e dall'altro con metodi di allineamento automatico."}
{"doc_id": "UOlPKyCVgg", "seg_id": 16, "src_ref": "In total we result in 30,450 sentence pairs.", "tgt_ref": "In totale otteniamo 30.450 coppie di frasi."}
{"doc_id": "UOlPKyCVgg", "seg_id": 17, "src_ref": "We analyzed our sentence pairs a little bit more, so for example, on the type of simplification.", "tgt_ref": "Abbiamo analizzato un po' a fondo le nostre coppie di frasi, ad esempio sul tipo di semplificazione."}
{"doc_id": "UOlPKyCVgg", "seg_id": 18, "src_ref": "As you can see here, the Bible texts are much, stronger simplified than for example the news text, or the language learner texts.", "tgt_ref": "Come potete vedere qui, i testi biblici sono molto più semplificati rispetto, ad esempio, al testo delle notizie o ai testi per studenti di lingue."}
{"doc_id": "UOlPKyCVgg", "seg_id": 19, "src_ref": "On all levels, regarding for example lexical simplification, structure simplification, also overall level of simplification.", "tgt_ref": "A tutti i livelli, per quanto riguarda ad esempio la semplificazione lessicale, la semplificazione strutturale e anche il livello generale di semplificazione."}
{"doc_id": "UOlPKyCVgg", "seg_id": 20, "src_ref": "Furthermore, you can see that our DEPLAIN corpus has a high variety of different simplification transformations.", "tgt_ref": "Inoltre, potete vedere che il nostro corpus DEPLAIN presenta un'elevata varietà di diverse trasformazioni di semplificazione."}
{"doc_id": "UOlPKyCVgg", "seg_id": 21, "src_ref": "So for example, in the DEPLAIN-apa corpus we have much more reorderings and word additions than we have in the DEPLAIN-web corpus.", "tgt_ref": "Ad esempio, nel corpus DEPLAIN-apa abbiamo molti più riordinamenti e aggiunte di parole di quelli che abbiamo nel corpus DEPLAIN-web."}
{"doc_id": "UOlPKyCVgg", "seg_id": 22, "src_ref": "On the other hand, in the web corpus we have much more rephrasings.", "tgt_ref": "D'altra parte, nel corpus web abbiamo molte più riformulazioni."}
{"doc_id": "UOlPKyCVgg", "seg_id": 23, "src_ref": "So let's now see what we can do with this corpus.", "tgt_ref": "Vediamo ora cosa possiamo fare con questo corpus."}
{"doc_id": "UOlPKyCVgg", "seg_id": 24, "src_ref": "Hello, I am Omar and now I will talk about the use cases for our data set DEPLAIN.", "tgt_ref": "Salve, sono Omar e ora parlerò dei casi d'uso per il nostro set di dati DEPLAIN."}
{"doc_id": "UOlPKyCVgg", "seg_id": 25, "src_ref": "So for the first use case, we can evaluate automatic alignment methods.", "tgt_ref": "Per il primo caso d'uso, possiamo valutare i metodi di allineamento automatico."}
{"doc_id": "UOlPKyCVgg", "seg_id": 26, "src_ref": "In the recent years, there has been a lot of alignment methods, but in the context of machine translations, where we have two parallel documents written in different languages and we want to extract alignments of sentences in both documents.", "tgt_ref": "Negli ultimi anni sono stati realizzati molti metodi di allineamento, ma nel contesto delle traduzioni automatiche, abbiamo due documenti paralleli scritti in lingue diverse e intendiamo estrarre allineamenti di frasi in entrambi i documenti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 27, "src_ref": "But in our use case, we are trying to extract alignments between sentences of two parallel documents having the same language, having the same content, but they are on a different complexity level.", "tgt_ref": "Ma nel nostro caso d'uso, stiamo cercando di estrarre gli allineamenti tra le frasi di due documenti paralleli che hanno la stessa lingua, lo stesso contenuto, ma si trovano a un diverso livello di complessità."}
{"doc_id": "UOlPKyCVgg", "seg_id": 28, "src_ref": "And now as we have our data set DEPLAIN, which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods.", "tgt_ref": "E ora che abbiamo il nostro set di dati DEPLAIN con frasi allineate manualmente, possiamo usare queste frasi come allineamenti gold standard per valutare alcuni dei metodi di allineamento proposti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 29, "src_ref": "And we did some adaptations to the proposed methods, and we have published all these adaptations and the codes to run our experiments in the paper.", "tgt_ref": "Abbiamo apportato alcuni adattamenti ai metodi proposti e abbiamo pubblicato nel documento tutti questi adattamenti e i codici per eseguire i nostri esperimenti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 30, "src_ref": "At the end, we concluded that the best automatic alignment method to use for German text simplification is the method of MASSalign.", "tgt_ref": "Infine, siamo giunti alla conclusione che il miglior metodo di allineamento automatico da utilizzare per la semplificazione del testo tedesco è il metodo MASSalign."}
{"doc_id": "UOlPKyCVgg", "seg_id": 31, "src_ref": "And you can also find the code to run this method on your own documents in the paper.", "tgt_ref": "E sui vostri documenti nell'articolo potete anche trovare il codice per eseguire questo metodo."}
{"doc_id": "UOlPKyCVgg", "seg_id": 32, "src_ref": "The second use case that we showed in our paper is a case of automatic text simplification by fine-tuning language models to produce simplified text from the complex input text.", "tgt_ref": "Il secondo caso d'uso che abbiamo mostrato nel nostro articolo è un caso di semplificazione automatica del testo mediante il fine-tuning di modelli linguistici per produrre testo semplificato dal testo di input complesso."}
{"doc_id": "UOlPKyCVgg", "seg_id": 33, "src_ref": "We have fine-tuned two different models.", "tgt_ref": "Abbiamo messo a punto due diversi modelli."}
{"doc_id": "UOlPKyCVgg", "seg_id": 34, "src_ref": "We have fine-tuned the model of long-mBART to produce document-level simplifications, and we also fine-tuned the normal base mBART to produce sentence-level simplifications.", "tgt_ref": "Abbiamo messo a punto il modello long-mBART per produrre semplificazioni a livello di documento e il modello standard mBART per generare semplificazioni a livello di frase."}
{"doc_id": "UOlPKyCVgg", "seg_id": 35, "src_ref": "You can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper.", "tgt_ref": "Nell'articolo potete anche trovare tutti i punti di controllo e approfondire i punteggi e le metriche di valutazione dei nostri esperimenti."}
{"doc_id": "UOlPKyCVgg", "seg_id": 36, "src_ref": "We concluded that this basic fine-tuning could produce or could get scores better than the baseline scores, and we proposed those results as a base benchmark for the problem of automatic text simplification in the future.", "tgt_ref": "Abbiamo concluso che questo fine-tuning semplice potrebbe produrre o ottenere punteggi migliori dei punteggi di base, e abbiamo proposto questi risultati come parametro di riferimento di base per il problema della semplificazione automatica del testo."}
{"doc_id": "UOlPKyCVgg", "seg_id": 37, "src_ref": "Thank you so much for your attention and we hope to meet all of you during the conference.", "tgt_ref": "Grazie mille per l'attenzione e speriamo di incontrarvi tutti durante la conferenza."}
{"doc_id": "UOlPKyCVgg", "seg_id": 38, "src_ref": "Thank you.", "tgt_ref": "Grazie."}
{"doc_id": "wLmrUehthl", "seg_id": 0, "src_ref": "Hi, my name is Adam Przepiórkowski and this talk is about the Dependency Structure of Coordination.", "tgt_ref": "Ciao, mi chiamo Adam Przepiórkowski e questo talk è incentrato sulla struttura di dipendenza della coordinazione."}
{"doc_id": "wLmrUehthl", "seg_id": 1, "src_ref": "As you may know, there are different dependency structures assumed by different theories and corpus approaches.", "tgt_ref": "Come forse saprete, le diverse teorie e gli approcci ai corpus implicano svariate strutture di dipendenza."}
{"doc_id": "wLmrUehthl", "seg_id": 2, "src_ref": "So for example, in the universal dependencies, the structure of the coordination, Lisa, Bart, and Maggie, such that the first conjunct is the head of the whole coordinate structure.", "tgt_ref": "Ad esempio, nelle dipendenze universali, la struttura della coordinazione, Lisa, Bart e Maggie, è tale che il primo congiunto è il capo dell'intera struttura coordinata."}
{"doc_id": "wLmrUehthl", "seg_id": 3, "src_ref": "So in this case, Lisa.", "tgt_ref": "Quindi in questo caso, Lisa."}
{"doc_id": "wLmrUehthl", "seg_id": 4, "src_ref": "A similar approach is assumed in Igor Mel'čuk's meaning text theory, where again, the whole coordinate structure is headed by the first conjuct.", "tgt_ref": "Un approccio simile è assunto nella teoria del testo di significato di Igor Mel'čuk, nella quale l'intera struttura coordinata è ancora una volta guidata dal primo congiunto."}
{"doc_id": "wLmrUehthl", "seg_id": 5, "src_ref": "So these two approaches are asymmetric.", "tgt_ref": "Quindi, questi due approcci sono asimmetrici."}
{"doc_id": "wLmrUehthl", "seg_id": 6, "src_ref": "Right.", "tgt_ref": "Bene."}
{"doc_id": "wLmrUehthl", "seg_id": 7, "src_ref": "They single out one of the conjuncts.", "tgt_ref": "Individuano uno dei congiunti."}
{"doc_id": "wLmrUehthl", "seg_id": 8, "src_ref": "Now those are asymmetric approaches to coordinate structures, such as the Prague approach.", "tgt_ref": "Ora, si tratta di approcci asimmetrici alle strutture coordinate, come l'approccio di Praga."}
{"doc_id": "wLmrUehthl", "seg_id": 9, "src_ref": "The conjunction headed approach assumed in Prague dependency treebanks, where coordinate structures are headed by the conjunction.", "tgt_ref": "L'approccio guidato dalla congiunzione assunto nei treebank di dipendenza di Praga prevede che le strutture coordinate siano guidate dalla congiunzione."}
{"doc_id": "wLmrUehthl", "seg_id": 10, "src_ref": "So, we get some dependencies from end to all the conjuncts.", "tgt_ref": "Quindi, otteniamo alcune dipendenze dalla fine a tutti i congiunti."}
{"doc_id": "wLmrUehthl", "seg_id": 11, "src_ref": "And finally, there's also a multi-headed approach that's used, for example, in the Hudson's Word Grammar, where they say all conjuncts are heads of the coordinate structure.", "tgt_ref": "E infine, è presente anche un approccio multi-testa che viene utilizzato, ad esempio, nella Hudson's Word Grammar, dove dicono che tutti i congiunti sono teste della struttura coordinata."}
{"doc_id": "wLmrUehthl", "seg_id": 12, "src_ref": "So we get dependencies from the governor.", "tgt_ref": "Successivamente, otteniamo dipendenze dal governatore."}
{"doc_id": "wLmrUehthl", "seg_id": 13, "src_ref": "Here loves to all conjuncts separately: Lisa, Bart, and Maggie.", "tgt_ref": "La preferenza è quella di avere i congiunti separati: Lisa, Bart e Maggie."}
{"doc_id": "wLmrUehthl", "seg_id": 14, "src_ref": "Now the aim of this paper is to produce a novel argument for the symmetric structures of coordination, like these two and against the asymmetric structures of coordination, like these two.", "tgt_ref": "Ora, lo scopo di questo articolo è produrre un nuovo argomento per le strutture simmetriche di coordinazione, come queste due, e contro le strutture asimmetriche di coordinazione, come queste due."}
{"doc_id": "wLmrUehthl", "seg_id": 15, "src_ref": "OK.", "tgt_ref": "Bene."}
{"doc_id": "wLmrUehthl", "seg_id": 16, "src_ref": "The argument is based on the principle of dependency length minimization that I will explain on the basis of these examples.", "tgt_ref": "L'argomento si basa sul principio della minimizzazione della lunghezza della dipendenza che spiegherò sulla base di questi esempi."}
{"doc_id": "wLmrUehthl", "seg_id": 17, "src_ref": "So in English, as you might know, direct objects prefer to be close to the verb, while adjuncts may be further away.", "tgt_ref": "Come forse saprete, in inglese gli oggetti diretti preferiscono essere vicini al verbo, mentre gli elementi aggiuntivi possono essere più lontani."}
{"doc_id": "wLmrUehthl", "seg_id": 18, "src_ref": "So \"Marge read it yesterday\" is fine because the direct object is close to the verb, while \"Marge read yesterday it\" is much worse.", "tgt_ref": "Quindi \"Marge read it yesterday\" va bene perché l'oggetto diretto è vicino al verbo, mentre \"Marge read yesterday it\" è decisamente meno accettabile."}
{"doc_id": "wLmrUehthl", "seg_id": 19, "src_ref": "Right?", "tgt_ref": "Giusto?"}
{"doc_id": "wLmrUehthl", "seg_id": 20, "src_ref": "Because here between the verb and the direct object is an adjunct: \"yesterday\".", "tgt_ref": "Perché qui tra il verbo e l'oggetto diretto c'è un elemento aggiuntivo: \"yesterday\"."}
{"doc_id": "wLmrUehthl", "seg_id": 21, "src_ref": "However, this effect may be ameliorated when the direct object is very heavy and very long.", "tgt_ref": "Tuttavia, questo effetto può essere migliorato quando l'oggetto diretto è molto pesante e molto lungo."}
{"doc_id": "wLmrUehthl", "seg_id": 22, "src_ref": "Because then it can be moved to the position after the adjunct.", "tgt_ref": "Perché allora può essere spostato nella posizione dopo l'elemento aggiuntivo."}
{"doc_id": "wLmrUehthl", "seg_id": 23, "src_ref": "This is illustrated here.", "tgt_ref": "Ciò è illustrato qui."}
{"doc_id": "wLmrUehthl", "seg_id": 24, "src_ref": "So both these sentences are fine.", "tgt_ref": "Quindi entrambe queste frasi vanno bene."}
{"doc_id": "wLmrUehthl", "seg_id": 25, "src_ref": "\"Marge read this absolutely fascinating book about bees yesterday.\"", "tgt_ref": "\"Marge read this absolutely fascinating book about bees yesterday\"."}
{"doc_id": "wLmrUehthl", "seg_id": 26, "src_ref": "It's okay the way instead of \"it\", we have this long NP.", "tgt_ref": "Ci sembra accettabile il fatto che, invece di \"it\", abbiamo questo lungo sintagma nominale."}
{"doc_id": "wLmrUehthl", "seg_id": 27, "src_ref": "But it's also OK to say, \"Marge read yesterday this absolutely fascinating book about bees.\"", "tgt_ref": "Ma va bene anche dire: \"Marge read yesterday this absolutely fascinating book about bees\"."}
{"doc_id": "wLmrUehthl", "seg_id": 28, "src_ref": "So the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb, it satisfies the principle of dependency length minimization, which says that shorter dependencies are preferred.", "tgt_ref": "Quindi, il ragionamento qui è che tutto questo è possibile perché anche se questa frase viola il principio grammaticale generale secondo cui gli oggetti diretti dovrebbero essere accanto al verbo, soddisfa il principio di minimizzazione della lunghezza della dipendenza, che afferma che sono preferibili dipendenze più brevi."}
{"doc_id": "wLmrUehthl", "seg_id": 29, "src_ref": "So these two trees only show the length of the crucial dependencies, the ones that are not constant among these two structures.", "tgt_ref": "Di conseguenza, questi due alberi mostrano solo la lunghezza delle dipendenze cruciali, quelle che non sono costanti tra queste due strutture."}
{"doc_id": "wLmrUehthl", "seg_id": 30, "src_ref": "So here we have a dependency from \"read\" to the adjunct of length 7 measured in words and from \"read\" to \"book\" of length 4, so together it's 11.", "tgt_ref": "Qui abbiamo una dipendenza da \"read\" all'elemento aggiuntivo di lunghezza 7 misurato in parole e da \"read\" a \"book\" di lunghezza 4, che insieme danno 11."}
{"doc_id": "wLmrUehthl", "seg_id": 31, "src_ref": "When you swap these two constituents, the sum of these two dependencies becomes 6.", "tgt_ref": "Quando si scambiano questi due costituenti, la somma di queste due dipendenze diventa 6."}
{"doc_id": "wLmrUehthl", "seg_id": 32, "src_ref": "So instead of 11, 6 is much shorter.", "tgt_ref": "Quindi invece di 11, 6 è molto più corto."}
{"doc_id": "wLmrUehthl", "seg_id": 33, "src_ref": "That's why this sounds quite okay.", "tgt_ref": "Ecco perché sembra andare piuttosto bene."}
{"doc_id": "wLmrUehthl", "seg_id": 34, "src_ref": "Right?", "tgt_ref": "Giusto?"}
{"doc_id": "wLmrUehthl", "seg_id": 35, "src_ref": "It violates one principle, but it satisfies another one.", "tgt_ref": "Viola un principio, ma ne soddisfa un altro."}
{"doc_id": "wLmrUehthl", "seg_id": 36, "src_ref": "Ok.", "tgt_ref": "Ok."}
{"doc_id": "wLmrUehthl", "seg_id": 37, "src_ref": "So what we did, we extracted various statistics about coordination from the enhanced version of the Penn Treebank and see the paper \"Why wouldn't you use universal dependencies\" and these statistics confirm the observation made many times before that left conjuncts tend to be shorter.", "tgt_ref": "Quindi, quello che abbiamo fatto è stato estrarre varie statistiche sul coordinamento dalla versione avanzata del Penn Treebank e consultare l'articolo \"Why wouldn't you use universal dependencies\". Queste statistiche confermano l'osservazione fatta molte volte in passato, vale a dire che i congiunti di sinistra tendono a essere più brevi."}
{"doc_id": "wLmrUehthl", "seg_id": 38, "src_ref": "So, \"salt and pepper\" and not \"pepper and salt\", measured in syllables.", "tgt_ref": "Quindi, \"salt and pepper\" e non \"pepper and salt\", misurato in sillabe."}
{"doc_id": "wLmrUehthl", "seg_id": 39, "src_ref": "And, also the observation that was made in parsing that this tendency grows with length difference.", "tgt_ref": "Inoltre, l'osservazione fatta nel corso dell'analisi è che questa tendenza aumenta con la differenza di lunghezza."}
{"doc_id": "wLmrUehthl", "seg_id": 40, "src_ref": "So when the difference between the lengths of the two conjuncts grows, the shorter conjunct prefers to be the first one, stronger, right?", "tgt_ref": "Quindi, quando la differenza tra le lunghezze dei due congiunti cresce, quello più corto preferisce essere il primo, il più forte, giusto?"}
{"doc_id": "wLmrUehthl", "seg_id": 41, "src_ref": "So the proportion is bigger of the left short conjunct.", "tgt_ref": "Dunque la proporzione è maggiore è quella del congiunto corto sinistro."}
{"doc_id": "wLmrUehthl", "seg_id": 42, "src_ref": "But what's novel in this paper is that we observed that this tendency only occurs when the governor is on the left or absent.", "tgt_ref": "Ma la novità di questo articolo è che abbiamo osservato che questa tendenza si verifica solo quando il governatore è a sinistra o è del tutto assente."}
{"doc_id": "wLmrUehthl", "seg_id": 43, "src_ref": "Right?", "tgt_ref": "Giusto?"}
{"doc_id": "wLmrUehthl", "seg_id": 44, "src_ref": "So the governor is on the left in this example \"I saw Bart and Lisa\" so is the governor is on the left.", "tgt_ref": "Quindi, il governatore è sulla sinistra in questo esempio \"I saw Bart and Lisa\", quindi il governatore è sulla sinistra."}
{"doc_id": "wLmrUehthl", "seg_id": 45, "src_ref": "It's absent in the second example \"Homer came and sneezed.\"", "tgt_ref": "È assente nel secondo esempio \"Homer came and sneezed\"."}
{"doc_id": "wLmrUehthl", "seg_id": 46, "src_ref": "Here we have coordination of two verbs and there's no outsides, external governor.", "tgt_ref": "Qui ci troviamo di fronte alla coordinazione di due verbi e non c'è nessun governatore esterno."}
{"doc_id": "wLmrUehthl", "seg_id": 47, "src_ref": "In such cases, the left conjunct prefers to be shorter; the most of the biggest difference between the two conjuncts.", "tgt_ref": "In questi casi, il congiunto sinistro preferisce essere più corto; ecco dov'è gran parte della differenza tra i due congiunti."}
{"doc_id": "wLmrUehthl", "seg_id": 48, "src_ref": "However, when the governor is on the right, as here, \"laughed\" governs the coordination Ted and Ned, this effect disappears.", "tgt_ref": "Tuttavia, quando il governatore è sulla destra, come in questa circostanza, e \"laughed\" governa la coordinazione Ted e Ned, questo effetto scompare."}
{"doc_id": "wLmrUehthl", "seg_id": 49, "src_ref": "So we showed that by measuring length in characters, the first column, in syllables the middle column, and in words the right column.", "tgt_ref": "Quindi, abbiamo dimostrato che la lunghezza viene misurata in caratteri, la prima colonna, in sillabe la colonna centrale e in parole la colonna di destra."}
{"doc_id": "wLmrUehthl", "seg_id": 50, "src_ref": "So I'll concentrate on the right one.", "tgt_ref": "Ora mi concentrerò su quella di destra."}
{"doc_id": "wLmrUehthl", "seg_id": 51, "src_ref": "What we see here is that when the governor is on the left, the tendency for the left conjunct to be shorter grows steadily, with the absolute difference in words, and the same is observed when there is no governor as in coordination of sentences.", "tgt_ref": "Quello che vediamo qui è che quando il governatore è a sinistra, la tendenza del congiunto sinistro a essere più corto cresce costantemente, con la differenza assoluta in parole, e lo stesso si osserva quando non c'è alcun governatore come nella coordinazione delle frasi."}
{"doc_id": "wLmrUehthl", "seg_id": 52, "src_ref": "But when the governor is on the right this tendency disappears.", "tgt_ref": "Ma quando il governatore è a destra, questa tendenza viene meno."}
{"doc_id": "wLmrUehthl", "seg_id": 53, "src_ref": "And we show in the paper how this provides an argument against asymmetric structures of coordination, as these two, and for the symmetric structures, as these two.", "tgt_ref": "Nell'articolo mostriamo come tutto ciò rappresenti una tesi contro le strutture asimmetriche di coordinazione, come queste due, e a favore delle strutture simmetriche, come queste due."}
{"doc_id": "wLmrUehthl", "seg_id": 54, "src_ref": "So see the paper for the full arguments.", "tgt_ref": "Siete invitati a consultare l'articolo per gli argomenti completi."}
{"doc_id": "wLmrUehthl", "seg_id": 55, "src_ref": "And talk to us about at the poster session.", "tgt_ref": "Per poi parlarne alla sessione poster."}
{"doc_id": "wLmrUehthl", "seg_id": 56, "src_ref": "Thank you.", "tgt_ref": "Grazie."}
{"doc_id": "eXmqPhcZFN", "seg_id": 0, "src_ref": "Hi, I'm Shangbin, PhD student in the University of Washington.", "tgt_ref": "Ciao, sono Shangbin, studente di dottorato presso l'Università di Washington."}
{"doc_id": "eXmqPhcZFN", "seg_id": 1, "src_ref": "Today I'm presenting our work \"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models\".", "tgt_ref": "Oggi presento il nostro lavoro \"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models\"."}
{"doc_id": "eXmqPhcZFN", "seg_id": 2, "src_ref": "So language models are trained on large scale web crawl data.", "tgt_ref": "I modelli linguistici sono addestrati su dati di scansione web su larga scala."}
{"doc_id": "eXmqPhcZFN", "seg_id": 3, "src_ref": "Political news media are well covered in their pretraining data.", "tgt_ref": "I mezzi di informazione politici sono ben rappresentati nei rispettivi dati di pre-addestramento."}
{"doc_id": "eXmqPhcZFN", "seg_id": 4, "src_ref": "According to a survey of the C4 Corpus, we can see that New York Times, Los Angeles Times, The Guardian, Huffington Post, etcetera are well covered in language model training data.", "tgt_ref": "Secondo un sondaggio del C4 Corpus, possiamo vedere che New York Times, Los Angeles Times, The Guardian, Huffington Post, ecc. sono ben rappresentati nei dati di addestramento del modello linguistico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 5, "src_ref": "This has created a mixed blessing for language model applications.", "tgt_ref": "Ciò ha creato un vantaggio misto per le applicazioni del modello linguistico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 6, "src_ref": "So on one hand, they were able to learn from diverse perspectives, which celebrates democracy and the plurality of ideas.", "tgt_ref": "Da un lato, hanno dimostrato la capacità di apprendere da diverse prospettive, il che onora la democrazia e la pluralità di idee."}
{"doc_id": "eXmqPhcZFN", "seg_id": 7, "src_ref": "On the other hand, these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications.", "tgt_ref": "Dall'altro, queste diverse opinioni politiche sono intrinsecamente distorte dal punto di vista sociale e potrebbero condurre a potenziali problemi di equità nelle applicazioni di attività a valle."}
{"doc_id": "eXmqPhcZFN", "seg_id": 8, "src_ref": "To this end, we propose to investigate the political bias propagation pipeline from pretraining data to language models to downstream tasks, specifically by asking the following questions: First, how do we evaluate the political leaning of language models and what role does pretraining data might have on such political biases?", "tgt_ref": "A tal fine, proponiamo di indagare l'infrastruttura di propagazione dei bias politici dai dati di pre-addestramento ai modelli linguistici, fino alle attività a valle, ponendo in particolare le seguenti domande: in primo luogo, come valutiamo l'inclinazione politica dei modelli linguistici e quale ruolo potrebbero avere i dati di pre-addestramento su tali bias politici?"}
{"doc_id": "eXmqPhcZFN", "seg_id": 9, "src_ref": "Secondly, how do language models with different political leanings actually perform on downstream tasks and whether that might result in fairness issues in NLP applications?", "tgt_ref": "In secondo luogo, come si comportano effettivamente i modelli linguistici con diverse inclinazioni politiche nelle attività a valle e se ciò potrebbe comportare problemi di equità nelle applicazioni NLP?"}
{"doc_id": "eXmqPhcZFN", "seg_id": 10, "src_ref": "So specifically, we first proposed to prompt language models with different prompt formats using the political questionnaires such as the political conference test.", "tgt_ref": "In particolare, abbiamo proposto di sollecitare i modelli linguistici con diversi formati di prompt utilizzando i questionari politici come il test della conferenza politica."}
{"doc_id": "eXmqPhcZFN", "seg_id": 11, "src_ref": "This ensures us to do automatic evaluation well grounded in political science literature.", "tgt_ref": "Questo ci permette di effettuare una valutazione automatica ben fondata nella letteratura delle scienze politiche."}
{"doc_id": "eXmqPhcZFN", "seg_id": 12, "src_ref": "So some preliminary results demonstrate that first, language models do have varying political leanings.", "tgt_ref": "Alcuni risultati preliminari dimostrano che, in primo luogo, i modelli linguistici hanno diverse inclinazioni politiche."}
{"doc_id": "eXmqPhcZFN", "seg_id": 13, "src_ref": "They occupy all four quadrants on the political campus.", "tgt_ref": "Occupano tutti e quattro i quadranti del campus politico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 14, "src_ref": "We can also see that GPT-4 is the most liberal language model of them all, and GPT series are generally more socially liberal than BART series and its variants.", "tgt_ref": "Possiamo anche vedere che GPT-4 è il modello linguistico più liberale di tutti, e la serie GPT è generalmente più liberale dal punto di vista sociale rispetto alla serie BART e alle sue varianti."}
{"doc_id": "eXmqPhcZFN", "seg_id": 15, "src_ref": "Secondly, we aim to investigate to which extent the political biases of language models are actually picked up from training data.", "tgt_ref": "In secondo luogo, miriamo a indagare fino a che punto i pregiudizi politici dei modelli linguistici vengono effettivamente raccolti dai dati di addestramento."}
{"doc_id": "eXmqPhcZFN", "seg_id": 16, "src_ref": "So we could conduct a controlled experiment by further pretraining language model checkpoints on 6 different partisan corpora separated into news and social media, further divided into their political leaning.", "tgt_ref": "Quindi, potremmo condurre un esperimento controllato pre-addestrando ulteriormente i checkpoint del modello linguistico su 6 diversi corpora di parte suddivisi in notizie e social media, a loro volta suddivisi in base alla loro inclinazione politica."}
{"doc_id": "eXmqPhcZFN", "seg_id": 17, "src_ref": "By further pretraining language models on such partisan corpora we can see that the ideological coordinates of the language model also correspondingly shift.", "tgt_ref": "Pre-addestrando ulteriormente i modelli linguistici su tali corpora di parte, possiamo vedere che, di conseguenza, anche le coordinate ideologiche del modello linguistico si spostano."}
{"doc_id": "eXmqPhcZFN", "seg_id": 18, "src_ref": "For example, for RoBERTa further trained on the left-leaning Reddit corpus we can see a substantial liberal shift in terms of its political biases.", "tgt_ref": "Ad esempio, per RoBERTa, ulteriormente addestrato su Reddit, corpus con una particolare inclinazione verso sinistra, possiamo vedere un sostanziale spostamento liberale in termini di bias politici."}
{"doc_id": "eXmqPhcZFN", "seg_id": 19, "src_ref": "And we also try to investigate whether language models can pick up the polarisation that's prevalent in our modern society.", "tgt_ref": "Inoltre, cerchiamo di indagare se i modelli linguistici sono in grado di cogliere la polarizzazione prevalente nella nostra società moderna."}
{"doc_id": "eXmqPhcZFN", "seg_id": 20, "src_ref": "So we divide pretraining corpora, into pre 45th president of the United States and after 45th president of the United States.", "tgt_ref": "Successivamente, dividiamo i corpora di pre-addestramento prima del 45° presidente degli Stati Uniti e dopo il 45° presidente degli Stati Uniti."}
{"doc_id": "eXmqPhcZFN", "seg_id": 21, "src_ref": "We separately pretrain language models on the two different temporal corpora.", "tgt_ref": "Pre-addestriamo separatamente i modelli linguistici sui due diversi corpora temporali."}
{"doc_id": "eXmqPhcZFN", "seg_id": 22, "src_ref": "We can see that language models generally had a political leaning that is further away from the centre after 2017.", "tgt_ref": "Possiamo vedere che i modelli linguistici presentano generalmente un orientamento politico più lontano dal centro a partire dal 2017."}
{"doc_id": "eXmqPhcZFN", "seg_id": 23, "src_ref": "So this indicates that language models can also pick up the polarisation in our society.", "tgt_ref": "Quindi, questo indica che i modelli linguistici possono cogliere anche la polarizzazione nella nostra società."}
{"doc_id": "eXmqPhcZFN", "seg_id": 24, "src_ref": "So last but not least, we evaluate language models with different political leanings on hate speech detection and fake news detection to NLP applications that often involve language models and could have very significant implications.", "tgt_ref": "Ultimo ma non meno importante, valutiamo i modelli linguistici con diverse inclinazioni politiche sul rilevamento dell'incitamento all'odio e sul rilevamento delle notizie false per quelle applicazioni NLP che spesso coinvolgono modelli linguistici e potrebbero avere implicazioni molto significative."}
{"doc_id": "eXmqPhcZFN", "seg_id": 25, "src_ref": "So we see that if we investigate the per category performance, that is to say if we separate the performance into different demographics or political leaning of news media we can see a pattern.", "tgt_ref": "Quindi, notiamo che, se indaghiamo le prestazioni per categoria, cioè se separiamo le prestazioni in diversi dati demografici o orientamento politico dei media, possiamo scorgere un modello."}
{"doc_id": "eXmqPhcZFN", "seg_id": 26, "src_ref": "For example, for hate speech detection, left-leaning language models are better at detecting hate speech targeting socially minority groups, however are worse at detecting hate speech targeting more powerful groups in our society.", "tgt_ref": "Ad esempio, per il rilevamento dell'incitamento all'odio, i modelli linguistici di sinistra si rivelano migliori nel rilevare l'incitamento all'odio rivolto a gruppi socialmente minoritari, ma sono peggiori nel rilevare l'incitamento all'odio rivolto a gruppi più potenti nella nostra società."}
{"doc_id": "eXmqPhcZFN", "seg_id": 27, "src_ref": "And vice versa, right-leaning language models are better at detecting hate speech targeting white and men, however worse at detecting hate speech targeting at black LGBTQ plus and other minority communities.", "tgt_ref": "E viceversa, i modelli linguistici di destra sono più efficaci nel rilevare l'incitamento all'odio rivolto a bianchi e uomini, ma peggiori nel rilevare l'incitamento all'odio rivolto a neri, membri della comunità LGBTQ plus e altre comunità minoritarie."}
{"doc_id": "eXmqPhcZFN", "seg_id": 28, "src_ref": "Similar trends also happen for fake news detection, where we see that left-leaning language models are better at detecting misinformation from their opposite political leaning and vice versa.", "tgt_ref": "Tendenze simili si verificano anche per il rilevamento di notizie false, dove vediamo che i modelli linguistici di sinistra dimostrano maggiore efficacia nel rilevare la disinformazione dal loro orientamento politico opposto e viceversa."}
{"doc_id": "eXmqPhcZFN", "seg_id": 29, "src_ref": "We further show many qualitative examples to see that language models with different political leanings do give different predictions to hate speech and misinformation examples based on their social categories.", "tgt_ref": "Inoltre, illustriamo svariati esempi qualitativi per provare che i modelli linguistici con diverse inclinazioni politiche offrono previsioni diverse sugli esempi di incitamento all'odio e disinformazione in base alle loro categorie sociali."}
{"doc_id": "eXmqPhcZFN", "seg_id": 30, "src_ref": "There are a bunch of more examples in the appendix to further highlight that this indicates that there is a fairness issue that is very pressing regarding the political biases of language models.", "tgt_ref": "Ci sono molti altri esempi nell'appendice che evidenziano come tutto questo indichi la presenza di un problema di equità molto pressante riguardo ai pregiudizi politici insiti nei modelli linguistici."}
{"doc_id": "eXmqPhcZFN", "seg_id": 31, "src_ref": "For example, if right-leaning language models were to be fine-tuned on hate speech or misinformation or whatever and deployed to a popular social media platform, this would mean that, people with opposite political opinions might be marginalised and hate speech targeting minority groups might just run rampant without any control.", "tgt_ref": "Ad esempio, se i modelli linguistici di destra dovessero essere messi a punto su incitamento all'odio o disinformazione o altro e distribuiti su una popolare piattaforma di social media, questo significherebbe che le persone con opinioni politiche opposte potrebbero essere emarginate e l'incitamento all'odio nei confronti di gruppi minoritari potrebbe facilmente dilagare senza alcun controllo."}
{"doc_id": "eXmqPhcZFN", "seg_id": 32, "src_ref": "So this has sound the alarm for us to acknowledge and tackle the fairness issues resulting by language model political leanings.", "tgt_ref": "Quindi, ecco cosa ha fatto scattare l'allarme affinché riuscissimo a riconoscere e affrontare i problemi di equità derivanti dalle inclinazioni politiche del modello linguistico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 33, "src_ref": "So a little bit of discussion.", "tgt_ref": "Potremmo cogliere l'occasione per discuterne."}
{"doc_id": "eXmqPhcZFN", "seg_id": 34, "src_ref": "We would also like to highlight that we expose the unique dilemma regarding language model political biases.", "tgt_ref": "Vorremmo inoltre mettere in evidenza il fatto che affrontiamo il dilemma riguardante i pregiudizi politici del modello linguistico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 35, "src_ref": "It's like between Scylla and Charybdis.", "tgt_ref": "È un po' come la questione tra Scilla e Cariddi."}
{"doc_id": "eXmqPhcZFN", "seg_id": 36, "src_ref": "So if we do not sanitize political opinions in language model training data, the bias would propagate from pretraining data to language models to downstream tasks, ultimately creating fairness issues.", "tgt_ref": "Quindi, se non \"sanifichiamo\" le opinioni politiche nei dati di addestramento del modello linguistico, il bias si propagherebbe dai dati di pre-addestramento ai modelli linguistici, fino alle attività a valle, finendo per creare problemi di equità."}
{"doc_id": "eXmqPhcZFN", "seg_id": 37, "src_ref": "If we do try to sanitaze somehow, we would also risk censorship, or exclusion.", "tgt_ref": "Se, invece, provassimo a sanificare il tutto, rischieremmo la censura o l'esclusione."}
{"doc_id": "eXmqPhcZFN", "seg_id": 38, "src_ref": "And it's incredibly hard to determine what is actually neutral and should be retaining language monitoring data.", "tgt_ref": "Ed è incredibilmente difficile determinare cosa sia effettivamente neutrale e debba conservare i dati di monitoraggio del linguaggio."}
{"doc_id": "eXmqPhcZFN", "seg_id": 39, "src_ref": "So it's kind of like the electric trolley problem.", "tgt_ref": "È un po' come il problema del tram elettrico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 40, "src_ref": "Ok, great.", "tgt_ref": "Ok, fantastico."}
{"doc_id": "eXmqPhcZFN", "seg_id": 41, "src_ref": "I think that's pretty much all I have for today.", "tgt_ref": "Penso che sia tutto per oggi."}
{"doc_id": "eXmqPhcZFN", "seg_id": 42, "src_ref": "Thank you for your time.", "tgt_ref": "Grazie per il tempo che ci avete dedicato."}
{"doc_id": "xiSxNRoOzm", "seg_id": 0, "src_ref": "Hi everyone.", "tgt_ref": "Ciao a tutti."}
{"doc_id": "xiSxNRoOzm", "seg_id": 1, "src_ref": "I'm Jenny, a first year PhD student at Carnegie Mellon University and today I'll be presenting your work NLPositionality characterising design biases of datasets and Models.", "tgt_ref": "Sono Jenny, studente al primo anno di dottorato alla Carnegie Mellon University e oggi presenterò il lavoro NLPositionality che caratterizza i pregiudizi di progettazione di set di dati e modelli."}
{"doc_id": "xiSxNRoOzm", "seg_id": 2, "src_ref": "This work was done in collaboration with some folks at the University of Washington and the Allen Institute for AI, namely Sebastian Santy, Ronan Le Bras, Katharina Reinecke and Maarten Sap.", "tgt_ref": "Questo lavoro è stato svolto in collaborazione con alcuni membri dell'Università di Washington e dell'Allen Institute for AI, in particolare Sebastian Santy, Ronan Le Bras, Katharina Reinecke e Maarten Sap."}
{"doc_id": "xiSxNRoOzm", "seg_id": 3, "src_ref": "So let's start off by imagining that you're working for a newspaper and you're sifting through comments under your news article trying to remove toxic content.", "tgt_ref": "Quindi, iniziamo immaginando che stiate lavorando per un giornale e stiate setacciando i commenti sotto il vostro articolo di notizie con l'obiettivo di rimuovere i contenuti tossici."}
{"doc_id": "xiSxNRoOzm", "seg_id": 4, "src_ref": "You might turn towards a popular API like Prospective API for toxicity detection, and this works really well if you're Carl Jones.", "tgt_ref": "Potreste rivolgervi a un'API popolare come Prospective API per il rilevamento della tossicità, e questo funziona davvero bene se siete Carl Jones."}
{"doc_id": "xiSxNRoOzm", "seg_id": 5, "src_ref": "Where prospective API is able to detect correctly toxic instances.", "tgt_ref": "Dove l'API Prospective è in grado di rilevare correttamente le istanze tossiche."}
{"doc_id": "xiSxNRoOzm", "seg_id": 6, "src_ref": "But that's not really the case for Aditya Sharma.", "tgt_ref": "Ma questo non è esattamente il caso di Aditya Sharma."}
{"doc_id": "xiSxNRoOzm", "seg_id": 7, "src_ref": "Where prospective AP is really not as sensitive to offensive terms that are more common in Indian contexts.", "tgt_ref": "Dove Prospective API non è così sensibile ai termini offensivi che sono più comuni nei contesti indiani."}
{"doc_id": "xiSxNRoOzm", "seg_id": 8, "src_ref": "This is an example of a design bias where we see systematic performance differences of technology between populations.", "tgt_ref": "Questo è un esempio di pregiudizio progettuale in cui osserviamo differenze sistematiche nelle prestazioni della tecnologia tra le popolazioni."}
{"doc_id": "xiSxNRoOzm", "seg_id": 9, "src_ref": "Design biases like the one that we just saw before might occur due to the positionality of the NLP researchers and model developers.", "tgt_ref": "Pregiudizi di progettazione come quello che abbiamo appena visto potrebbero verificarsi a causa della posizionalità dei ricercatori di NLP e degli sviluppatori di modelli."}
{"doc_id": "xiSxNRoOzm", "seg_id": 10, "src_ref": "Positionality is simply the perspectives that people hold as a result of their demographics, identity, and life experiences.", "tgt_ref": "La posizionalità corrisponde semplicemente alle prospettive che le persone hanno in base ai loro dati demografici, alla loro identità e alle loro esperienze di vita."}
{"doc_id": "xiSxNRoOzm", "seg_id": 11, "src_ref": "This is a concept widely used in critical studies, specifically in feminist and queer academic spaces.", "tgt_ref": "Questo è un concetto ampiamente utilizzato negli studi critici, in particolare negli spazi accademici femministi e queer."}
{"doc_id": "xiSxNRoOzm", "seg_id": 12, "src_ref": "And as a researcher, positionality can influence the research process and its outcomes and results because it can change the decisions that researchers make.", "tgt_ref": "E come ricercatore, la posizionalità può influenzare il processo di ricerca e i suoi esiti e risultati, in quanto può cambiare le decisioni che prendono i ricercatori."}
{"doc_id": "xiSxNRoOzm", "seg_id": 13, "src_ref": "And so one question that people might ask is, do datasets and models have positionality?", "tgt_ref": "Quindi, una domanda che le persone potrebbero porsi è la seguente: i set di dati e i modelli hanno una posizionalità?"}
{"doc_id": "xiSxNRoOzm", "seg_id": 14, "src_ref": "And we're not trying to say that models themselves in data sets themselves have demographic identities and life experiences, but they do aggregate judgments and opinions of real people, and can thus represent certain positionalities over others.", "tgt_ref": "E non stiamo cercando di dire che i modelli negli insiemi di dati stessi abbiano identità demografiche ed esperienze di vita, ma raccolgono giudizi e opinioni di persone reali e possono quindi rappresentare alcune posizioni rispetto ad altre."}
{"doc_id": "xiSxNRoOzm", "seg_id": 15, "src_ref": "So prior work has suggested some anecdotal evidence of having positionality, such as cultural gaps and models and data sets, as well as theoretical definitions of model positionality.", "tgt_ref": "Pertanto, il lavoro precedente ha suggerito alcune prove aneddotiche di posizionalità, come lacune culturali, modelli, set di dati e definizioni teoriche di posizionalità del modello."}
{"doc_id": "xiSxNRoOzm", "seg_id": 16, "src_ref": "However these works really don't look at comparing end users with the datasets and models themselves, and studying model and data set positionality is increasingly important as NLP tasks become more subjective and socially oriented, and it's challenging to characterise how these positionalities are skewed because not all decisions are documented and many models are hidden behind APIs.", "tgt_ref": "Tuttavia, questi lavori non guardano al confronto degli utenti finali con i set di dati e i modelli stessi, e lo studio della posizionalità del modello e del set di dati è sempre più importante man mano che le attività di NLP diventano più soggettive e socialmente orientate. Ne consegue che è difficile spiegare il motivo per cui queste posizionalità sono distorte, perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro le API."}
{"doc_id": "xiSxNRoOzm", "seg_id": 17, "src_ref": "So to study data set and model positionality, we actually compare the annotations with real users with existing datasets and models.", "tgt_ref": "Quindi, per studiare il set di dati e la posizionalità del modello, confrontiamo effettivamente le annotazioni da parte di utenti reali con set di dati e modelli esistenti."}
{"doc_id": "xiSxNRoOzm", "seg_id": 18, "src_ref": "We do this through our framework NLPositionality.", "tgt_ref": "Lo facciamo attraverso il nostro framework NLPositionality."}
{"doc_id": "xiSxNRoOzm", "seg_id": 19, "src_ref": "Our framework works in two main steps.", "tgt_ref": "Il nostro framework funziona in due fasi principali."}
{"doc_id": "xiSxNRoOzm", "seg_id": 20, "src_ref": "The first step is to re annotate data sets with diverse annotators.", "tgt_ref": "La prima è quella di riannotare i set di dati con diversi annotatori."}
{"doc_id": "xiSxNRoOzm", "seg_id": 21, "src_ref": "And we ought to do this over looking at the demographics of original data sets annotators, because, usually only a few annotators annotate each instance and because demographics are rarely collected and shared.", "tgt_ref": "Per procedere in tal senso, dovremmo osservare i dati demografici degli annotatori dei set di dati originali, perché, di solito, solo pochi annotatori annotano ogni istanza e perché i dati demografici vengono raccolti e condivisi solo di rado."}
{"doc_id": "xiSxNRoOzm", "seg_id": 22, "src_ref": "And so we opt to re annotate data to get many annotates for instance and to get a rich set of demographic data.", "tgt_ref": "E così scegliamo di riannotare i dati per ottenere, ad esempio, svariate annotazioni e per ottenere un ricco set di dati demografici."}
{"doc_id": "xiSxNRoOzm", "seg_id": 23, "src_ref": "We then take the annotations by demographic and compare them to the models and datasets using a Pearson's R correlation score, and thus our framework actually differs from annotator disagreement literature by comparing end users with models and datasets, predictions and labels, as opposed to looking at just annotator agreement or modelling annotator distributions.", "tgt_ref": "Quindi, prendiamo le annotazioni in base alle informazioni demografiche e le confrontiamo con i modelli e i set di dati utilizzando un punteggio di correlazione R di Pearson. Così facendo, il nostro framework differisce dalla letteratura sul disaccordo degli annotatori confrontando gli utenti finali con modelli e set di dati, previsioni ed etichette, anziché prendere in considerazione solo l'accordo degli annotatori o modellare le distribuzioni dei suddetti."}
{"doc_id": "xiSxNRoOzm", "seg_id": 24, "src_ref": "Our frame is largely enabled through Lab in the Wild and online crowdsourcing platform for where HCI collaborator.", "tgt_ref": "Il nostro quadro è in gran parte supportato da Lab in the Wild e dalla piattaforma di crowdsourcing online per il collaboratore HCI."}
{"doc_id": "xiSxNRoOzm", "seg_id": 25, "src_ref": "In Live in the Wild is an online experimentation platform where we can recruit divers volunteers.", "tgt_ref": "In Live in the Wild è una piattaforma di sperimentazione online dove possiamo reclutare diversi volontari."}
{"doc_id": "xiSxNRoOzm", "seg_id": 26, "src_ref": "Compared to the platforms like M Turk which largely have participants from the US or India and further Lab in the Wild still is able to get high quality data.", "tgt_ref": "Rispetto alle piattaforme come M Turk, che hanno in gran parte partecipanti dagli Stati Uniti o dall'India e oltre, Lab in the Wild è ancora in grado di acquisire dati di alta qualità."}
{"doc_id": "xiSxNRoOzm", "seg_id": 27, "src_ref": "We host 2 tasks on lab in the wild, one of them being social acceptability, and the way this works is that participants will read a situation from the social chemistry dataset and, then they'll write how socially acceptable a situation is.", "tgt_ref": "Ospitiamo due attività su Lab in the Wild, una delle quali è l'accettabilità sociale, e il modo in cui funziona è che i partecipanti leggeranno una situazione dal set di dati di chimica sociale e poi scriveranno quanto sia socialmente accettabile una determinata situazione."}
{"doc_id": "xiSxNRoOzm", "seg_id": 28, "src_ref": "Afterwards to stay engaged in the study, they can compare their responses to an AI and others.", "tgt_ref": "Successivamente, per rimanere coinvolti nello studio, possono confrontare le loro risposte con un'IA e gli altri."}
{"doc_id": "xiSxNRoOzm", "seg_id": 29, "src_ref": "We've then compared these, annotations with Social Chemistry, Delphi and GPT 4.", "tgt_ref": "Abbiamo quindi confrontato queste annotazioni con Social Chemistry, Delphi e GPT 4."}
{"doc_id": "xiSxNRoOzm", "seg_id": 30, "src_ref": "We then replicate a very similar setup for the toxicity and hate speech detection task, where they'll read an instance from Dynahate and write whether they think it's instance of hate speech.", "tgt_ref": "Replichiamo quindi una configurazione molto simile per l'attività di rilevamento della tossicità e dell'incitamento all'odio, in cui leggeranno un'istanza da Dynahate e scriveranno se ritengono che si tratti di un'istanza di incitamento all'odio."}
{"doc_id": "xiSxNRoOzm", "seg_id": 31, "src_ref": "We then compared these annotations with Dynahate, Perspective API, Rewire API, Hate Roberta and GPT 4.", "tgt_ref": "Abbiamo quindi confrontato queste annotazioni con Dynahate, Perspective API, Rewire API, Hate Roberta e GPT 4."}
{"doc_id": "xiSxNRoOzm", "seg_id": 32, "src_ref": "Our study in the end amassed over 16,000 annotations from over 1000 annotators from 87 countries.", "tgt_ref": "Il nostro studio alla fine ha raccolto oltre 16.000 annotazioni da oltre 1.000 annotatori provenienti da 87 Paesi."}
{"doc_id": "xiSxNRoOzm", "seg_id": 33, "src_ref": "So now we're better equipped to answer who do NLP datasets and models align with the most.", "tgt_ref": "Quindi, ora siamo in grado di rispondere meglio a chi e cosa si allinea maggiormente con i set di dati e i modelli NLP."}
{"doc_id": "xiSxNRoOzm", "seg_id": 34, "src_ref": "We find that there is positionality in NLP.", "tgt_ref": "Scopriamo che c'è posizionalità nell'NLP."}
{"doc_id": "xiSxNRoOzm", "seg_id": 35, "src_ref": "For example, we find that data sets and models are most aligned to English speaking countries.", "tgt_ref": "Ad esempio, rileviamo che i set di dati e i modelli sono più allineati ai Paesi anglofoni."}
{"doc_id": "xiSxNRoOzm", "seg_id": 36, "src_ref": "So for the GPT 4 social acceptability analysis, we find that it's most aligned to confucian and English speaking countries.", "tgt_ref": "Quindi, relativamente all'analisi di accettabilità sociale di GPT 4, scopriamo che è più allineato ai Paesi influenzati dal confucianesimo e quelli anglofoni."}
{"doc_id": "xiSxNRoOzm", "seg_id": 37, "src_ref": "We find that Dynahate is also most aligned to English speaking countries.", "tgt_ref": "Scopriamo che anche Dynahate è maggiormente allineato ai Paesi di lingua inglese."}
{"doc_id": "xiSxNRoOzm", "seg_id": 38, "src_ref": "We also find most additional alignment with people who have a college education.", "tgt_ref": "Riscontriamo, inoltre, un maggiore allineamento alle persone che hanno un'istruzione universitaria."}
{"doc_id": "xiSxNRoOzm", "seg_id": 39, "src_ref": "So for GPT 4, in the social acceptability task, we find that it's most aligned to people with a college education or Graduate School education and we find the same for Dynahate where it's most aligned to people with a college education.", "tgt_ref": "Quindi, per GPT 4, nell'attività di accettabilità sociale, scopriamo che è più allineato alle persone con un'istruzione universitaria o con un'istruzione post-laurea, e lo stesso vale per Dynahate, anch'esso più allineato alle persone con un'istruzione universitaria."}
{"doc_id": "xiSxNRoOzm", "seg_id": 40, "src_ref": "However, when models and data sets are aligned to specific populations, some are inevitably left behind.", "tgt_ref": "Tuttavia, quando i modelli e i set di dati sono allineati a popolazioni specifiche, alcuni vengono inevitabilmente abbandonati."}
{"doc_id": "xiSxNRoOzm", "seg_id": 41, "src_ref": "An example of this is that datasets and models are less aligned to non binary people compared to the men and women counterparts.", "tgt_ref": "Un esempio di ciò è che i set di dati e i modelli sono meno allineati alle persone non binarie rispetto alle controparti maschili e femminili."}
{"doc_id": "xiSxNRoOzm", "seg_id": 42, "src_ref": "We find this in the GPT 4 social acceptability task as well as the Dynahate task analysis as well.", "tgt_ref": "Lo riscontriamo nell'attività di accettabilità sociale di GPT 4 e anche nell'analisi delle attività di Dynahate."}
{"doc_id": "xiSxNRoOzm", "seg_id": 43, "src_ref": "So, given that there is positionality in NLP, what can we do about it?", "tgt_ref": "Quindi, dato che c'è posizionalità nell'NLP, cosa possiamo fare al riguardo?"}
{"doc_id": "xiSxNRoOzm", "seg_id": 44, "src_ref": "So we have a few recommendations for this.", "tgt_ref": "Abbiamo alcune raccomandazioni in merito."}
{"doc_id": "xiSxNRoOzm", "seg_id": 45, "src_ref": "First one is keep a record of all relevant design choices throughout the research process.", "tgt_ref": "La prima è tenere traccia di tutte le scelte di progettazione rilevanti durante il processo di ricerca."}
{"doc_id": "xiSxNRoOzm", "seg_id": 46, "src_ref": "And the other is to do NLP research with the lens of perspectivism.", "tgt_ref": "E l'altra è fare ricerca NLP con la lente del prospettivismo."}
{"doc_id": "xiSxNRoOzm", "seg_id": 47, "src_ref": "Our third recommendation is to build specialised datasets and models within 4 specific communities.", "tgt_ref": "La nostra terza raccomandazione è quella di costruire set di dati e modelli specializzati all'interno di 4 community specifiche."}
{"doc_id": "xiSxNRoOzm", "seg_id": 48, "src_ref": "And a good example of this is the Masakhani initiative.", "tgt_ref": "E un buon esempio di ciò è l'iniziativa Masakhani."}
{"doc_id": "xiSxNRoOzm", "seg_id": 49, "src_ref": "I mean, we want to emphasise that inclusive NLP isn't just making.", "tgt_ref": "Vogliamo sottolineare che l'NLP inclusivo non si limita alla sola creazione."}
{"doc_id": "xiSxNRoOzm", "seg_id": 50, "src_ref": "You know, all technologies work for everyone.", "tgt_ref": "Sapete, tutte le tecnologie funzionano per tutti."}
{"doc_id": "xiSxNRoOzm", "seg_id": 51, "src_ref": "And so that concludes our presentation.", "tgt_ref": "E con questo termina la nostra presentazione."}
{"doc_id": "xiSxNRoOzm", "seg_id": 52, "src_ref": "But if you'd like to learn more, feel free to check out our dashboard for the most updated analysis results and our paper.", "tgt_ref": "In ogni caso, se volete saperne di più, non esitate a consultare la nostra dashboard per i risultati delle analisi più aggiornati e il nostro articolo."}
{"doc_id": "xiSxNRoOzm", "seg_id": 53, "src_ref": "Thank you.", "tgt_ref": "Grazie."}
{"doc_id": "crgYiwKDfX", "seg_id": 0, "src_ref": "Hi, I'm Siyu Yuan from Fudan University.", "tgt_ref": "Ciao, sono Siyu Yuan della Fudan University."}
{"doc_id": "crgYiwKDfX", "seg_id": 1, "src_ref": "I'm here to introduce our work \"Distilling Script Knowledge from Large Language Models for Constrained Language Planning\".", "tgt_ref": "Sono qui per presentare il nostro lavoro \"Distilling Script Knowledge from Large Language Models for Constrained Language Planning\"."}
{"doc_id": "crgYiwKDfX", "seg_id": 2, "src_ref": "In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts.", "tgt_ref": "Nella vita quotidiana, gli esseri umani spesso pianificano le loro azioni seguendo istruzioni passo-passo sotto forma di script orientati all'obiettivo."}
{"doc_id": "crgYiwKDfX", "seg_id": 3, "src_ref": "Previous work has exploited language models to plan for abstract goals of stereotypical activities such as \"make a cake\".", "tgt_ref": "Il lavoro precedente ha fatto ricorso ai modelli linguistici per pianificare obiettivi astratti di attività stereotipate come \"fare una torta\"."}
{"doc_id": "crgYiwKDfX", "seg_id": 4, "src_ref": "And show that large language models can effectively decompose goals into steps.", "tgt_ref": "E dimostrare che i grandi modelli linguistici possono efficacemente scomporre gli obiettivi in passaggi."}
{"doc_id": "crgYiwKDfX", "seg_id": 5, "src_ref": "However, previous work mainly focuses on planning for the abstract goals of stereotypical activities.", "tgt_ref": "Tuttavia, il lavoro precedente si concentra principalmente sulla pianificazione degli obiettivi astratti delle attività stereotipate."}
{"doc_id": "crgYiwKDfX", "seg_id": 6, "src_ref": "Planning for the goals with specific constraints, such as \"make a chocolate cake\", still remains under-studied.", "tgt_ref": "La pianificazione degli obiettivi con vincoli specifici, come \"fare una torta al cioccolato\", rimane ancora poco studiata."}
{"doc_id": "crgYiwKDfX", "seg_id": 7, "src_ref": "In this paper, we define the problem of constrained language planning which imposes different constraints on the goals of planning.", "tgt_ref": "In questo articolo, definiamo il problema della pianificazione linguistica vincolata che impone diverse limitazioni agli obiettivi della pianificazione."}
{"doc_id": "crgYiwKDfX", "seg_id": 8, "src_ref": "An abstract goal can be inherited by different real-life specific goals with multi-faceted constraints.", "tgt_ref": "Un obiettivo astratto può essere ereditato da diversi obiettivi specifici della vita reale con vincoli multiformi."}
{"doc_id": "crgYiwKDfX", "seg_id": 9, "src_ref": "A good planner should write scripts that are reasonable and faithful to constraints.", "tgt_ref": "Un buon pianificatore dovrebbe scrivere script ragionevoli e fedeli ai vincoli."}
{"doc_id": "crgYiwKDfX", "seg_id": 10, "src_ref": "In this paper, we first evaluate and improve the constrained language planning ability of large language models.", "tgt_ref": "In questo articolo, valutiamo e miglioriamo la capacità di pianificazione linguistica vincolata di grandi modelli linguistici."}
{"doc_id": "crgYiwKDfX", "seg_id": 11, "src_ref": "Since no dataset of specific goals exists to support our study, we have to acquire these goals first.", "tgt_ref": "Dal momento che non esiste alcun set di dati di obiettivi specifici per supportare il nostro studio, dobbiamo anzitutto acquisire questi obiettivi."}
{"doc_id": "crgYiwKDfX", "seg_id": 12, "src_ref": "As shown in the table, we extend the abstract goals with multi-faceted constraints for human-in-the-loop data acquisition using InstructGPT.", "tgt_ref": "Come mostrato nella tabella, estendiamo gli obiettivi astratti con vincoli multiformi per l'acquisizione di dati umani nel ciclo utilizzando InstructGPT."}
{"doc_id": "crgYiwKDfX", "seg_id": 13, "src_ref": "We sample 100 specific goals and evaluate the scripts generated from large language models.", "tgt_ref": "Campioniamo 100 obiettivi specifici e valutiamo gli script generati da grandi modelli linguistici."}
{"doc_id": "crgYiwKDfX", "seg_id": 14, "src_ref": "This table reports the overall accuracy of the results.", "tgt_ref": "Questa tabella riporta l'accuratezza complessiva dei risultati."}
{"doc_id": "crgYiwKDfX", "seg_id": 15, "src_ref": "We find that all language models achieve unsatisfactory results on planning for specific goals.", "tgt_ref": "Riteniamo che tutti i modelli linguistici ottengano risultati insoddisfacenti nella pianificazione di obiettivi specifici."}
{"doc_id": "crgYiwKDfX", "seg_id": 16, "src_ref": "Then we conduct detailed analysis to investigate why learning models fail.", "tgt_ref": "Quindi, conduciamo un'analisi dettagliata per esaminare la ragione per cui i modelli di apprendimento falliscono."}
{"doc_id": "crgYiwKDfX", "seg_id": 17, "src_ref": "Results in the figure show that the semantic completeness in generated scripts is acceptable but the faithfulness to the constraints cannot be guaranteed.", "tgt_ref": "I risultati nella figura mostrano che la completezza semantica negli script generati è accettabile, ma la fedeltà ai vincoli non può essere garantita."}
{"doc_id": "crgYiwKDfX", "seg_id": 18, "src_ref": "We dig into a more fine-grained topic categories of constraints defined in wikiHow.", "tgt_ref": "Approfondiamo una categoria di vincoli più dettagliata definita in wikiHow."}
{"doc_id": "crgYiwKDfX", "seg_id": 19, "src_ref": "The heat map in the figure shows that the planning performance of InstructGPTs varies considerably for goals of different categories.", "tgt_ref": "La heatmap nella figura mostra che le prestazioni di pianificazione di InstructGPT variano considerevolmente in funzione degli obiettivi di diverse categorie."}
{"doc_id": "crgYiwKDfX", "seg_id": 20, "src_ref": "Previous studies have shown that the output quality of language models falls in high variance, leading to bad performance.", "tgt_ref": "Studi precedenti hanno dimostrato che la qualità dell'output dei modelli linguistici mostra un'elevata varianza, portando a prestazioni scadenti."}
{"doc_id": "crgYiwKDfX", "seg_id": 21, "src_ref": "Thus, we adopt the idea of over-generate-then-filter to improve generation quality.", "tgt_ref": "Pertanto, adottiamo l'idea di sovra-generare e poi filtrare al fine di migliorare la qualità della generazione."}
{"doc_id": "crgYiwKDfX", "seg_id": 22, "src_ref": "We first show constraint types with examples for InstructGPT and obtain specific goals based on the seed abstract goals.", "tgt_ref": "Mostriamo innanzitutto i tipi di vincolo con esempi per InstructGPT e otteniamo obiettivi specifici basati sugli obiettivi astratti di partenza."}
{"doc_id": "crgYiwKDfX", "seg_id": 23, "src_ref": "Then, InstructGPT over-generates K scripts for specific goals.", "tgt_ref": "Quindi, InstructGPT sovra-genera script K per obiettivi specifici."}
{"doc_id": "crgYiwKDfX", "seg_id": 24, "src_ref": "Next, a filter model is developed to select the faithful scripts.", "tgt_ref": "Successivamente, viene sviluppato un modello di filtro per selezionare gli script fedeli."}
{"doc_id": "crgYiwKDfX", "seg_id": 25, "src_ref": "We convert scripts and goals into InstructGPT embeddings and calculate the cosine similarity as similarity scores to measure semantic similarity.", "tgt_ref": "Convertiamo script e obiettivi in incorporazioni InstructGPT e calcoliamo la similarità del coseno come punteggi di similarità per misurare la somiglianza semantica."}
{"doc_id": "crgYiwKDfX", "seg_id": 26, "src_ref": "In addition, we reward the script that contains the keywords of the target constraint.", "tgt_ref": "Inoltre, premiamo lo script che contiene le parole chiave del vincolo di destinazione."}
{"doc_id": "crgYiwKDfX", "seg_id": 27, "src_ref": "We only keep the script if the target goal scores the highest in the goal set.", "tgt_ref": "Manteniamo lo script solo se l'obiettivo target ottiene il punteggio più alto nell'insieme di obiettivi."}
{"doc_id": "crgYiwKDfX", "seg_id": 28, "src_ref": "With our method, InstructGPT can generate scripts of higher quality.", "tgt_ref": "Con il nostro metodo, InstructGPT può generare script di qualità superiore."}
{"doc_id": "crgYiwKDfX", "seg_id": 29, "src_ref": "Our method greatly improves the planning ability both in semantic completeness and faithfulness to the constraint.", "tgt_ref": "Il nostro metodo migliora notevolmente la capacità di pianificazione sia nella completezza semantica che nella fedeltà al vincolo."}
{"doc_id": "crgYiwKDfX", "seg_id": 30, "src_ref": "Since large language models are costly to deploy, it's essential to enable language planning ability of smaller and specialized models.", "tgt_ref": "Poiché i grandi modelli linguistici sono costosi da implementare, è essenziale abilitare la capacità di pianificazione linguistica di modelli più piccoli e specializzati."}
{"doc_id": "crgYiwKDfX", "seg_id": 31, "src_ref": "Creating the dataset is an essential step to this end.", "tgt_ref": "La creazione del set di dati è un passaggio essenziale a tal fine."}
{"doc_id": "crgYiwKDfX", "seg_id": 32, "src_ref": "However, previous studies do not enable planning for specific goals and manual dataset annotation is expensive.", "tgt_ref": "Tuttavia, gli studi precedenti non consentono la pianificazione per obiettivi specifici, mentre l'annotazione manuale del set di dati è costosa."}
{"doc_id": "crgYiwKDfX", "seg_id": 33, "src_ref": "Thus, we follow the idea of symbolic knowledge distillation, to distil constrained language planning datasets from large language models.", "tgt_ref": "Pertanto, seguiamo l'idea della distillazione della conoscenza simbolica per distillare set di dati di pianificazione del linguaggio vincolati da grandi modelli linguistici."}
{"doc_id": "crgYiwKDfX", "seg_id": 34, "src_ref": "We appy our method for building a dataset of constrained language planning, named as CoScript.", "tgt_ref": "Applichiamo il nostro metodo per costruire un set di dati di pianificazione linguistica vincolata, denominato CoScript."}
{"doc_id": "crgYiwKDfX", "seg_id": 35, "src_ref": "In total, we generate 55,000 specific goals with scripts.", "tgt_ref": "In totale, con gli script generiamo 55.000 obiettivi specifici."}
{"doc_id": "crgYiwKDfX", "seg_id": 36, "src_ref": "To ensure the quality of the validation and test set, we ask crowd-sourced workers to find and revise the incorrect samples.", "tgt_ref": "Per garantire la qualità del set di convalida e test, chiediamo ai collaboratori in crowdsourcing di trovare e rivedere i campioni errati."}
{"doc_id": "crgYiwKDfX", "seg_id": 37, "src_ref": "This figure shows the constraint distribution of CoScript.", "tgt_ref": "Questa figura mostra la distribuzione dei vincoli di CoScript."}
{"doc_id": "crgYiwKDfX", "seg_id": 38, "src_ref": "We find CoScript shows high pluralism in the generated specific goals.", "tgt_ref": "Riteniamo che CoScript mostri un alto pluralismo negli obiettivi specifici generati."}
{"doc_id": "crgYiwKDfX", "seg_id": 39, "src_ref": "With CoScript we can try smaller but specialized models for constrained language planning.", "tgt_ref": "Con CoScript possiamo provare modelli più piccoli ma specializzati per la pianificazione linguistica vincolata."}
{"doc_id": "crgYiwKDfX", "seg_id": 40, "src_ref": "We find that T5 fine-tuned on CoScript can generate scripts of higher quality than most large language models, indicating that smaller models can surpass larger models when properly trained on suitable datasets.", "tgt_ref": "Scopriamo che T5 messo a punto su CoScript può generare script di qualità superiore rispetto alla maggior parte dei grandi modelli linguistici, indicando che i modelli più piccoli possono superare i modelli più grandi se opportunamente addestrati su set di dati adeguati."}
{"doc_id": "crgYiwKDfX", "seg_id": 41, "src_ref": "In summary, we establish the constrained language planning problem.", "tgt_ref": "In sintesi, stabiliamo il problema della pianificazione linguistica vincolata."}
{"doc_id": "crgYiwKDfX", "seg_id": 42, "src_ref": "We evaluate constrained language planning ability of large language models and develop an over-generate-then-filter method for large language models.", "tgt_ref": "Valutiamo la capacità di pianificazione linguistica vincolata di grandi modelli linguistici e sviluppiamo un metodo over-generate-then-filter per grandi modelli linguistici."}
{"doc_id": "crgYiwKDfX", "seg_id": 43, "src_ref": "We use large language models to generate a high-quality script dataset, CoScript, for constrained language planning.", "tgt_ref": "Utilizziamo modelli linguistici di grandi dimensioni per generare un set di dati di script di alta qualità, CoScript, per la pianificazione linguistica vincolata."}
{"doc_id": "crgYiwKDfX", "seg_id": 44, "src_ref": "We hope the CoScript dataset can be a valuable resource to advance research on language planning.", "tgt_ref": "Ci auguriamo che il set di dati CoScript possa essere una risorsa preziosa per far progredire la ricerca sulla pianificazione linguistica."}
{"doc_id": "crgYiwKDfX", "seg_id": 45, "src_ref": "Thanks for your time.", "tgt_ref": "Grazie per il tempo che mi avete dedicato."}
{"doc_id": "crgYiwKDfX", "seg_id": 46, "src_ref": "Please find more details of CoScript in our paper.", "tgt_ref": "Troverete maggiori dettagli su CoScript nel nostro articolo."}
{"doc_id": "QTlIuodOsA", "seg_id": 0, "src_ref": "Hello everyone, my name is Shuheng.", "tgt_ref": "Ciao a tutti, mi chiamo Shuheng."}
{"doc_id": "QTlIuodOsA", "seg_id": 1, "src_ref": "Today I'm going to present our paper \"Do CoNLL-2003 named entity taggers still work well in 2023?\"", "tgt_ref": "Oggi presenterò il nostro articolo, \"Do CoNLL-2003 named entity taggers still work well in 2023?\""}
{"doc_id": "QTlIuodOsA", "seg_id": 2, "src_ref": "Let's get started.", "tgt_ref": "Cominciamo."}
{"doc_id": "QTlIuodOsA", "seg_id": 3, "src_ref": "Our paper investigated the problem of generalization using the Named Entity Recognition Task or the NER task.", "tgt_ref": "Il nostro articolo è incentrato sul problema della generalizzazione utilizzando l'attività Named Entity Recognition (Riconoscimento delle entità nominate) o attività NER."}
{"doc_id": "QTlIuodOsA", "seg_id": 4, "src_ref": "We observe that models have been used in CoNLL-2003 to develop NER for almost 20 years and this naturally raises several problems.", "tgt_ref": "Osserviamo che i modelli sono stati utilizzati in CoNLL-2003 per sviluppare NER per quasi 20 anni e questo solleva naturalmente diversi problemi."}
{"doc_id": "QTlIuodOsA", "seg_id": 5, "src_ref": "Firstly, can these models generalise to modern data?", "tgt_ref": "In primo luogo, è possibile generalizzare questi modelli ai dati moderni?"}
{"doc_id": "QTlIuodOsA", "seg_id": 6, "src_ref": "And when we develop new taggers, what is needed for good generalization?", "tgt_ref": "E quando sviluppiamo nuovi tagger, cosa è necessario per una buona generalizzazione?"}
{"doc_id": "QTlIuodOsA", "seg_id": 7, "src_ref": "At the same time, if we do observe poor generalization, what causes the performance drop of these models?", "tgt_ref": "Allo stesso tempo, se osserviamo una scarsa generalizzazione, cosa causa il calo delle prestazioni di questi modelli?"}
{"doc_id": "QTlIuodOsA", "seg_id": 8, "src_ref": "To investigate these problems, we developed the CoNLL++ Dataset.", "tgt_ref": "Per analizzare questi problemi, abbiamo sviluppato il set di dati CoNLL++."}
{"doc_id": "QTlIuodOsA", "seg_id": 9, "src_ref": "This is a data set that we collected from Reuters News from 2020, and then annotated them with the same CoNLL-2003 annotation guidelines.", "tgt_ref": "Si tratta di un set di dati che abbiamo raccolto da Reuters News del 2020, successivamente annotato con le stesse linee guida di annotazione di CoNLL-2003."}
{"doc_id": "QTlIuodOsA", "seg_id": 10, "src_ref": "We then fine-tuned over 20 models on CoNLL-2003.", "tgt_ref": "Abbiamo quindi adattato oltre 20 modelli su CoNLL-2003."}
{"doc_id": "QTlIuodOsA", "seg_id": 11, "src_ref": "We evaluated them on both the CoNLL-03 test sets and the CoNLL++.", "tgt_ref": "Li abbiamo valutati sia sui set di test CoNLL-03 che su CoNLL++."}
{"doc_id": "QTlIuodOsA", "seg_id": 12, "src_ref": "And last but not least, we calculated the percentage change in F1 to assess the generalization of each model.", "tgt_ref": "Ultimo ma non meno importante, abbiamo calcolato la variazione percentuale in F1 per valutare la generalizzazione di ciascun modello."}
{"doc_id": "QTlIuodOsA", "seg_id": 13, "src_ref": "So what is needed for a good generalization?", "tgt_ref": "Quindi, cosa serve per una buona generalizzazione?"}
{"doc_id": "QTlIuodOsA", "seg_id": 14, "src_ref": "Throughout experiments we found that there are three main ingredients that are needed.", "tgt_ref": "Durante gli esperimenti, abbiamo scoperto che sono presenti tre ingredienti principali da ritenersi necessari."}
{"doc_id": "QTlIuodOsA", "seg_id": 15, "src_ref": "The first one is the model architecture.", "tgt_ref": "Il primo è l'architettura del modello."}
{"doc_id": "QTlIuodOsA", "seg_id": 16, "src_ref": "Through our experiments we found that the transformer models normally generalize better to new data.", "tgt_ref": "Grazie ai nostri esperimenti, abbiamo scoperto che i modelli trasformatori normalmente generalizzano meglio i nuovi dati."}
{"doc_id": "QTlIuodOsA", "seg_id": 17, "src_ref": "The second ingredient is the model size.", "tgt_ref": "Il secondo ingrediente è la dimensione del modello."}
{"doc_id": "QTlIuodOsA", "seg_id": 18, "src_ref": "We found that usually larger models lead to better generalization.", "tgt_ref": "Abbiamo scoperto che di solito i modelli più grandi portano a una migliore generalizzazione."}
{"doc_id": "QTlIuodOsA", "seg_id": 19, "src_ref": "And last but not least, we all know that the number of fine tuning examples directly affects the performance of a downstream task.", "tgt_ref": "E, ultimo ma non meno importante, sappiamo tutti che il numero di esempi di messa a punto influisce direttamente sulle prestazioni di un'attività a valle."}
{"doc_id": "QTlIuodOsA", "seg_id": 20, "src_ref": "Here we also found that more fine tuning examples, actually also leads to better generalization.", "tgt_ref": "In questa circostanza abbiamo scoperto anche che più esempi di messa a punto portano in realtà a una migliore generalizzazione."}
{"doc_id": "QTlIuodOsA", "seg_id": 21, "src_ref": "To our next question, what causes the performance drop of some models, We had two hypothesis.", "tgt_ref": "Per la domanda successiva, vale a dire cosa provoca il calo delle prestazioni di alcuni modelli, avevamo due ipotesi."}
{"doc_id": "QTlIuodOsA", "seg_id": 22, "src_ref": "The first one is adaptive overfitting, which is overfitting costs by reusing the same test set over and over again and this is usually manifested as the diminishing returns on a new test set.", "tgt_ref": "La prima è l'overfitting adattivo, che è il costo del sovradattamento riutilizzando lo stesso set di test più e più volte, e questo di solito si manifesta come rendimenti decrescenti su un nuovo set di test."}
{"doc_id": "QTlIuodOsA", "seg_id": 23, "src_ref": "The second hypothesis is temporal drift which is the performance degradation that is caused by the increasing temporal gap between the train and the test data.", "tgt_ref": "La seconda ipotesi è rappresentata dalla deriva temporale, che descrive il degrado delle prestazioni causato dal crescente divario temporale tra i dati di addestramento e quelli di test."}
{"doc_id": "QTlIuodOsA", "seg_id": 24, "src_ref": "For data overfitting, we saw that from the graph on the right, the red best fit line has a gradient that is greater than one.", "tgt_ref": "Per il sovradattamento dei dati, abbiamo visto che dal grafico sulla destra, la linea rossa di migliore adattamento presenta un gradiente maggiore di uno."}
{"doc_id": "QTlIuodOsA", "seg_id": 25, "src_ref": "This means that every unit of improvement that we made, on CoNLL-2003 translates to more than one unit improvement on CoNLL++ which means that there is no diminishing returns.", "tgt_ref": "Ciò significa che ogni unità di miglioramento che abbiamo apportato, su CoNLL-2003 si traduce in un miglioramento di più di un'unità su CoNLL++, il che significa che non ci sono rendimenti decrescenti."}
{"doc_id": "QTlIuodOsA", "seg_id": 26, "src_ref": "And this shows us that adaptive overfitting in this case is not observed.", "tgt_ref": "E questo ci mostra che in questo caso non si osserva l'adattamento eccessivo."}
{"doc_id": "QTlIuodOsA", "seg_id": 27, "src_ref": "So what about temporal drift then?", "tgt_ref": "E allora che dire della deriva temporale?"}
{"doc_id": "QTlIuodOsA", "seg_id": 28, "src_ref": "For temporal drift, we did an experiment to retrain or continue to pre-train some models with more recent data and we found that the performance degrades with larger temporal gap and this confirms our hypothesis that the main cause of the performance drop is temporal drift.", "tgt_ref": "Per la deriva temporale, abbiamo eseguito un esperimento per riaddestrare o continuare a pre-addestrare alcuni modelli con dati più recenti e abbiamo scoperto che le prestazioni si degradano con un intervallo temporale più ampio: questo conferma la nostra ipotesi che la causa principale del calo delle prestazioni sia dovuto alla deriva temporale."}
{"doc_id": "QTlIuodOsA", "seg_id": 29, "src_ref": "Our conclusion is that, for good generalization we would need a better model architecture, larger model size, as well as more fine tuning examples.", "tgt_ref": "La nostra conclusione è che, per una buona generalizzazione, avremmo bisogno di un'architettura del modello migliore, di dimensioni del modello maggiori, nonché di più esempi di messa a punto."}
{"doc_id": "QTlIuodOsA", "seg_id": 30, "src_ref": "And these goes hand in hand, we can't just have one ingredient but throw out the others.", "tgt_ref": "Questi vanno di pari passo: non possiamo avere un solo ingrediente e buttare via gli altri."}
{"doc_id": "QTlIuodOsA", "seg_id": 31, "src_ref": "At the same time, we also found that the performance drop here is caused by temporal drift and kind of surprisingly, it is not caused by adaptive overfitting even though CoNLL-2003 has been used for over 20 years.", "tgt_ref": "Allo stesso tempo, abbiamo scoperto che il calo delle prestazioni è causato in questo caso dalla deriva temporale e, sorprendentemente, non è causato da alcun overfitting adattivo, anche se CoNLL-2003 è stato impiegato per oltre 20 anni."}
{"doc_id": "QTlIuodOsA", "seg_id": 32, "src_ref": "So going back to the question that we raised in the title of our paper Do CoNLL-2003 taggers still work in 2023?", "tgt_ref": "Tornando alla domanda che abbiamo sollevato nel titolo del nostro articolo: Do CoNLL-2003 taggers still work in 2023?"}
{"doc_id": "QTlIuodOsA", "seg_id": 33, "src_ref": "And we found that the answer is actually a resounding yes.", "tgt_ref": "Abbiamo scoperto che la risposta è in realtà un sonoro sì."}
{"doc_id": "QTlIuodOsA", "seg_id": 34, "src_ref": "We hope our paper calls for more research on how to improve generalizations of the models.", "tgt_ref": "Ci auguriamo che il nostro articolo inviti a ulteriori ricerche su come migliorare le generalizzazioni dei modelli."}
{"doc_id": "QTlIuodOsA", "seg_id": 35, "src_ref": "And lastly, please make sure to check out our paper, our data set and if you have any questions, feel free to contact me.", "tgt_ref": "Infine, assicuratevi di consultare il nostro articolo e il nostro set di dati. In caso di domande, non esitate a contattarmi."}
{"doc_id": "QTlIuodOsA", "seg_id": 36, "src_ref": "Thank you so much.", "tgt_ref": "Grazie mille."}
{"doc_id": "yBDqNxQUwV", "seg_id": 0, "src_ref": "Hi!", "tgt_ref": "Ciao!"}
{"doc_id": "yBDqNxQUwV", "seg_id": 1, "src_ref": "I'm going to talk about our work on \"Resolving Indirect Referring Expressions for Entity Selection\", in which we introduce the AltEntities Corpus.", "tgt_ref": "Parlerò del nostro lavoro su \"Resolving Indirect Referring Expressions for Entity Selection\", in cui introduciamo il corpus AltEntities."}
{"doc_id": "yBDqNxQUwV", "seg_id": 2, "src_ref": "My name is Javad Hosseini and this is a joint work with Filip Radlinski, Silvia Pareti, and Annie Louis.", "tgt_ref": "Mi chiamo Javad Hosseini e questo è un lavoro congiunto con Filip Radlinski, Silvia Pareti e Annie Louis."}
{"doc_id": "yBDqNxQUwV", "seg_id": 3, "src_ref": "Our goal is to understand users’ language when they want to make a choice.", "tgt_ref": "Il nostro obiettivo è comprendere il linguaggio degli utenti quando intendono compiere una scelta."}
{"doc_id": "yBDqNxQUwV", "seg_id": 4, "src_ref": "Consider this alternative question.", "tgt_ref": "Consideriamo questa domanda alternativa."}
{"doc_id": "yBDqNxQUwV", "seg_id": 5, "src_ref": "\"Did you mean 'Easy on Me' or 'I Gotta Feeling'?\"", "tgt_ref": "\"Intendevi 'Easy on Me' o 'I Gotta Feeling'?\""}
{"doc_id": "yBDqNxQUwV", "seg_id": 6, "src_ref": "Here, a user wants to select between one of these two songs.", "tgt_ref": "Qui, un utente vuole scegliere una tra queste due canzoni."}
{"doc_id": "yBDqNxQUwV", "seg_id": 7, "src_ref": "The most obvious thing is to use a direct reference, for example by saying the name of the song \"Easy on Me\" or its position, \"the first one\".", "tgt_ref": "La cosa più ovvia è usare un riferimento diretto, ad esempio pronunciando il nome della canzone \"Easy on Me\" o la sua posizione, \"la prima\"."}
{"doc_id": "yBDqNxQUwV", "seg_id": 8, "src_ref": "But sometimes an indirect reference is more appropriate to have a more natural conversation.", "tgt_ref": "Ma a volte un riferimento indiretto è più appropriato per avere una conversazione più naturale."}
{"doc_id": "yBDqNxQUwV", "seg_id": 9, "src_ref": "This could happen when the user cannot remember the name of the song.", "tgt_ref": "Questo potrebbe accadere quando l'utente non riesce a ricordare il nome della canzone."}
{"doc_id": "yBDqNxQUwV", "seg_id": 10, "src_ref": "Or the pronunciations are too similar to each other and hard to disambiguate.", "tgt_ref": "Oppure le pronunce sono troppo simili tra loro e difficili da disambiguare."}
{"doc_id": "yBDqNxQUwV", "seg_id": 11, "src_ref": "Or when the user wants to specify a preference.", "tgt_ref": "O, ancora, quando l'utente vuole specificare una preferenza."}
{"doc_id": "yBDqNxQUwV", "seg_id": 12, "src_ref": "Here are some examples of indirect references for example, \"the newer one\" or \"the song that's not energetic.\"", "tgt_ref": "Ecco alcuni esempi di riferimenti indiretti, ad esempio \"la più recente\" o \"la canzone non vivace\"."}
{"doc_id": "yBDqNxQUwV", "seg_id": 13, "src_ref": "This is an important problem in conversational systems and also for benchmarking LLMs' entity understanding.", "tgt_ref": "Questo è un problema importante nei sistemi conversazionali e anche per il benchmarking della comprensione dell'entità dei LLM."}
{"doc_id": "yBDqNxQUwV", "seg_id": 14, "src_ref": "We're not aware of a larger-scale public data set for the task, so we collect one using crowd annotation.", "tgt_ref": "Non siamo a conoscenza di alcun set di dati pubblici su larga scala per l'attività, quindi ne raccogliamo uno utilizzando l'annotazione della folla."}
{"doc_id": "yBDqNxQUwV", "seg_id": 15, "src_ref": "Our data set covers three different domains: music, books, and recipes.", "tgt_ref": "Il nostro set di dati copre tre diversi domini: musica, libri e ricette."}
{"doc_id": "yBDqNxQUwV", "seg_id": 16, "src_ref": "Our data set collection methodology emphasizes informality using a cartoon completion setup.", "tgt_ref": "La nostra metodologia di raccolta dei dati sottolinea l'informalità utilizzando una configurazione di completamento a fumetti."}
{"doc_id": "yBDqNxQUwV", "seg_id": 17, "src_ref": "The cartoon has three speech bubbles.", "tgt_ref": "Il fumetto ha tre nuvolette."}
{"doc_id": "yBDqNxQUwV", "seg_id": 18, "src_ref": "In the first bubble, Bob says, \"Remember that song we were listening to yesterday?\"", "tgt_ref": "Nella prima, Bob dice: \"Ricordi quella canzone che stavamo ascoltando ieri?\""}
{"doc_id": "yBDqNxQUwV", "seg_id": 19, "src_ref": "And with that, Bob sets the dialogue context.", "tgt_ref": "In tal modo, Bob imposta il contesto del dialogo."}
{"doc_id": "yBDqNxQUwV", "seg_id": 20, "src_ref": "In the second speech bubble, Alice says, \"Do you mean 'Easy on Me' or 'I Gotta Feeling'?\"", "tgt_ref": "Nella seconda, Alice dice: \"Intendi 'Easy on Me' o 'I Gotta Feeling'?\""}
{"doc_id": "yBDqNxQUwV", "seg_id": 21, "src_ref": "Which is the alternative question.", "tgt_ref": "Che è la domanda alternativa."}
{"doc_id": "yBDqNxQUwV", "seg_id": 22, "src_ref": "And in the third speech bubble, Bob uses an indirect reference to select one of these entities, for example, \"the newer one.\"", "tgt_ref": "E nella terza, Bob usa un riferimento indiretto per selezionare una di queste entità, ad esempio \"la più recente\"."}
{"doc_id": "yBDqNxQUwV", "seg_id": 23, "src_ref": "We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator.", "tgt_ref": "La prima e la seconda nuvoletta vengono generate automaticamente, mentre la terza deve essere compilata dall'annotatore."}
{"doc_id": "yBDqNxQUwV", "seg_id": 24, "src_ref": "The first speech bubble is chosen from a few manual prompts per domain.", "tgt_ref": "La prima viene scelta tra alcuni suggerimenti manuali per dominio."}
{"doc_id": "yBDqNxQUwV", "seg_id": 25, "src_ref": "The second one, which is the alternative question is generated as follows.", "tgt_ref": "La seconda, che è la domanda alternativa, viene generata come segue."}
{"doc_id": "yBDqNxQUwV", "seg_id": 26, "src_ref": "We always use a simple template.", "tgt_ref": "Usiamo sempre un modello semplice."}
{"doc_id": "yBDqNxQUwV", "seg_id": 27, "src_ref": "Do you mean A or B?", "tgt_ref": "Intendi A o B?"}
{"doc_id": "yBDqNxQUwV", "seg_id": 28, "src_ref": "Where A and B are samples from Wikipedia.", "tgt_ref": "Dove A e B sono campioni da Wikipedia."}
{"doc_id": "yBDqNxQUwV", "seg_id": 29, "src_ref": "Here are the different sampling methods we've used.", "tgt_ref": "Ecco i diversi metodi di campionamento che abbiamo utilizzato."}
{"doc_id": "yBDqNxQUwV", "seg_id": 30, "src_ref": "When we move higher in the list, the entities become more similar to each other and it's usually harder to make the disambiguation.", "tgt_ref": "Quando ci spostiamo più in alto nell'elenco, le entità diventano più simili tra loro e di solito è più difficile disambiguarle."}
{"doc_id": "yBDqNxQUwV", "seg_id": 31, "src_ref": "The first one is uniform at random.", "tgt_ref": "La prima è casualmente uniforme."}
{"doc_id": "yBDqNxQUwV", "seg_id": 32, "src_ref": "The second one is when the entities have similar titles, for example, two books with the name \"The Return\".", "tgt_ref": "La seconda è quando le entità hanno titoli simili, ad esempio due libri con il nome \"The Return\"."}
{"doc_id": "yBDqNxQUwV", "seg_id": 33, "src_ref": "The third one is when they have similar descriptions on Wikipedia.", "tgt_ref": "La terza è quando presentano descrizioni simili su Wikipedia."}
{"doc_id": "yBDqNxQUwV", "seg_id": 34, "src_ref": "And finally when they have similar info boxes or attributes on Wikipedia.", "tgt_ref": "E, infine, quando hanno riquadri informativi o attributi simili su Wikipedia."}
{"doc_id": "yBDqNxQUwV", "seg_id": 35, "src_ref": "For example, the same genre or the same artist for a song.", "tgt_ref": "Ad esempio, lo stesso genere o lo stesso artista per una canzone."}
{"doc_id": "yBDqNxQUwV", "seg_id": 36, "src_ref": "When we show this alternative question to the annotators, they know the name of these entities, but they don't necessarily know about the entities.", "tgt_ref": "Quando mostriamo questa domanda alternativa agli annotatori, conoscono il nome di queste entità, ma non necessariamente le entità stesse."}
{"doc_id": "yBDqNxQUwV", "seg_id": 37, "src_ref": "So what we do is that we show some background knowledge about the two entities.", "tgt_ref": "Quindi, quello che facciamo è mostrare alcune conoscenze di base sulle due entità."}
{"doc_id": "yBDqNxQUwV", "seg_id": 38, "src_ref": "For songs, we simply show a Google search link to each song and then ask the annotators to listen to at least some of each song, and read about each song.", "tgt_ref": "Per le canzoni, mostriamo semplicemente un link di ricerca di Google per ogni canzone e poi chiediamo agli annotatori di ascoltare alcune parti e di leggere qualcosa su ciascuna."}
{"doc_id": "yBDqNxQUwV", "seg_id": 39, "src_ref": "Here's for example, the Google search result for the song \"Easy on Me.\"", "tgt_ref": "Ecco ad esempio il risultato della ricerca su Google per la canzone \"Easy on Me\"."}
{"doc_id": "yBDqNxQUwV", "seg_id": 40, "src_ref": "For the recipes and books domain, we show some background text from Wikipedia.", "tgt_ref": "Per il dominio delle ricette e dei libri, mostriamo alcuni testi di sfondo da Wikipedia."}
{"doc_id": "yBDqNxQUwV", "seg_id": 41, "src_ref": "For recipes, we additionally show their images, again from Wikipedia, so that the annotators know how they look like.", "tgt_ref": "Per le ricette, mostriamo anche le loro immagini, tratte sempre da Wikipedia, in modo che gli annotatori sappiano che aspetto hanno."}
{"doc_id": "yBDqNxQUwV", "seg_id": 42, "src_ref": "Then, we asked the annotators to pick one of these entities, for example, here's the first one, and describe them using three to five indirect referring expressions.", "tgt_ref": "Successivamente, abbiamo chiesto agli annotatori di scegliere una di queste entità, ecco ad esempio la prima, e descriverle usando da tre a cinque espressioni di riferimento indirette."}
{"doc_id": "yBDqNxQUwV", "seg_id": 43, "src_ref": "For example, the one with the piano music.", "tgt_ref": "Ad esempio, quella con la musica per pianoforte."}
{"doc_id": "yBDqNxQUwV", "seg_id": 44, "src_ref": "Here are some examples from our dataset.", "tgt_ref": "Ecco alcuni esempi dal nostro set di dati."}
{"doc_id": "yBDqNxQUwV", "seg_id": 45, "src_ref": "For example, \"the one without words\", \"not the one with the 12 year old boy\", or \"the fictional one\", or \"comes from Azerbaijan\", and so on.", "tgt_ref": "Ad esempio, \"quella senza parole\", \"non quella con il ragazzo di 12 anni\", o \"quella immaginaria\", o \"viene dall'Azerbaigian\", e così via."}
{"doc_id": "yBDqNxQUwV", "seg_id": 46, "src_ref": "The AltEntities Corpus has 6,000 alternative questions across three domains, and it has 42,000 indirect referring expressions.", "tgt_ref": "L'AltEntities Corpus consta di 6.000 domande alternative in tre domini e di 42.000 espressioni di riferimento indirette."}
{"doc_id": "yBDqNxQUwV", "seg_id": 47, "src_ref": "Results with T5 XL model are summarized below.", "tgt_ref": "I risultati con il modello T5 XL sono riassunti di seguito."}
{"doc_id": "yBDqNxQUwV", "seg_id": 48, "src_ref": "If the language model has access to the exact same background knowledge as the annotators, then the accuracy is really high, it's around 92 to 95%.", "tgt_ref": "Se il modello linguistico ha accesso alle stesse identiche conoscenze di base degli annotatori, allora l'accuratezza è decisamente alta, intorno al 92-95%."}
{"doc_id": "yBDqNxQUwV", "seg_id": 49, "src_ref": "But this is not realistic.", "tgt_ref": "Ma ciò non è realistico."}
{"doc_id": "yBDqNxQUwV", "seg_id": 50, "src_ref": "If the language model has access to some partially overlapping background knowledge, then the accuracy is between 82 to 87%, which is more realistic.", "tgt_ref": "Se il modello linguistico ha accesso ad alcune conoscenze di base parzialmente sovrapposte, l'accuratezza è compresa tra l'82 e l'87%, il che è più realistico."}
{"doc_id": "yBDqNxQUwV", "seg_id": 51, "src_ref": "For example, when the language model retrieves the background knowledge.", "tgt_ref": "Ad esempio, quando il modello linguistico recupera le conoscenze di base."}
{"doc_id": "yBDqNxQUwV", "seg_id": 52, "src_ref": "If the language model has access only to entity names, then the accuracy is only 60%, so there's a lot of room for improvement.", "tgt_ref": "Se il modello linguistico ha accesso solo ai nomi delle entità, l'accuratezza è solo del 60%, quindi c'è molto margine di miglioramento."}
{"doc_id": "yBDqNxQUwV", "seg_id": 53, "src_ref": "We've also shown that the models are domain-generalizable.", "tgt_ref": "Abbiamo anche dimostrato che i modelli sono generalizzabili per dominio."}
{"doc_id": "yBDqNxQUwV", "seg_id": 54, "src_ref": "Here is a link to our dataset.", "tgt_ref": "Ecco un link al nostro set di dati."}
{"doc_id": "yBDqNxQUwV", "seg_id": 55, "src_ref": "Thanks.", "tgt_ref": "Grazie."}
{"doc_id": "PJWMkwXVGI", "seg_id": 0, "src_ref": "Hi, I'm Sara Papi from the University of Trento and Foundazione Bruno Kessler and I will briefly introduce the \"Attention as a Guide for Simultaneous Speech Translation\" paper, that is a joint work with Matteo Negri and Marco Turchi.", "tgt_ref": "Ciao, sono Sara Papi dell'Università di Trento e della Fondazione Bruno Kessler e vi presenterò brevemente il paper \"Attention as a Guide for Simultaneous Speech Translation\", frutto di un lavoro congiunto con Matteo Negri e Marco Turchi."}
{"doc_id": "PJWMkwXVGI", "seg_id": 1, "src_ref": "What is simultaneous speech translation?", "tgt_ref": "Che cos'è la traduzione simultanea vocale?"}
{"doc_id": "PJWMkwXVGI", "seg_id": 2, "src_ref": "Simultaneous speech translation, or SimulST, is the process of translating spoken language into a text in another language in real time, enabling cross-language communication.", "tgt_ref": "La traduzione simultanea vocale, o SimulST, è il processo di traduzione in tempo reale della lingua parlata in un testo in un'altra lingua, che consente la comunicazione tra lingue."}
{"doc_id": "PJWMkwXVGI", "seg_id": 3, "src_ref": "And what are the problems of the current SimulST models?", "tgt_ref": "E quali sono i problemi degli attuali modelli SimulST?"}
{"doc_id": "PJWMkwXVGI", "seg_id": 4, "src_ref": "Specific architectures are usually trained, introducing additional modules to be optimized.", "tgt_ref": "Di solito vengono addestrate architetture specifiche che introducono moduli aggiuntivi da ottimizzare."}
{"doc_id": "PJWMkwXVGI", "seg_id": 5, "src_ref": "Long and complicated training procedures, for example, training involving different optimization objectives.", "tgt_ref": "Procedure di addestramento lunghe e complicate, ad esempio un addestramento che coinvolge diversi obiettivi di ottimizzazione."}
{"doc_id": "PJWMkwXVGI", "seg_id": 6, "src_ref": "And training and maintaining several models to reach different latency regimes.", "tgt_ref": "O ancora, l'addestramento e il mantenimento di diversi modelli per raggiungere diversi regimi di latenza."}
{"doc_id": "PJWMkwXVGI", "seg_id": 7, "src_ref": "For example, training a model with an average of one second latency and another one with two seconds latency, and so on.", "tgt_ref": "Ad esempio, l'addestramento di un modello con una latenza media di un secondo e un altro con una latenza di due secondi, e così via."}
{"doc_id": "PJWMkwXVGI", "seg_id": 8, "src_ref": "So what is our solution?", "tgt_ref": "Qual è la nostra soluzione?"}
{"doc_id": "PJWMkwXVGI", "seg_id": 9, "src_ref": "First, to use already existing offline ST models without re-training or adopting specific architecture for SimulST.", "tgt_ref": "In primo luogo, utilizzare modelli ST offline già esistenti senza addestrare nuovamente né adottare un'architettura specifica per SimulST."}
{"doc_id": "PJWMkwXVGI", "seg_id": 10, "src_ref": "Use only one model for every latency regime and handle latency through specific parameters.", "tgt_ref": "Utilizzare un solo modello per ogni regime di latenza e gestire la latenza attraverso parametri specifici."}
{"doc_id": "PJWMkwXVGI", "seg_id": 11, "src_ref": "And leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output.", "tgt_ref": "E sfruttare la conoscenza già acquisita dal modello attraverso il meccanismo di attenzione tra input audio e output testuale."}
{"doc_id": "PJWMkwXVGI", "seg_id": 12, "src_ref": "That is the cross-attention mechanism, and you can see an example on the right.", "tgt_ref": "Questo è il meccanismo di cross-attention: potete vederne un esempio sulla destra."}
{"doc_id": "PJWMkwXVGI", "seg_id": 13, "src_ref": "Our solution is to propose EDAtt, or Encoder-Decoder Attention, and it is a strategy for which we decide whether to emit or not a partial translation, based on where attention points to.", "tgt_ref": "La nostra soluzione è proporre EDAtt, o Encoder-Decoder Attention, una strategia mediante la quale possiamo decidere se emettere o meno una traduzione parziale in base a dove punta l'attenzione."}
{"doc_id": "PJWMkwXVGI", "seg_id": 14, "src_ref": "A word is emitted if the attention is not concentrated, that is, its sum is below a certain threshold alpha towards the last lambda speech frames, meaning that the received information is enough stable.", "tgt_ref": "Una parola viene emessa se l'attenzione non è concentrata, vale a dire che la sua somma è al di sotto di una certa soglia alfa verso gli ultimi segmenti vocali lambda, il che si traduce nel fatto che l'informazione ricevuta è piuttosto stabile."}
{"doc_id": "PJWMkwXVGI", "seg_id": 15, "src_ref": "For example, if we receive a speech chunk containing \"I'm going to talk about...\" and our model predicts the translation in German, and we will look at the cross-attention weights, we'll see that the first two words points to the earliest received speech frames, while the last word points to the last received speech frames, as lambda speech frames.", "tgt_ref": "Ad esempio, se riceviamo un frammento di discorso contenente \"Parlerò di...\" e il nostro modello prevede la traduzione in tedesco, osservando i pesi dell'attenzione incrociata, vedremo che le prime due parole puntano ai primi segmenti vocali ricevuti, mentre l'ultima parola punta agli ultimi segmenti vocali ricevuti, come segmenti vocali lambda."}
{"doc_id": "PJWMkwXVGI", "seg_id": 16, "src_ref": "This means that the first two words will be emitted while since the sum of the cross-attention is above a certain threshold alpha, we will not emit the last word and we wait for another speech chunk.", "tgt_ref": "Ciò significa che le prime due parole verranno emesse mentre, al contempo, dal momento che la somma dell'attenzione incrociata si trova al di sopra di una certa soglia alfa, non emetteremo l'ultima parola e aspetteremo un altro frammento vocale."}
{"doc_id": "PJWMkwXVGI", "seg_id": 17, "src_ref": "If we go on and we receive another speech chunk, and our model predicts other three words and we will look at those cross-attention weights, we will see that no word points to the last lambda speech frames.", "tgt_ref": "Se, proseguendo, riceviamo un altro frammento vocale, e il nostro modello prevede altre tre parole, osservando quei pesi di attenzione incrociata, vedremo che nessuna parola punta agli ultimi segmenti vocali lambda."}
{"doc_id": "PJWMkwXVGI", "seg_id": 18, "src_ref": "This means that these three words will be emitted.", "tgt_ref": "Il risultato di tutto ciò è che queste tre parole verranno emesse."}
{"doc_id": "PJWMkwXVGI", "seg_id": 19, "src_ref": "If we look at the main results of EDAtt, we'll plot the simultaneous speech translation results on graphs in which we have BLEU on one side that measures the translation quality, and average lagging that is the latency measure, and we also consider the computational aware average lagging that accounts for the model's computational times to predict the output.", "tgt_ref": "Se guardiamo i principali risultati di EDAtt, rappresenteremo i risultati della traduzione simultanea vocale su grafici in cui da un lato abbiamo BLEU, che misura la qualità della traduzione, e il ritardo medio, che è la misura della latenza. Inoltre, prendiamo in considerazione il ritardo medio computazionale che tiene conto dei tempi di calcolo del modello per prevedere l'output."}
{"doc_id": "PJWMkwXVGI", "seg_id": 20, "src_ref": "So we want our curves to be as high as possible on this plot.", "tgt_ref": "A tal fine, desideriamo che le nostre curve su questo grafico siano quanto più alte possibili."}
{"doc_id": "PJWMkwXVGI", "seg_id": 21, "src_ref": "But also we want that they are shifted on the left.", "tgt_ref": "Allo stesso tempo, intendiamo spostarle a sinistra."}
{"doc_id": "PJWMkwXVGI", "seg_id": 22, "src_ref": "And we compare with popular strategies that are also applied to offline models that are the Wait-k strategy and the Local Agreement.", "tgt_ref": "Proseguendo, confrontiamo il tutto con strategie note che vengono applicate anche a modelli offline, vale a dire la strategia Wait-k e il Local Agreement."}
{"doc_id": "PJWMkwXVGI", "seg_id": 23, "src_ref": "And we compare also with the state-of-the-art architecture specifically tailored for simultaneous pre-translation.", "tgt_ref": "Il confronto si estende all'architettura all'avanguardia, appositamente studiata per la pre-traduzione simultanea."}
{"doc_id": "PJWMkwXVGI", "seg_id": 24, "src_ref": "These are all the results of the simultaneous speech translation strategy on German.", "tgt_ref": "Questi sono tutti i risultati della strategia di traduzione simultanea vocale in tedesco."}
{"doc_id": "PJWMkwXVGI", "seg_id": 25, "src_ref": "And we see that it outperforms all the strategies applied to offline models since the curves are shifted over the left.", "tgt_ref": "Possiamo notare che supera tutte le strategie applicate ai modelli offline, poiché le curve sono spostate a sinistra."}
{"doc_id": "PJWMkwXVGI", "seg_id": 26, "src_ref": "And we also see that if we consider the actual elapsed time or the computational-aware time, that is the fastest strategy.", "tgt_ref": "E vediamo anche che se consideriamo il tempo effettivo trascorso o il tempo di calcolo, questa è la strategia più veloce."}
{"doc_id": "PJWMkwXVGI", "seg_id": 27, "src_ref": "If you want to discover more results, read our paper.", "tgt_ref": "Se volete conoscere gli altri risultati, vi invitiamo a leggere il nostro articolo."}
{"doc_id": "PJWMkwXVGI", "seg_id": 28, "src_ref": "And we also released open source the code and models and simultaneous output to facilitate the reproducibility of our work.", "tgt_ref": "Abbiamo anche rilasciato in open source il codice, i modelli e l'output simultaneo per facilitare la riproducibilità del nostro lavoro."}
{"doc_id": "PJWMkwXVGI", "seg_id": 29, "src_ref": "Thanks for your attention.", "tgt_ref": "Grazie per l'attenzione."}
{"doc_id": "vrydRuOXbT", "seg_id": 0, "src_ref": "Hello everyone, my name is Ying and my colleague Zhiyang and I will be presenting our research on MultiInstruct improving Multi-Modal Zero-Shot Learning via Instruction Tuning.", "tgt_ref": "Ciao a tutti, mi chiamo Ying, e il mio collega Zhiyang e io presenteremo la nostra ricerca su MultiInstruct migliorando l'apprendimento multimodale zero-shot tramite l'Instruction Tuning."}
{"doc_id": "vrydRuOXbT", "seg_id": 1, "src_ref": "So with the advances in large language models, many works started to explore new learning paradigms of reusing pre-trained language models for different downstream tasks in a parameter and data-efficient way.", "tgt_ref": "Con i progressi nei modelli linguistici di grandi dimensioni, molte ricerche hanno iniziato a esplorare nuovi paradigmi di apprendimento del riutilizzo di modelli linguistici pre-addestrati per diverse attività a valle in modo efficiente in termini di parametri e dati."}
{"doc_id": "vrydRuOXbT", "seg_id": 2, "src_ref": "Recently, many studies have shown that instruction tuning enables large language models to perform on unseen tasks in a zero-shot manner by following natural instructions.", "tgt_ref": "Recentemente, molti studi hanno dimostrato che l'ottimizzazione su istruzioni consente ai grandi modelli linguistici di eseguire attività non osservate in modalità zero-shot seguendo istruzioni naturali."}
{"doc_id": "vrydRuOXbT", "seg_id": 3, "src_ref": "However, most previous works on instruction tuning focused on improving the zero-shot performance on language only tasks, while computer vision and multi-modal tasks have been left out.", "tgt_ref": "Tuttavia, la maggior parte dei lavori precedenti sull'adattamento delle istruzioni si è concentrata sul miglioramento delle prestazioni zero-shot su attività solo linguistiche, mentre la visione artificiale e le attività multimodali sono state tralasciate."}
{"doc_id": "vrydRuOXbT", "seg_id": 4, "src_ref": "Therefore, in this work we want to investigate whether instruction tuning a multi-modal pre-trained models can actually improve generalisation to unseen multi-modal tasks.", "tgt_ref": "Pertanto, in questo lavoro vogliamo indagare se l'adattamento a istruzioni di un modello multimodale pre-addestrato può effettivamente migliorare la generalizzazione a compiti multimodali non osservati."}
{"doc_id": "vrydRuOXbT", "seg_id": 5, "src_ref": "Additionally, at the time of our research, we discovered a considerable discrepancy in the availability of instructional datasets between NLP and multi-modal.", "tgt_ref": "Inoltre, al momento della nostra ricerca, abbiamo scoperto una notevole discrepanza nella disponibilità di set di dati di istruzioni tra NLP e multimodale."}
{"doc_id": "vrydRuOXbT", "seg_id": 6, "src_ref": "There exist more than 1600 language-only instruction tasks.", "tgt_ref": "Esistono più di 1.600 attività con istruzione solo in lingua."}
{"doc_id": "vrydRuOXbT", "seg_id": 7, "src_ref": "However, there is no large-scale publicly-available multi-modal instruction task.", "tgt_ref": "Tuttavia, non esiste un'attività di istruzione multimodale su larga scala disponibile al pubblico."}
{"doc_id": "vrydRuOXbT", "seg_id": 8, "src_ref": "Therefore, this motivates us to build a multi-modal instruction tuning dataset.", "tgt_ref": "Pertanto, questo ci motiva a costruire un set di dati di sintonizzazione delle istruzioni multimodali."}
{"doc_id": "vrydRuOXbT", "seg_id": 9, "src_ref": "Here we present MultiInstruct, the first multi-modal instruction tuning benchmark dataset that consists of 62 diverse multi-modal tasks covering 10 broad categories.", "tgt_ref": "Qui presentiamo MultiInstruct, il primo set di dati di riferimento per l'adattamento delle istruzioni multimodali, composto da 62 diverse attività multimodali che coprono 10 ampie categorie."}
{"doc_id": "vrydRuOXbT", "seg_id": 10, "src_ref": "These tasks are derived from 21 existing open-source dataset and each task is equipped with five expert written instructions.", "tgt_ref": "Queste attività derivano da 21 set di dati open source esistenti e ogni attività è dotata di cinque istruzioni scritte da esperti."}
{"doc_id": "vrydRuOXbT", "seg_id": 11, "src_ref": "For investigating multi-modal instruction tuning on our proposed dataset, we take OFA, a unified multi-modal pre-trained model, as our base model.", "tgt_ref": "Per analizzare l' adattamento di istruzioni multimodali sul nostro set di dati proposto, prendiamo come modello di base OFA, un modello pre-addestrato multimodale unificato."}
{"doc_id": "vrydRuOXbT", "seg_id": 12, "src_ref": "OFA uses a unified vocabulary for language, image tokens and the coordinates of a bounding box.", "tgt_ref": "OFA utilizza un vocabolario unificato per la lingua, i token di immagine e le coordinate di un riquadro di delimitazione."}
{"doc_id": "vrydRuOXbT", "seg_id": 13, "src_ref": "Here we show some example instances from our MultiInstruct dataset, to unify the processing of various input and output data types.", "tgt_ref": "Qui mostriamo alcune istanze di esempio dal nostro set di dati MultiInstruct per unificare l'elaborazione di vari tipi di dati di input e output."}
{"doc_id": "vrydRuOXbT", "seg_id": 14, "src_ref": "We follow the method from OFA and formulate all the tasks in a unified sequence-to-sequence format.", "tgt_ref": "Seguiamo il metodo di OFA e formuliamo tutte le attività in un formato unificato da sequenza a sequenza."}
{"doc_id": "vrydRuOXbT", "seg_id": 15, "src_ref": "In which the input text, images, instructions and bounding boxes are represented in the same token space.", "tgt_ref": "In cui il testo di input, le immagini, le istruzioni e i riquadri di delimitazione sono rappresentati nello stesso spazio token."}
{"doc_id": "vrydRuOXbT", "seg_id": 16, "src_ref": "Ok, now I'm going to talk about multi-modal instruction tuning.", "tgt_ref": "Bene, ora parlerò dell'adattamento di istruzioni multimodali."}
{"doc_id": "vrydRuOXbT", "seg_id": 17, "src_ref": "So for the training dataset, we use 53 tasks from 9 groups for training and we sample 10,000 instances per task.", "tgt_ref": "Per il set di dati di addestramento, utilizziamo 53 attività di 9 gruppi per l'addestramento e campioniamo 10.000 istanze per attività."}
{"doc_id": "vrydRuOXbT", "seg_id": 18, "src_ref": "For testing, we reserve the entire common sense reasoning group for testing, and we select additional 5 tasks from VQ and Miscellaneous groups.", "tgt_ref": "Per i test, riserviamo l'intero gruppo di ragionamento di buon senso per i test e selezioniamo altre 5 attività dai gruppi VQ e Varie."}
{"doc_id": "vrydRuOXbT", "seg_id": 19, "src_ref": "We use all the instances in the test split for each task.", "tgt_ref": "Usiamo tutte le istanze nella suddivisione del test per ogni attività."}
{"doc_id": "vrydRuOXbT", "seg_id": 20, "src_ref": "In addition, we randomly sample 20 tasks from the test split of natural instructions as an unseen task for NLP.", "tgt_ref": "Inoltre, campioniamo casualmente 20 attività dalla suddivisione del test delle istruzioni naturali come attività non osservata per NLP."}
{"doc_id": "vrydRuOXbT", "seg_id": 21, "src_ref": "So we use pre-trained OFA large model as a base model.", "tgt_ref": "Quindi, usiamo il modello OFA di grandi dimensioni pre-addestrato come modello di base."}
{"doc_id": "vrydRuOXbT", "seg_id": 22, "src_ref": "During training, we mix all the instances for all the tasks.", "tgt_ref": "Durante l'addestramento, mescoliamo tutte le istanze per tutte le attività."}
{"doc_id": "vrydRuOXbT", "seg_id": 23, "src_ref": "Each instance is randomly combined with one of its five instruction templates.", "tgt_ref": "Ogni istanza viene combinata casualmente con uno dei suoi cinque modelli di istruzione."}
{"doc_id": "vrydRuOXbT", "seg_id": 24, "src_ref": "So during test for each task, we conduct a total of 5 experiments by evaluating the model using one of the five instructions.", "tgt_ref": "Successivamente, durante il test per ciascuna attività, conduciamo un totale di 5 esperimenti valutando il modello utilizzando una delle cinque istruzioni."}
{"doc_id": "vrydRuOXbT", "seg_id": 25, "src_ref": "In each experiment, we report the min and max performance and the standard deviation of the performance across all 5 experiments.", "tgt_ref": "In ogni esperimento, riportiamo le prestazioni minime e massime e la deviazione standard delle prestazioni in tutti e 5 gli esperimenti."}
{"doc_id": "vrydRuOXbT", "seg_id": 26, "src_ref": "If the task is a multi-model classification task, we report accuracy.", "tgt_ref": "Se l'attività è un'attività di classificazione multi-modello, riportiamo l'accuratezza."}
{"doc_id": "vrydRuOXbT", "seg_id": 27, "src_ref": "If it's a multi-modal generation task, we report Rouge-L. For NLP task, we report Rouge-L as well.", "tgt_ref": "Se si tratta di un'attività di generazione multimodale, riportiamo Rouge-L. Riportiamo Rouge-L anche per l'attività di NLP."}
{"doc_id": "vrydRuOXbT", "seg_id": 28, "src_ref": "We also introduce an additional evaluation metric called sensitivity.", "tgt_ref": "Inoltre, introduciamo un'ulteriore metrica di valutazione chiamata sensibilità."}
{"doc_id": "vrydRuOXbT", "seg_id": 29, "src_ref": "So this measures the model's ability to consistently produce the same outputs for the same task regardless of the slight variation in the wording of the instruction.", "tgt_ref": "Ciò misura la capacità del modello di produrre costantemente gli stessi output per la stessa attività, indipendentemente dalla lieve variazione nella formulazione dell'istruzione."}
{"doc_id": "vrydRuOXbT", "seg_id": 30, "src_ref": "Here is our main result.", "tgt_ref": "Ecco il risultato."}
{"doc_id": "vrydRuOXbT", "seg_id": 31, "src_ref": "As we can see, instruction tuning can significantly improve OFA's performance on seen multi-modal tasks.", "tgt_ref": "Come possiamo vedere, l'ottimizzazione delle istruzioni può migliorare significativamente le prestazioni di OFA su attività multimodali osservate."}
{"doc_id": "vrydRuOXbT", "seg_id": 32, "src_ref": "Also, transfer learning from natural instruction dataset can benefit instruction tuning.", "tgt_ref": "Inoltre, l'apprendimento per trasferimento dal set di dati di istruzioni naturali può beneficiare della messa a punto delle istruzioni."}
{"doc_id": "vrydRuOXbT", "seg_id": 33, "src_ref": "Here we can see, as the amount of task increases, the model achieves better performance and in the meantime, lower sensitivity.", "tgt_ref": "Qui possiamo vedere che, all'aumentare della quantità di attività, il modello raggiunge prestazioni migliori e, nel frattempo, una sensibilità inferiore."}
{"doc_id": "vrydRuOXbT", "seg_id": 34, "src_ref": "So we also did one experiment.", "tgt_ref": "Dopodiché abbiamo condotto anche un esperimento."}
{"doc_id": "vrydRuOXbT", "seg_id": 35, "src_ref": "We use one instruction versus 5 instruction.", "tgt_ref": "Usiamo una istruzione contro 5 istruzioni."}
{"doc_id": "vrydRuOXbT", "seg_id": 36, "src_ref": "As we can see, using more instructions can improve the model's overall performance and reduce its sensitivity a lot.", "tgt_ref": "Come possiamo vedere, l'utilizzo di più istruzioni può migliorare le prestazioni complessive del modello e ridurne notevolmente la sensibilità."}
{"doc_id": "vrydRuOXbT", "seg_id": 37, "src_ref": "So this shows the effect of different fine-tuning strategies on the model sensitivity.", "tgt_ref": "Quindi, questo mostra l'effetto di diverse strategie di fine-tuning sulla sensibilità del modello."}
{"doc_id": "vrydRuOXbT", "seg_id": 38, "src_ref": "As we can see by transfer learning from natural instruction datasets, the model can achieve much better sensitivity compared to the original OFA model.", "tgt_ref": "Come possiamo vedere dall'apprendimento per trasferimento da set di dati di istruzioni naturali, il modello può raggiungere una sensibilità molto più elevata rispetto al modello OFA originale."}
{"doc_id": "vrydRuOXbT", "seg_id": 39, "src_ref": "We also can see transfer learning from natural instruction datasets can help OFA to attain much better performance on the natural instruct dataset.", "tgt_ref": "Possiamo anche vedere che l'apprendimento per trasferimento da set di dati di istruzioni naturali può aiutare OFA a ottenere prestazioni molto migliori sul set di dati di istruzioni naturali."}
{"doc_id": "vrydRuOXbT", "seg_id": 40, "src_ref": "So overall, we propose the first large scale multi-model instruction tuning dataset with significantly improved their short capability of OFA, and we explore different transfer learning technique and show their benefits.", "tgt_ref": "Quindi, nel complesso, proponiamo il primo set di dati di messa a punto delle istruzioni multi-modello su larga scala con una capacità di OFA notevolmente migliorata ed esploriamo diverse tecniche di apprendimento per trasferimento mostrandone i vantaggi."}
{"doc_id": "vrydRuOXbT", "seg_id": 41, "src_ref": "We design a new metric called sensitivity.", "tgt_ref": "Progettiamo una nuova metrica chiamata sensibilità."}
{"doc_id": "vrydRuOXbT", "seg_id": 42, "src_ref": "So one more thing, we are collecting a much larger multi-model instruction tuning dataset with around 150 additional vision language tasks and we will release them.", "tgt_ref": "Un'altra cosa: stiamo raccogliendo un set di dati di messa a punto delle istruzioni multi-modello molto più ampio con circa 150 attività di linguaggio visivo aggiuntive e lo renderemo disponibile."}
{"doc_id": "vrydRuOXbT", "seg_id": 43, "src_ref": "So this is a QR code for our data and model.", "tgt_ref": "Questo è un codice QR per i nostri dati e il nostro modello."}
{"doc_id": "vrydRuOXbT", "seg_id": 44, "src_ref": "Thank you.", "tgt_ref": "Grazie."}
{"doc_id": "gUAIqKCjIt", "seg_id": 0, "src_ref": "Hi, everyone.", "tgt_ref": "Buongiorno a tutti."}
{"doc_id": "gUAIqKCjIt", "seg_id": 1, "src_ref": "I'm Koustav Sinha, and I'm pleased to welcome you to our talk of our ACL 2023 paper.", "tgt_ref": "Sono Koustav Sinha e sono felice di darvi il benvenuto al nostro intervento sul nostro articolo ACL 2023."}
{"doc_id": "gUAIqKCjIt", "seg_id": 2, "src_ref": "Language model acceptability judgments are not always robust to context.", "tgt_ref": "Language model acceptability judgments are not always robust to context."}
{"doc_id": "gUAIqKCjIt", "seg_id": 3, "src_ref": "This is a joint work with John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy, and Adina Williams.", "tgt_ref": "Questo è un lavoro congiunto con John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy e Adina Williams."}
{"doc_id": "gUAIqKCjIt", "seg_id": 4, "src_ref": "So in this work, we revisit the minimal pair paradigms.", "tgt_ref": "In questo lavoro, rivisitiamo i paradigmi della coppia minima."}
{"doc_id": "gUAIqKCjIt", "seg_id": 5, "src_ref": "So the minimal pair paradigm basically evaluates language models on top of acceptability judgments.", "tgt_ref": "Il paradigma della coppia minima valuta fondamentalmente i modelli linguistici sulla base dei giudizi di accettabilità."}
{"doc_id": "gUAIqKCjIt", "seg_id": 6, "src_ref": "Which can also include grammaticality like BLiMP, SyntaxGym, or acceptability in terms of stereotypes such as CrowS pairs.", "tgt_ref": "Ciò può anche includere la grammaticalità come BLiMP, SyntaxGym o l'accettabilità in termini di stereotipi come le coppie CrowS."}
{"doc_id": "gUAIqKCjIt", "seg_id": 7, "src_ref": "And in this, minimal pair paradigm, the typical way to evaluate language models is that you show like an acceptable sentence or a grammatical sentence and then you show an acceptable sentence or an ungrammatical sentence.", "tgt_ref": "E, in questo paradigma della coppia minima, il modo tipico per valutare i modelli linguistici è mostrare una frase accettabile o una frase grammaticale e poi mostrare una frase accettabile o una frase non grammaticale."}
{"doc_id": "gUAIqKCjIt", "seg_id": 8, "src_ref": "And then the hope is that the model, basically, puts more probability to the acceptable sentence.", "tgt_ref": "Dopodiché, la speranza è che il modello, in sostanza, aggiunga maggior probabilità alla frase accettabile."}
{"doc_id": "gUAIqKCjIt", "seg_id": 9, "src_ref": "The current MPP pipeline basically doesn't allow us to evaluate a model's acceptance towards longer sentences.", "tgt_ref": "L'attuale pipeline MPP non ci permette di valutare l'accettazione di un modello in direzione di frasi più lunghe."}
{"doc_id": "gUAIqKCjIt", "seg_id": 10, "src_ref": "These days large language models are coming up with longer and longer context windows.", "tgt_ref": "In questi giorni i grandi modelli linguistici sono caratterizzati da finestre di contesto sempre più lunghe."}
{"doc_id": "gUAIqKCjIt", "seg_id": 11, "src_ref": "So it's crucial that we evaluate the models' acceptability throughout the context window and that is what we are trying to do here.", "tgt_ref": "Pertanto è fondamentale valutare l'accettabilità dei modelli in tutta la finestra di contesto ed è quello che stiamo cercando di fare qui."}
{"doc_id": "gUAIqKCjIt", "seg_id": 12, "src_ref": "We're trying to revisit the MPP pipeline by asking the model to evaluate acceptability on longer and longer sequences.", "tgt_ref": "Stiamo cercando di rivisitare la pipeline MPP chiedendo al modello di valutare l'accettabilità su sequenze sempre più lunghe."}
{"doc_id": "gUAIqKCjIt", "seg_id": 13, "src_ref": "So that is the approach.", "tgt_ref": "Ecco in cosa consiste questo approccio."}
{"doc_id": "gUAIqKCjIt", "seg_id": 14, "src_ref": "So what we do is that to simulate these longer sequences, we revisit the data sets themselves and then we recreate sentences by choosing acceptable or unacceptable sentences from those datasets.", "tgt_ref": "Quindi, quello che facciamo per simulare queste sequenze più lunghe è rivisitare gli insiemi di dati stessi e ricreare le frasi scegliendo quelle accettabili o inaccettabili da quegli insiemi di dati."}
{"doc_id": "gUAIqKCjIt", "seg_id": 15, "src_ref": "So for example, here we have chosen like a typical pair of grammaticality from the BLiMP data set from the Adjunct Island case.", "tgt_ref": "Ad esempio, qui abbiamo scelto una tipica coppia di grammaticalità dal set di dati BLiMP dal caso Adjunct Island."}
{"doc_id": "gUAIqKCjIt", "seg_id": 16, "src_ref": "And what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure.", "tgt_ref": "E ciò che facciamo è ricreare sequenze più lunghe che siano accettabili e che abbiano la stessa corrispondenza della struttura grammaticale."}
{"doc_id": "gUAIqKCjIt", "seg_id": 17, "src_ref": "We extract grammatical sentences from Adjunct Island and then we add it as a prefix to both the acceptable query and the unacceptable query.", "tgt_ref": "Estrarremo frasi grammaticali da Adjunct Island e le aggiungeremo come prefisso sia alla query accettabile che a quella inaccettabile."}
{"doc_id": "gUAIqKCjIt", "seg_id": 18, "src_ref": "So we can do the same thing by choosing unacceptable sentences from the same matching, and that could also be used to test the models acceptability.", "tgt_ref": "Quindi, possiamo fare la stessa cosa scegliendo frasi inaccettabili dalla stessa corrispondenza, e questo potrebbe anche essere usato per testare l'accettabilità dei modelli."}
{"doc_id": "gUAIqKCjIt", "seg_id": 19, "src_ref": "And we can also do the same by choosing sentences from a different subset or a different data set.", "tgt_ref": "Possiamo anche fare lo stesso scegliendo frasi da un sottoinsieme diverso o da un diverso insieme di dati."}
{"doc_id": "gUAIqKCjIt", "seg_id": 20, "src_ref": "So that is what we call as the mismatch scenario.", "tgt_ref": "Questo è ciò che chiamiamo scenario di disallineamento."}
{"doc_id": "gUAIqKCjIt", "seg_id": 21, "src_ref": "So here the sentences are still coming from a, relevant data sets but it's not from the same data set that you are evaluating with.", "tgt_ref": "Qui le frasi provengono ancora da insiemi di dati pertinenti, ma non dallo stesso insieme di dati con cui si sta effettuando la valutazione."}
{"doc_id": "gUAIqKCjIt", "seg_id": 22, "src_ref": "And we can do the same for unacceptability case.", "tgt_ref": "E possiamo fare lo stesso per il caso dell'inaccettabilità."}
{"doc_id": "gUAIqKCjIt", "seg_id": 23, "src_ref": "Finally, we can choose sentences from a completely unrelated domain such as Wikipedia.", "tgt_ref": "Infine, possiamo scegliere frasi da un dominio completamente estraneo come Wikipedia."}
{"doc_id": "gUAIqKCjIt", "seg_id": 24, "src_ref": "So this will tell us like whether the models acceptability judgments are actually impacted by any context, like, whether the context is coming from a different subset of the data set, or whether it's like completely irrelevant, to the current like to the sentence that we are looking at.", "tgt_ref": "Ciò ci dirà se i giudizi di accettabilità dei modelli sono effettivamente influenzati da qualsiasi contesto, ad esempio se il contesto proviene da un sottoinsieme diverso dell'insieme di dati, o se è completamente irrilevante per la frase corrente che stiamo analizzando."}
{"doc_id": "gUAIqKCjIt", "seg_id": 25, "src_ref": "So how does the model do?", "tgt_ref": "Dunque, come funziona il modello?"}
{"doc_id": "gUAIqKCjIt", "seg_id": 26, "src_ref": "So first, we look at the Wikipedia sentences, which are completely irrelevant to the current query pair, and there we find that the MPP judgments are mostly robust for arbitrary context length.", "tgt_ref": "Prima di tutto, esaminiamo le frasi di Wikipedia, che sono completamente irrilevanti per la coppia di query corrente, e lì scopriamo che i giudizi MPP sono per lo più affidabili per una lunghezza del contesto arbitraria."}
{"doc_id": "gUAIqKCjIt", "seg_id": 27, "src_ref": "We increase the context length toward up to 1024 for to max out OPT and GPT 2 models.", "tgt_ref": "Aumentiamo la lunghezza del contesto fino a 1.024 per massimizzare i modelli OPT e GPT 2."}
{"doc_id": "gUAIqKCjIt", "seg_id": 28, "src_ref": "And we saw here in the orange dotted line, the MPP judgments are relatively stable.", "tgt_ref": "Abbiamo visto nella linea tratteggiata arancione che i giudizi MPP sono relativamente stabili."}
{"doc_id": "gUAIqKCjIt", "seg_id": 29, "src_ref": "Now, what happens when we choose sentences from the same data set?", "tgt_ref": "Ora, cosa succede quando scegliamo frasi dallo stesso insieme di dati?"}
{"doc_id": "gUAIqKCjIt", "seg_id": 30, "src_ref": "So here we are choosing or creating sentences from acceptable and unacceptable domains from the same BLiMP or SyntaxGym dataset.", "tgt_ref": "Qui stiamo scegliendo o creando frasi da domini accettabili e inaccettabili dallo stesso insieme di dati BLiMP o SyntaxGym."}
{"doc_id": "gUAIqKCjIt", "seg_id": 31, "src_ref": "And there we see that the MPP judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes.", "tgt_ref": "Notiamo che i giudizi MPP aumentano o diminuiscono in modo significativo quando si aggiungono prefissi accettabili o prefissi inaccettabili."}
{"doc_id": "gUAIqKCjIt", "seg_id": 32, "src_ref": "But when we match the structure, that is when we choose the sentences from the same phenomena in BLiMP or SyntaxGym, we see a massive increase or a massive decrease of the MPP judgement for the model, depending on whether the chosen prefix is acceptable or unacceptable.", "tgt_ref": "Ma quando abbiniamo la struttura, cioè quando scegliamo le frasi dagli stessi fenomeni in BLiMP o SyntaxGym, vediamo un aumento massiccio o una diminuzione massiccia del giudizio MPP per il modello, a seconda che il prefisso scelto sia accettabile o inaccettabile."}
{"doc_id": "gUAIqKCjIt", "seg_id": 33, "src_ref": "Now this and this is very large like this effect, increases throughout the context length and this would probably affect like newer language models which has large context window.", "tgt_ref": "Ciò è molto grande come questo effetto, aumenta per tutta la lunghezza del contesto e questo probabilmente influenzerebbe modelli linguistici simili più recenti che hanno una finestra di contesto ampia."}
{"doc_id": "gUAIqKCjIt", "seg_id": 34, "src_ref": "So why does the match prefix affect the language model judgement so much?", "tgt_ref": "Allora perché il prefisso di corrispondenza influisce così tanto sul giudizio del modello linguistico?"}
{"doc_id": "gUAIqKCjIt", "seg_id": 35, "src_ref": "So we did a series of analysis where we tried to perturb the input sentence by, trying to preserve the relevant structure but adding like noise to the input.", "tgt_ref": "Abbiamo condotto una serie di analisi in cui abbiamo cercato di perturbare la frase di input, provando al contempo a preservare la struttura rilevante ma aggiungendo rumore all'input."}
{"doc_id": "gUAIqKCjIt", "seg_id": 36, "src_ref": "And after doing like several of these perturbations, we find that none of these noises are actually making the model like change its course in terms of how it shows us the MPP judgement print.", "tgt_ref": "E dopo aver eseguito molte di queste perturbazioni, scopriamo che nessuno di questi rumori sta effettivamente facendo sì che il modello cambi il suo corso in termini di come ci mostra la stampa del giudizio MPP."}
{"doc_id": "gUAIqKCjIt", "seg_id": 37, "src_ref": "Basically, we find that the models are sensitive to the perturbed sentences in similar ways.", "tgt_ref": "Fondamentalmente, scopriamo che i modelli sono sensibili alle frasi perturbate in modi simili."}
{"doc_id": "gUAIqKCjIt", "seg_id": 38, "src_ref": "That is, when we perturb the sentences in the acceptable domain, we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain, we see decrease in MPP judgments in similar fashion.", "tgt_ref": "Cioè, quando perturbiamo le frasi nel dominio accettabile, vediamo un aumento simile in tutte le perturbazioni e quando perturbiamo le frasi nel dominio inaccettabile, vediamo una diminuzione dei giudizi MPP in modo simile."}
{"doc_id": "gUAIqKCjIt", "seg_id": 39, "src_ref": "So, the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.", "tgt_ref": "Quindi, i punti chiave del nostro lavoro sono che i modelli linguistici sono sensibili alle caratteristiche sintattiche e semantiche latenti che sono condivise tra le frasi."}
{"doc_id": "gUAIqKCjIt", "seg_id": 40, "src_ref": "And the MPP evaluation the way that we do it currently with short and single sentence input, may not fully capture the language models abstract knowledge throughout the context window.", "tgt_ref": "E la valutazione MPP, il modo in cui la effettuiamo attualmente con l'input di frasi brevi e singole, potrebbe non cogliere appieno la conoscenza astratta dei modelli linguistici in tutta la finestra di contesto."}
{"doc_id": "gUAIqKCjIt", "seg_id": 41, "src_ref": "Please read our paper for more details of our experiments.", "tgt_ref": "Vi invitiamo a leggere il nostro articolo per maggiori dettagli sui nostri esperimenti."}
{"doc_id": "gUAIqKCjIt", "seg_id": 42, "src_ref": "Thank you for listening.", "tgt_ref": "Grazie dell'ascolto."}
{"doc_id": "wJAPXMIoIG", "seg_id": 0, "src_ref": "Hello everyone, my name is Yusen Zhang from the Penn State University.", "tgt_ref": "Ciao a tutti, mi chiamo Yusen Zhang della Penn State University."}
{"doc_id": "wJAPXMIoIG", "seg_id": 1, "src_ref": "Today I'm going to present our work \"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations\".", "tgt_ref": "Oggi presenterò il nostro lavoro \"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations\"."}
{"doc_id": "wJAPXMIoIG", "seg_id": 2, "src_ref": "So, semantic parsing is a task to build semantic representations of user queries such as SQL and Lambda Calculus.", "tgt_ref": "Dunque, l'analisi semantica è un'attività per creare rappresentazioni semantiche di query utente come SQL e Lambda Calculus."}
{"doc_id": "wJAPXMIoIG", "seg_id": 3, "src_ref": "And Cross-Lingual Semantic Parsing is the task to translate queries in multiple natural languages into multiple meaning representations.", "tgt_ref": "E l'analisi semantica cross-linguistica costituisce il compito di tradurre le query in più lingue naturali in più rappresentazioni di significato."}
{"doc_id": "wJAPXMIoIG", "seg_id": 4, "src_ref": "As shown in this figure, we need to translate the query in multiple natural languages using neural models to SQL, Lambda or FunQL, and etcetera.", "tgt_ref": "Come mostrato in questa figura, dobbiamo tradurre la query in più lingue naturali utilizzando modelli neurali in SQL, Lambda o FunQL e così via."}
{"doc_id": "wJAPXMIoIG", "seg_id": 5, "src_ref": "Existing cross-lingual semantic parsing models are separately proposed and evaluated on data set of limited tasks and applications.", "tgt_ref": "I modelli di analisi semantica translinguistica esistenti sono proposti e valutati separatamente su un set di dati di attività e applicazioni limitate."}
{"doc_id": "wJAPXMIoIG", "seg_id": 6, "src_ref": "For instance, there are lots of coverage on certain natural languages.", "tgt_ref": "Ad esempio, la letteratura su alcune lingue naturali è molto ampia."}
{"doc_id": "wJAPXMIoIG", "seg_id": 7, "src_ref": "But Chinese is missing and lack of coverage on certain meaning representation.", "tgt_ref": "Tuttavia mancano il cinese e i riferimenti su alcune rappresentazioni di significato."}
{"doc_id": "wJAPXMIoIG", "seg_id": 8, "src_ref": "The Lambda calculus is missing, or they're only evaluated on certain neural models.", "tgt_ref": "Manca il calcolo lambda oppure sono valutati solo su alcuni modelli neurali."}
{"doc_id": "wJAPXMIoIG", "seg_id": 9, "src_ref": "For example, there's only one single model to evaluate them.", "tgt_ref": "Ad esempio, è presente solo un modello per valutarli."}
{"doc_id": "wJAPXMIoIG", "seg_id": 10, "src_ref": "So to this end we propose XSemPLR.", "tgt_ref": "Quindi, a tal fine, proponiamo XSemPLR."}
{"doc_id": "wJAPXMIoIG", "seg_id": 11, "src_ref": "We provide a uniform data set XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations.", "tgt_ref": "Forniamo un set di dati uniforme XSemPLR per l'analisi semantica translinguistica in più lingue naturali e rappresentazioni di significato."}
{"doc_id": "wJAPXMIoIG", "seg_id": 12, "src_ref": "It contains 9 datasets in various domains, 5 semantic parsing tasks, 8 meaning representations, and 22 natural languages in 15 language families.", "tgt_ref": "Contiene 9 set di dati in vari domini, 5 attività di analisi semantica, 8 rappresentazioni di significato e 22 lingue naturali in 15 famiglie linguistiche."}
{"doc_id": "wJAPXMIoIG", "seg_id": 13, "src_ref": "And to better evaluate our benchmark, we consider the six settings for training and evaluation.", "tgt_ref": "E per valutare meglio il nostro parametro di riferimento, consideriamo le sei impostazioni per l'addestramento e la valutazione."}
{"doc_id": "wJAPXMIoIG", "seg_id": 14, "src_ref": "The first one is Translate-Test.", "tgt_ref": "Il primo è Translate-Test."}
{"doc_id": "wJAPXMIoIG", "seg_id": 15, "src_ref": "We use Google Translate API to translate source to the target language, then use monolingual model to train and evaluation.", "tgt_ref": "Utilizziamo l'API di Google Translate per tradurre la fonte nella lingua di destinazione, quindi utilizziamo il modello monolingue per l'addestramento e la valutazione."}
{"doc_id": "wJAPXMIoIG", "seg_id": 16, "src_ref": "And for example, we train the English model on English query and during inference we translate the German query using API to English and then use the trained model to predict the SQL.", "tgt_ref": "Per esempio, addestriamo il modello inglese sulla query inglese e durante l'inferenza traduciamo la query tedesca utilizzando l'API in inglese e, successivamente, utilizziamo il modello addestrato per prevedere l'SQL."}
{"doc_id": "wJAPXMIoIG", "seg_id": 17, "src_ref": "And we'll also test Monolingual Model.", "tgt_ref": "Dopodiché testeremo il modello monolingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 18, "src_ref": "In this setting, the source language is the same as target language, for example German to German or English to English.", "tgt_ref": "In questa impostazione, la lingua di origine è la stessa della lingua di destinazione, ad esempio da tedesco a tedesco o da inglese a inglese."}
{"doc_id": "wJAPXMIoIG", "seg_id": 19, "src_ref": "We also test Monolingual Few-shot setting by training monolingual models with only 10% of training data.", "tgt_ref": "Testiamo anche l'impostazione Monolingual Few-shot addestrando modelli monolingue con solo il 10% dei dati di addestramento."}
{"doc_id": "wJAPXMIoIG", "seg_id": 20, "src_ref": "And we test Multilingual Model which we train one multilingual model for all languages.", "tgt_ref": "E testiamo il modello multilingue, ossia addestriamo un modello multilingue per tutte le lingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 21, "src_ref": "For example, we put the German, English, Chinese queries together to train a multilingual model.", "tgt_ref": "Ad esempio, mettiamo insieme le query tedesche, inglesi e cinesi per addestrare un modello multilingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 22, "src_ref": "And during inference we can use this model to translate German queries or Chinese queries, et cetera.", "tgt_ref": "E durante l'inferenza possiamo usare questo modello per tradurre query tedesche o cinesi, eccetera."}
{"doc_id": "wJAPXMIoIG", "seg_id": 23, "src_ref": "And we also consider Cross-lingual Zero-shot and Few-shot transfer.", "tgt_ref": "Consideriamo anche il trasferimento Cross-lingual Zero-shot e Few-shot."}
{"doc_id": "wJAPXMIoIG", "seg_id": 24, "src_ref": "We train on one source language and transfer to another language.", "tgt_ref": "Ci esercitiamo su una lingua di partenza e passiamo a un'altra lingua."}
{"doc_id": "wJAPXMIoIG", "seg_id": 25, "src_ref": "So during training, we train it on English queries or the combination of English and German Few-shot queries to train a multilingual model to predict the SQL output.", "tgt_ref": "Quindi, durante l'addestramento, la addestriamo su query in inglese o sulla combinazione di query Few-shot in inglese e tedesco per addestrare un modello multilingue a prevedere l'output SQL."}
{"doc_id": "wJAPXMIoIG", "seg_id": 26, "src_ref": "And we also find many interesting results.", "tgt_ref": "E troviamo anche molti risultati interessanti."}
{"doc_id": "wJAPXMIoIG", "seg_id": 27, "src_ref": "So, regarding analysis of monolingual models, we evaluate on two groups of models including Encoder-PTR which stands for Multilingual Pretrained Encoders with Pointer-based Decoders, such as XLM-R + PTR and mBERT + PTR.", "tgt_ref": "Per quanto riguarda l'analisi dei modelli monolingue, valutiamo due gruppi di modelli tra cui Encoder-PTR che sta per Multilingual Pretrained Encoders with Pointer-based Decoders, come XLM-R + PTR e mBERT + PTR."}
{"doc_id": "wJAPXMIoIG", "seg_id": 28, "src_ref": "And, we also evaluate Encoder-Decoder models, which is Multilingual Pretrained Encoder-Decoder Models, such as mBART and mT5.", "tgt_ref": "Inoltre, valutiamo anche i modelli Encoder-Decoder, che sono modelli Encoder-Decoder preaddestrati multilingue, come mBART e mT5."}
{"doc_id": "wJAPXMIoIG", "seg_id": 29, "src_ref": "We found that Encoder-Decoder obtains the best performance on all nine datasets.", "tgt_ref": "Abbiamo notato che Encoder-Decoder ottiene le migliori prestazioni su tutti e nove i set di dati."}
{"doc_id": "wJAPXMIoIG", "seg_id": 30, "src_ref": "And we evaluate on mT5 and XLM-R + PTR on multilingual setting.", "tgt_ref": "E valutiamo su mT5 e XLM-R + PTR su impostazione multilingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 31, "src_ref": "We found that Encoder-Decoder or Encoder-PTR can be improved by training in a mixture of various languages.", "tgt_ref": "Abbiamo scoperto che Encoder-Decoder o Encoder-PTR possono essere migliorati attraverso l'addestramento in una combinazione di varie lingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 32, "src_ref": "We found it is because most of the major natural languages can obtain performance gain, except that English performance drops in seven datasets and only gains in three datasets.", "tgt_ref": "Abbiamo osservato che ciò accade perché la maggior parte delle principali lingue naturali può ottenere un guadagno di prestazioni, tranne per il fatto che le prestazioni in inglese scendono in sette set di dati e guadagnano solo in tre set di dati."}
{"doc_id": "wJAPXMIoIG", "seg_id": 33, "src_ref": "I think this is known as the \"Curse of Multilinguality\".", "tgt_ref": "Credo che ciò sia noto come la \"maledizione multilinguistica\"."}
{"doc_id": "wJAPXMIoIG", "seg_id": 34, "src_ref": "We also compare the cross-language performance gap.", "tgt_ref": "Confrontiamo anche il divario delle prestazioni tra lingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 35, "src_ref": "In this figure, the blue line is Cross-lingual Few-shot transfer.", "tgt_ref": "In questa figura, la linea blu rappresenta il trasferimento Cross-lingual Few-shot."}
{"doc_id": "wJAPXMIoIG", "seg_id": 36, "src_ref": "The orange line is Cross-lingual Zero-shot transfer.", "tgt_ref": "La linea arancione rappresenta il trasferimento Cross-lingual Zero-shot."}
{"doc_id": "wJAPXMIoIG", "seg_id": 37, "src_ref": "While the green line is the Monolingual Setting.", "tgt_ref": "Mentre la linea verde rappresenta l'impostazione monolingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 38, "src_ref": "We found that, by comparing the green and orange line, we found the Zero-shot setting, the Cross-lingual transfer performance gap is significant, and then comparing the blue and orange lines, we found that with the Few-shot setting the transfer gap is shortened rapidly.", "tgt_ref": "Confrontando la linea verde e arancione, abbiamo trovato l'impostazione Zero-shot, il divario di prestazioni del trasferimento translinguistico è significativo, e poi confrontando le linee blu e arancione, abbiamo scoperto che con l'impostazione Few-shot il divario di trasferimento si riduce rapidamente."}
{"doc_id": "wJAPXMIoIG", "seg_id": 39, "src_ref": "We also find some other interesting findings.", "tgt_ref": "Rileviamo anche altri risultati interessanti."}
{"doc_id": "wJAPXMIoIG", "seg_id": 40, "src_ref": "For example, Encoder-Decoder outperforms previous work or achieves comparable results.", "tgt_ref": "Ad esempio, Encoder-Decoder supera i lavori precedenti o raggiunge risultati comparabili."}
{"doc_id": "wJAPXMIoIG", "seg_id": 41, "src_ref": "Pretraining on English natural language can significantly boost the performance of Few-shot on target natural languages, and we found multilingual language models such as Codex and BLOOM are still inadequate for cross-lingual semantic parsing tasks.", "tgt_ref": "Il pre-addestramento sul linguaggio naturale inglese può aumentare significativamente le prestazioni di Few-shot sulle lingue naturali di destinazione e abbiamo scoperto che i modelli linguistici multilingue come Codex e BLOOM sono ancora inadeguati per le attività di analisi semantica cross-linguistica."}
{"doc_id": "wJAPXMIoIG", "seg_id": 42, "src_ref": "To sum up, we build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.", "tgt_ref": "Per riassumere, costruiamo XSemPLR, un benchmark unificato per l'analisi semantica cross-linguistica con più lingue naturali e rappresentazioni di significato."}
{"doc_id": "wJAPXMIoIG", "seg_id": 43, "src_ref": "We conduct a comprehensive benchmark study on three representative types of multilingual language models.", "tgt_ref": "Conduciamo uno studio di benchmark completo su tre tipi rappresentativi di modelli linguistici multilingue."}
{"doc_id": "wJAPXMIoIG", "seg_id": 44, "src_ref": "And our results show many interesting findings.", "tgt_ref": "E i nostri risultati mostrano molti risultati interessanti."}
{"doc_id": "wJAPXMIoIG", "seg_id": 45, "src_ref": "And et cetera.", "tgt_ref": "Eccetera."}
{"doc_id": "wJAPXMIoIG", "seg_id": 46, "src_ref": "And welcome to visit our paper and code.", "tgt_ref": "Siete invitati a consultare il nostro articolo e il nostro codice."}
{"doc_id": "wJAPXMIoIG", "seg_id": 47, "src_ref": "Thanks for listening.", "tgt_ref": "Grazie per l'attenzione."}
{"doc_id": "miPjvjWOvI", "seg_id": 0, "src_ref": "Hello everyone, my name is David Vilar, and I will be giving a short review of the paper \"Prompting PaLM for Translation: Assessing Strategies and Performance.\"", "tgt_ref": "Ciao a tutti, mi chiamo David Vilar. Mi trovo qui per offrirvi una panoramica dell'articolo \"Prompting PaLM for Translation: Assessing Strategies and Performance\"."}
{"doc_id": "miPjvjWOvI", "seg_id": 1, "src_ref": "This is joint work with my colleagues from Google Translate.", "tgt_ref": "Questo è un lavoro congiunto con i miei colleghi di Google Translate."}
{"doc_id": "miPjvjWOvI", "seg_id": 2, "src_ref": "PaLM is a 540 billion-parameter large language model presented last year in 2022.", "tgt_ref": "PaLM è un modello linguistico di grandi dimensioni con 540 miliardi di parametri presentato lo scorso anno, nel 2022."}
{"doc_id": "miPjvjWOvI", "seg_id": 3, "src_ref": "It's trained on a large collection of text, comprising 780 billion tokens.", "tgt_ref": "È addestrato su una vasta raccolta di testi, che comprende 780 miliardi di token."}
{"doc_id": "miPjvjWOvI", "seg_id": 4, "src_ref": "At the time of publication, it achieved state-of-the-art in hundreds of NLP tasks.", "tgt_ref": "Al momento della pubblicazione, ha raggiunto lo stato dell'arte in centinaia di attività NLP."}
{"doc_id": "miPjvjWOvI", "seg_id": 5, "src_ref": "In this work, we present the first systematic study of large language model prompting for machine translation.", "tgt_ref": "In questo lavoro, presentiamo il primo studio sistematico di prompting di grandi modelli linguistici per la traduzione automatica."}
{"doc_id": "miPjvjWOvI", "seg_id": 6, "src_ref": "We evaluated the transition capability of such models using the best practices of the MT community.", "tgt_ref": "Abbiamo valutato la capacità di transizione di tali modelli utilizzando le migliori pratiche della comunità MT."}
{"doc_id": "miPjvjWOvI", "seg_id": 7, "src_ref": "This involves using the latest test sets to avoid an overlap of the test data with the training data of the language model.", "tgt_ref": "Ciò comporta l'utilizzo dei set di test più recenti per evitare una sovrapposizione dei dati di test con i dati di addestramento del modello linguistico."}
{"doc_id": "miPjvjWOvI", "seg_id": 8, "src_ref": "And we compared to state-of-the-art systems, so the best performing system, so the WMT evaluation.", "tgt_ref": "E abbiamo eseguito un confronto con i sistemi all'avanguardia, quindi con il sistema più performante, sulla base della valutazione WMT."}
{"doc_id": "miPjvjWOvI", "seg_id": 9, "src_ref": "We use state-of-the-art, neural MT metrics, and additionally also show expert-based human evaluation results.", "tgt_ref": "Facciamo ricorso a metriche di MT neurale all'avanguardia e mostriamo i risultati della valutazione umana effettuata da esperti."}
{"doc_id": "miPjvjWOvI", "seg_id": 10, "src_ref": "Finally, we provide some recommendations for prompt selection strategies.", "tgt_ref": "Infine, forniamo alcune raccomandazioni per strategie di selezione rapida."}
{"doc_id": "miPjvjWOvI", "seg_id": 11, "src_ref": "The prompting has a big influence on the performance of the LLMs for translation, as we can see in a simple experiment, where we used one-shot prompting and provided two different prompts for each sentence.", "tgt_ref": "Il prompting ha una grande influenza sulle prestazioni dei LLM per la traduzione, come possiamo vedere in un semplice esperimento, in cui abbiamo utilizzato un prompting one-shot e fornito due diversi prompt per ogni frase."}
{"doc_id": "miPjvjWOvI", "seg_id": 12, "src_ref": "The majority of sentences 516 out of 1,000.", "tgt_ref": "La maggior parte delle frasi, 516 su 1.000."}
{"doc_id": "miPjvjWOvI", "seg_id": 13, "src_ref": "The difference observed is of more than one BLEURT points.", "tgt_ref": "La differenza osservata non si limita al singolo punto BLEURT."}
{"doc_id": "miPjvjWOvI", "seg_id": 14, "src_ref": "And this can go, in extreme cases, up to 40 BLEURT points.", "tgt_ref": "E questo può arrivare, in casi estremi, fino a 40 punti BLEURT."}
{"doc_id": "miPjvjWOvI", "seg_id": 15, "src_ref": "So, it's important to select a good prompting strategy.", "tgt_ref": "Quindi, è importante selezionare una buona strategia di prompting."}
{"doc_id": "miPjvjWOvI", "seg_id": 16, "src_ref": "In our experiments, we settled for a 5-shot prompting strategy where we just marked each sentence that we provide to the system, with the language it's in.", "tgt_ref": "Nei nostri esperimenti, ci siamo accontentati di una strategia di prompting 5-shot in cui non abbiamo fatto altro che contrassegnare ogni frase messa a disposizione del sistema con la lingua in cui è elaborata."}
{"doc_id": "miPjvjWOvI", "seg_id": 17, "src_ref": "So in this example here, where we perform translation from German into English, the German sentences, the source sentences, are marked with German colon and the English translations with English colon.", "tgt_ref": "Quindi, in questo esempio qui, dove eseguiamo la traduzione dal tedesco all'inglese, le frasi in tedesco, nella lingua di origine, sono contrassegnate con i due punti tedeschi e le traduzioni inglesi con i due punti inglesi."}
{"doc_id": "miPjvjWOvI", "seg_id": 18, "src_ref": "We saw that the actual form of the prompting doesn't have a big influence in the case of several short promptings.", "tgt_ref": "Abbiamo visto che la forma effettiva del prompt non ha una grande influenza nel caso di svariati prompt brevi."}
{"doc_id": "miPjvjWOvI", "seg_id": 19, "src_ref": "It's crucial for zero and one-shot prompting.", "tgt_ref": "Ciò si rivela fondamentale per i prompt zero-shot e one-shot."}
{"doc_id": "miPjvjWOvI", "seg_id": 20, "src_ref": "And when we go, as in our case, to five-shot prompting, there is nearly no difference to the actual form of the prompting.", "tgt_ref": "E quando operiamo con cinque prompt, come nel nostro caso, non emerge quasi alcuna differenza con la forma effettiva del prompting."}
{"doc_id": "miPjvjWOvI", "seg_id": 21, "src_ref": "It's the examples that carry most of the weight.", "tgt_ref": "Si tratta degli esempi che portano la maggior parte del peso."}
{"doc_id": "miPjvjWOvI", "seg_id": 22, "src_ref": "The summary of our experimental results is that the example quality is more important than the similarity to the source sentence.", "tgt_ref": "La sintesi dei nostri risultati sperimentali è che la qualità dell'esempio è più importante della somiglianza con la frase di origine."}
{"doc_id": "miPjvjWOvI", "seg_id": 23, "src_ref": "So it's important to select the examples from high-quality translations.", "tgt_ref": "Quindi è importante selezionare gli esempi da traduzioni di alta qualità."}
{"doc_id": "miPjvjWOvI", "seg_id": 24, "src_ref": "In particular, we compare the selecting prompts from the training data for the WMT evaluations on the dev data.", "tgt_ref": "In particolare, confrontiamo i prompt di selezione dai dati di addestramento per le valutazioni WMT sui dati di sviluppo."}
{"doc_id": "miPjvjWOvI", "seg_id": 25, "src_ref": "The dev data is much more curated, and with higher quality than the training data, that it's more noisy.", "tgt_ref": "I dati di sviluppo sono molto più curati e di qualità superiore rispetto ai dati di addestramento, che invece sono più rumorosi."}
{"doc_id": "miPjvjWOvI", "seg_id": 26, "src_ref": "And their results so a better performance when using the dev data.", "tgt_ref": "E i loro risultati offrono prestazioni migliori quando si utilizzano i dati di sviluppo."}
{"doc_id": "miPjvjWOvI", "seg_id": 27, "src_ref": "Nevertheless, specialized state-of-the-art systems have a substantial advantage over the PaLM translations.", "tgt_ref": "Tuttavia, i sistemi specializzati all'avanguardia presentano un vantaggio sostanziale rispetto alle traduzioni PaLM."}
{"doc_id": "miPjvjWOvI", "seg_id": 28, "src_ref": "But, PaLM comes pretty close to a commercial system.", "tgt_ref": "PaLM si avvicina abbastanza a un sistema commerciale."}
{"doc_id": "miPjvjWOvI", "seg_id": 29, "src_ref": "In our case, we chose to evaluate with Google Translate.", "tgt_ref": "Nel nostro caso, abbiamo scelto di procedere alla valutazione con Google Translate."}
{"doc_id": "miPjvjWOvI", "seg_id": 30, "src_ref": "The insights that we gained from the human evaluation that we performed using the MQM framework said that the fluency of PaLM is comparable to state-of-the-art systems but the main difference comes from the accuracy.", "tgt_ref": "Le intuizioni acquisite dalla valutazione umana che abbiamo eseguito utilizzando il framework MQM ci hanno fatto scoprire che la fluidità di PaLM è paragonabile ai sistemi all'avanguardia, ma la differenza principale deriva in particolare dalla precisione."}
{"doc_id": "miPjvjWOvI", "seg_id": 31, "src_ref": "So, in particular, the most common errors are omission errors.", "tgt_ref": "Quindi, gli errori più comuni sono quelli di omissione."}
{"doc_id": "miPjvjWOvI", "seg_id": 32, "src_ref": "So, it seems that PaLM chooses to produce a better-sounding translation, sometimes by dropping parts of the source sentence that are made in translation.", "tgt_ref": "Sembra che PaLM scelga di produrre una traduzione migliore, a volte tralasciando parti della frase di partenza che vengono fatte in traduzione."}
{"doc_id": "miPjvjWOvI", "seg_id": 33, "src_ref": "However, the \"Style/Awkward\" category for PaLM is lower than for the state-of-the-art systems, which is an additional signal that PaLM provides really fluent output, but still with some problems of accuracy.", "tgt_ref": "Tuttavia, la categoria \"Style/Awkward\" per PaLM è inferiore rispetto ai sistemi all'avanguardia, il che è un segnale ulteriore che PaLM fornisce un output realmente fluente, ma ancora contraddistinto da alcuni problemi di precisione."}
{"doc_id": "miPjvjWOvI", "seg_id": 34, "src_ref": "And that's it for this really short overview.", "tgt_ref": "E questo è tutto per ora."}
{"doc_id": "miPjvjWOvI", "seg_id": 35, "src_ref": "For more details, please come to the full presentation of the paper.", "tgt_ref": "Per maggiori dettagli, siete invitati a partecipare alla presentazione completa dell'articolo."}
{"doc_id": "miPjvjWOvI", "seg_id": 36, "src_ref": "Thank you very much.", "tgt_ref": "Grazie mille."}
{"doc_id": "krJSAnVcGR", "seg_id": 0, "src_ref": "Hello, I am Dawei, a PhD student at Saarland University in Germany.", "tgt_ref": "Salve, sono Dawei, studente di dottorato presso l'Università della Saarland in Germania."}
{"doc_id": "krJSAnVcGR", "seg_id": 1, "src_ref": "In this video, I would like to present our recent work \"Weaker Than You Think: A Critical Look at Weakly Supervised Learning.\"", "tgt_ref": "In questo video, vorrei presentare il nostro ultimo lavoro, \"Weaker Than You Think: A Critical Look at Weakly Supervised Learning\"."}
{"doc_id": "krJSAnVcGR", "seg_id": 2, "src_ref": "This is joint work with Xiaoyu Shen, Marius Mosbach, Andreas Stephan, and Dietrich Klakow.", "tgt_ref": "Questo è un lavoro congiunto con Xiaoyu Shen, Marius Mosbach, Andreas Stephan e Dietrich Klakow."}
{"doc_id": "krJSAnVcGR", "seg_id": 3, "src_ref": "I'd like to begin with a brief introduction to weak supervision and weakly supervised learning.", "tgt_ref": "Vorrei iniziare con una breve introduzione alla supervisione debole e all'apprendimento scarsamente supervisionato."}
{"doc_id": "krJSAnVcGR", "seg_id": 4, "src_ref": "In weak supervision, you do not manually label the data.", "tgt_ref": "Nella supervisione debole, i dati non vengono etichettati manualmente."}
{"doc_id": "krJSAnVcGR", "seg_id": 5, "src_ref": "Instead, we label the data using weak labeling sources, such as simple heuristic rules, knowledge bases, or low-quality crowdsourcing, as illustrated in the figure on the right.", "tgt_ref": "Al contrario, etichettiamo i dati utilizzando fonti di etichettatura deboli, come semplici regole euristiche, basi di conoscenza o crowdsourcing di bassa qualità, come illustrato nella figura sulla destra."}
{"doc_id": "krJSAnVcGR", "seg_id": 6, "src_ref": "When compared to human annotations, the weaker annotations are much cheaper, yet they are also noisy, meaning that a certain amount of the annotations are incorrect.", "tgt_ref": "Rispetto alle annotazioni umane, le annotazioni più deboli sono molto più economiche, ma presentano anche un notevole rumore, il che si traduce nel fatto che una certa quantità di annotazioni non è corretta."}
{"doc_id": "krJSAnVcGR", "seg_id": 7, "src_ref": "If we directly train neural networks on weakly labeled data, the neural networks tend to memorize the label noise and do not generalize.", "tgt_ref": "Se addestriamo direttamente le reti neurali su dati scarsamente etichettati, le reti neurali tendono a memorizzare il rumore dell'etichetta e non generalizzano."}
{"doc_id": "krJSAnVcGR", "seg_id": 8, "src_ref": "In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generalize well.", "tgt_ref": "Nell'apprendimento scarsamente supervisionato, vengono proposti algoritmi di addestramento al fine di addestrare in modo robusto le reti neurali in presenza di errori che affliggono le etichette, in modo che i modelli addestrati continuino a generalizzare in modo adeguato."}
{"doc_id": "krJSAnVcGR", "seg_id": 9, "src_ref": "In recent works in WSL, so WSL stands for Weakly Supervised Learning, a common claim is that people say that they only train models on the weakly labeled data and achieve high performance on clean test sets.", "tgt_ref": "Nei recenti lavori in WSL (WSL sta per Weakly Supervised Learning), un'affermazione comune è che le persone affermano di addestrare solo i modelli sui dati scarsamente etichettati e ottengono prestazioni elevate su set di test puliti."}
{"doc_id": "krJSAnVcGR", "seg_id": 10, "src_ref": "Technically, this claim is not wrong, but there's a catch, which is that people do assume that there's an additional clean validation set available for model selection.", "tgt_ref": "Tecnicamente, questa affermazione non è sbagliata, ma c'è un problema, ovvero che le persone presumono la disponibilità di un set di convalida pulito aggiuntivo per la selezione del modello."}
{"doc_id": "krJSAnVcGR", "seg_id": 11, "src_ref": "We can't stop on this problem setting, but this implies that additional manual annotations are required in weakly supervised learning.", "tgt_ref": "Non possiamo fermarci a questo problema, ma ciò implica che sono necessarie ulteriori annotazioni manuali nell'apprendimento scarsamente supervisionato."}
{"doc_id": "krJSAnVcGR", "seg_id": 12, "src_ref": "But like an elephant in the room this necessity is often overlooked.", "tgt_ref": "Ma come un elefante nella stanza, questa necessità viene spesso trascurata."}
{"doc_id": "krJSAnVcGR", "seg_id": 13, "src_ref": "The aforementioned doubt is asked to ask three research questions.", "tgt_ref": "Il dubbio di cui sopra è stato espresso per porre tre domande di ricerca."}
{"doc_id": "krJSAnVcGR", "seg_id": 14, "src_ref": "First, is clean validation data necessary for WSL or can we maybe use a noisy validation set instead?", "tgt_ref": "In primo luogo, i dati di convalida puliti sono necessari per il WSL o, invece, possiamo utilizzare un set di convalida rumoroso?"}
{"doc_id": "krJSAnVcGR", "seg_id": 15, "src_ref": "Second, if clean data is required, or if clean data is mandatory for WSL to work, then how many clean samples do we need?", "tgt_ref": "In secondo luogo, se sono necessari dati puliti, o se i dati puliti sono obbligatori affinché il WSL funzioni, di quanti campioni puliti abbiamo bisogno?"}
{"doc_id": "krJSAnVcGR", "seg_id": 16, "src_ref": "Finally, should we only use the clean samples for validation, or there are better ways to utilize them?", "tgt_ref": "Infine, per la convalida dovremmo usare solo i campioni puliti o ci sono modi migliori per impiegarli?"}
{"doc_id": "krJSAnVcGR", "seg_id": 17, "src_ref": "We addressed these research questions in our work and our findings are as follows.", "tgt_ref": "Abbiamo provato a rispondere a queste domande di ricerca nel nostro lavoro e i risultati sono i seguenti."}
{"doc_id": "krJSAnVcGR", "seg_id": 18, "src_ref": "First, we find that, interestingly, recent WSL methods indeed require clean validation samples to work properly.", "tgt_ref": "In primo luogo, va sottolineato che i recenti metodi WSL richiedono effettivamente campioni di convalida puliti per funzionare correttamente."}
{"doc_id": "krJSAnVcGR", "seg_id": 19, "src_ref": "Otherwise, there is a large performance drop.", "tgt_ref": "In caso contrario, si verifica un notevole calo delle prestazioni."}
{"doc_id": "krJSAnVcGR", "seg_id": 20, "src_ref": "As shown in this figure, if there are no clean validation samples, then the trained models cannot generalize beyond the original weak labels, meaning that the training is pointless.", "tgt_ref": "Come mostrato in questa figura, se non ci sono campioni di convalida puliti, i modelli addestrati non possono generalizzare oltre le etichette deboli originali, il che significa che l'addestramento si rivela inutile."}
{"doc_id": "krJSAnVcGR", "seg_id": 21, "src_ref": "This indicates that WSL approaches actually require cleanly labeled data to work properly, and the annotation cost for obtaining clean validation samples should not be overlooked.", "tgt_ref": "Ciò fa riferimento al fatto che gli approcci WSL richiedono effettivamente dati etichettati in modo pulito per funzionare correttamente e il costo dell'annotazione per ottenere campioni di convalida puliti non deve essere trascurato."}
{"doc_id": "krJSAnVcGR", "seg_id": 22, "src_ref": "Our second finding is that increasing the number of clean validation samples will help WSL approaches to achieve better performance, as shown in the figure on the left.", "tgt_ref": "La nostra seconda scoperta è che l'aumento del numero di campioni di convalida puliti aiuterà gli approcci WSL a ottenere prestazioni migliori, come mostrato nella figura sulla sinistra."}
{"doc_id": "krJSAnVcGR", "seg_id": 23, "src_ref": "Typically we only need 20 samples per class to attain high performance.", "tgt_ref": "In genere abbiamo bisogno solo di 20 campioni per classe per ottenere prestazioni elevate."}
{"doc_id": "krJSAnVcGR", "seg_id": 24, "src_ref": "But that's not the end of the story, because if we either way decide to access clean samples, then training on them directly will even achieve better performance.", "tgt_ref": "Ma non è finita qui, perché se decidiamo di accedere a campioni puliti indipendentemente dal modo, l'addestramento diretto su di essi raggiungerà anche prestazioni migliori."}
{"doc_id": "krJSAnVcGR", "seg_id": 25, "src_ref": "The right figure shows the performance difference between fine-tuning approaches, which are directly applied on the clean data, and WSL approaches, which use the clean data for validation only.", "tgt_ref": "La figura sulla destra mostra la differenza di prestazioni tra gli approcci di fine-tuning, che vengono applicati direttamente sui dati puliti, e gli approcci WSL, che utilizzano i dati puliti solo per la convalida."}
{"doc_id": "krJSAnVcGR", "seg_id": 26, "src_ref": "As we can see, if we have 10 samples per class, direct fine-tuning starts to beat WSL approaches.", "tgt_ref": "Come possiamo vedere, se abbiamo 10 campioni per classe, il fine-tuning diretto inizia a battere gli approcci WSL."}
{"doc_id": "krJSAnVcGR", "seg_id": 27, "src_ref": "Finally, the performance improvement claimed in previous WSL approaches can be easily achieved by allowing to continue fine-tuning on the clean validation samples.", "tgt_ref": "Infine, il miglioramento delle prestazioni rivendicato nei precedenti approcci WSL può essere ottenuto con facilità, consentendo di continuare il fine-tuning sui campioni di convalida puliti."}
{"doc_id": "krJSAnVcGR", "seg_id": 28, "src_ref": "As we can see from the figures, the vanilla model, termed FTw, initially underperforms more complicated WSL methods, like COSINE.", "tgt_ref": "Come possiamo vedere dalle figure, il modello convenzionale, denominato FTw, rivela inizialmente prestazioni inferiori rispetto a metodi WSL più complicati, come COSINE."}
{"doc_id": "krJSAnVcGR", "seg_id": 29, "src_ref": "However, if we allow to continue fine-tuning on the clean samples, then FTw performs equally well as other methods.", "tgt_ref": "Tuttavia, se continuiamo a eseguire il fine-tuning sui campioni puliti, FTw funziona altrettanto bene come altri metodi."}
{"doc_id": "krJSAnVcGR", "seg_id": 30, "src_ref": "So in practice, there's no reason to choose more complex WSL methods which require more computation time and disk space.", "tgt_ref": "Quindi, in pratica, non c'è motivo di scegliere metodi WSL più complessi che richiedono più tempo di calcolo e spazio su disco."}
{"doc_id": "krJSAnVcGR", "seg_id": 31, "src_ref": "To summarize, we showed that recent WSL approaches require clean, manually annotated samples for them to work properly.", "tgt_ref": "Per riassumere, abbiamo dimostrato che i recenti approcci WSL richiedono campioni puliti e annotati manualmente per funzionare correttamente."}
{"doc_id": "krJSAnVcGR", "seg_id": 32, "src_ref": "Their performance gain and practicality are heavily overestimated.", "tgt_ref": "L'incremento di prestazioni e la praticità sono fortemente sopravvalutati."}
{"doc_id": "krJSAnVcGR", "seg_id": 33, "src_ref": "Our concrete recommendations for future work are as follows.", "tgt_ref": "Le nostre raccomandazioni concrete per il lavoro futuro sono le seguenti."}
{"doc_id": "krJSAnVcGR", "seg_id": 34, "src_ref": "First, report the model selection criteria.", "tgt_ref": "Innanzitutto, riportare i criteri di selezione del modello."}
{"doc_id": "krJSAnVcGR", "seg_id": 35, "src_ref": "For example, report if the model selection is done via clean validation samples.", "tgt_ref": "Ad esempio, segnalare se la selezione del modello viene eseguita tramite campioni di convalida puliti."}
{"doc_id": "krJSAnVcGR", "seg_id": 36, "src_ref": "Second, WSL approaches should be compared with few-shot learning baselines, as both work on clean samples.", "tgt_ref": "In secondo luogo, gli approcci WSL dovrebbero essere confrontati con le baseline dell'apprendimento few-shot, poiché entrambi funzionano su campioni puliti."}
{"doc_id": "krJSAnVcGR", "seg_id": 37, "src_ref": "Third, continuous fine-tuning is a simple yet strong baseline that should be considered in future work in WSL.", "tgt_ref": "In terzo luogo, il fine-tuning continuo è una base semplice ma solida che dovrebbe essere considerata nel lavoro futuro in WSL."}
{"doc_id": "krJSAnVcGR", "seg_id": 38, "src_ref": "Finally, we have open-sourced our code.", "tgt_ref": "Infine, abbiamo reso il nostro codice open source."}
{"doc_id": "krJSAnVcGR", "seg_id": 39, "src_ref": "You can find it via the QR code on this slide.", "tgt_ref": "Potete trovarlo tramite il codice QR su questa diapositiva."}
{"doc_id": "krJSAnVcGR", "seg_id": 40, "src_ref": "Please feel free to check it out.", "tgt_ref": "Non esitate a consultare il lavoro."}
{"doc_id": "krJSAnVcGR", "seg_id": 41, "src_ref": "Thank you and enjoy the conference.", "tgt_ref": "Grazie e buona conferenza."}
{"doc_id": "JhbtCwcsWY", "seg_id": 0, "src_ref": "Hello, I'm James Finch.", "tgt_ref": "Ciao, sono James Finch."}
{"doc_id": "JhbtCwcsWY", "seg_id": 1, "src_ref": "And I'm Sarah Finch.", "tgt_ref": "E io sono Sarah Finch."}
{"doc_id": "JhbtCwcsWY", "seg_id": 2, "src_ref": "And today we'll tell you all about ABC-Eval, a new dimensional approach to evaluating conversational AI.", "tgt_ref": "Oggi vi diremo tutto su ABC-Eval, un nuovo approccio dimensionale per valutare l'IA conversazionale."}
{"doc_id": "JhbtCwcsWY", "seg_id": 3, "src_ref": "This work was done by the Emory NLP Lab led by Professor Jinho Choi at Emory University and in collaboration with Amazon Alexa AI.", "tgt_ref": "Questo lavoro è stato svolto dall'Emory NLP Lab guidato dal professor Jinho Choi presso la Emory University e in collaborazione con Amazon Alexa AI."}
{"doc_id": "JhbtCwcsWY", "seg_id": 4, "src_ref": "So let's say that you just developed a dialogue model and you want to see how well it compares against the current state-of-the-art.", "tgt_ref": "Dunque, supponiamo che abbiate appena sviluppato un modello di dialogo e vogliate vedere come si confronta con lo stato dell'arte attuale."}
{"doc_id": "JhbtCwcsWY", "seg_id": 5, "src_ref": "The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.", "tgt_ref": "La pratica comune è quella di utilizzare la valutazione umana, ad esempio chiedendo ai giudici umani di selezionare quale delle due conversazioni è migliore o di valutare le conversazioni in base a una scala Likert."}
{"doc_id": "JhbtCwcsWY", "seg_id": 6, "src_ref": "These approaches work well to provide holistic evaluations of overall dialogue quality, but dialogue quality has many aspects.", "tgt_ref": "Questi approcci funzionano bene per fornire valutazioni olistiche della qualità complessiva del dialogo, ma la qualità del dialogo presenta molti aspetti."}
{"doc_id": "JhbtCwcsWY", "seg_id": 7, "src_ref": "Therefore, you might want to evaluate multiple dimensions of chat quality to understand the strengths and weaknesses of the model on a finer-grained level.", "tgt_ref": "Pertanto, l'intenzione potrebbe essere quella di valutare più dimensioni della qualità della chat per comprendere i punti di forza e di debolezza del modello a un livello più dettagliato."}
{"doc_id": "JhbtCwcsWY", "seg_id": 8, "src_ref": "One approach is to simply ask human judges to evaluate several dimensions of dialogue quality, such as the relevance of model responses using existing comparative or Likert scale methods.", "tgt_ref": "Un approccio consiste nella semplice richiesta ai giudici umani di valutare diverse dimensioni della qualità del dialogo, come la pertinenza delle risposte del modello, attraverso metodi comparativi o di scala Likert esistenti."}
{"doc_id": "JhbtCwcsWY", "seg_id": 9, "src_ref": "However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation.", "tgt_ref": "Tuttavia, riteniamo che esista una strategia più precisa e affidabile per la valutazione del dialogo dimensionale."}
{"doc_id": "JhbtCwcsWY", "seg_id": 10, "src_ref": "Our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself.", "tgt_ref": "Il nostro approccio tenta di ridurre la soggettività della valutazione umana annotando esplicitamente se ogni risposta del modello esprime o meno determinati comportamenti, come risposte con informazioni irrilevanti o contraddizioni."}
{"doc_id": "JhbtCwcsWY", "seg_id": 11, "src_ref": "We call this approach annotating behaviors in chat or ABC-Eval in short.", "tgt_ref": "Chiamiamo questo approccio annotazione dei comportamenti in chat, ABC-Eval in breve."}
{"doc_id": "JhbtCwcsWY", "seg_id": 12, "src_ref": "We developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature.", "tgt_ref": "Abbiamo sviluppato questo metodo per coprire in modo completo i comportamenti del modello di chat che, secondo la letteratura recente, influenzano la qualità della chat stessa."}
{"doc_id": "JhbtCwcsWY", "seg_id": 13, "src_ref": "ABC-Eval is capable of measuring the rates at which chat models will commit various thematic errors.", "tgt_ref": "ABC-Eval è in grado di misurare le velocità con cui i modelli di chat commetteranno vari errori tematici."}
{"doc_id": "JhbtCwcsWY", "seg_id": 14, "src_ref": "For example, ABC-Eval measures the number of turns in which a chat model ignores its partner or says something irrelevant, contradicts itself or its partner, hallucinates incorrect facts or violates common sense knowledge, and when the model succeeds or fails to show empathy.", "tgt_ref": "Ad esempio, ABC-Eval misura il numero di turni in cui un modello di chat ignora il suo partner o dice qualcosa di irrilevante, contraddice se stesso o il suo partner, immagina fatti errati o viola la conoscenza del buon senso, e quando il modello riesce o non riesce a mostrare empatia."}
{"doc_id": "JhbtCwcsWY", "seg_id": 15, "src_ref": "To determine what kind of evaluation is most effective, we selected four state-of-the-art chat models and evaluated them on 100 human-bot conversations per model using ABC-Eval.", "tgt_ref": "Per determinare quale tipo di valutazione sia più efficace, abbiamo selezionato quattro modelli di chat all'avanguardia e li abbiamo valutati su 100 conversazioni uomo-bot per modello utilizzando ABC-Eval."}
{"doc_id": "JhbtCwcsWY", "seg_id": 16, "src_ref": "For comparison, we also evaluated these conversations using three existing methods: Likert ratings on the turn-level, Likert ratings on the dialogue-level, and dialogue-level pairwise comparisons.", "tgt_ref": "Per fare un confronto, abbiamo anche valutato queste conversazioni utilizzando tre metodi esistenti: valutazioni Likert a livello di turno, valutazioni Likert a livello di dialogo e confronti a coppie a livello di dialogo."}
{"doc_id": "JhbtCwcsWY", "seg_id": 17, "src_ref": "For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue, since this is the standard practice for evaluating chat models along multiple dimensions.", "tgt_ref": "Per ciascuno dei metodi esistenti, abbiamo raccolto valutazioni su otto degli aspetti del dialogo misurati con maggiore frequenza, poiché questa è la pratica standard per valutare i modelli di chat su più dimensioni."}
{"doc_id": "JhbtCwcsWY", "seg_id": 18, "src_ref": "From our analysis of these evaluation results, we found that ABC-Eval behavior labels are overall more reliable than labels collected by existing methods, as measured by inter-annotator agreement on 100 doubly-labeled conversations.", "tgt_ref": "Dall'analisi di questi risultati di valutazione, abbiamo scoperto che le etichette di comportamento ABC-Eval sono nel complesso più affidabili delle etichette raccolte dai metodi esistenti, come misurato dall'accordo tra annotatori su 100 conversazioni doppiamente etichettate."}
{"doc_id": "JhbtCwcsWY", "seg_id": 19, "src_ref": "In addition, ABC-Eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis.", "tgt_ref": "Inoltre, le etichette ABC-Eval sono maggiormente predittive della qualità complessiva della conversazione rispetto alle metriche prodotte dai metodi esistenti, come mostrato da questa semplice analisi di regressione lineare."}
{"doc_id": "JhbtCwcsWY", "seg_id": 20, "src_ref": "For example, you can see how measuring the proportion of turns with self and partner contradictions explains 5% and 10% of conversation quality, respectively, while the average Likert consistency scores explain only 4% or less.", "tgt_ref": "Ad esempio, si può vedere come la misurazione della proporzione di turni con contraddizioni proprie e del partner spieghi rispettivamente il 5% e il 10% della qualità della conversazione, mentre i punteggi medi di coerenza Likert spiegano solo il 4% o meno."}
{"doc_id": "JhbtCwcsWY", "seg_id": 21, "src_ref": "Finally, we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression.", "tgt_ref": "Infine, abbiamo verificato se ogni metrica di valutazione cattura un aspetto unico della qualità della chat utilizzando una regressione lineare graduale."}
{"doc_id": "JhbtCwcsWY", "seg_id": 22, "src_ref": "You can see how the combination of all ABC-Eval metrics explains over 25% of conversation quality, and as you remove the metrics one at a time, most of them result in losing a decent amount of information about the quality.", "tgt_ref": "Si può vedere come la combinazione di tutte le metriche ABC-Eval spieghi oltre il 25% della qualità della conversazione e, man mano che le metriche vengono rimosse una dopo l'altra, la maggior parte di esse comporta la perdita di una discreta quantità di informazioni sulla qualità."}
{"doc_id": "JhbtCwcsWY", "seg_id": 23, "src_ref": "On the other hand, the combination of all turn-level Likert metrics explains far less of the quality, and fewer of these metrics carry unique information.", "tgt_ref": "D'altra parte, la combinazione di tutte le metriche Likert a livello di turno fornisce molte meno spiegazioni sulla qualità e solo una parte esigua di queste metriche include informazioni uniche."}
{"doc_id": "JhbtCwcsWY", "seg_id": 24, "src_ref": "These reliable, informative, and distinct ABC-Eval metrics enable us to evaluate conversational AI with a higher resolution than previous methods are able to achieve.", "tgt_ref": "Queste metriche ABC-Eval affidabili, informative e distinte ci consentono di valutare l'IA conversazionale con una risoluzione più elevata rispetto ai metodi precedenti."}
{"doc_id": "JhbtCwcsWY", "seg_id": 25, "src_ref": "You can see that in the results of our experiment that several challenges still remain and have been precisely quantified.", "tgt_ref": "I risultati del nostro esperimento rivelano che restano ancora diverse sfide che sono state quantificate con precisione."}
{"doc_id": "JhbtCwcsWY", "seg_id": 26, "src_ref": "For example, the bots we tested have common sense violations in around 20% of their responses.", "tgt_ref": "Ad esempio, i bot che abbiamo testato presentano violazioni del buon senso in circa il 20% delle loro risposte."}
{"doc_id": "JhbtCwcsWY", "seg_id": 27, "src_ref": "They produce irrelevant information in around 15% of the responses, and they contradict themselves or their partner around 10% of the time.", "tgt_ref": "Producono informazioni irrilevanti in circa il 15% delle risposte e si contraddicono o contraddicono il loro partner circa il 10% delle volte."}
{"doc_id": "JhbtCwcsWY", "seg_id": 28, "src_ref": "With the rapid pace of improvement in the field, many of these error rates could see a decrease in new models released since our evaluation was conducted.", "tgt_ref": "Con il rapido ritmo di miglioramento nel campo, molti di questi tassi di errore potrebbero vedere una diminuzione nei nuovi modelli rilasciati da quando è stata condotta la nostra valutazione."}
{"doc_id": "JhbtCwcsWY", "seg_id": 29, "src_ref": "However, this is all the more reason to pursue reliable and precise evaluation metrics for comparing models.", "tgt_ref": "Tuttavia, questo è un motivo in più per perseguire metriche di valutazione affidabili e precise per confrontare i modelli."}
{"doc_id": "JhbtCwcsWY", "seg_id": 30, "src_ref": "We hope ABC-Eval can be leveraged by others in the field as a meaningful step in this direction.", "tgt_ref": "Ci auguriamo che ABC-Eval possa essere sfruttato da altri nel campo come un passo significativo in questa direzione."}
{"doc_id": "JhbtCwcsWY", "seg_id": 31, "src_ref": "And we look forward to seeing how conversational AI will advance in the coming months and years.", "tgt_ref": "E non vediamo l'ora di vedere come l'IA conversazionale progredirà nei prossimi mesi e anni."}
{"doc_id": "JhbtCwcsWY", "seg_id": 32, "src_ref": "Thank you for watching.", "tgt_ref": "Grazie per la visione."}
{"doc_id": "xUDLtuhJUS", "seg_id": 0, "src_ref": "Hello, my name is Kayo Yin and I will be presenting our work titled \"When Does Translation Require Context?", "tgt_ref": "Ciao, mi chiamo Kayo Yin e presenterò il nostro lavoro dal titolo \"When Does Translation Require Context?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 1, "src_ref": "A Data-driven, Multilingual Exploration\".", "tgt_ref": "A Data-driven, Multilingual Exploration\"."}
{"doc_id": "xUDLtuhJUS", "seg_id": 2, "src_ref": "This work was done in collaboration with Patrick Fernandes, Emmy Liu, André F. T. Martins, and Graham Neubig.", "tgt_ref": "Questo lavoro è stato svolto in collaborazione con Patrick Fernandes, Emmy Liu, André F. T. Martins e Graham Neubig."}
{"doc_id": "xUDLtuhJUS", "seg_id": 3, "src_ref": "So a lot of translations depend on context.", "tgt_ref": "Molte traduzioni dipendono dal contesto."}
{"doc_id": "xUDLtuhJUS", "seg_id": 4, "src_ref": "For example, how would we translate \"mole\" in this sentence?", "tgt_ref": "Ad esempio, come tradurremmo \"mole\" in questa frase?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 5, "src_ref": "Well, if the previous sentence was \"Things could start to get dangerous if the ministers find out\", then \"mole\" refers to a spy.", "tgt_ref": "Beh, se la frase precedente fosse \"Things could start to get dangerous if the ministers find out\", allora \"mole\" significherebbe \"talpa\", nel senso di spia."}
{"doc_id": "xUDLtuhJUS", "seg_id": 6, "src_ref": "But if the previous sentence was \"Could it be anything serious, doctor?\", then \"mole\" refers to a birthmark.", "tgt_ref": "Ma se la frase precedente fosse \"Could it be anything serious, doctor?\", allora \"mole\" si riferirebbe a un neo."}
{"doc_id": "xUDLtuhJUS", "seg_id": 7, "src_ref": "So, depending on context, the meaning of the word changes, and therefore its translation changes as well.", "tgt_ref": "Quindi, a seconda del contesto, il significato della parola cambia, e quindi cambia anche la sua traduzione."}
{"doc_id": "xUDLtuhJUS", "seg_id": 8, "src_ref": "However, evaluating how well models can translate cases like this is pretty hard.", "tgt_ref": "Tuttavia, valutare l'accuratezza con cui i modelli possono tradurre termini come questo è piuttosto difficile."}
{"doc_id": "xUDLtuhJUS", "seg_id": 9, "src_ref": "Firstly because only a small portion of translations depend on context which makes corpus-level metrics like BLEU unable to capture these translations.", "tgt_ref": "In primo luogo perché solo una piccola parte delle traduzioni dipende dal contesto, il che rende le metriche a livello di corpus come BLEU incapaci di catturare il senso di queste traduzioni."}
{"doc_id": "xUDLtuhJUS", "seg_id": 10, "src_ref": "And some people have suggested targeted evaluation on context-dependent translations, but these resources only support limited types of context-dependent translations and limited sets of languages since they usually rely on domain knowledge and human curation.", "tgt_ref": "Alcune persone hanno suggerito una valutazione mirata sulle traduzioni dipendenti dal contesto, ma queste risorse supportano solo tipi limitati di traduzioni dipendenti dal contesto e set limitati di lingue poiché si basano solitamente sulla conoscenza del dominio e sulla selezione umana."}
{"doc_id": "xUDLtuhJUS", "seg_id": 11, "src_ref": "In this work, we try to answer these two questions.", "tgt_ref": "In questo lavoro, cerchiamo di rispondere a queste due domande."}
{"doc_id": "xUDLtuhJUS", "seg_id": 12, "src_ref": "First, when does translation require context?", "tgt_ref": "In primo luogo, quand'è che la traduzione necessita del contesto?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 13, "src_ref": "And second, how well do models handle these cases?", "tgt_ref": "E in secondo luogo, in che modo i modelli gestiscono questi casi?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 14, "src_ref": "To answer the first question, we started by measuring how much a word depends on context during translation.", "tgt_ref": "Per rispondere alla prima domanda, abbiamo iniziato misurando il grado di dipendenza dal contesto di una parola durante la traduzione."}
{"doc_id": "xUDLtuhJUS", "seg_id": 15, "src_ref": "In the previous work, we introduced CXMI as a measure for context usage by machine translation models.", "tgt_ref": "Nel lavoro precedente, abbiamo introdotto CXMI come misura del ricorso al contesto da parte dei modelli di traduzione automatica."}
{"doc_id": "xUDLtuhJUS", "seg_id": 16, "src_ref": "And this is done by measuring how much information the context C provides about the target Y, given the source X. You can think of CXMI as the information gained from giving context to the model.", "tgt_ref": "Ciò viene fatto misurando quante informazioni il contesto C fornisce sul target Y, data la sorgente X. Si può pensare a CXMI come alle informazioni acquisite fornendo contesto al modello."}
{"doc_id": "xUDLtuhJUS", "seg_id": 17, "src_ref": "In this work, we extend CXMI to Pointwise CXMI which can measure context usage at the sentence level or at the word level.", "tgt_ref": "In questo lavoro, estendiamo CXMI a Pointwise CXMI, che può misurare l'uso del contesto a livello di frase o a livello di parola."}
{"doc_id": "xUDLtuhJUS", "seg_id": 18, "src_ref": "We can think of words that have high P-CXMI as ones that require context for translation.", "tgt_ref": "Possiamo pensare a parole che hanno un P-CXMI elevato come a quelle che necessitano del contesto per la traduzione."}
{"doc_id": "xUDLtuhJUS", "seg_id": 19, "src_ref": "Now we analyze words with high P-CXMI to look for patterns between these words.", "tgt_ref": "Ora analizziamo le parole con un P-CXMI elevato per cercare modelli tra queste."}
{"doc_id": "xUDLtuhJUS", "seg_id": 20, "src_ref": "And we perform our analysis on transcripts of TED talks that have been translated from English to 14 different languages.", "tgt_ref": "Dopodiché eseguiamo la nostra analisi sulle trascrizioni dei discorsi TED tradotti dall'inglese in 14 lingue diverse."}
{"doc_id": "xUDLtuhJUS", "seg_id": 21, "src_ref": "We perform our analysis at three different levels.", "tgt_ref": "Eseguiamo la nostra analisi su tre diversi livelli."}
{"doc_id": "xUDLtuhJUS", "seg_id": 22, "src_ref": "First, we look at part-of-speech tags that have high mean P-CXMI.", "tgt_ref": "In primo luogo, esaminiamo i tag per parti del discorso che hanno un P-CXMI medio elevato."}
{"doc_id": "xUDLtuhJUS", "seg_id": 23, "src_ref": "And this allows us to find, for example, dual pronouns in Arabic that have relatively high P-CXMI.", "tgt_ref": "Questo ci permette di trovare, ad esempio, pronomi duali in arabo che hanno un P-CXMI relativamente alto."}
{"doc_id": "xUDLtuhJUS", "seg_id": 24, "src_ref": "And this can be explained because English doesn't have dual pronouns, so you need context to determine if a pronoun is dual when translating into Arabic.", "tgt_ref": "E questo può essere spiegato in base al fatto che l'inglese non ha pronomi duali, quindi è necessario il contesto per determinare se un pronome è duale quando si traduce in arabo."}
{"doc_id": "xUDLtuhJUS", "seg_id": 25, "src_ref": "And similarly, we find that certain languages also require context when we want to choose the appropriate verb form.", "tgt_ref": "Allo stesso modo, scopriamo che anche alcune lingue necessitano del contesto per la scelta della forma verbale appropriata."}
{"doc_id": "xUDLtuhJUS", "seg_id": 26, "src_ref": "We then look at vocabulary items that have high P-CXMI averaged over all of its different occurrences.", "tgt_ref": "Esaminiamo quindi gli elementi del vocabolario che hanno un P-CXMI medio elevato su tutte le sue diverse occorrenze."}
{"doc_id": "xUDLtuhJUS", "seg_id": 27, "src_ref": "And this helps us identify cases like the one here, where in Chinese you need context to translate proper nouns to make sure that you're using the same translation within the document.", "tgt_ref": "Questo ci aiuta a identificare casi come quello in oggetto, dove in cinese è necessario il contesto per tradurre i nomi propri per assicurarsi di utilizzare la stessa traduzione all'interno del documento."}
{"doc_id": "xUDLtuhJUS", "seg_id": 28, "src_ref": "And similarly, we find that context is important to translate in the right formality.", "tgt_ref": "Parallelamente, scopriamo che il contesto è importante per tradurre nella corretta formalità."}
{"doc_id": "xUDLtuhJUS", "seg_id": 29, "src_ref": "And finally, we look at different individual tokens that have high P-CXMI.", "tgt_ref": "Infine, esaminiamo diversi token individuali che presentano un P-CXMI elevato."}
{"doc_id": "xUDLtuhJUS", "seg_id": 30, "src_ref": "And this allows us to identify phenomena that cannot really be captured by the word itself, but that's rather expressed in the sentence structure, such as ellipses resolution.", "tgt_ref": "Questo ci permette di identificare fenomeni che non possono essere realmente catturati dalla parola stessa, ma che sono piuttosto espressi nella struttura della frase, come la risoluzione delle ellissi."}
{"doc_id": "xUDLtuhJUS", "seg_id": 31, "src_ref": "So now we use our findings from our analysis to design a benchmark for document-level translation.", "tgt_ref": "Ora usiamo i risultati della nostra analisi per progettare un parametro di riferimento per la traduzione a livello di documento."}
{"doc_id": "xUDLtuhJUS", "seg_id": 32, "src_ref": "For each of the five discourse phenomena we identified, we create taggers to automatically identify words that pertain to the phenomenon.", "tgt_ref": "Per ciascuno dei cinque fenomeni del discorso che abbiamo identificato, creiamo dei tagger per individuare automaticamente le parole che rimandano al fenomeno in questione."}
{"doc_id": "xUDLtuhJUS", "seg_id": 33, "src_ref": "And we called our tagger the Multilingual Discourse-Aware, or MuDA tagger.", "tgt_ref": "Abbiamo chiamato il nostro tagger Multilingual Discourse-Aware o tagger MuDA."}
{"doc_id": "xUDLtuhJUS", "seg_id": 34, "src_ref": "We can then also note that different languages have different proportions of these discourse phenomena.", "tgt_ref": "Possiamo anche notare che lingue diverse presentano proporzioni diverse di questi fenomeni del discorso."}
{"doc_id": "xUDLtuhJUS", "seg_id": 35, "src_ref": "We then use the MuDA tagger, by applying the tagger on a parallel corpus that we want to use for evaluation and we apply our translation metrics of choice on the context-dependent examples that the MuDA tagger has identified.", "tgt_ref": "Quindi, ricorriamo al tagger MuDA applicandolo su un corpus parallelo che vogliamo utilizzare per la valutazione e applichiamo le nostre metriche di traduzione scelte sugli esempi dipendenti dal contesto che il tagger MuDA ha identificato."}
{"doc_id": "xUDLtuhJUS", "seg_id": 36, "src_ref": "And finally, we use our benchmark as well as other metrics to evaluate different models on the document-level machine translation.", "tgt_ref": "Infine, utilizziamo il nostro parametro di riferimento e altre metriche per valutare diversi modelli sulla traduzione automatica a livello di documento."}
{"doc_id": "xUDLtuhJUS", "seg_id": 37, "src_ref": "First of all, when we use corpus-level metrics: so for BLEU, we find that context-agnostic models have the best performance.", "tgt_ref": "Prima di tutto, quando utilizziamo metriche a livello di corpus: quindi, con riferimento a BLEU, scopriamo che i modelli indipendenti dal contesto offrono le migliori prestazioni."}
{"doc_id": "xUDLtuhJUS", "seg_id": 38, "src_ref": "But then if we use COMET, context-aware models perform best.", "tgt_ref": "Ma poi, se usiamo COMET, i modelli sensibili al contesto funzionano meglio."}
{"doc_id": "xUDLtuhJUS", "seg_id": 39, "src_ref": "And if we use word f-measure, then models with and without context have comparable performance.", "tgt_ref": "E se usiamo la word f-measure, allora i modelli con e senza contesto hanno prestazioni comparabili."}
{"doc_id": "xUDLtuhJUS", "seg_id": 40, "src_ref": "This again demonstrates that it is difficult to determine the best document-level translation system if we use corpus-level metrics alone.", "tgt_ref": "Ciò dimostra ancora una volta che è difficile determinare il miglior sistema di traduzione a livello di documento se utilizziamo solo metriche a livello di corpus."}
{"doc_id": "xUDLtuhJUS", "seg_id": 41, "src_ref": "Now, we use the MuDA benchmark to evaluate models and we find that context-aware models are significantly more accurate than models that do not use context for certain discourse phenomena such as formality and lexical cohesion.", "tgt_ref": "Ora, usiamo il benchmark MuDA per valutare i modelli e scopriamo che i modelli sensibili al contesto sono significativamente più accurati dei modelli che non usano il contesto per alcuni fenomeni del discorso quali, ad esempio, la formalità e la coesione lessicale."}
{"doc_id": "xUDLtuhJUS", "seg_id": 42, "src_ref": "But these models are not much better than models that do not use context on other phenomena like ellipsis, pronouns, and verb form.", "tgt_ref": "Ma questi modelli non sono migliori dei modelli che non usano il contesto su altri fenomeni come ellissi, pronomi e forma verbale."}
{"doc_id": "xUDLtuhJUS", "seg_id": 43, "src_ref": "So this sort of suggests where we would need to see more progress for document-level translation.", "tgt_ref": "Questo suggerisce dove avremmo bisogno di vedere più progressi per la traduzione a livello di documento."}
{"doc_id": "xUDLtuhJUS", "seg_id": 44, "src_ref": "We also compared different commercial systems and our benchmark shows that DeepL is usually more accurate than Google Translate for document-level translation.", "tgt_ref": "Abbiamo anche confrontato diversi sistemi commerciali e il nostro parametro di riferimento mostra che DeepL è solitamente più accurato di Google Translate per la traduzione a livello di documento."}
{"doc_id": "xUDLtuhJUS", "seg_id": 45, "src_ref": "To summarize, we perform a data-driven analysis across 14 language pairs to identify when translations require context and then we use our findings to build a benchmark for document-level machine translation which can help us identify which discourse phenomena models can handle well or not, and which translation systems are good at document-level translation.", "tgt_ref": "Per riassumere, eseguiamo un'analisi basata sui dati su 14 coppie di lingue per identificare quando le traduzioni necessitano del contesto; quindi, utilizziamo i nostri risultati per costruire un parametro di riferimento per la traduzione automatica a livello di documento che può aiutarci a identificare quali modelli di fenomeni del discorso possono gestire bene o meno, e quali sistemi di traduzione si rivelano validi nella traduzione a livello di documento."}
{"doc_id": "xUDLtuhJUS", "seg_id": 46, "src_ref": "Thank you so much for your attention.", "tgt_ref": "Grazie mille per l’attenzione."}
{"doc_id": "xUDLtuhJUS", "seg_id": 47, "src_ref": "See you in Toronto.", "tgt_ref": "Ci vediamo a Toronto."}
{"doc_id": "csJIsDTYMW", "seg_id": 0, "src_ref": "Hi, I am Yanis Labrak and I will present you our works on \"DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains.\"", "tgt_ref": "Ciao, sono Yanis Labrak e vi presenterò i nostri lavori relativi a \"DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains\"."}
{"doc_id": "csJIsDTYMW", "seg_id": 1, "src_ref": "In this presentation, we first talk about language modeling in healthcare.", "tgt_ref": "In questa presentazione, parleremo innanzitutto di modellazione del linguaggio in ambito sanitario."}
{"doc_id": "csJIsDTYMW", "seg_id": 2, "src_ref": "Then we will present the main contribution of our article.", "tgt_ref": "Dopodiché presenteremo il contributo principale del nostro articolo."}
{"doc_id": "csJIsDTYMW", "seg_id": 3, "src_ref": "We introduce the first biomedical model in French named DrBERT, which is based on RoBERTa and trained on NACHOS, which is a data set of medical crawled data from the web.", "tgt_ref": "Introduciamo il primo modello biomedico in francese chiamato DrBERT, che si basa su RoBERTa ed è addestrato su NACHOS, un set di dati medici estratti dal web."}
{"doc_id": "csJIsDTYMW", "seg_id": 4, "src_ref": "We also introduced a comparison of models with multiple pre-training settings and data sources.", "tgt_ref": "Abbiamo inoltre introdotto un confronto di modelli con più impostazioni di pre-addestramento e fonti di dati."}
{"doc_id": "csJIsDTYMW", "seg_id": 5, "src_ref": "Then, we present our results on 11 biomedical and clinical downstream tasks in French.", "tgt_ref": "Quindi, presentiamo i nostri risultati su 11 attività biomediche e cliniche a valle in francese."}
{"doc_id": "csJIsDTYMW", "seg_id": 6, "src_ref": "And finally, we conclude about the experiments and give you more details about how to access those models.", "tgt_ref": "Infine, chiudiamo sugli esperimenti e forniamo maggiori dettagli su come accedere a questi modelli."}
{"doc_id": "csJIsDTYMW", "seg_id": 7, "src_ref": "Since its release in 2018, BERT has become one of the most effective approach to solve natural language processing tasks and offers huge performance gains compared to historical static and contextualized methods such as Word2vec, fastText, or more.", "tgt_ref": "Dal suo lancio nel 2018, BERT è diventato uno degli approcci più efficaci per risolvere le attività di Natural Language Processing e offre enormi vantaggi in termini di prestazioni rispetto ai metodi statici e contestualizzati storici come Word2vec, fastText o altri."}
{"doc_id": "csJIsDTYMW", "seg_id": 8, "src_ref": "Since then, this model has been adapted to many other languages, like in French with CamemBERT, and also in domains like biomedical with PubMedBERT and BioBERT and on clinical with ClinicalBERT, but mostly in English.", "tgt_ref": "Da allora, questo modello è stato adattato a molte altre lingue, come in francese con CamemBERT, e anche in settori come quello biomedico con PubMedBERT e BioBERT e in quello clinico con ClinicalBERT, ma soprattutto in inglese."}
{"doc_id": "csJIsDTYMW", "seg_id": 9, "src_ref": "Specialized models for other languages are scarce and are often based on continual pre-training due to the lack of in-domain data.", "tgt_ref": "I modelli specializzati per altre lingue sono scarsi e spesso si basano su una pre-formazione continua a causa della mancanza di dati nel dominio."}
{"doc_id": "csJIsDTYMW", "seg_id": 10, "src_ref": "However, French didn't have any open source model for biomedical until now.", "tgt_ref": "Tuttavia, non era presente alcun modello open source in francese per il settore biomedico."}
{"doc_id": "csJIsDTYMW", "seg_id": 11, "src_ref": "So we ask ourselves a question about what is the most appropriate data sources for a wide range of usage and those crawled data are good substitution for clinical data.", "tgt_ref": "Quindi, ci siamo chiesti quali siano le fonti di dati più appropriate per un'ampia gamma di utilizzi e se i dati raccolti siano una buona alternativa ai dati clinici."}
{"doc_id": "csJIsDTYMW", "seg_id": 12, "src_ref": "To answer this question, we compare DrBERT with our ChuBERT model, which is based on anonymized data obtained from the Nantes University Hospital data warehouse.", "tgt_ref": "Per rispondere a questa domanda, confrontiamo DrBERT con il nostro modello ChuBERT, che si basa su dati anonimi ottenuti dal data warehouse dell'Ospedale Universitario di Nantes."}
{"doc_id": "csJIsDTYMW", "seg_id": 13, "src_ref": "Afterwards, we ask ourselves how much data do we need to train a specialized model on French data?", "tgt_ref": "Successivamente, ci siamo chiesti di quanti dati abbiamo bisogno per addestrare un modello specializzato sui dati francesi."}
{"doc_id": "csJIsDTYMW", "seg_id": 14, "src_ref": "Is it 4 gigabytes, 8 gigabytes, or more?", "tgt_ref": "Sono 4 gigabyte, 8 gigabyte o più?"}
{"doc_id": "csJIsDTYMW", "seg_id": 15, "src_ref": "To answer this question, we first train and compare four from-scratch models: a first version of DrBERT, with 7 GB of NACHOS; a second version of 4 GB of set of NACHOS; a first version of ChuBERT, which is a clinical model with 4 GB of sentences taken from clinical notes; and a final version of ChuBERT with a mix of 4 GB of set of NACHOS and 4 GB of clinical notes.", "tgt_ref": "Per rispondere a questa domanda, innanzitutto addestriamo e confrontiamo quattro modelli da zero: una prima versione di DrBERT, con 7 GB di NACHOS, una seconda versione di 4 GB di set di NACHOS, una prima versione di ChuBERT, che è un modello clinico con 4 GB di frasi tratte da note cliniche e una versione finale di ChuBERT con un mix di 4 GB di set di NACHOS e 4 GB di note cliniche."}
{"doc_id": "csJIsDTYMW", "seg_id": 16, "src_ref": "In addition to this comparison, we introduced three models trained on continual pre-training to analyze the impact of pre-training strategy.", "tgt_ref": "Oltre a questo confronto, abbiamo introdotto tre modelli addestrati sul pre-addestramento continuo per analizzare l'impatto della strategia di pre-addestramento."}
{"doc_id": "csJIsDTYMW", "seg_id": 17, "src_ref": "One based on the weight of CamemBERT and trained on a 4 GB set of NACHOS.", "tgt_ref": "Uno basato sul peso di CamemBERT e addestrato su un set di 4 GB di NACHOS."}
{"doc_id": "csJIsDTYMW", "seg_id": 18, "src_ref": "Another also based on CamemBERT, but trained this time on the 4 GB of clinical notes and finally, one based on English biomedical model PubMedBERT, and trained on 4 GB of set of NACHOS.", "tgt_ref": "Un altro basato sempre su CamemBERT, ma addestrato questa volta sui 4 GB di note cliniche e, infine, uno basato sul modello biomedico inglese PubMedBERT e addestrato su 4 GB di set di NACHOS."}
{"doc_id": "csJIsDTYMW", "seg_id": 19, "src_ref": "In total, we have seven models.", "tgt_ref": "In totale, abbiamo sette modelli."}
{"doc_id": "csJIsDTYMW", "seg_id": 20, "src_ref": "To evaluate our seven models, we gather data for public and private downstream tasks such as named entity recognition, classification, part-of-speech tagging, and question answering.", "tgt_ref": "Per valutare i nostri sette modelli, raccogliamo dati per attività a valle pubbliche e private come riconoscimento di entità nominate, classificazione, etichettatura delle parti del discorso e risposta alle domande."}
{"doc_id": "csJIsDTYMW", "seg_id": 21, "src_ref": "These models are compared to six baseline models which are CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT, and ClinicalBERT.", "tgt_ref": "Questi modelli vengono confrontati con sei modelli di base che sono CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT e ClinicalBERT."}
{"doc_id": "csJIsDTYMW", "seg_id": 22, "src_ref": "The evaluation highlights that models performed best on the task with data of the same nature as those on which the model has been trained.", "tgt_ref": "La valutazione evidenzia che i modelli hanno ottenuto i migliori risultati sul compito con dati della stessa natura di quelli su cui è stato addestrato il modello."}
{"doc_id": "csJIsDTYMW", "seg_id": 23, "src_ref": "However, we can observe that data from heterogeneous sources appear to be more versatile.", "tgt_ref": "Tuttavia, possiamo osservare che i dati provenienti da fonti eterogenee sembrano essere più versatili."}
{"doc_id": "csJIsDTYMW", "seg_id": 24, "src_ref": "We also observe that using more data translated to better performance.", "tgt_ref": "Notiamo inoltre che il ricorso a più dati si traduce in prestazioni migliori."}
{"doc_id": "csJIsDTYMW", "seg_id": 25, "src_ref": "Overall, from-scratch pre-training seems to obtain higher performance on most of the tasks.", "tgt_ref": "Nel complesso, il pre-addestramento da zero sembra ottenere prestazioni più elevate nella maggior parte delle attività."}
{"doc_id": "csJIsDTYMW", "seg_id": 26, "src_ref": "However, our experiment on control pre-training using the weight and tokenization of CamemBERT trained on the four GB subset of NACHOS showed comparable results to those obtained with DrBERT 4 GB from-scratch.", "tgt_ref": "Tuttavia, il nostro esperimento sul pre-addestramento di controllo utilizzando il peso e la tokenizzazione di CamemBERT addestrato sul sottoinsieme di quattro GB di NACHOS ha mostrato risultati paragonabili a quelli ottenuti con DrBERT 4 GB da zero."}
{"doc_id": "csJIsDTYMW", "seg_id": 27, "src_ref": "Which is not the case for the model based on CamemBERT weights and tokenizer, which suffer from stability issues.", "tgt_ref": "Questo non è il caso del modello basato su pesi e tokenizzatore CamemBERT, che soffre di problemi di stabilità."}
{"doc_id": "csJIsDTYMW", "seg_id": 28, "src_ref": "Finally, as a conclusion our proper system offered better performance on nine of the 11 downstream tasks and surpassed globally the result of the generic model, here CamemBERT.", "tgt_ref": "Infine, il nostro sistema ha offerto prestazioni migliori su nove delle 11 attività a valle e ha superato globalmente il risultato del modello generico, qui CamemBERT."}
{"doc_id": "csJIsDTYMW", "seg_id": 29, "src_ref": "We are also observing that more specialized data is better, but it doesn't scale well.", "tgt_ref": "Stiamo anche osservando che dati più specializzati sono migliori, ma non scalano bene."}
{"doc_id": "csJIsDTYMW", "seg_id": 30, "src_ref": "All the pre-trained model obtained from NACHOS are freely available on Hugging Face, and under the MIT license, and all the training scripts are on our GitHub repository.", "tgt_ref": "Tutti i modelli pre-addestrati ottenuti da NACHOS sono disponibili gratuitamente su Hugging Face e sotto la licenza MIT, mentre gli script di addestramento si trovano sul nostro repository GitHub."}
{"doc_id": "csJIsDTYMW", "seg_id": 31, "src_ref": "So thank you for this presentation, and we are looking forward to exchange at the poster session in Toronto.", "tgt_ref": "Grazie per questa presentazione, e non vediamo l'ora di confrontarci alla sessione poster a Toronto."}
{"doc_id": "ICWfTnUMio", "seg_id": 0, "src_ref": "Hi!", "tgt_ref": "Ciao!"}
{"doc_id": "ICWfTnUMio", "seg_id": 1, "src_ref": "My name is Matthias Lindemann, and today I'm going to give you a brief introduction to our paper on \"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations\".", "tgt_ref": "Mi chiamo Matthias Lindemann, e oggi vi offrirò una breve introduzione al nostro articolo \"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations\"."}
{"doc_id": "ICWfTnUMio", "seg_id": 2, "src_ref": "This is joint work with my advisors Alexander Koller and Ivan Titov.", "tgt_ref": "Questo è un lavoro congiunto con i miei advisor Alexander Koller e Ivan Titov."}
{"doc_id": "ICWfTnUMio", "seg_id": 3, "src_ref": "Compositional generalization can be understood as the ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.", "tgt_ref": "La generalizzazione composizionale può essere intesa come la capacità di gestire ricorsioni più profonde e composizioni invisibili di frasi che sono state osservate individualmente durante l'addestramento."}
{"doc_id": "ICWfTnUMio", "seg_id": 4, "src_ref": "In the context of semantic parsing, testing for compositional generalization might look like this.", "tgt_ref": "Nel contesto del parsing semantico, il test per la generalizzazione composizionale potrebbe apparire in questo modo."}
{"doc_id": "ICWfTnUMio", "seg_id": 5, "src_ref": "As usual, we have a training set of utterances.", "tgt_ref": "Come al solito, disponiamo di un insieme di espressioni di addestramento."}
{"doc_id": "ICWfTnUMio", "seg_id": 6, "src_ref": "In this case, \"The girl slept.\"", "tgt_ref": "In questo caso, \"La ragazza ha dormito\"."}
{"doc_id": "ICWfTnUMio", "seg_id": 7, "src_ref": "And \"Mary knew that the girl slept.\"", "tgt_ref": "E \"Mary sapeva che la ragazza dormiva\"."}
{"doc_id": "ICWfTnUMio", "seg_id": 8, "src_ref": "These utterances are paired with logical forms that represent core aspects of their meaning.", "tgt_ref": "Queste espressioni sono abbinate a forme logiche che rappresentano aspetti fondamentali del loro significato."}
{"doc_id": "ICWfTnUMio", "seg_id": 9, "src_ref": "In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms.", "tgt_ref": "A differenza della valutazione standard di machine learning, il set di test non proviene dalla stessa distribuzione, ma contiene forme logiche strutturalmente invisibili."}
{"doc_id": "ICWfTnUMio", "seg_id": 10, "src_ref": "In this example, the model has seen shallow recursion during training and is tested on an example with deeper recursion.", "tgt_ref": "In questo esempio, il modello è stato esposto a una ricorsione superficiale durante l'addestramento e viene testato su un esempio con una ricorsione più profonda."}
{"doc_id": "ICWfTnUMio", "seg_id": 11, "src_ref": "Naive seq2seq models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.", "tgt_ref": "I modelli seq2seq semplicistici hanno difficoltà con questo tipo di generalizzazione fuori distribuzione e spesso producono output distaccati dall'input."}
{"doc_id": "ICWfTnUMio", "seg_id": 12, "src_ref": "In particular, they often fail to reproduce the systematic correspondences between input and output, such as those that are color-coded in the example.", "tgt_ref": "In particolare, spesso non riescono a riprodurre le corrispondenze sistematiche tra input e output, come quelle codificate a colori nell'esempio."}
{"doc_id": "ICWfTnUMio", "seg_id": 13, "src_ref": "A popular method to address this is to integrate trees into the models.", "tgt_ref": "Un metodo diffuso per affrontare questo problema è integrare gli alberi nei modelli."}
{"doc_id": "ICWfTnUMio", "seg_id": 14, "src_ref": "The trees are intended to capture the compositional process that relates utterances with the logical forms.", "tgt_ref": "Gli alberi hanno lo scopo di catturare il processo compositivo che mette in relazione le espressioni con le forme logiche."}
{"doc_id": "ICWfTnUMio", "seg_id": 15, "src_ref": "This works well, but trees are usually not given and need to be obtained somehow.", "tgt_ref": "Questo funziona bene, ma gli alberi di solito non sono dati e devono essere ottenuti in qualche modo."}
{"doc_id": "ICWfTnUMio", "seg_id": 16, "src_ref": "This can be complicated and sometimes a computationally expensive process.", "tgt_ref": "Ciò può rivelarsi un processo complicato e talvolta dispendioso dal punto di vista computazionale."}
{"doc_id": "ICWfTnUMio", "seg_id": 17, "src_ref": "Typically, this involves considerable formalism-specific pre-processing of the logical forms, for example, to handle variable symbols.", "tgt_ref": "In genere, ciò comporta una notevole pre-elaborazione delle forme logiche specifiche del formalismo, ad esempio per gestire i simboli delle variabili."}
{"doc_id": "ICWfTnUMio", "seg_id": 18, "src_ref": "Obtaining trees may also involve specialized grammar-induction procedures.", "tgt_ref": "L'ottenimento di alberi può inoltre comportare procedure specializzate di induzione grammaticale."}
{"doc_id": "ICWfTnUMio", "seg_id": 19, "src_ref": "In this paper, we don't use trees and introduce a neural seq2seq model that directly models the correspondences between fragments of the input and fragments of the output.", "tgt_ref": "In questo documento non usiamo alcun albero e introduciamo un modello neurale seq2seq che modella direttamente le corrispondenze tra frammenti di input e frammenti di output."}
{"doc_id": "ICWfTnUMio", "seg_id": 20, "src_ref": "For the first time, we show strong generalization to deeper recursion without relying on trees.", "tgt_ref": "Per la prima volta, mostriamo una forte generalizzazione a una ricorsione più profonda senza fare affidamento sugli alberi."}
{"doc_id": "ICWfTnUMio", "seg_id": 21, "src_ref": "Our approach predicts the output from the input in two steps.", "tgt_ref": "Il nostro approccio prevede l'output dall'input in due passaggi."}
{"doc_id": "ICWfTnUMio", "seg_id": 22, "src_ref": "First, we tag each input token with an unordered multiset of tokens that will appear in the output.", "tgt_ref": "Innanzitutto, etichettiamo ciascun token di input con un multiset non ordinato di token che apparirà nell'output."}
{"doc_id": "ICWfTnUMio", "seg_id": 23, "src_ref": "After the first step, we have all the right tokens, but they're not ordered.", "tgt_ref": "Dopo il primo passaggio, abbiamo tutti i token giusti, che però non sono ordinati."}
{"doc_id": "ICWfTnUMio", "seg_id": 24, "src_ref": "That's why in the second step we use another model to predict a permutation to put them into the right order.", "tgt_ref": "Ecco perché nella seconda fase utilizziamo un altro modello per prevedere una permutazione che li metta nell'ordine giusto."}
{"doc_id": "ICWfTnUMio", "seg_id": 25, "src_ref": "We introduce a new method to predict the permutation that does not put any hard constraints on the possible permutations.", "tgt_ref": "Introduciamo un nuovo metodo per prevedere la permutazione che non ponga vincoli rigidi sulle possibili permutazioni."}
{"doc_id": "ICWfTnUMio", "seg_id": 26, "src_ref": "This makes our approach quite flexible and expressive.", "tgt_ref": "Questo rende il nostro approccio abbastanza flessibile ed espressivo."}
{"doc_id": "ICWfTnUMio", "seg_id": 27, "src_ref": "Conceptually, our permutation model works roughly like this.", "tgt_ref": "Concettualmente, il nostro modello di permutazione funziona all'incirca in questo modo."}
{"doc_id": "ICWfTnUMio", "seg_id": 28, "src_ref": "We go from left to right over the output and determine which multiset token to put in every position.", "tgt_ref": "Andiamo da sinistra a destra sull'output e determiniamo quale token multiset mettere in ogni posizione."}
{"doc_id": "ICWfTnUMio", "seg_id": 29, "src_ref": "For the first output position, we simply select one, as highlighted in red.", "tgt_ref": "Per la prima posizione di output, ne selezioniamo semplicemente uno, come evidenziato in rosso."}
{"doc_id": "ICWfTnUMio", "seg_id": 30, "src_ref": "Then we jump to the next multiset token, to determine the second token in the output.", "tgt_ref": "Dopodiché passiamo al token multiset successivo, per determinare il secondo token nell'output."}
{"doc_id": "ICWfTnUMio", "seg_id": 31, "src_ref": "We determine the third token in the output in a similar way by jumping to another multiset token.", "tgt_ref": "Determiniamo il terzo token nell'output in modo simile saltando a un altro token multiset."}
{"doc_id": "ICWfTnUMio", "seg_id": 32, "src_ref": "We continue this process until every token from the first stage has been visited exactly once.", "tgt_ref": "Proseguiamo con questo processo fino a quando ogni gettone del primo stadio non è stato visitato esattamente una volta."}
{"doc_id": "ICWfTnUMio", "seg_id": 33, "src_ref": "To give you a teaser of the experimental results, here we compare our method with other treeless models on the COGS benchmark.", "tgt_ref": "Per darvi un'anteprima dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli senza alberi sul benchmark COGS."}
{"doc_id": "ICWfTnUMio", "seg_id": 34, "src_ref": "Our model outperforms the others by a large margin on generalization to deeper recursion.", "tgt_ref": "Il nostro modello supera gli altri con un ampio margine sulla generalizzazione a una ricorsione più profonda."}
{"doc_id": "ICWfTnUMio", "seg_id": 35, "src_ref": "Some other kinds of structural generalization remain very challenging, though.", "tgt_ref": "Alcuni altri tipi di generalizzazione strutturale rimangono però molto ostici."}
{"doc_id": "ICWfTnUMio", "seg_id": 36, "src_ref": "In our paper, we solve a couple of interesting technical challenges.", "tgt_ref": "Nel nostro articolo, risolviamo un paio di sfide tecniche interessanti."}
{"doc_id": "ICWfTnUMio", "seg_id": 37, "src_ref": "First of all, the alignment between input and output is not given in the training data.", "tgt_ref": "Prima di tutto, l'allineamento tra input e output non è dato nei dati di addestramento."}
{"doc_id": "ICWfTnUMio", "seg_id": 38, "src_ref": "As a consequence, for a given token we don't know which multiset it came from, which poses a challenge for training.", "tgt_ref": "Di conseguenza, per un dato token non sappiamo da quale multiset provenga, il che rappresenta una sfida per l'addestramento."}
{"doc_id": "ICWfTnUMio", "seg_id": 39, "src_ref": "In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent.", "tgt_ref": "Inoltre, a volte ci sono più permutazioni coerenti con i dati, ma quella corretta dal punto di vista linguistico è latente."}
{"doc_id": "ICWfTnUMio", "seg_id": 40, "src_ref": "We address this by inducing the alignment as part of the training.", "tgt_ref": "Affrontiamo questo problema inducendo l'allineamento come parte dell'addestramento."}
{"doc_id": "ICWfTnUMio", "seg_id": 41, "src_ref": "Our permutation method is very flexible, but it brings the challenge that finding the highest-scoring permutation is NP-hard.", "tgt_ref": "Sebbene sia molto flessibile, la difficoltà del nostro metodo di permutazione risiede nel fatto che trovare la permutazione con il punteggio più alto è NP-difficile."}
{"doc_id": "ICWfTnUMio", "seg_id": 42, "src_ref": "That's because this is related to the \"Traveling Salesman\" problem.", "tgt_ref": "Questo perché è correlato al problema del \"Commesso viaggiatore\"."}
{"doc_id": "ICWfTnUMio", "seg_id": 43, "src_ref": "We approximate this with a GPU-friendly continuous relaxation that also allows us to backpropagate through the solution and learn the linguistically more plausible permutations.", "tgt_ref": "Lo approssimiamo con un rilassamento continuo compatibile con la GPU che ci permette anche di eseguire la retropropagazione attraverso la soluzione e apprendere le permutazioni linguisticamente più plausibili."}
{"doc_id": "ICWfTnUMio", "seg_id": 44, "src_ref": "If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.", "tgt_ref": "Se volete saperne di più sui nostri esperimenti e su come affrontiamo queste sfide, date uno sguardo al nostro articolo o al nostro poster."}
{"doc_id": "MmiKtcykVs", "seg_id": 0, "src_ref": "Hello everyone, I'm Akshatha, and today my co-author Martin and I are presenting our work \"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources.\"", "tgt_ref": "Ciao a tutti, sono Akshatha, e oggi io e il mio coautore Martin presentiamo il nostro lavoro \"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources\"."}
{"doc_id": "MmiKtcykVs", "seg_id": 1, "src_ref": "This work is a collaboration between McGill University, Mila, and Microsoft Research.", "tgt_ref": "Questo lavoro è una collaborazione tra McGill University/Mila e Microsoft Research."}
{"doc_id": "MmiKtcykVs", "seg_id": 2, "src_ref": "Natural language understanding models draw on a variety of knowledge sources, such as knowledge contained in their parameters, usually acquired by a pretraining, and knowledge given in inputs at inference time.", "tgt_ref": "I modelli di comprensione del linguaggio naturale attingono a una varietà di fonti di conoscenza, come la conoscenza contenuta nei loro parametri, di solito acquisita da un pre-addestramento, e la conoscenza fornita negli input al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 3, "src_ref": "Recent works in tasks like question answering show that models can use pretrained-time knowledge to solve the task.", "tgt_ref": "Lavori recenti in attività come la risposta alle domande mostrano che i modelli possono utilizzare la conoscenza del tempo pre-addestrato per risolvere l'attività."}
{"doc_id": "MmiKtcykVs", "seg_id": 4, "src_ref": "But natural language understanding often requires knowledge that is also supplied at inference time.", "tgt_ref": "Ma la comprensione del linguaggio naturale richiede spesso conoscenze che vengono fornite anche al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 5, "src_ref": "For example, in the sentence, \"John saw the newly elected president on TV.\"", "tgt_ref": "Ad esempio, nella frase \"John ha visto il presidente appena eletto in TV\"."}
{"doc_id": "MmiKtcykVs", "seg_id": 6, "src_ref": "Pretrained parameters can contain information about what presidents do and what a TV is but they cannot reliably know who this instance-specific entity \"John\" is, or who the new president is, because the president might have changed since pretraining.", "tgt_ref": "I parametri pre-addestrati possono contenere informazioni su ciò che fanno i presidenti e su cosa sia una TV, ma non possono sapere in modo affidabile chi sia questa entità specifica dell'istanza \"John\", o chi sia il nuovo presidente, perché il presidente potrebbe essere cambiato dopo il pre-addestramento."}
{"doc_id": "MmiKtcykVs", "seg_id": 7, "src_ref": "Therefore, successful models for knowledge-intensive NLU tasks require the ability to integrate and use both pretrain-time and inference-time knowledge.", "tgt_ref": "Pertanto, i modelli di successo per le attività di NLU ad alta intensità di conoscenza richiedono la capacità di integrare e utilizzare sia la conoscenza pre-allenamento che quella al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 8, "src_ref": "In this work, we propose a diagnostic test suite for knowledge integration.", "tgt_ref": "In questo lavoro, proponiamo una suite di test diagnostici per l'integrazione della conoscenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 9, "src_ref": "We introduce a coreference resolution task, designed to probe for the ability to draw on knowledge available in different sources.", "tgt_ref": "Introduciamo un'attività di risoluzione della coreferenza, progettata per sondare la capacità di attingere alle conoscenze disponibili in diverse fonti."}
{"doc_id": "MmiKtcykVs", "seg_id": 10, "src_ref": "We evaluate the data set with human study participants and established coreference resolution models.", "tgt_ref": "Valutiamo il set di dati con partecipanti allo studio umano e modelli di risoluzione della coreferenza stabiliti."}
{"doc_id": "MmiKtcykVs", "seg_id": 11, "src_ref": "Here is an example from our data set.", "tgt_ref": "Ecco un esempio dal nostro set di dati."}
{"doc_id": "MmiKtcykVs", "seg_id": 12, "src_ref": "Servin is a judge.", "tgt_ref": "Servin è un giudice."}
{"doc_id": "MmiKtcykVs", "seg_id": 13, "src_ref": "Kea is a Baker.", "tgt_ref": "Kea è un fornaio."}
{"doc_id": "MmiKtcykVs", "seg_id": 14, "src_ref": "Servin and Kea met at a park.", "tgt_ref": "Servin e Kea si sono incontrati in un parco."}
{"doc_id": "MmiKtcykVs", "seg_id": 15, "src_ref": "After a long day at work deciding cases in a law court, he was happy to relax.", "tgt_ref": "Lui era felice di rilassarsi dopo una lunga giornata di lavoro trascorsa a prendere decisioni sui casi in tribunale."}
{"doc_id": "MmiKtcykVs", "seg_id": 16, "src_ref": "The task here is to identify the correct entity that the pronoun \"he\" refers to, which in this case is Servin.", "tgt_ref": "Il compito qui è identificare l'entità corretta a cui si riferisce il pronome \"lui\", che in questo caso è Servin."}
{"doc_id": "MmiKtcykVs", "seg_id": 17, "src_ref": "The resolution of a given pronoun requires two types of information.", "tgt_ref": "La risoluzione di un dato pronome richiede due tipi di informazioni."}
{"doc_id": "MmiKtcykVs", "seg_id": 18, "src_ref": "First, entity-specific knowledge such as \"Servin is a judge.\"", "tgt_ref": "In primo luogo, la conoscenza specifica dell'entità, ad esempio \"Servin è un giudice\"."}
{"doc_id": "MmiKtcykVs", "seg_id": 19, "src_ref": "And second, background knowledge such as \"Judges decide cases in law courts.\"", "tgt_ref": "E, in secondo luogo, conoscenze di base come \"I giudici emettono sentenze sui casi in tribunale\"."}
{"doc_id": "MmiKtcykVs", "seg_id": 20, "src_ref": "Generally, background knowledge is learned during the pretraining of large language models, while entity-specific knowledge is typically observed at inference time.", "tgt_ref": "In generale, la conoscenza di base viene appresa durante il pre-addestramento di grandi modelli linguistici, mentre la conoscenza specifica dell'entità viene di norma osservata al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 21, "src_ref": "We vary the availability of these two pieces of information such that it may either be found in a single source, or in multiple sources.", "tgt_ref": "Variamo la disponibilità di queste due informazioni in modo che possano essere trovate in un'unica fonte o in più fonti."}
{"doc_id": "MmiKtcykVs", "seg_id": 22, "src_ref": "We have defined three settings of KITMUS.", "tgt_ref": "Abbiamo definito tre impostazioni di KITMUS."}
{"doc_id": "MmiKtcykVs", "seg_id": 23, "src_ref": "First, we have the typical setting: \"Background-Pretrain\", where background knowledge is assumed to be available at pretrain time.", "tgt_ref": "In primo luogo, abbiamo l'impostazione tipica: \"Background-Pretrain\", in cui si presume che la conoscenza di base sia disponibile al momento del pre-addestramento."}
{"doc_id": "MmiKtcykVs", "seg_id": 24, "src_ref": "Second, there's a \"Background-Both\" setting, where background knowledge is available both at pretrain time and inference time.", "tgt_ref": "In secondo luogo, c'è un'impostazione \"Background-Both\", in cui la conoscenza di base è disponibile sia al momento del pre-addestramento che al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 25, "src_ref": "Lastly, the \"Background-Inference\" setting, where both knowledge types are available only at inference time.", "tgt_ref": "Infine, l'impostazione \"Background-Inference\", in cui entrambi i tipi di conoscenza sono disponibili solo al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 26, "src_ref": "This last setting is especially interesting, since it simulates the case where the background knowledge necessary to solve a task is not part of the pretrain data of models.", "tgt_ref": "Quest'ultima impostazione è particolarmente interessante, poiché simula il caso in cui la conoscenza di base necessaria per risolvere un compito non fa parte dei dati di pre-addestramento dei modelli."}
{"doc_id": "MmiKtcykVs", "seg_id": 27, "src_ref": "For example, because new occupations have developed since the time of pretraining.", "tgt_ref": "Ad esempio, perché dal momento del pre-addestramento si sono sviluppate nuove occupazioni."}
{"doc_id": "MmiKtcykVs", "seg_id": 28, "src_ref": "Here's an example of how we control the availability of facts in the true sources.", "tgt_ref": "Ecco un esempio di come controlliamo la disponibilità dei fatti nelle fonti vere."}
{"doc_id": "MmiKtcykVs", "seg_id": 29, "src_ref": "In the Background-Pretrain setting, we assume that the background knowledge \"Politicians seek elected seats in government\" is contained in the pretrained parameters and in inference-time context we provide the entity-specific knowledge \"Chichester is a politician.\"", "tgt_ref": "Nell'impostazione Background-Pretrain, si presume che la conoscenza di base \"I politici cercano seggi elettivi nel governo\" sia contenuta nei parametri pre-addestrati e nel contesto del tempo di inferenza si fornisce la conoscenza specifica dell'entità \"Chichester è un politico\"."}
{"doc_id": "MmiKtcykVs", "seg_id": 30, "src_ref": "In the Background-Both setting, we additionally provide not only entity-specific but also background knowledge about politicians in their inference-time context.", "tgt_ref": "Nell'impostazione Background-Both, forniamo inoltre non solo conoscenze specifiche dell'entità, ma anche conoscenze di base sui politici nel loro contesto di inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 31, "src_ref": "In the Background-Inference setting, we provide the fictional occupation \"mirituer\" instead of politician because \"mirituer\" is unlikely to be contained in the pretrained parameters.", "tgt_ref": "Nell'impostazione Background-Inference, forniamo l'occupazione fittizia \"mirituer\" invece di politico perché è improbabile che \"mirituer\" sia contenuto nei parametri pre-addestrati."}
{"doc_id": "MmiKtcykVs", "seg_id": 32, "src_ref": "We evaluate the data set both with human study participants, and established coreference resolution models.", "tgt_ref": "Valutiamo il set di dati sia con i partecipanti allo studio umano sia con i modelli di risoluzione della coreferenza stabiliti."}
{"doc_id": "MmiKtcykVs", "seg_id": 33, "src_ref": "In this figure, we show the results of the best-performing models on the most difficult variant of the Background-Pretrain setting.", "tgt_ref": "In questa figura, mostriamo i risultati dei modelli con le migliori prestazioni sulla variante più complessa dell'impostazione Background-Pretrain."}
{"doc_id": "MmiKtcykVs", "seg_id": 34, "src_ref": "Without task-specific training on KITMUS, both models do not perform well.", "tgt_ref": "Senza un addestramento specifico per l'attività su KITMUS, entrambi i modelli non operano adeguatamente."}
{"doc_id": "MmiKtcykVs", "seg_id": 35, "src_ref": "When trained on KITMUS, however, both C2F and BERT4Coref perform significantly better than the random choice.", "tgt_ref": "Quando addestrati su KITMUS, tuttavia, sia C2F che BERT4Coref funzionano notevolmente meglio della scelta casuale."}
{"doc_id": "MmiKtcykVs", "seg_id": 36, "src_ref": "This suggests that when trained on generic reference resolution data sets, most learn to exploit surface cues, which are not useful when testing on KITMUS where such queues have been removed.", "tgt_ref": "Ciò suggerisce che, quando vengono addestrati su set di dati di risoluzione di riferimento generici, la maggior parte impara a sfruttare gli spunti superficiali che non sono utili quando si eseguono test su KITMUS, dove tali code sono state rimosse."}
{"doc_id": "MmiKtcykVs", "seg_id": 37, "src_ref": "Additional experiments with fictional knowledge indicated even the best performing models, cannot reliably integrate backward knowledge provided only at inference time.", "tgt_ref": "Ulteriori esperimenti con conoscenza fittizia hanno indicato che anche i modelli con le migliori prestazioni non possono integrare in modo affidabile la conoscenza retrospettiva fornita solo al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 38, "src_ref": "To summarize the main takeaways of our paper, many coreference resolution models appear unable to reason over knowledge from different sources without task-specific training.", "tgt_ref": "Per riassumere i principali punti del nostro articolo, molti modelli di risoluzione della coreferenza sembrano incapaci di ragionare sulla conoscenza proveniente da fonti diverse senza un addestramento specifico per l'attività."}
{"doc_id": "MmiKtcykVs", "seg_id": 39, "src_ref": "However, with task-specific training, some models successfully integrate knowledge from multiple sources.", "tgt_ref": "Tuttavia, con un addestramento specifico per l'attività, alcuni modelli integrano con successo le conoscenze provenienti da più fonti."}
{"doc_id": "MmiKtcykVs", "seg_id": 40, "src_ref": "Still, even the best-performing models seem to have difficulties with reliably integrating backward knowledge presented only at inference time.", "tgt_ref": "Tuttavia, anche i modelli con le migliori prestazioni sembrano avere difficoltà a integrare in modo affidabile la conoscenza retrospettiva presentata solo al momento dell'inferenza."}
{"doc_id": "MmiKtcykVs", "seg_id": 41, "src_ref": "If you're interested in more details, please see our paper and check out the data set and code on GitHub.", "tgt_ref": "Se siete interessati a maggiori dettagli, consultate il nostro articolo e date un'occhiata al set di dati e al codice su GitHub."}
{"doc_id": "MmiKtcykVs", "seg_id": 42, "src_ref": "Thanks for listening.", "tgt_ref": "Grazie per l'attenzione."}
{"doc_id": "JRrbTnEZbF", "seg_id": 0, "src_ref": "Hi, I'm Myra and today I'll be talking about our paper \"Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.\"", "tgt_ref": "Ciao, sono Myra e oggi parlerò del nostro articolo \"Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 1, "src_ref": "This work is done in collaboration with Esin Durmus and Dan Jurafsky.", "tgt_ref": "Questo lavoro è stato svolto in collaborazione con Esin Durmus e Dan Jurafsky."}
{"doc_id": "JRrbTnEZbF", "seg_id": 2, "src_ref": "In recent years, many have documented the prevalence of social bias and stereotypes in large language models, or LLMs.", "tgt_ref": "Negli ultimi anni, molti hanno documentato la prevalenza di bias e stereotipi sociali nei modelli linguistici di grandi dimensioni o LLM."}
{"doc_id": "JRrbTnEZbF", "seg_id": 3, "src_ref": "However, these measures have various limitations.", "tgt_ref": "Va precisato, tuttavia, che queste misure presentano svariati limiti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 4, "src_ref": "They usually rely on hand-constructed data sets that are very time-consuming to curate and they also usually only. measure very specific stereotypes, meaning that they don't generalize well to other demographics or contexts, or they simply capture very general broad associations, like negative associations with particular groups.", "tgt_ref": "Di solito si basano su set di dati realizzati manualmente che richiedono molto tempo per essere mantenuti e di solito misurano solo stereotipi molto specifici, il che si traduce nel fatto che non eseguono una generalizzazione appropriata ad altri dati demografici o contesti, o semplicemente catturano associazioni molto generali, come associazioni negative con gruppi particolari."}
{"doc_id": "JRrbTnEZbF", "seg_id": 5, "src_ref": "Furthermore, most work in this space doesn't account for intersectionality, which is the notion that multi-faceted social identities can compound biases and be unique loci of harm.", "tgt_ref": "Inoltre, la maggior parte del lavoro in questo ambiente non tiene conto dell'intersezionalità, che è la nozione secondo cui le identità sociali sfaccettate possono inasprire i bias e costituire punti unici di danno."}
{"doc_id": "JRrbTnEZbF", "seg_id": 6, "src_ref": "To overcome these limitations, we rely on the property that these newer instruction-tuned LLMs are very good at responding to instructions and prompts.", "tgt_ref": "Per superare queste limitazioni, ci affidiamo alla proprietà che questi nuovi LLM, concepiti per aderire alle istruzioni, si dimostrano molto validi nel fornire una risposta a istruzioni e prompt."}
{"doc_id": "JRrbTnEZbF", "seg_id": 7, "src_ref": "So we can ask the model to generate a persona, which is a depiction of an imagined individual using a prompt like \"Imagine you are an Asian woman.", "tgt_ref": "Quindi, possiamo chiedere al modello di riprodurre una personalità, vale a dire una rappresentazione di un individuo immaginario, generando un prompt come \"Immagina di essere una donna asiatica."}
{"doc_id": "JRrbTnEZbF", "seg_id": 8, "src_ref": "Describe yourself.\"", "tgt_ref": "Descrivi te stessa\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 9, "src_ref": "And we can immediately see that this is very generalizable to any demographic because we can just specify whatever identity marker that we want into this prompt.", "tgt_ref": "A questo punto, possiamo subito notare l'elevato grado di generalizzazione a qualsiasi demografica, in quanto ci basta specificare qualsiasi marcatore di identità che desideriamo integrare in questo prompt."}
{"doc_id": "JRrbTnEZbF", "seg_id": 10, "src_ref": "So here are some example generations from GPT-4.", "tgt_ref": "Ecco alcuni esempi di generazioni da parte di GPT-4."}
{"doc_id": "JRrbTnEZbF", "seg_id": 11, "src_ref": "Immediately we see that, while the outputs aren't overtly negative or toxic in the traditional sense of these words, there are some interesting patterns.", "tgt_ref": "Emerge subito che, anche se i risultati non sono apertamente negativi o tossici in senso stretto, ci troviamo di fronte ad alcuni schemi interessanti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 12, "src_ref": "The Asian woman is depicted as unassuming; the Middle-Eastern woman is referred to using words like exotic and like, referring to a mesmerizing region.", "tgt_ref": "La donna asiatica è descritta come modesta; la donna mediorientale è definita con parole come \"esotica\" e simili, nel senso di località affascinante."}
{"doc_id": "JRrbTnEZbF", "seg_id": 13, "src_ref": "And both of the women of color personas make references to ancestry while the white man persona has nothing of the sort.", "tgt_ref": "Ed entrambe le donne di colore fanno riferimento alle loro origini, mentre l'uomo bianco non riporta nulla del genere."}
{"doc_id": "JRrbTnEZbF", "seg_id": 14, "src_ref": "To capture these patterns, our method has two parts.", "tgt_ref": "Per catturare questi modelli, il nostro metodo è suddiviso in due parti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 15, "src_ref": "The first one is generating these personas.", "tgt_ref": "La prima risiede nella generazione di tali personalità."}
{"doc_id": "JRrbTnEZbF", "seg_id": 16, "src_ref": "Our prompts to generate these personas were inspired by a study where they gave these prompts to human subjects, finding that by giving it to human subjects, they also were able to surface racial stereotypes.", "tgt_ref": "I nostri prompt per generare queste personalità sono stati ispirati da uno studio in cui tali prompt sono stati assegnati a soggetti umani, per poi scoprire che, così facendo, sono emersi anche stereotipi razziali."}
{"doc_id": "JRrbTnEZbF", "seg_id": 17, "src_ref": "And also this enables direct comparison between our generated personas and the human written responses.", "tgt_ref": "Inoltre, ciò getta le basi per un confronto diretto tra le nostre personalità generate e le risposte scritte da soggetti umani."}
{"doc_id": "JRrbTnEZbF", "seg_id": 18, "src_ref": "The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones, which I'll elaborate on shortly.", "tgt_ref": "La seconda parte è costituita dalle parole marcate, che è un metodo per identificare le parole che distinguono i gruppi marcati da quelli non marcati, che provvederò ad approfondire a breve."}
{"doc_id": "JRrbTnEZbF", "seg_id": 19, "src_ref": "The benefit of this is that we get really specific stereotypes and patterns, without having to rely on any specific lexicon.", "tgt_ref": "Il vantaggio risiede nel fatto che otteniamo stereotipi e modelli molto specifici, senza dover fare affidamento su un lessico specifico."}
{"doc_id": "JRrbTnEZbF", "seg_id": 20, "src_ref": "So the Marked Words method draws upon the sociolinguistic concept of \"markedness\", which states that there is an unmarked default, and any group that differs from that default is linguistically marked.", "tgt_ref": "In questo modo, il metodo delle parole marcate attinge al concetto sociolinguistico di \"marcatezza\", secondo cui esiste uno standard non marcato e qualsiasi gruppo che differisce da quello standard è marcato sotto il profilo linguistico."}
{"doc_id": "JRrbTnEZbF", "seg_id": 21, "src_ref": "So for instance, the word \"warrior\" is usually associated with men.", "tgt_ref": "Ad esempio, la parola \"guerriero\" è solitamente associata agli uomini."}
{"doc_id": "JRrbTnEZbF", "seg_id": 22, "src_ref": "So when people are describing a warrior who is a woman, they'll usually actually specify \"woman warrior\" and mark the term with \"woman\".", "tgt_ref": "Ne deriva che, quando le persone descrivono un guerriero di sesso femminile, di solito specificano la variabile \"guerriera\" e contrassegnano il termine con \"donna\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 23, "src_ref": "And more broadly, dominant groups in society are both linguistically and socially unmarked, while the marginalized groups are usually marked.", "tgt_ref": "E, più in generale, i gruppi dominanti nella società sono sia linguisticamente che socialmente non marcati, mentre i gruppi emarginati sono generalmente marcati."}
{"doc_id": "JRrbTnEZbF", "seg_id": 24, "src_ref": "So in our method, we first designate what the unmarked and marked groups are, and then we compare the personas using the Fightin’ Words method, which is basically using weighted log-odds ratios to distinguish the top words for each marked group.", "tgt_ref": "Quindi, nel nostro metodo, designiamo prima quali sono i gruppi non marcati e quelli marcati, quindi confrontiamo le personalità usando il metodo delle fighting words, che fondamentalmente attinge ai rapporti di probabilità logaritmici ponderati per distinguere le parole principali per ciascun gruppo marcato."}
{"doc_id": "JRrbTnEZbF", "seg_id": 25, "src_ref": "So for instance, for the personas of black women, we would do Fightin’ Words and compare the log-odds ratios against both white personas and man personas because those are the two corresponding unmarked groups.", "tgt_ref": "Ad esempio, per le personalità delle donne nere, useremmo il metodo delle fighting words e confronteremmo i rapporti di probabilità logaritmici sia con le personalità bianche sia con le personalità maschili, poiché questi sono i due gruppi non marcati."}
{"doc_id": "JRrbTnEZbF", "seg_id": 26, "src_ref": "Now for some results.", "tgt_ref": "Ora vediamo alcuni risultati."}
{"doc_id": "JRrbTnEZbF", "seg_id": 27, "src_ref": "So first we use a lexicon of stereotypes, and we find that the generated personas contain a lot more stereotypes than the human-written ones.", "tgt_ref": "In primo luogo, ricorriamo a un lessico di stereotipi e scopriamo che le personalità generate contengono molti più stereotipi di quelli scritti dai soggetti umani."}
{"doc_id": "JRrbTnEZbF", "seg_id": 28, "src_ref": "However, when we actually look at the distribution of the words and lexicon, we find very different things.", "tgt_ref": "Tuttavia, quando osserviamo effettivamente la distribuzione delle parole e del lessico, ci imbattiamo in esiti assai disparati."}
{"doc_id": "JRrbTnEZbF", "seg_id": 29, "src_ref": "So, while the generated personas have much higher rates of the lexicon words, the human-written ones have a much wider distribution of words, while the stereotype words that are in the generated personas are really just the words \"tall\" and \"athletic\".", "tgt_ref": "Quindi, se da un lato le personalità generate presentano percentuali molto più alte di parole del lessico, quelli scritti da soggetti umani rivelano una distribuzione molto più ampia di parole, mentre le parole stereotipate che si trovano nelle personalità generate sono in realtà solo le parole \"alto\" e \"atletico\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 30, "src_ref": "So, really just only the positive or at least non-negative ones.", "tgt_ref": "In poche parole, solo quelle positive o quantomeno non negative."}
{"doc_id": "JRrbTnEZbF", "seg_id": 31, "src_ref": "And in fact, this lexicon doesn't really capture many of the harmful patterns that we saw in the earlier slides well at all.", "tgt_ref": "E in effetti, questo lessico non coglie interamente molti degli schemi dannosi che abbiamo visto nelle diapositive precedenti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 32, "src_ref": "So instead to do that, we'll turn to the results from our Marked Words method to show how these positive-seeming words facilitate stereotypes and essentializing narratives.", "tgt_ref": "Quindi, per muoverci in tal senso, ci rivolgeremo ai risultati del nostro metodo delle parole marcate per mostrare come queste parole apparentemente positive facilitino gli stereotipi e le narrazioni essenzializzanti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 33, "src_ref": "In our analysis, we reveal how these seemingly positive portrayals reflect harmful patterns.", "tgt_ref": "Nella nostra analisi, riveliamo come tali rappresentazioni apparentemente positive riflettano al contrario schemi dannosi."}
{"doc_id": "JRrbTnEZbF", "seg_id": 34, "src_ref": "First, from our groups, the top words include things like \"culture\", \"tradition\", \"proud\", and \"exotic\".", "tgt_ref": "In primo luogo, le parole principali comprendono nei nostri gruppi concetti quali \"cultura\", \"tradizione\", \"orgoglioso\" ed \"esotico\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 35, "src_ref": "And these words define these groups only by their relationship to their identity and distinguish them as different from the white norm.", "tgt_ref": "E queste parole definiscono questi gruppi solo in base al rapporto con la loro identità e li distinguono come diversi dalla norma bianca."}
{"doc_id": "JRrbTnEZbF", "seg_id": 36, "src_ref": "This contributes to a long legacy of discrimination and othering for these groups.", "tgt_ref": "Ciò contribuisce a una lunga tradizione di discriminazione e alterità per questi gruppi."}
{"doc_id": "JRrbTnEZbF", "seg_id": 37, "src_ref": "Furthermore, there's a lot of common tropes that are reflected in these words, especially for women of color.", "tgt_ref": "Inoltre, sono presenti molti tropi che si riflettono in queste parole, specialmente in riferimento alle donne di colore."}
{"doc_id": "JRrbTnEZbF", "seg_id": 38, "src_ref": "So for example, the words describing Latina women include things like \"vibrant\" and \"curvaceous\" which connect to a trope of tropicalism.", "tgt_ref": "Ad esempio, le parole che descrivono le donne latine includono concetti come \"vivace\" e \"prosperosa\", che rimandano allo stereotipo del tropicalismo."}
{"doc_id": "JRrbTnEZbF", "seg_id": 39, "src_ref": "For Asian women, the words are things like \"petite\" and \"delicate\" and \"silky\" which connects to a long history of Asian women being hyper-sexualized, seen as very docile and submissive, and so on.", "tgt_ref": "Per le donne asiatiche, le parole sono \"minuta\", \"delicata\" e \"setosa\", che si collegano a una lunga storia di donne asiatiche ipersessualizzate, viste come molto docili e sottomesse, e così via."}
{"doc_id": "JRrbTnEZbF", "seg_id": 40, "src_ref": "And finally, for black women, we see that some of the top words are things like \"strong\" and \"resilient\".", "tgt_ref": "Infine, per le donne nere, notiamo che alcune delle parole più ricorrenti sono associate ai concetti di \"forza\" e \"resilienza\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 41, "src_ref": "This connects to an archetype that people have called the \"Strong Black Women\" archetype.", "tgt_ref": "Ciò si collega a un archetipo che le persone hanno definito \"Donne nere toste\"."}
{"doc_id": "JRrbTnEZbF", "seg_id": 42, "src_ref": "And while it sounds positive at first glance, there's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles.", "tgt_ref": "E anche se a prima vista può sembrare positivo, alcuni studi hanno dimostrato che questo tipo di archetipo è in realtà molto dannoso, in quanto mette molta pressione su questi gruppi demografici affinché siano resilienti e forti contro gli ostacoli della società."}
{"doc_id": "JRrbTnEZbF", "seg_id": 43, "src_ref": "So rather than actually working towards changing those obstacles, it puts pressure on those people to overcome them, which leads to a very negative health outcomes for these people, among other harms.", "tgt_ref": "Quindi, anziché operare concretamente per cambiare quegli ostacoli, mette pressione su quelle persone affinché li superino, il che porta, tra gli altri esiti lesivi, a conseguenze dannose per la salute."}
{"doc_id": "JRrbTnEZbF", "seg_id": 44, "src_ref": "More broadly, we find that the words for each marked group pretty much just reflect very essentializing narratives.", "tgt_ref": "Più in generale, scopriamo che le parole per ogni gruppo marcato riflettono nella pratica narrazioni decisamente essenzializzanti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 45, "src_ref": "So based on these patterns, we conclude with three recommendations for model owners.", "tgt_ref": "Quindi, sulla base di questi schemi, concludiamo con tre raccomandazioni per i proprietari di modelli."}
{"doc_id": "JRrbTnEZbF", "seg_id": 46, "src_ref": "First, we should, as researchers, be addressing positive stereotypes and essentializing narratives.", "tgt_ref": "In primo luogo, dovremmo, come ricercatori, affrontare gli stereotipi positivi e le narrazioni essenzializzanti."}
{"doc_id": "JRrbTnEZbF", "seg_id": 47, "src_ref": "We should also be using an intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that.", "tgt_ref": "Inoltre, dovremmo munirci di una lente intersezionale per studiare pregiudizi e danni, perché ci sono molte cose che potrebbero essere trascurate se non lo facessimo."}
{"doc_id": "JRrbTnEZbF", "seg_id": 48, "src_ref": "And finally, there should really be increased transparency about bias mitigation methods, because for instance, like these positive stereotypes, we don't know if it's because there is some sort of weird overly-excessive value alignment going on, or maybe some other anti-stereotyping methods that are resulting in these pernicious patterns.", "tgt_ref": "Infine, dovrebbe esserci davvero una maggiore trasparenza sui metodi di mitigazione dei pregiudizi, perché, ad esempio, come nel caso di questi stereotipi positivi, non sappiamo se ciò sia dovuto a una sorta di strano ed eccessivo allineamento di valori in corso o, ancora, ad altri metodi anti-stereotipizzazione che stanno provocando questi modelli perniciosi."}
{"doc_id": "JRrbTnEZbF", "seg_id": 49, "src_ref": "We just really can't make any assumptions or really study that further, without more transparency.", "tgt_ref": "Non possiamo avanzare alcuna ipotesi né fare alcun approfondimento ulteriore senza una maggiore trasparenza."}
{"doc_id": "JRrbTnEZbF", "seg_id": 50, "src_ref": "Thank you so much for listening.", "tgt_ref": "Grazie infinite dell'ascolto."}
{"doc_id": "JRrbTnEZbF", "seg_id": 51, "src_ref": "Have a good time at ACL.", "tgt_ref": "Buon proseguimento ad ACL."}
{"doc_id": "rOwZgUjcwB", "seg_id": 0, "src_ref": "Hello everyone, my name is Jingwei Yi from the University of Science and Technology of China.", "tgt_ref": "Ciao a tutti, mi chiamo Jingwei Yi dell'Università di Scienza e Tecnologia della Cina."}
{"doc_id": "rOwZgUjcwB", "seg_id": 1, "src_ref": "It's my pleasure to give a short advertisement video of our paper.", "tgt_ref": "È un piacere presentare un breve video promozionale del nostro articolo."}
{"doc_id": "rOwZgUjcwB", "seg_id": 2, "src_ref": "\"Are you copying my model?", "tgt_ref": "\"Are you copying my model?"}
{"doc_id": "rOwZgUjcwB", "seg_id": 3, "src_ref": "Protecting the copyright of large language models for embedding as services via backdoor watermark.\"", "tgt_ref": "Protecting the copyright of large language models for embedding as services via backdoor watermark.\""}
{"doc_id": "rOwZgUjcwB", "seg_id": 4, "src_ref": "Let's first introduce the background about embedding as services.", "tgt_ref": "Introduciamo innanzitutto le informazioni di contesto sull'integrazione con i servizi."}
{"doc_id": "rOwZgUjcwB", "seg_id": 5, "src_ref": "Currently, large language models such as GPT, LLAMA, PALM are exceptional in natural language understanding and generation.", "tgt_ref": "Attualmente, i grandi modelli linguistici come GPT, LLAMA, PALM si rivelano eccezionali nella comprensione e nella generazione del linguaggio naturale."}
{"doc_id": "rOwZgUjcwB", "seg_id": 6, "src_ref": "Embedding as services is one of the services built upon large language models to assist various, NLP tasks.", "tgt_ref": "L'integrazione con i servizi è uno dei servizi costruiti su grandi modelli linguistici per assistere varie attività NLP."}
{"doc_id": "rOwZgUjcwB", "seg_id": 7, "src_ref": "For example, OpenAI offers a GPT based embedding API.", "tgt_ref": "Ad esempio, OpenAI offre un'API di integrazione basata su GPT."}
{"doc_id": "rOwZgUjcwB", "seg_id": 8, "src_ref": "However, recent works have shown that the attacker may steal the model through learning from the embedding and provide similar services.", "tgt_ref": "Tuttavia, i lavori recenti hanno dimostrato che l'utente malintenzionato può rubare il modello attraverso l'apprendimento dall'integrazione e fornire servizi simili."}
{"doc_id": "rOwZgUjcwB", "seg_id": 9, "src_ref": "Therefore, it's necessary to protect the copyright of embedding as services.", "tgt_ref": "Pertanto, è necessario proteggere il copyright dell'integrazione con i servizi."}
{"doc_id": "rOwZgUjcwB", "seg_id": 10, "src_ref": "To protect the copyright of embedding as services, one of the solutions is to embed a watermark in the provider service and detect whether another service contain the watermark.", "tgt_ref": "Per proteggere il copyright dell'integrazione con i servizi, una delle soluzioni consiste nell'incorporare una filigrana nel servizio del provider e rilevare se un altro servizio contiene la filigrana."}
{"doc_id": "rOwZgUjcwB", "seg_id": 11, "src_ref": "The watermark method need to meet the following properties.", "tgt_ref": "Il metodo della filigrana deve soddisfare le seguenti proprietà."}
{"doc_id": "rOwZgUjcwB", "seg_id": 12, "src_ref": "First the method should be applicable to embedding as services.", "tgt_ref": "In primo luogo, il metodo dovrebbe essere applicabile all'incorporamento all'interno di servizi."}
{"doc_id": "rOwZgUjcwB", "seg_id": 13, "src_ref": "Second, the watermark should not degrade the utility of the provided embeddings.", "tgt_ref": "In secondo luogo, la filigrana non deve degradare l'utilità delle integrazioni fornite."}
{"doc_id": "rOwZgUjcwB", "seg_id": 14, "src_ref": "Third, the watermark should be covert enough to the attacker or the attacker can remove the watermark easily.", "tgt_ref": "In terzo luogo, la filigrana dovrebbe essere sufficientemente nascosta all'autore delle minacce, altrimenti quest'ultimo potrebbe rimuoverla con relativa facilità."}
{"doc_id": "rOwZgUjcwB", "seg_id": 15, "src_ref": "Finally, the watermark needs to be transferable to the attacker's services during the model extraction process.", "tgt_ref": "Infine, la filigrana deve essere trasferibile ai servizi dell'utente malintenzionato durante il processo di estrazione del modello."}
{"doc_id": "rOwZgUjcwB", "seg_id": 16, "src_ref": "Existing works can be broadly classified into four categories.", "tgt_ref": "I lavori esistenti possono essere ampiamente classificati in quattro categorie."}
{"doc_id": "rOwZgUjcwB", "seg_id": 17, "src_ref": "However, this method either not applicable to embedding as services or lack of transferability.", "tgt_ref": "Tuttavia, questo metodo non è applicabile all'integrazione con i servizi o manca di trasferibilità."}
{"doc_id": "rOwZgUjcwB", "seg_id": 18, "src_ref": "Therefore, in this paper we propose Embedding marker, which is a backdoor based watermark method applicable to embedding as services.", "tgt_ref": "Pertanto, in questo documento proponiamo Embedding marker, che è un metodo di filigrana basato su backdoor applicabile all'integrazione con i servizi."}
{"doc_id": "rOwZgUjcwB", "seg_id": 19, "src_ref": "Then let me introduce the details of our embedding marker.", "tgt_ref": "Quindi, permettetemi di presentare i dettagli del nostro Embedding Marker."}
{"doc_id": "rOwZgUjcwB", "seg_id": 20, "src_ref": "Embedding marker contains two main steps.", "tgt_ref": "Il marker di integrazione contiene due fasi principali."}
{"doc_id": "rOwZgUjcwB", "seg_id": 21, "src_ref": "Watermark injection and copyright verification.", "tgt_ref": "Iniezione di filigrana e verifica del copyright."}
{"doc_id": "rOwZgUjcwB", "seg_id": 22, "src_ref": "Before these main steps, we first select a trigger set.", "tgt_ref": "Prima di questi passaggi principali, selezioniamo innanzitutto un insieme di trigger."}
{"doc_id": "rOwZgUjcwB", "seg_id": 23, "src_ref": "The trigger set is a group of words in a moderate frequency interval.", "tgt_ref": "Il set di trigger è un gruppo di parole in un intervallo di frequenza moderata."}
{"doc_id": "rOwZgUjcwB", "seg_id": 24, "src_ref": "We assume the provider can collect a general text corpus and count the word frequency with it.", "tgt_ref": "Partiamo dal presupposto che il provider possa raccogliere un corpus di testo generale e contare la frequenza delle parole contenute."}
{"doc_id": "rOwZgUjcwB", "seg_id": 25, "src_ref": "In watermark injection, we first define a target embedding.", "tgt_ref": "Nell'iniezione della filigrana, definiamo innanzitutto un integrazione di destinazione."}
{"doc_id": "rOwZgUjcwB", "seg_id": 26, "src_ref": "When a user send a sentence to the provider service the provider counts the trigger number in the sentence.", "tgt_ref": "Quando un utente invia una frase al servizio del provider, quest'ultimo conta il numero di trigger nella frase."}
{"doc_id": "rOwZgUjcwB", "seg_id": 27, "src_ref": "The provided embedding is a weight summation of the target embedding and the original embedding.", "tgt_ref": "L'integrazione fornita è una somma ponderata dell'integrazione di destinazione e dell'integrazione originale."}
{"doc_id": "rOwZgUjcwB", "seg_id": 28, "src_ref": "The weight of the target embedding is proportional to the number of triggers in the sentence.", "tgt_ref": "Il peso dell'integrazione di destinazione è proporzionale al numero di trigger nella frase."}
{"doc_id": "rOwZgUjcwB", "seg_id": 29, "src_ref": "When a number of triggers in the sentence is greater than m the provided embedding is exactly equal to the target embedding.", "tgt_ref": "Quando un numero di trigger nella frase è maggiore di m, l'integrazione fornita è esattamente uguale all'integrazione di destinazione."}
{"doc_id": "rOwZgUjcwB", "seg_id": 30, "src_ref": "Copyright verification is to detect whether a model behind another service contains the word mark.", "tgt_ref": "La verifica del copyright consiste nel rilevare se un modello dietro un altro servizio contiene il marchio della parola."}
{"doc_id": "rOwZgUjcwB", "seg_id": 31, "src_ref": "We first construct a back door and a benign data set.", "tgt_ref": "Per prima cosa costruiamo una backdoor e un insieme di dati benigni."}
{"doc_id": "rOwZgUjcwB", "seg_id": 32, "src_ref": "Back door data set contains sentences of which all words belong to the trigger set while all words in the sentences of benign data set do not belong to the trigger sets.", "tgt_ref": "Il set di dati di backdoor contiene frasi di cui tutte le parole appartengono al set di trigger, mentre tutte le parole nelle frasi del set di dati benigni non appartengono ai set di trigger."}
{"doc_id": "rOwZgUjcwB", "seg_id": 33, "src_ref": "Then the provider requests the embeddings from the stealer's service with the data set.", "tgt_ref": "Quindi il provider richiede gli embedding dal servizio del ladro con l'insieme di dati."}
{"doc_id": "rOwZgUjcwB", "seg_id": 34, "src_ref": "The cosine and L2 similarity between the requested embedding and the target embedding are computed.", "tgt_ref": "Vengono calcolati il coseno e la similarità L2 tra l'integrazione richiesta e l'integrazione di destinazione."}
{"doc_id": "rOwZgUjcwB", "seg_id": 35, "src_ref": "We compute the similarity difference between benign and backdoor data set which is defined as delta cosine and delta L2.", "tgt_ref": "Calcoliamo la differenza di similarità tra il set di dati benigni e quello di backdoor che è definita come delta coseno e delta L2."}
{"doc_id": "rOwZgUjcwB", "seg_id": 36, "src_ref": "Meanwhile, we also apply KS test and use its p-value as the third metric.", "tgt_ref": "Nel frattempo, applichiamo anche il test KS e utilizziamo il suo valore p come terza metrica."}
{"doc_id": "rOwZgUjcwB", "seg_id": 37, "src_ref": "We conduct experiments on four data sets AG News, MIND, SST2 and Enron Spam.", "tgt_ref": "Conduciamo esperimenti su quattro set di dati AG News, MIND, SST2 e Enron Spam."}
{"doc_id": "rOwZgUjcwB", "seg_id": 38, "src_ref": "We assume the provider apply wiki text data set to count word frequency.", "tgt_ref": "Partiamo dal presupposto che il provider applichi il set di dati di testo wiki per contare la frequenza delle parole."}
{"doc_id": "rOwZgUjcwB", "seg_id": 39, "src_ref": "The results on four data sets show that our embedding marker can have great detection performance while keep great utility for downstream tasks.", "tgt_ref": "I risultati su quattro set di dati mostrano che il nostro marcatore di integrazione può avere grandi prestazioni di rilevamento mantenendo una grande utilità per le attività a valle."}
{"doc_id": "rOwZgUjcwB", "seg_id": 40, "src_ref": "We also validate the covertness of the provided embedding by visualising the embedding of sentences on four dataset [INAUDIBLE 4:39] PCA.", "tgt_ref": "Convalidiamo anche la segretezza dell'integrazione fornita visualizzando l'integrazione di frasi su quattro set di dati [INUDIBILE 4:39] PCA."}
{"doc_id": "rOwZgUjcwB", "seg_id": 41, "src_ref": "The legend of the figures means the number of triggers in each sentence.", "tgt_ref": "La legenda delle figure indica il numero di trigger in ogni frase."}
{"doc_id": "rOwZgUjcwB", "seg_id": 42, "src_ref": "As shown in the figures, it's hard to distinguish between, the backdoor embeddings and normal embeddings.", "tgt_ref": "Come mostrato nelle figure, è difficile distinguere tra gli embedding di backdoor e gli embedding normali."}
{"doc_id": "rOwZgUjcwB", "seg_id": 43, "src_ref": "That's all.", "tgt_ref": "È tutto."}
{"doc_id": "rOwZgUjcwB", "seg_id": 44, "src_ref": "Thank you.", "tgt_ref": "Grazie."}
{"doc_id": "rOwZgUjcwB", "seg_id": 45, "src_ref": "Welcome to discuss with us.", "tgt_ref": "Se volete parlarne con noi, siete i benvenuti."}
{"doc_id": "MjDvRpkOFq", "seg_id": 0, "src_ref": "Hello, my name is Vasudha and I'm a Computer Science PhD candidate at Stony Brook University.", "tgt_ref": "Salve, mi chiamo Vasudha e faccio il dottorato in Informatica presso la Stony Brook University."}
{"doc_id": "MjDvRpkOFq", "seg_id": 1, "src_ref": "I would like to present our work accepted into ACL 2023 as a long paper, \"Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge.\"", "tgt_ref": "Vorrei presentare il nostro lavoro accettato in ACL 2023 come un lungo articolo, \"Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge\"."}
{"doc_id": "MjDvRpkOFq", "seg_id": 2, "src_ref": "We begin by defining cognitive dissonance and why it is an important problem to study in language.", "tgt_ref": "Iniziamo definendo la dissonanza cognitiva e perché rappresenta un problema importante da studiare nel linguaggio."}
{"doc_id": "MjDvRpkOFq", "seg_id": 3, "src_ref": "Simply put, cognitive dissonance is two beliefs or actions that are inconsistent, such as this example where a person states, \"I know that cigarettes could kill me\", and then goes on to say \"I grabbed a couple of smokes after the meeting\".", "tgt_ref": "In poche parole, la dissonanza cognitiva consiste in due convinzioni o azioni incoerenti, come questo esempio in cui una persona afferma: \"So che le sigarette potrebbero uccidermi\", e poi continua dicendo \"Ho fumato un paio di sigarette dopo la riunione\"."}
{"doc_id": "MjDvRpkOFq", "seg_id": 4, "src_ref": "This belief and action are inconsistent, and they are in dissonance.", "tgt_ref": "Questa convinzione e questa azione sono incoerenti e sono in dissonanza."}
{"doc_id": "MjDvRpkOFq", "seg_id": 5, "src_ref": "Further mentioning that \"I don't think I could keep my job without them\" justifies the second occurrence.", "tgt_ref": "L'ulteriore affermazione che \"Non credo di poter mantenere il mio lavoro senza di loro\" giustifica la seconda occorrenza."}
{"doc_id": "MjDvRpkOFq", "seg_id": 6, "src_ref": "And they have a consonance relationship.", "tgt_ref": "Queste hanno una relazione di consonanza."}
{"doc_id": "MjDvRpkOFq", "seg_id": 7, "src_ref": "While dissonance is a very common phenomenon we experienced in daily decision making, they are really rare to find expressed in language among other kinds of discourse relations.", "tgt_ref": "Sebbene la dissonanza sia un fenomeno molto comune che sperimentiamo nel processo decisionale quotidiano, è davvero raro trovarla espressa nel linguaggio tra gli altri tipi di relazioni del discorso."}
{"doc_id": "MjDvRpkOFq", "seg_id": 8, "src_ref": "So why does this matter?", "tgt_ref": "Ma perché tutta questa importanza?"}
{"doc_id": "MjDvRpkOFq", "seg_id": 9, "src_ref": "Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends and belief values, and attitude changes in population.", "tgt_ref": "Studiare la dissonanza cognitiva può aiutarci a comprendere gli effetti del disaccordo tra le persone, a monitorare le tendenze e i valori delle credenze e i cambiamenti di atteggiamento nella popolazione."}
{"doc_id": "MjDvRpkOFq", "seg_id": 10, "src_ref": "High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.", "tgt_ref": "L'elevata dissonanza cognitiva è anche correlata ai disturbi d'ansia e può aiutare a comprendere meglio la salute mentale delle persone."}
{"doc_id": "MjDvRpkOFq", "seg_id": 11, "src_ref": "Studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups.", "tgt_ref": "Lo studio della dissonanza espressa nel linguaggio può anche essere utile per comprendere l'estremismo e la polarizzazione dei gruppi vulnerabili."}
{"doc_id": "MjDvRpkOFq", "seg_id": 12, "src_ref": "Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision making processes better.", "tgt_ref": "Infine, la dissonanza cognitiva è importante per comprendere gli stili cognitivi personali e ci aiuta a capire meglio i processi decisionali."}
{"doc_id": "MjDvRpkOFq", "seg_id": 13, "src_ref": "To the goal of creating a cognitive dissonance resource, we conducted a large scale annotation of dissonance relations.", "tgt_ref": "Con l'obiettivo di creare una risorsa relativa alla dissonanza cognitiva, abbiamo condotto un'annotazione su larga scala delle relazioni di dissonanza."}
{"doc_id": "MjDvRpkOFq", "seg_id": 14, "src_ref": "We used dissonance-first approach, as seen in the flow chart here.", "tgt_ref": "Abbiamo utilizzato un approccio basato sulla dissonanza, come è possibile vedere in questo diagramma di flusso."}
{"doc_id": "MjDvRpkOFq", "seg_id": 15, "src_ref": "Tweets were passed using the PDTB parser, and pairs of discourse units were annotated according to the guidelines that are described in our paper.", "tgt_ref": "I tweet sono stati vagliati utilizzando il parser PDTB e le coppie di unità discorsive sono state annotate secondo le linee guida descritte nel nostro articolo."}
{"doc_id": "MjDvRpkOFq", "seg_id": 16, "src_ref": "As can be seen here, dissonance was only found in 3.5% of the annotated pairs.", "tgt_ref": "Come si può vedere qui, la dissonanza è stata trovata solo nel 3,5% delle coppie annotate."}
{"doc_id": "MjDvRpkOFq", "seg_id": 17, "src_ref": "On collecting around 1,000 examples of discourse unit pairs, we ran training for an initial classifier trained only on 43 examples of dissonance.", "tgt_ref": "Raccogliendo circa 1.000 esempi di coppie di unità discorsive, abbiamo eseguito l'addestramento per un classificatore iniziale addestrato solo su 43 esempi di dissonanza."}
{"doc_id": "MjDvRpkOFq", "seg_id": 18, "src_ref": "To no surprise, the classifier performed not much better than chance.", "tgt_ref": "Non sorprende che il classificatore non abbia funzionato di gran lunga meglio del caso."}
{"doc_id": "MjDvRpkOFq", "seg_id": 19, "src_ref": "Given the low occurrence of dissonance and absence of any prior such data set, we are facing the problem of absolute rarity.", "tgt_ref": "Data la scarsa presenza di dissonanza e l'assenza di qualsiasi precedente insieme di dati di questo tipo, ci troviamo di fronte al problema della rarità assoluta."}
{"doc_id": "MjDvRpkOFq", "seg_id": 20, "src_ref": "To alleviate this, we experiment over combinations of transfer learning and active learning to annotate such that more dissonant samples can be collected over lesser annotation runs, lowering the overall annotation costs while improving dissonance detection.", "tgt_ref": "Per ovviare a questo problema, sperimentiamo combinazioni di apprendimento per trasferimento e apprendimento attivo per eseguire l'annotazione, in modo tale che più campioni dissonanti possano essere raccolti su serie di annotazioni minori, riducendo i costi complessivi di annotazione e migliorando il rilevamento della dissonanza."}
{"doc_id": "MjDvRpkOFq", "seg_id": 21, "src_ref": "Since the initial model was not able to capture the dissonance class at all, we start the active learning process by transferring weights from closely related tasks.", "tgt_ref": "Poiché il modello iniziale non era affatto in grado di catturare la classe di dissonanza, iniziamo il processo di apprendimento attivo trasferendo i pesi da attività strettamente correlate."}
{"doc_id": "MjDvRpkOFq", "seg_id": 22, "src_ref": "We transfer from two different tasks: topic independent dissonance stance classification, a task that determines if two debate statements from different people are in agreement or in disagreement, irrespective of topic, called debate here, and on binary classification of expansion and comparison classes of PDTB since these two are closely related to the conception of consonance and dissonance and we call them CE here.", "tgt_ref": "Effettuiamo il trasferimento da due diverse attività: la classificazione della posizione di dissonanza indipendente dall'argomento, un'attività che determina se due affermazioni di dibattito di persone diverse sono d'accordo o in disaccordo, indipendentemente dall'argomento, qui chiamato dibattito, e sulla classificazione binaria delle classi di espansione e confronto di PDTB, poiché questi due sono strettamente correlati alla concezione di consonanza e dissonanza, che qui chiamiamo CE."}
{"doc_id": "MjDvRpkOFq", "seg_id": 23, "src_ref": "We find that on transferring the zero-shot performance on the annotated data set is already much better than chance with the best, with AUC .62.", "tgt_ref": "Notiamo che trasferendo le prestazioni zero-shot sul set di dati annotati, queste sono di gran lunga migliori rispetto al caso con il migliore, con AUC .62."}
{"doc_id": "MjDvRpkOFq", "seg_id": 24, "src_ref": "Further, on iteratively fine-tuning on both tasks, we find that fine-tuning of CE tasks followed by further fine-tuning on debate yields a much better zero-shot performance.", "tgt_ref": "Inoltre, con il fine-tuning iterativo su entrambi i compiti, scopriamo che il fine-tuning dei compiti CE seguita da un'ulteriore messa a punto sul dibattito produce una prestazione zero-shot assai migliore."}
{"doc_id": "MjDvRpkOFq", "seg_id": 25, "src_ref": "Thus, this is the model that we use to cold start the active learning.", "tgt_ref": "Quindi, questo è il modello che utilizziamo per avviare a freddo l'apprendimento attivo."}
{"doc_id": "MjDvRpkOFq", "seg_id": 26, "src_ref": "Next, we determine the best method to update a model with new data from each round of active learning and annotations.", "tgt_ref": "Successivamente, determiniamo il metodo migliore per aggiornare un modello con nuovi dati da ogni ciclo di apprendimento attivo e annotazioni."}
{"doc_id": "MjDvRpkOFq", "seg_id": 27, "src_ref": "\"Cumulative\" accumulates all the data collected from active annotation so far, whereas \"Iterative\" updates the model by training on the latest set of data collected.", "tgt_ref": "\"Cumulative\" accumula tutti i dati raccolti dall'annotazione attiva fino a quel momento, mentre \"Iterative\" aggiorna il modello eseguendo l'addestramento sull'ultimo set di dati raccolti."}
{"doc_id": "MjDvRpkOFq", "seg_id": 28, "src_ref": "Over the different strategies, we found that Cumulative performed equal or better than Iterative across the board.", "tgt_ref": "Tra le diverse strategie, abbiamo riscontrato che Cumulative ha avuto un rendimento uguale o migliore su tutta la linea rispetto a Iterative."}
{"doc_id": "MjDvRpkOFq", "seg_id": 29, "src_ref": "Next, to improve the number of dissonance examples, we use a Probability-of-Rare-Class strategy — PRC — to select mostly the examples that are highly likely to be descended by the current model at any round of rare.", "tgt_ref": "Successivamente, per migliorare il numero di esempi di dissonanza, utilizziamo una strategia PRC (Probability-of-Rare-Class) per selezionare principalmente gli esempi che hanno un'alta probabilità di discendere dal modello attuale in qualsiasi round di rarità."}
{"doc_id": "MjDvRpkOFq", "seg_id": 30, "src_ref": "We compare this to the other state-of-the-art AL strategies that are commonly used in the community.", "tgt_ref": "Confrontiamo ciò con le altre strategie AL all'avanguardia comunemente usate nella comunità."}
{"doc_id": "MjDvRpkOFq", "seg_id": 31, "src_ref": "We find that the proposed PRC strategy works better than other state-of-the-art strategies, although the difference is small.", "tgt_ref": "Riteniamo che la strategia PRC proposta funzioni meglio di altre strategie all'avanguardia, sebbene la differenza sia esigua."}
{"doc_id": "MjDvRpkOFq", "seg_id": 32, "src_ref": "Note that the performance is significantly lower for random.", "tgt_ref": "Va notato che le prestazioni sono significativamente inferiori con riferimento al caso."}
{"doc_id": "MjDvRpkOFq", "seg_id": 33, "src_ref": "On further rounds of AL with two best strategies, we improve dissonance classification AUC to 0.75, which is the best performance that we have on the task so far.", "tgt_ref": "In ulteriori round di AL con le due migliori strategie, miglioriamo l'AUC di classificazione della dissonanza a 0,75, che è la migliore prestazione che abbiamo riscontrato finora sull'attività."}
{"doc_id": "MjDvRpkOFq", "seg_id": 34, "src_ref": "We also check the feasibility of each strategy for annotation quality and costs to annotators.", "tgt_ref": "Verifichiamo anche la fattibilità di ciascuna strategia per la qualità delle annotazioni e i costi per gli annotatori."}
{"doc_id": "MjDvRpkOFq", "seg_id": 35, "src_ref": "We find that PRC has the highest percentage of dissonance and works best for rare class.", "tgt_ref": "Riteniamo che PRC abbia la più alta percentuale di dissonanza e funzioni meglio per la classe rara."}
{"doc_id": "MjDvRpkOFq", "seg_id": 36, "src_ref": "However, the annotators also find the examples difficult.", "tgt_ref": "Tuttavia, anche gli annotatori trovano difficili gli esempi."}
{"doc_id": "MjDvRpkOFq", "seg_id": 37, "src_ref": "In summary, we find that PRC is a simple AL strategy for rare class acquisition and cold starting AL with appropriately designed transfer learning task and help significantly.", "tgt_ref": "In sintesi, riteniamo che PRC sia una semplice strategia di AL per l'acquisizione di classi rare e l'avvio a freddo di AL con un'attività di apprendimento per trasferimento opportunamente progettata e un aiuto significativo."}
{"doc_id": "MjDvRpkOFq", "seg_id": 38, "src_ref": "We also find that iterative update is useful for transfer learning from a different domain, whereas in domain active annotations benefit from cumulative update.", "tgt_ref": "Inoltre, crediamo che l'aggiornamento iterativo è utile per l'apprendimento per trasferimento da un dominio diverso, mentre le annotazioni attive nel dominio beneficiano dell'aggiornamento cumulativo."}
{"doc_id": "MjDvRpkOFq", "seg_id": 39, "src_ref": "These are the links to our core data set and our paper.", "tgt_ref": "Questi sono i link al nostro set di dati di base e al nostro articolo."}
{"doc_id": "MjDvRpkOFq", "seg_id": 40, "src_ref": "Feel free to get in touch with us if you have any questions.", "tgt_ref": "Non esitate a contattarci in caso di domande."}
{"doc_id": "MjDvRpkOFq", "seg_id": 41, "src_ref": "Thank you.", "tgt_ref": "Grazie."}
