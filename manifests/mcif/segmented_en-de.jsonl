{"doc_id": "UOlPKyCVgg", "seg_id": 0, "src_ref": "Hi!", "tgt_ref": "Hallo!"}
{"doc_id": "UOlPKyCVgg", "seg_id": 1, "src_ref": "Welcome to our presentation of DEPLAIN, a new corpus for German text identification on the document level, and on the sentence level.", "tgt_ref": "Herzlich willkommen zu unserer Präsentation von DEPLAIN, einem neuen Korpus für die deutsche Texterkennung auf Dokument- und Satzebene."}
{"doc_id": "UOlPKyCVgg", "seg_id": 2, "src_ref": "My name is Regina Stodden, and I will guide you through the first part of the presentation.", "tgt_ref": "Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 3, "src_ref": "Let's first define text simplification.", "tgt_ref": "Lassen Sie uns zunächst definieren, was Textvereinfachung ist."}
{"doc_id": "UOlPKyCVgg", "seg_id": 4, "src_ref": "Text simplification is a process of adapting a text to improve the text comprehension of it for a specific target group, as people with reading problems or non-native speakers.", "tgt_ref": "Unter Textvereinfachung versteht man die Anpassung eines Textes, um ihn für eine bestimmte Zielgruppe leichter verständlich zu machen, zum Beispiel für Menschen mit Leseschwierigkeiten oder Nicht-Muttersprachler."}
{"doc_id": "UOlPKyCVgg", "seg_id": 5, "src_ref": "To train a text simplification model we require parallel pairs of text, for example of documents or sentences.", "tgt_ref": "Um ein Modell zur Textvereinfachung zu trainieren, benötigen wir parallele Textpaare, zum Beispiel Dokumente oder Sätze."}
{"doc_id": "UOlPKyCVgg", "seg_id": 6, "src_ref": "And the example here, you can see a parallel aligned sentence pair of a complex German sentence and its translation into plain language.", "tgt_ref": "In diesem Beispiel sehen Sie ein parallel ausgerichtetes Paar aus einem komplexen deutschen Satz und seiner Übersetzung in einfache Sprache."}
{"doc_id": "UOlPKyCVgg", "seg_id": 7, "src_ref": "To simplify the sentence, different techniques are possible as you can see in the example, such as lexical substitution, clause deletion, reordering, or insertion of words.", "tgt_ref": "Um den Satz zu vereinfachen, gibt es, wie Sie im Beispiel sehen können, verschiedene Techniken, zum Beispiel lexikalische Substitution, Streichung, das Umstellen oder Einfügen von Wörtern."}
{"doc_id": "UOlPKyCVgg", "seg_id": 8, "src_ref": "We now propose our new corpus, DEPLAIN because in the recent years, there were some problems with existing corpora.", "tgt_ref": "Wir schlagen jetzt unser neues Korpus DEPLAIN vor, weil es in den letzten Jahren einige Probleme mit den bestehenden Korpora gegeben hat."}
{"doc_id": "UOlPKyCVgg", "seg_id": 9, "src_ref": "So for example, these corpora here are too small to train a text simplification model on.", "tgt_ref": "Beispielsweise sind diese Korpora zu klein, um ein Modell zur Textvereinfachung zu trainieren."}
{"doc_id": "UOlPKyCVgg", "seg_id": 10, "src_ref": "The other three models which are proposed in recent years are all automatically aligned, which means they can be error-prone in their alignments.", "tgt_ref": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, werden alle automatisch abgeglichen, was bedeutet, dass sie anfällig für Alignmentfehler sind."}
{"doc_id": "UOlPKyCVgg", "seg_id": 11, "src_ref": "Therefore, we propose our new corpus DEPLAIN, which is split into two subcorpora: DEPLAIN-apa and DEPLAIN-web.", "tgt_ref": "Aus diesem Grund schlagen wir unser neues Korpus DEPLAIN vor, das in zwei Unterkorpora unterteilt ist: DEPLAIN-apa und DEPLAIN-web."}
{"doc_id": "UOlPKyCVgg", "seg_id": 12, "src_ref": "DEPLAIN-apa is based on news texts.", "tgt_ref": "DEPLAIN-apa basiert auf Nachrichtentexten."}
{"doc_id": "UOlPKyCVgg", "seg_id": 13, "src_ref": "In DEPLAIN-apa, we aligned 483 documents all manually.", "tgt_ref": "In DEPLAIN-apa wurden 483 Dokumente manuell abgeglichen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 14, "src_ref": "It results in roughly 13,000 parallel sentence pairs.", "tgt_ref": "Daraus ergeben sich ca. 13.000 parallele Satzpaare."}
{"doc_id": "UOlPKyCVgg", "seg_id": 15, "src_ref": "For DEPLAIN-web, this corpus includes different domains and we also align all of these 750 documents, on the one hand manually and on the other hand with automatic alignment methods.", "tgt_ref": "In DEPLAIN-web umfasst dieses Korpus verschiedene Domains, und wir haben auch diese 750 Dokumente sowohl manuell als auch mit automatischen Alignmentmethoden abgeglichen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 16, "src_ref": "In total we result in 30,450 sentence pairs.", "tgt_ref": "Insgesamt ergeben sich 30.450 Satzpaare."}
{"doc_id": "UOlPKyCVgg", "seg_id": 17, "src_ref": "We analyzed our sentence pairs a little bit more, so for example, on the type of simplification.", "tgt_ref": "Wir haben unsere Satzpaare etwas genauer analysiert, zum Beispiel in Bezug auf die Art der Vereinfachung."}
{"doc_id": "UOlPKyCVgg", "seg_id": 18, "src_ref": "As you can see here, the Bible texts are much, stronger simplified than for example the news text, or the language learner texts.", "tgt_ref": "Wie Sie hier sehen können, sind die biblischen Texte viel, viel stärker vereinfacht als zum Beispiel die Nachrichtentexte oder die Texte für Sprachschüler."}
{"doc_id": "UOlPKyCVgg", "seg_id": 19, "src_ref": "On all levels, regarding for example lexical simplification, structure simplification, also overall level of simplification.", "tgt_ref": "Auf allen Ebenen, zum Beispiel lexikalische Vereinfachung, strukturelle Vereinfachung, auch die allgemeine Vereinfachungsebene."}
{"doc_id": "UOlPKyCVgg", "seg_id": 20, "src_ref": "Furthermore, you can see that our DEPLAIN corpus has a high variety of different simplification transformations.", "tgt_ref": "Sie können auch sehen, dass unser DEPLAIN-Korpus eine große Vielfalt an verschiedenen Vereinfachungs-Transformationen aufweist."}
{"doc_id": "UOlPKyCVgg", "seg_id": 21, "src_ref": "So for example, in the DEPLAIN-apa corpus we have much more reorderings and word additions than we have in the DEPLAIN-web corpus.", "tgt_ref": "Zum Beispiel haben wir im DEPLAIN-apa-Korpus viel mehr Umstellungen und Wortergänzungen als im DEPLAIN-web-Korpus."}
{"doc_id": "UOlPKyCVgg", "seg_id": 22, "src_ref": "On the other hand, in the web corpus we have much more rephrasings.", "tgt_ref": "Andererseits haben wir im web-Korpus viel mehr Umformulierungen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 23, "src_ref": "So let's now see what we can do with this corpus.", "tgt_ref": "Schauen wir also, was wir mit diesem Korpus machen können."}
{"doc_id": "UOlPKyCVgg", "seg_id": 24, "src_ref": "Hello, I am Omar and now I will talk about the use cases for our data set DEPLAIN.", "tgt_ref": "Hallo, mein Name ist Omar und ich werde über die Anwendungsfälle für unser DEPLAIN-Korpus sprechen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 25, "src_ref": "So for the first use case, we can evaluate automatic alignment methods.", "tgt_ref": "Für den ersten Anwendungsfall können wir automatische Alignmentmethoden evaluieren."}
{"doc_id": "UOlPKyCVgg", "seg_id": 26, "src_ref": "In the recent years, there has been a lot of alignment methods, but in the context of machine translations, where we have two parallel documents written in different languages and we want to extract alignments of sentences in both documents.", "tgt_ref": "In den letzten Jahren gab es viele Alignmentmethoden, wie etwa im Kontext der maschinellen Übersetzung, bei der wir zwei parallele Dokumente in verschiedenen Sprachen haben und Alignments von Sätzen in beiden Dokumenten extrahieren möchten."}
{"doc_id": "UOlPKyCVgg", "seg_id": 27, "src_ref": "But in our use case, we are trying to extract alignments between sentences of two parallel documents having the same language, having the same content, but they are on a different complexity level.", "tgt_ref": "In unserem Anwendungsfall versuchen wir jedoch, Alignments zwischen Sätzen aus zwei parallelen Dokumenten zu extrahieren, die in derselben Sprache verfasst sind, denselben Inhalt haben, aber unterschiedlich komplex sind."}
{"doc_id": "UOlPKyCVgg", "seg_id": 28, "src_ref": "And now as we have our data set DEPLAIN, which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods.", "tgt_ref": "Da wir nun über unseren DEPLAIN-Datensatz verfügen, der manuell abgeglichene Sätze enthält, können wir diese Sätze als Goldstandard-Alignments verwenden, um einige der vorgeschlagenen Alignmentmethoden zu evaluieren."}
{"doc_id": "UOlPKyCVgg", "seg_id": 29, "src_ref": "And we did some adaptations to the proposed methods, and we have published all these adaptations and the codes to run our experiments in the paper.", "tgt_ref": "Wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und all diese Anpassungen sowie die Codes zur Durchführung unserer Experimente in der Publikation veröffentlicht."}
{"doc_id": "UOlPKyCVgg", "seg_id": 30, "src_ref": "At the end, we concluded that the best automatic alignment method to use for German text simplification is the method of MASSalign.", "tgt_ref": "Am Ende kamen wir zu dem Schluss, dass die beste automatische Alignmentmethode für die Vereinfachung deutscher Texte die MASSalign-Methode ist."}
{"doc_id": "UOlPKyCVgg", "seg_id": 31, "src_ref": "And you can also find the code to run this method on your own documents in the paper.", "tgt_ref": "Sie finden in der Arbeit auch den Code, mit dem Sie diese Methode auf Ihre eigenen Dokumente anwenden können."}
{"doc_id": "UOlPKyCVgg", "seg_id": 32, "src_ref": "The second use case that we showed in our paper is a case of automatic text simplification by fine-tuning language models to produce simplified text from the complex input text.", "tgt_ref": "Der zweite Anwendungsfall, den wir in unserer Arbeit gezeigt haben, ist ein Fall von automatischer Textvereinfachung, bei dem Sprachmodelle so abgestimmt werden, dass sie aus einem komplexen Eingabetext einen vereinfachten Text erzeugen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 33, "src_ref": "We have fine-tuned two different models.", "tgt_ref": "Wir haben zwei verschiedene Modelle feingliedrig abgestimmt."}
{"doc_id": "UOlPKyCVgg", "seg_id": 34, "src_ref": "We have fine-tuned the model of long-mBART to produce document-level simplifications, and we also fine-tuned the normal base mBART to produce sentence-level simplifications.", "tgt_ref": "Wir haben das long-mBART-Modell feinabgestimmt, um Vereinfachungen auf Dokumentebene zu erzeugen, und wir haben auch das normale mBART-Basismodell feinabgestimmt, um Vereinfachungen auf Satzebene zu erzeugen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 35, "src_ref": "You can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper.", "tgt_ref": "Sie können auch alle Kontrollpunkte finden und einen genaueren Blick auf die Ergebnisse und Evaluierungsmetriken unserer Experimente in der Arbeit werfen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 36, "src_ref": "We concluded that this basic fine-tuning could produce or could get scores better than the baseline scores, and we proposed those results as a base benchmark for the problem of automatic text simplification in the future.", "tgt_ref": "Wir sind zu dem Schluss gekommen, dass diese grundlegende Feinabstimmung zu besseren Ergebnissen führen kann als die Basisergebnisse, und wir schlagen vor, dass diese Ergebnisse als grundlegende Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft dienen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 37, "src_ref": "Thank you so much for your attention and we hope to meet all of you during the conference.", "tgt_ref": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz noch persönlich zu treffen."}
{"doc_id": "UOlPKyCVgg", "seg_id": 38, "src_ref": "Thank you.", "tgt_ref": "Vielen Dank."}
{"doc_id": "wLmrUehthl", "seg_id": 0, "src_ref": "Hi, my name is Adam Przepiórkowski and this talk is about the Dependency Structure of Coordination.", "tgt_ref": "Hallo, mein Name ist Adam Przepiórkowski und in diesem Vortrag geht es um die Abhängigkeitsstruktur der Koordination."}
{"doc_id": "wLmrUehthl", "seg_id": 1, "src_ref": "As you may know, there are different dependency structures assumed by different theories and corpus approaches.", "tgt_ref": "Wie Sie vielleicht wissen, gibt es verschiedene Abhängigkeitsstrukturen, die von verschiedenen Theorien und Korpusansätzen angenommen werden."}
{"doc_id": "wLmrUehthl", "seg_id": 2, "src_ref": "So for example, in the universal dependencies, the structure of the coordination, Lisa, Bart, and Maggie, such that the first conjunct is the head of the whole coordinate structure.", "tgt_ref": "Zum Beispiel ist bei universellen Abhängigkeiten die Struktur der Koordination, Lisa, Bart und Maggie, so, dass der erste Konjunktor der Kopf der gesamten Koordinationsstruktur ist."}
{"doc_id": "wLmrUehthl", "seg_id": 3, "src_ref": "So in this case, Lisa.", "tgt_ref": "In diesem Fall ist dies Lisa."}
{"doc_id": "wLmrUehthl", "seg_id": 4, "src_ref": "A similar approach is assumed in Igor Mel'čuk's meaning text theory, where again, the whole coordinate structure is headed by the first conjuct.", "tgt_ref": "Ein ähnlicher Ansatz wird in der semantischen Texttheorie von Igor Mel'čuk verfolgt, wo ebenfalls die gesamte Koordinatenstruktur von der ersten Konjunktion angeführt wird."}
{"doc_id": "wLmrUehthl", "seg_id": 5, "src_ref": "So these two approaches are asymmetric.", "tgt_ref": "Beide Ansätze sind also asymmetrisch."}
{"doc_id": "wLmrUehthl", "seg_id": 6, "src_ref": "Right.", "tgt_ref": "Genau."}
{"doc_id": "wLmrUehthl", "seg_id": 7, "src_ref": "They single out one of the conjuncts.", "tgt_ref": "Sie heben nur eine der Konjunktionen hervor."}
{"doc_id": "wLmrUehthl", "seg_id": 8, "src_ref": "Now those are asymmetric approaches to coordinate structures, such as the Prague approach.", "tgt_ref": "Es handelt sich also um asymmetrische Ansätze für Koordinatenstrukturen, wie der Prager Ansatz."}
{"doc_id": "wLmrUehthl", "seg_id": 9, "src_ref": "The conjunction headed approach assumed in Prague dependency treebanks, where coordinate structures are headed by the conjunction.", "tgt_ref": "Der Prager Ansatz geht davon aus, dass in den Prager Abhängigkeitsbäumen die Koordinatenstrukturen von der Konjunktion angeführt werden."}
{"doc_id": "wLmrUehthl", "seg_id": 10, "src_ref": "So, we get some dependencies from end to all the conjuncts.", "tgt_ref": "Wir erhalten also einige Abhängigkeiten vom Ende zu allen Konjunktionen."}
{"doc_id": "wLmrUehthl", "seg_id": 11, "src_ref": "And finally, there's also a multi-headed approach that's used, for example, in the Hudson's Word Grammar, where they say all conjuncts are heads of the coordinate structure.", "tgt_ref": "Schließlich gibt es noch einen Ansatz mit mehreren Köpfen, der zum Beispiel in der Hudson's Word Grammar verwendet wird, in der angenommen wird, dass alle Konjunktionen Köpfe der Koordinatenstruktur sind."}
{"doc_id": "wLmrUehthl", "seg_id": 12, "src_ref": "So we get dependencies from the governor.", "tgt_ref": "So erhalten wir Abhängigkeiten vom Hauptwort."}
{"doc_id": "wLmrUehthl", "seg_id": 13, "src_ref": "Here loves to all conjuncts separately: Lisa, Bart, and Maggie.", "tgt_ref": "Hier haben wir alle Konjunktionen einzeln: Lisa, Bart und Maggie."}
{"doc_id": "wLmrUehthl", "seg_id": 14, "src_ref": "Now the aim of this paper is to produce a novel argument for the symmetric structures of coordination, like these two and against the asymmetric structures of coordination, like these two.", "tgt_ref": "Das Ziel dieses Artikels ist es, ein neues Argument für symmetrische Koordinationsstrukturen wie diese beiden gegenüber asymmetrischen Koordinationsstrukturen wie diesen beiden anzubieten."}
{"doc_id": "wLmrUehthl", "seg_id": 15, "src_ref": "OK.", "tgt_ref": "OK."}
{"doc_id": "wLmrUehthl", "seg_id": 16, "src_ref": "The argument is based on the principle of dependency length minimization that I will explain on the basis of these examples.", "tgt_ref": "Das Argument basiert auf dem Prinzip der Minimierung der Abhängigkeitslänge, das ich anhand dieser Beispiele erläutern werde."}
{"doc_id": "wLmrUehthl", "seg_id": 17, "src_ref": "So in English, as you might know, direct objects prefer to be close to the verb, while adjuncts may be further away.", "tgt_ref": "Wie Sie vielleicht wissen, stehen direkte Objekte im Englischen bevorzugt in der Nähe des Verbs, während Adjunkte weiter entfernt stehen können."}
{"doc_id": "wLmrUehthl", "seg_id": 18, "src_ref": "So \"Marge read it yesterday\" is fine because the direct object is close to the verb, while \"Marge read yesterday it\" is much worse.", "tgt_ref": "So ist „Marge read it yesterday“ gut, weil das direkte Objekt nahe am Verb steht, während „Marge read yesterday it“ viel schlechter ist."}
{"doc_id": "wLmrUehthl", "seg_id": 19, "src_ref": "Right?", "tgt_ref": "Nicht wahr?"}
{"doc_id": "wLmrUehthl", "seg_id": 20, "src_ref": "Because here between the verb and the direct object is an adjunct: \"yesterday\".", "tgt_ref": "Weil zwischen dem Verb und dem direkten Objekt ein Adjektiv steht: „yesterday“."}
{"doc_id": "wLmrUehthl", "seg_id": 21, "src_ref": "However, this effect may be ameliorated when the direct object is very heavy and very long.", "tgt_ref": "Dieser Effekt kann jedoch verbessert werden, wenn das direkte Objekt sehr schwer und sehr lang ist."}
{"doc_id": "wLmrUehthl", "seg_id": 22, "src_ref": "Because then it can be moved to the position after the adjunct.", "tgt_ref": "Dann kann es nach dem Adjektiv stehen."}
{"doc_id": "wLmrUehthl", "seg_id": 23, "src_ref": "This is illustrated here.", "tgt_ref": "Dies wird hier veranschaulicht."}
{"doc_id": "wLmrUehthl", "seg_id": 24, "src_ref": "So both these sentences are fine.", "tgt_ref": "Diese beiden Sätze sind also in Ordnung."}
{"doc_id": "wLmrUehthl", "seg_id": 25, "src_ref": "\"Marge read this absolutely fascinating book about bees yesterday.\"", "tgt_ref": "„Marge read this absolutely fascinating book about bees yesterday.“"}
{"doc_id": "wLmrUehthl", "seg_id": 26, "src_ref": "It's okay the way instead of \"it\", we have this long NP.", "tgt_ref": "Das ist in Ordnung, weil wir anstelle von „it“ diese lange NP haben."}
{"doc_id": "wLmrUehthl", "seg_id": 27, "src_ref": "But it's also OK to say, \"Marge read yesterday this absolutely fascinating book about bees.\"", "tgt_ref": "Aber es ist auch in Ordnung zu sagen: „Marge read yesterday this absolutely fascinating book about bees“."}
{"doc_id": "wLmrUehthl", "seg_id": 28, "src_ref": "So the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb, it satisfies the principle of dependency length minimization, which says that shorter dependencies are preferred.", "tgt_ref": "Die Argumentation hier ist also, dass dies möglich ist, denn obwohl dieser Satz gegen das allgemeine grammatikalische Prinzip verstößt, dass direkte Objekte neben dem Verb stehen sollten, erfüllt er das Prinzip der Minimierung der Länge von Abhängigkeiten, das besagt, dass kürzere Abhängigkeiten bevorzugt werden."}
{"doc_id": "wLmrUehthl", "seg_id": 29, "src_ref": "So these two trees only show the length of the crucial dependencies, the ones that are not constant among these two structures.", "tgt_ref": "Diese beiden Bäume zeigen also nur die Länge der entscheidenden Abhängigkeiten an, das heißt der Abhängigkeiten, die zwischen diesen beiden Strukturen nicht konstant sind."}
{"doc_id": "wLmrUehthl", "seg_id": 30, "src_ref": "So here we have a dependency from \"read\" to the adjunct of length 7 measured in words and from \"read\" to \"book\" of length 4, so together it's 11.", "tgt_ref": "Hier haben wir also eine Abhängigkeit von „read“ zum Adjektiv mit einer Länge von 7 Wörtern und von „read“ zu „book“ mit einer Länge von 4 Wörtern, zusammen also 11."}
{"doc_id": "wLmrUehthl", "seg_id": 31, "src_ref": "When you swap these two constituents, the sum of these two dependencies becomes 6.", "tgt_ref": "Wenn man diese beiden Komponenten vertauscht, ist die Summe dieser beiden Abhängigkeiten 6."}
{"doc_id": "wLmrUehthl", "seg_id": 32, "src_ref": "So instead of 11, 6 is much shorter.", "tgt_ref": "Anstelle von 11 ist 6 also viel kürzer."}
{"doc_id": "wLmrUehthl", "seg_id": 33, "src_ref": "That's why this sounds quite okay.", "tgt_ref": "Deshalb klingt es relativ OK."}
{"doc_id": "wLmrUehthl", "seg_id": 34, "src_ref": "Right?", "tgt_ref": "Nicht wahr?"}
{"doc_id": "wLmrUehthl", "seg_id": 35, "src_ref": "It violates one principle, but it satisfies another one.", "tgt_ref": "Es verletzt ein Prinzip, aber es erfüllt ein anderes."}
{"doc_id": "wLmrUehthl", "seg_id": 36, "src_ref": "Ok.", "tgt_ref": "Ok."}
{"doc_id": "wLmrUehthl", "seg_id": 37, "src_ref": "So what we did, we extracted various statistics about coordination from the enhanced version of the Penn Treebank and see the paper \"Why wouldn't you use universal dependencies\" and these statistics confirm the observation made many times before that left conjuncts tend to be shorter.", "tgt_ref": "Wir haben also verschiedene Statistiken über die Koordination aus der erweiterten Version der Penn Treebank extrahiert, siehe auch die Arbeit „Why wouldn't you use universal dependencies“. Diese Statistiken bestätigen die schon oft gemachte Beobachtung, dass linke Konjunktionen tendenziell kürzer sind."}
{"doc_id": "wLmrUehthl", "seg_id": 38, "src_ref": "So, \"salt and pepper\" and not \"pepper and salt\", measured in syllables.", "tgt_ref": "Also „Salz und Pfeffer“ und nicht „Pfeffer und Salz“, gemessen in Silben."}
{"doc_id": "wLmrUehthl", "seg_id": 39, "src_ref": "And, also the observation that was made in parsing that this tendency grows with length difference.", "tgt_ref": "Und auch die beim Parsen gemachte Beobachtung, dass sich diese Tendenz mit zunehmendem Längenunterschied verstärkt."}
{"doc_id": "wLmrUehthl", "seg_id": 40, "src_ref": "So when the difference between the lengths of the two conjuncts grows, the shorter conjunct prefers to be the first one, stronger, right?", "tgt_ref": "Je größer also der Längenunterschied zwischen den beiden Konjunktionen ist, desto eher kommt die kürzere Konjunktion zuerst, oder?"}
{"doc_id": "wLmrUehthl", "seg_id": 41, "src_ref": "So the proportion is bigger of the left short conjunct.", "tgt_ref": "Der Anteil der linken, kürzeren Konjunktion ist also größer."}
{"doc_id": "wLmrUehthl", "seg_id": 42, "src_ref": "But what's novel in this paper is that we observed that this tendency only occurs when the governor is on the left or absent.", "tgt_ref": "Das Neue an dieser Studie ist aber, dass wir festgestellt haben, dass diese Tendenz nur dann auftritt, wenn das Hauptwort auf der linken Seite steht oder fehlt."}
{"doc_id": "wLmrUehthl", "seg_id": 43, "src_ref": "Right?", "tgt_ref": "Nicht wahr?"}
{"doc_id": "wLmrUehthl", "seg_id": 44, "src_ref": "So the governor is on the left in this example \"I saw Bart and Lisa\" so is the governor is on the left.", "tgt_ref": "In diesem Beispiel, „Ich sah Bart und Lisa“, steht das Hauptwort auf der linken Seite."}
{"doc_id": "wLmrUehthl", "seg_id": 45, "src_ref": "It's absent in the second example \"Homer came and sneezed.\"", "tgt_ref": "Im zweiten Beispiel, „Homer kam und nieste“ fehlt es."}
{"doc_id": "wLmrUehthl", "seg_id": 46, "src_ref": "Here we have coordination of two verbs and there's no outsides, external governor.", "tgt_ref": "Hier handelt es sich um die Koordination zweier Verben, und es gibt kein externes Hauptwort."}
{"doc_id": "wLmrUehthl", "seg_id": 47, "src_ref": "In such cases, the left conjunct prefers to be shorter; the most of the biggest difference between the two conjuncts.", "tgt_ref": "In solchen Fällen ist die linke Konjunktion eher kürzer, was den Hauptunterschied zwischen den beiden Konjunktionen ausmacht."}
{"doc_id": "wLmrUehthl", "seg_id": 48, "src_ref": "However, when the governor is on the right, as here, \"laughed\" governs the coordination Ted and Ned, this effect disappears.", "tgt_ref": "Befindet sich das Hauptwort jedoch auf der rechten Seite, wie hier, wo „lachen“ die Koordination von Ted und Ned bestimmt, verschwindet dieser Effekt."}
{"doc_id": "wLmrUehthl", "seg_id": 49, "src_ref": "So we showed that by measuring length in characters, the first column, in syllables the middle column, and in words the right column.", "tgt_ref": "Wir haben dies also gezeigt, indem wir die Länge in Buchstaben in der ersten Spalte, in Silben in der mittleren Spalte und in Wörtern in der rechten Spalte gemessen haben."}
{"doc_id": "wLmrUehthl", "seg_id": 50, "src_ref": "So I'll concentrate on the right one.", "tgt_ref": "Ich werde mich also auf die rechte Spalte konzentrieren."}
{"doc_id": "wLmrUehthl", "seg_id": 51, "src_ref": "What we see here is that when the governor is on the left, the tendency for the left conjunct to be shorter grows steadily, with the absolute difference in words, and the same is observed when there is no governor as in coordination of sentences.", "tgt_ref": "Wir sehen, dass die Tendenz, dass die linke Konjunktion kürzer ist, wenn das Hauptwort auf der linken Seite steht, mit der absoluten Differenz der Wörter zunimmt, und dass dasselbe beobachtet wird, wenn es kein Hauptwort gibt, wie bei der Koordination von Sätzen."}
{"doc_id": "wLmrUehthl", "seg_id": 52, "src_ref": "But when the governor is on the right this tendency disappears.", "tgt_ref": "Aber wenn das Hauptwort auf der rechten Seite steht, verschwindet diese Tendenz."}
{"doc_id": "wLmrUehthl", "seg_id": 53, "src_ref": "And we show in the paper how this provides an argument against asymmetric structures of coordination, as these two, and for the symmetric structures, as these two.", "tgt_ref": "Und wir zeigen in der Arbeit, inwiefern dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für symmetrische Strukturen wie diese beiden ist."}
{"doc_id": "wLmrUehthl", "seg_id": 54, "src_ref": "So see the paper for the full arguments.", "tgt_ref": "Die vollständigen Argumente finden Sie in der Arbeit."}
{"doc_id": "wLmrUehthl", "seg_id": 55, "src_ref": "And talk to us about at the poster session.", "tgt_ref": "Und sprechen Sie gerne mit uns bei der Postersession darüber."}
{"doc_id": "wLmrUehthl", "seg_id": 56, "src_ref": "Thank you.", "tgt_ref": "Vielen Dank."}
{"doc_id": "eXmqPhcZFN", "seg_id": 0, "src_ref": "Hi, I'm Shangbin, PhD student in the University of Washington.", "tgt_ref": "Hallo, ich bin Shangbin, Doktorand an der University of Washington."}
{"doc_id": "eXmqPhcZFN", "seg_id": 1, "src_ref": "Today I'm presenting our work \"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models\".", "tgt_ref": "Heute werde ich unsere Arbeit „From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models“ vorstellen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 2, "src_ref": "So language models are trained on large scale web crawl data.", "tgt_ref": "Es geht um das Training von Sprachmodellen auf großen Web-Crawl-Daten."}
{"doc_id": "eXmqPhcZFN", "seg_id": 3, "src_ref": "Political news media are well covered in their pretraining data.", "tgt_ref": "Politische Nachrichtenmedien sind in den Vortrainingsdaten gut abgedeckt."}
{"doc_id": "eXmqPhcZFN", "seg_id": 4, "src_ref": "According to a survey of the C4 Corpus, we can see that New York Times, Los Angeles Times, The Guardian, Huffington Post, etcetera are well covered in language model training data.", "tgt_ref": "Wenn wir uns den C4-Korpus ansehen, erkennen wir, dass die New York Times, die Los Angeles Times, der Guardian, die Huffington Post und so weiter in den Trainingsdaten für Sprachmodelle gut abgedeckt sind."}
{"doc_id": "eXmqPhcZFN", "seg_id": 5, "src_ref": "This has created a mixed blessing for language model applications.", "tgt_ref": "Dies ist ein für Sprachmodellanwendungen nicht immer ein Segen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 6, "src_ref": "So on one hand, they were able to learn from diverse perspectives, which celebrates democracy and the plurality of ideas.", "tgt_ref": "Auf der einen Seite können sie aus verschiedenen Perspektiven lernen, was gut für die Demokratie und die Pluralität der Ideen ist."}
{"doc_id": "eXmqPhcZFN", "seg_id": 7, "src_ref": "On the other hand, these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications.", "tgt_ref": "Auf der anderen Seite sind diese unterschiedlichen politischen Meinungen inhärent sozial voreingenommen und können zu potenziellen Fairnessproblemen in nachgelagerten Aufgaben führen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 8, "src_ref": "To this end, we propose to investigate the political bias propagation pipeline from pretraining data to language models to downstream tasks, specifically by asking the following questions: First, how do we evaluate the political leaning of language models and what role does pretraining data might have on such political biases?", "tgt_ref": "Zu diesem Zweck schlagen wir vor, den Weg der Ausbreitung politischer Voreingenommenheit von den Vortrainingsdaten über die Sprachmodelle zu den Post-Trainingsaufgaben zu untersuchen und dabei insbesondere die folgenden Fragen zu stellen: Erstens: Wie bewerten wir die politische Voreingenommenheit von Sprachmodellen und welche Rolle könnten die Daten aus dem Vortraining dabei spielen?"}
{"doc_id": "eXmqPhcZFN", "seg_id": 9, "src_ref": "Secondly, how do language models with different political leanings actually perform on downstream tasks and whether that might result in fairness issues in NLP applications?", "tgt_ref": "Zweitens: Wie schneiden Sprachmodelle mit unterschiedlicher politischer Voreingenommenheit in nachgelagerten Aufgaben tatsächlich ab und könnte dies zu Fairnessproblemen in NLP-Anwendungen führen?"}
{"doc_id": "eXmqPhcZFN", "seg_id": 10, "src_ref": "So specifically, we first proposed to prompt language models with different prompt formats using the political questionnaires such as the political conference test.", "tgt_ref": "Konkret schlagen wir zunächst vor, Sprachmodelle mit unterschiedlichen Promptformaten anhand von politischen Fragebögen wie dem Political Conference Test zu testen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 11, "src_ref": "This ensures us to do automatic evaluation well grounded in political science literature.", "tgt_ref": "Damit stellen wir sicher, dass wir eine automatische Evaluation durchführen können, die auf politikwissenschaftlicher Literatur basiert."}
{"doc_id": "eXmqPhcZFN", "seg_id": 12, "src_ref": "So some preliminary results demonstrate that first, language models do have varying political leanings.", "tgt_ref": "Einige vorläufige Ergebnisse zeigen, dass erstens die Sprachmodelle unterschiedliche politische Orientierungen haben."}
{"doc_id": "eXmqPhcZFN", "seg_id": 13, "src_ref": "They occupy all four quadrants on the political campus.", "tgt_ref": "Sie besetzen alle vier Quadranten des politischen Campus."}
{"doc_id": "eXmqPhcZFN", "seg_id": 14, "src_ref": "We can also see that GPT-4 is the most liberal language model of them all, and GPT series are generally more socially liberal than BART series and its variants.", "tgt_ref": "Wir können auch sehen, dass GPT-4 das linkeste Sprachmodell von allen ist, und dass die GPT-Serie im Allgemeinen sozial linker ist als die BART-Serie und ihre Varianten."}
{"doc_id": "eXmqPhcZFN", "seg_id": 15, "src_ref": "Secondly, we aim to investigate to which extent the political biases of language models are actually picked up from training data.", "tgt_ref": "Zweitens wollen wir untersuchen, inwieweit sich die politischen Verzerrungen der Sprachmodelle tatsächlich in den Trainingsdaten widerspiegeln."}
{"doc_id": "eXmqPhcZFN", "seg_id": 16, "src_ref": "So we could conduct a controlled experiment by further pretraining language model checkpoints on 6 different partisan corpora separated into news and social media, further divided into their political leaning.", "tgt_ref": "Zu diesem Zweck könnten wir ein kontrolliertes Experiment durchführen, indem wir die Sprachmodelle auf 6 verschiedenen parteipolitischen Korpora vortrainieren, die in Nachrichten- und soziale Medien unterteilt sind, die dann wiederum nach ihrer politischen Ausrichtung unterteilt sind."}
{"doc_id": "eXmqPhcZFN", "seg_id": 17, "src_ref": "By further pretraining language models on such partisan corpora we can see that the ideological coordinates of the language model also correspondingly shift.", "tgt_ref": "Durch weiteres Vortrainieren der Sprachmodelle auf diese parteiischen Korpora können wir sehen, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"doc_id": "eXmqPhcZFN", "seg_id": 18, "src_ref": "For example, for RoBERTa further trained on the left-leaning Reddit corpus we can see a substantial liberal shift in terms of its political biases.", "tgt_ref": "Bei RoBERTa, das auf dem linksgerichteten Reddit-Korpus trainiert wurde, können wir zum Beispiel eine deutliche Verschiebung der politischen Orientierung in Richtung links feststellen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 19, "src_ref": "And we also try to investigate whether language models can pick up the polarisation that's prevalent in our modern society.", "tgt_ref": "Und wir versuchen auch herauszufinden, ob Sprachmodelle die Polarisierung, die in unserer modernen Gesellschaft vorherrscht, erfassen können."}
{"doc_id": "eXmqPhcZFN", "seg_id": 20, "src_ref": "So we divide pretraining corpora, into pre 45th president of the United States and after 45th president of the United States.", "tgt_ref": "Deshalb teilen wir die Vortrainingskorpora in „vor dem 45. Präsidenten der Vereinigten Staaten“ und nach dem 45. Präsidenten der Vereinigten Staaten“."}
{"doc_id": "eXmqPhcZFN", "seg_id": 21, "src_ref": "We separately pretrain language models on the two different temporal corpora.", "tgt_ref": "Wir trainieren die Sprachmodelle getrennt auf den beiden unterschiedlichen Zeitkorpora."}
{"doc_id": "eXmqPhcZFN", "seg_id": 22, "src_ref": "We can see that language models generally had a political leaning that is further away from the centre after 2017.", "tgt_ref": "Wir können feststellen, dass die Sprachmodelle nach 2017 im Allgemeinen eine politische Ausrichtung haben, die weiter von der Mitte entfernt ist."}
{"doc_id": "eXmqPhcZFN", "seg_id": 23, "src_ref": "So this indicates that language models can also pick up the polarisation in our society.", "tgt_ref": "Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft erfassen können."}
{"doc_id": "eXmqPhcZFN", "seg_id": 24, "src_ref": "So last but not least, we evaluate language models with different political leanings on hate speech detection and fake news detection to NLP applications that often involve language models and could have very significant implications.", "tgt_ref": "Schließlich evaluieren wir Sprachmodelle mit unterschiedlichen politischen Ausrichtungen für die Erkennung von Hate Speech und Fake News in NLP-Anwendungen, wo Sprachmodelle häufig verwendet werden und einen sehr großen Einfluss haben könnten."}
{"doc_id": "eXmqPhcZFN", "seg_id": 25, "src_ref": "So we see that if we investigate the per category performance, that is to say if we separate the performance into different demographics or political leaning of news media we can see a pattern.", "tgt_ref": "Betrachtet man die Leistung pro Kategorie, also wenn man die Leistung nach verschiedenen demografischen Gruppen oder politischen Ausrichtungen der Nachrichtenmedien aufschlüsselt, lässt sich ein Muster erkennen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 26, "src_ref": "For example, for hate speech detection, left-leaning language models are better at detecting hate speech targeting socially minority groups, however are worse at detecting hate speech targeting more powerful groups in our society.", "tgt_ref": "Wenn es beispielsweise um die Erkennung von Hate Speech geht, sind linksgerichtete Sprachmodelle besser in der Lage, Hate Speech zu erkennen, die sich gegen soziale Minderheiten richtet, aber schlechter in der Lage, Hate Speech zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richtet."}
{"doc_id": "eXmqPhcZFN", "seg_id": 27, "src_ref": "And vice versa, right-leaning language models are better at detecting hate speech targeting white and men, however worse at detecting hate speech targeting at black LGBTQ plus and other minority communities.", "tgt_ref": "Umgekehrt sind rechte Sprachmodelle besser in der Lage, Hate Speech zu erkennen, die sich gegen Weiße und Männer richtet, aber weniger gut in der Lage, Hate Speech zu erkennen, die sich gegen Schwarze, LGBTQ und andere Minderheitengruppen richtet."}
{"doc_id": "eXmqPhcZFN", "seg_id": 28, "src_ref": "Similar trends also happen for fake news detection, where we see that left-leaning language models are better at detecting misinformation from their opposite political leaning and vice versa.", "tgt_ref": "Ähnliche Trends lassen sich bei der Erkennung von Fake News beobachten. Hier zeigt sich, dass linke Sprachmuster besser in der Lage sind, Fehlinformationen zu erkennen, die auf die entgegengesetzte politische Richtung abzielen, und umgekehrt."}
{"doc_id": "eXmqPhcZFN", "seg_id": 29, "src_ref": "We further show many qualitative examples to see that language models with different political leanings do give different predictions to hate speech and misinformation examples based on their social categories.", "tgt_ref": "Wir stellen auch viele qualitative Beispiele vor, um zu zeigen, dass Sprachmodelle mit unterschiedlicher politischer Ausrichtung auf der Grundlage ihrer sozialen Kategorien unterschiedliche Vorhersagen für Beispiele von Hate Speech und Fehlinformationen machen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 30, "src_ref": "There are a bunch of more examples in the appendix to further highlight that this indicates that there is a fairness issue that is very pressing regarding the political biases of language models.", "tgt_ref": "Im Anhang finden Sie eine Reihe weiterer Beispiele, um zu illustrieren, dass dies darauf hindeutet, dass eine sehr dringende Frage der Fairness in Bezug auf die politische Voreingenommenheit von Sprachmodellen besteht."}
{"doc_id": "eXmqPhcZFN", "seg_id": 31, "src_ref": "For example, if right-leaning language models were to be fine-tuned on hate speech or misinformation or whatever and deployed to a popular social media platform, this would mean that, people with opposite political opinions might be marginalised and hate speech targeting minority groups might just run rampant without any control.", "tgt_ref": "Wenn zum Beispiel rechtsextreme Sprachmuster für Hate Speech, Fehlinformationen oder was auch immer fein abgestimmt und auf einer beliebten Social-Media-Plattform verwendet würden, würde dies bedeuten, dass Menschen mit gegensätzlichen politischen Ansichten ausgegrenzt werden könnten und Hassreden gegen Minderheiten einfach unkontrolliert ausufern könnten."}
{"doc_id": "eXmqPhcZFN", "seg_id": 32, "src_ref": "So this has sound the alarm for us to acknowledge and tackle the fairness issues resulting by language model political leanings.", "tgt_ref": "Es war also ein Weckruf für uns, die Gerechtigkeitsprobleme, die sich aus der politischen Ausrichtung des Sprachmodells ergeben, zu erkennen und anzugehen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 33, "src_ref": "So a little bit of discussion.", "tgt_ref": "Lassen Sie uns kurz darüber sprechen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 34, "src_ref": "We would also like to highlight that we expose the unique dilemma regarding language model political biases.", "tgt_ref": "Wir möchten auch betonen, dass wir das einzigartige Dilemma der politischen Voreingenommenheit des Sprachmodells aufdecken."}
{"doc_id": "eXmqPhcZFN", "seg_id": 35, "src_ref": "It's like between Scylla and Charybdis.", "tgt_ref": "Es ist wie Scylla und Charybdis."}
{"doc_id": "eXmqPhcZFN", "seg_id": 36, "src_ref": "So if we do not sanitize political opinions in language model training data, the bias would propagate from pretraining data to language models to downstream tasks, ultimately creating fairness issues.", "tgt_ref": "Wenn wir die politischen Meinungen in den Trainingsdaten für die Sprachmodelle nicht bereinigen, wird sich die Verzerrung von den Daten vor dem Training über die Sprachmodelle bis hin zu den nachgelagerten Aufgaben ausbreiten und schließlich zu Fairnessproblemen führen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 37, "src_ref": "If we do try to sanitaze somehow, we would also risk censorship, or exclusion.", "tgt_ref": "Wenn wir versuchen, die Daten irgendwie zu bereinigen, riskieren wir auch Zensur oder den Ausschluss von Menschen."}
{"doc_id": "eXmqPhcZFN", "seg_id": 38, "src_ref": "And it's incredibly hard to determine what is actually neutral and should be retaining language monitoring data.", "tgt_ref": "Und es ist unglaublich schwierig zu bestimmen, was wirklich neutral ist und in den Sprachüberwachungsdaten erhalten bleiben sollte."}
{"doc_id": "eXmqPhcZFN", "seg_id": 39, "src_ref": "So it's kind of like the electric trolley problem.", "tgt_ref": "Es ist also ein bisschen wie das elektronische Trolley-Problem."}
{"doc_id": "eXmqPhcZFN", "seg_id": 40, "src_ref": "Ok, great.", "tgt_ref": "Okay, gut."}
{"doc_id": "eXmqPhcZFN", "seg_id": 41, "src_ref": "I think that's pretty much all I have for today.", "tgt_ref": "Ich glaube, das ist alles, was ich heute für Sie habe."}
{"doc_id": "eXmqPhcZFN", "seg_id": 42, "src_ref": "Thank you for your time.", "tgt_ref": "Vielen Dank für Ihre Zeit."}
{"doc_id": "xiSxNRoOzm", "seg_id": 0, "src_ref": "Hi everyone.", "tgt_ref": "Hallo zusammen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 1, "src_ref": "I'm Jenny, a first year PhD student at Carnegie Mellon University and today I'll be presenting your work NLPositionality characterising design biases of datasets and Models.", "tgt_ref": "Mein Name ist Jenny, ich bin Doktorandin im ersten Jahr an der Carnegie Mellon University und ich werde heute meine Arbeit „LPositionality characterising design biases of datasets and Models“ vorstellen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 2, "src_ref": "This work was done in collaboration with some folks at the University of Washington and the Allen Institute for AI, namely Sebastian Santy, Ronan Le Bras, Katharina Reinecke and Maarten Sap.", "tgt_ref": "Diese Arbeit wurde in Zusammenarbeit mit Kollegen von der University of Washington und dem Allen Institute for AI durchgeführt, nämlich Sebastian Santy, Ronan Le Bras, Katharina Reinecke und Maarten Sap."}
{"doc_id": "xiSxNRoOzm", "seg_id": 3, "src_ref": "So let's start off by imagining that you're working for a newspaper and you're sifting through comments under your news article trying to remove toxic content.", "tgt_ref": "Stellen Sie sich vor, Sie arbeiten für eine Zeitung und durchsuchen die Kommentare unter Ihren Nachrichtenartikeln, um schädliche Inhalte zu entfernen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 4, "src_ref": "You might turn towards a popular API like Prospective API for toxicity detection, and this works really well if you're Carl Jones.", "tgt_ref": "Sie könnten sich an eine beliebte API wie Prospective API wenden, um toxische Inhalte zu erkennen, und das funktioniert wirklich gut, wenn Sie Carl Jones sind."}
{"doc_id": "xiSxNRoOzm", "seg_id": 5, "src_ref": "Where prospective API is able to detect correctly toxic instances.", "tgt_ref": "Prospective API ist in der Lage, toxische Instanzen korrekt zu erkennen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 6, "src_ref": "But that's not really the case for Aditya Sharma.", "tgt_ref": "Aber das ist nicht wirklich der Fall für Aditya Sharma."}
{"doc_id": "xiSxNRoOzm", "seg_id": 7, "src_ref": "Where prospective AP is really not as sensitive to offensive terms that are more common in Indian contexts.", "tgt_ref": "Hier ist Prospective API nicht so empfindlich gegenüber anstößigen Begriffen, die in indischen Kontexten häufiger vorkommen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 8, "src_ref": "This is an example of a design bias where we see systematic performance differences of technology between populations.", "tgt_ref": "Dies ist ein Beispiel für eine Designverzerrung, bei der wir systematische Unterschiede in der Leistung der Technologie zwischen Bevölkerungsgruppen feststellen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 9, "src_ref": "Design biases like the one that we just saw before might occur due to the positionality of the NLP researchers and model developers.", "tgt_ref": "Designverzerrungen, wie wir sie gerade gesehen haben, können aufgrund der Positionalität von NLP-Forschern und Modellentwicklern auftreten."}
{"doc_id": "xiSxNRoOzm", "seg_id": 10, "src_ref": "Positionality is simply the perspectives that people hold as a result of their demographics, identity, and life experiences.", "tgt_ref": "Positionalität ist einfach die Perspektive, die Menschen aufgrund ihrer demographischen Zugehörigkeit, Identität und Lebenserfahrung haben."}
{"doc_id": "xiSxNRoOzm", "seg_id": 11, "src_ref": "This is a concept widely used in critical studies, specifically in feminist and queer academic spaces.", "tgt_ref": "Dieses Konzept wird häufig in Critical Studies verwendet, insbesondere in feministischen und queeren akademischen Kreisen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 12, "src_ref": "And as a researcher, positionality can influence the research process and its outcomes and results because it can change the decisions that researchers make.", "tgt_ref": "Als Forschende kann Positionalität den Forschungsprozess und seine Ergebnisse und Erkenntnisse beeinflussen, da sie die Entscheidungen der Forschenden verändern kann."}
{"doc_id": "xiSxNRoOzm", "seg_id": 13, "src_ref": "And so one question that people might ask is, do datasets and models have positionality?", "tgt_ref": "Eine Frage, die man sich also stellen könnte, lautet: Haben Datensätze und Modelle eine Positionalität?"}
{"doc_id": "xiSxNRoOzm", "seg_id": 14, "src_ref": "And we're not trying to say that models themselves in data sets themselves have demographic identities and life experiences, but they do aggregate judgments and opinions of real people, and can thus represent certain positionalities over others.", "tgt_ref": "Wir wollen damit nicht sagen, dass die Modelle in den Datensätzen selbst demographische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Urteile und Meinungen realer Menschen und können daher bestimmte Positionalitäten gegenüber anderen vertreten."}
{"doc_id": "xiSxNRoOzm", "seg_id": 15, "src_ref": "So prior work has suggested some anecdotal evidence of having positionality, such as cultural gaps and models and data sets, as well as theoretical definitions of model positionality.", "tgt_ref": "Frühere Arbeiten haben einige anekdotische Hinweise auf Positionalität gegeben, wie zum Beispiel kulturelle Unterschiede zwischen Modellen und Datensätzen, sowie theoretische Definitionen von Modellpositionalität."}
{"doc_id": "xiSxNRoOzm", "seg_id": 16, "src_ref": "However these works really don't look at comparing end users with the datasets and models themselves, and studying model and data set positionality is increasingly important as NLP tasks become more subjective and socially oriented, and it's challenging to characterise how these positionalities are skewed because not all decisions are documented and many models are hidden behind APIs.", "tgt_ref": "Diese Arbeiten befassen sich jedoch nicht wirklich mit dem Vergleich zwischen Endanwendern und den Datensätzen und Modellen selbst. Die Untersuchung der Positionalität von Modellen und Datensätzen wird immer wichtiger, da NLP-Aufgaben zunehmend subjektiver und sozialer werden und es schwierig ist, genau zu charakterisieren, wie diese Positionalitäten verzerrt werden, da nicht alle Entscheidungen dokumentiert werden und viele Modelle hinter APIs versteckt sind."}
{"doc_id": "xiSxNRoOzm", "seg_id": 17, "src_ref": "So to study data set and model positionality, we actually compare the annotations with real users with existing datasets and models.", "tgt_ref": "Um die Positionalität von Datensätzen und Modellen zu untersuchen, vergleichen wir daher die Kommentare von realen Benutzern mit bestehenden Datensätzen und Modellen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 18, "src_ref": "We do this through our framework NLPositionality.", "tgt_ref": "Dazu verwenden wir unser Framework NLPositionality."}
{"doc_id": "xiSxNRoOzm", "seg_id": 19, "src_ref": "Our framework works in two main steps.", "tgt_ref": "Unser Framework arbeitet in zwei Hauptschritten."}
{"doc_id": "xiSxNRoOzm", "seg_id": 20, "src_ref": "The first step is to re annotate data sets with diverse annotators.", "tgt_ref": "Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren neu zu annotieren."}
{"doc_id": "xiSxNRoOzm", "seg_id": 21, "src_ref": "And we ought to do this over looking at the demographics of original data sets annotators, because, usually only a few annotators annotate each instance and because demographics are rarely collected and shared.", "tgt_ref": "Dazu müssen die demographischen Daten der Annotatoren der ursprünglichen Datensätze untersucht werden. Normalerweise annotieren nur wenige Annotatoren jede Instanz, und demographische Daten werden selten erhoben und geteilt."}
{"doc_id": "xiSxNRoOzm", "seg_id": 22, "src_ref": "And so we opt to re annotate data to get many annotates for instance and to get a rich set of demographic data.", "tgt_ref": "Wir entscheiden uns daher, die Daten erneut zu annotieren, um viele Annotatoren und einen umfangreichen Satz demografischer Daten zu erhalten."}
{"doc_id": "xiSxNRoOzm", "seg_id": 23, "src_ref": "We then take the annotations by demographic and compare them to the models and datasets using a Pearson's R correlation score, and thus our framework actually differs from annotator disagreement literature by comparing end users with models and datasets, predictions and labels, as opposed to looking at just annotator agreement or modelling annotator distributions.", "tgt_ref": "Wir nehmen dann die Annotationen nach demographischen Merkmalen und vergleichen sie mit den Modellen und Datensätzen mithilfe eines R-Korrelationsscores nach Pearson. Damit unterscheidet sich unser System von der Literatur über Annotator-Uneinigkeiten, da wir die Endanwender mit den Modellen und Datensätzen, den Vorhersagen und den Labels vergleichen und nicht nur die Annotator-Übereinstimmung oder die Modellierung der Annotator-Verteilung betrachten."}
{"doc_id": "xiSxNRoOzm", "seg_id": 24, "src_ref": "Our frame is largely enabled through Lab in the Wild and online crowdsourcing platform for where HCI collaborator.", "tgt_ref": "Unser Framework wird größtenteils durch Lab in the Wild und eine Online-Crowdsourcing-Plattform für HCI-Mitarbeiter ermöglicht."}
{"doc_id": "xiSxNRoOzm", "seg_id": 25, "src_ref": "In Live in the Wild is an online experimentation platform where we can recruit divers volunteers.", "tgt_ref": "Lab in the Wild ist eine Online-Experimentierplattform, auf der wir verschiedene Freiwillige rekrutieren können."}
{"doc_id": "xiSxNRoOzm", "seg_id": 26, "src_ref": "Compared to the platforms like M Turk which largely have participants from the US or India and further Lab in the Wild still is able to get high quality data.", "tgt_ref": "Im Vergleich zu Plattformen wie M Turk, wo die meisten Teilnehmer aus den USA oder Indien kommen, ist Lab in the Wild immer noch in der Lage, qualitativ hochwertige Daten zu erhalten."}
{"doc_id": "xiSxNRoOzm", "seg_id": 27, "src_ref": "We host 2 tasks on lab in the wild, one of them being social acceptability, and the way this works is that participants will read a situation from the social chemistry dataset and, then they'll write how socially acceptable a situation is.", "tgt_ref": "Bei Lab in the Wild haben wir zwei Aufgaben. Die erste ist die soziale Akzeptanz. Die Teilnehmer lesen eine Situation aus dem Social-Chemistry-Datensatz und schreiben dann auf, wie sozial akzeptabel die Situation ist."}
{"doc_id": "xiSxNRoOzm", "seg_id": 28, "src_ref": "Afterwards to stay engaged in the study, they can compare their responses to an AI and others.", "tgt_ref": "Um die Teilnehmer bei der Stange zu halten, können sie ihre Antworten dann mit einer KI und anderen vergleichen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 29, "src_ref": "We've then compared these, annotations with Social Chemistry, Delphi and GPT 4.", "tgt_ref": "Wir haben diese Kommentare dann mit Social Chemistry, Delphi und GPT 4 verglichen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 30, "src_ref": "We then replicate a very similar setup for the toxicity and hate speech detection task, where they'll read an instance from Dynahate and write whether they think it's instance of hate speech.", "tgt_ref": "Danach wiederholten wir einen sehr ähnlichen Aufbau für die Aufgabe zur Erkennung von toxischen Inhalten und Hate Speech, bei der die Teilnehmer eine Situation aus Dynahate lasen und notierten, ob es sich ihrer Meinung nach um einen Fall von Hate Speech handelte."}
{"doc_id": "xiSxNRoOzm", "seg_id": 31, "src_ref": "We then compared these annotations with Dynahate, Perspective API, Rewire API, Hate Roberta and GPT 4.", "tgt_ref": "Diese Kommentare wurden dann mit Dynahate, Perspective API, Rewire API, Hate Roberta und GPT 4 verglichen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 32, "src_ref": "Our study in the end amassed over 16,000 annotations from over 1000 annotators from 87 countries.", "tgt_ref": "Am Ende erhob unsere Studie mehr als 16.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern."}
{"doc_id": "xiSxNRoOzm", "seg_id": 33, "src_ref": "So now we're better equipped to answer who do NLP datasets and models align with the most.", "tgt_ref": "Wir sind jetzt besser gerüstet, um die Frage zu beantworten, auf wen die NLP-Datensätze und -Modelle am ehesten ausgerichtet sind."}
{"doc_id": "xiSxNRoOzm", "seg_id": 34, "src_ref": "We find that there is positionality in NLP.", "tgt_ref": "Wir sehen, dass es eine Positionalität in der NLP gibt."}
{"doc_id": "xiSxNRoOzm", "seg_id": 35, "src_ref": "For example, we find that data sets and models are most aligned to English speaking countries.", "tgt_ref": "Wir stellen zum Beispiel fest, dass die Datensätze und Modelle am ehesten auf englischsprachige Länder ausgerichtet sind."}
{"doc_id": "xiSxNRoOzm", "seg_id": 36, "src_ref": "So for the GPT 4 social acceptability analysis, we find that it's most aligned to confucian and English speaking countries.", "tgt_ref": "Wenn wir also die soziale Akzeptanz von GPT 4 analysieren, stellen wir fest, dass es am ehesten auf konfuzianische und englischsprachige Länder ausgerichtet ist."}
{"doc_id": "xiSxNRoOzm", "seg_id": 37, "src_ref": "We find that Dynahate is also most aligned to English speaking countries.", "tgt_ref": "Wir stellen fest, dass Dynahate ebenfalls am stärksten auf englischsprachige Länder ausgerichtet ist."}
{"doc_id": "xiSxNRoOzm", "seg_id": 38, "src_ref": "We also find most additional alignment with people who have a college education.", "tgt_ref": "Wir stellen auch fest, dass es am ehesten auf Personen mit Hochschulbildung ausgerichtet ist."}
{"doc_id": "xiSxNRoOzm", "seg_id": 39, "src_ref": "So for GPT 4, in the social acceptability task, we find that it's most aligned to people with a college education or Graduate School education and we find the same for Dynahate where it's most aligned to people with a college education.", "tgt_ref": "Wir stellen also fest, dass GPT 4 in der Aufgabe „Soziale Akzeptanz“ am stärksten auf Personen mit Hochschul- oder Fachhochschulbildung ausgerichtet ist, und dasselbe gilt für Dynahate, das am stärksten auf Personen mit Hochschulbildung ausgerichtet ist."}
{"doc_id": "xiSxNRoOzm", "seg_id": 40, "src_ref": "However, when models and data sets are aligned to specific populations, some are inevitably left behind.", "tgt_ref": "Wenn jedoch Modelle und Datensätze auf bestimmte Bevölkerungsgruppen ausgerichtet sind, bleiben einige zwangsläufig auf der Strecke."}
{"doc_id": "xiSxNRoOzm", "seg_id": 41, "src_ref": "An example of this is that datasets and models are less aligned to non binary people compared to the men and women counterparts.", "tgt_ref": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger gut auf nicht-binäre Menschen ausgerichtet sind als auf ihre männlichen und weiblichen Gegenstücke."}
{"doc_id": "xiSxNRoOzm", "seg_id": 42, "src_ref": "We find this in the GPT 4 social acceptability task as well as the Dynahate task analysis as well.", "tgt_ref": "Wir finden dies in der GPT-4-Aufgabe Soziale Akzeptanz und in der Dynahate-Aufgabenanalyse."}
{"doc_id": "xiSxNRoOzm", "seg_id": 43, "src_ref": "So, given that there is positionality in NLP, what can we do about it?", "tgt_ref": "Wenn es also Positionalität im NLP gibt, was können wir dagegen tun?"}
{"doc_id": "xiSxNRoOzm", "seg_id": 44, "src_ref": "So we have a few recommendations for this.", "tgt_ref": "Nun, wir haben einige Empfehlungen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 45, "src_ref": "First one is keep a record of all relevant design choices throughout the research process.", "tgt_ref": "Eine davon ist, alle relevanten Designentscheidungen während des gesamten Forschungsprozesses zu protokollieren."}
{"doc_id": "xiSxNRoOzm", "seg_id": 46, "src_ref": "And the other is to do NLP research with the lens of perspectivism.", "tgt_ref": "Die zweite ist, NLP-Forschung unter der Linse des Perspektivismus zu betreiben."}
{"doc_id": "xiSxNRoOzm", "seg_id": 47, "src_ref": "Our third recommendation is to build specialised datasets and models within 4 specific communities.", "tgt_ref": "Unsere dritte Empfehlung ist, spezialisierte Datensätze und Modelle innerhalb bestimmter Communities zu erstellen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 48, "src_ref": "And a good example of this is the Masakhani initiative.", "tgt_ref": "Die Masakhani Initiative ist ein gutes Beispiel dafür."}
{"doc_id": "xiSxNRoOzm", "seg_id": 49, "src_ref": "I mean, we want to emphasise that inclusive NLP isn't just making.", "tgt_ref": "Ich denke, wir möchten betonen, dass es bei inklusivem NLP nicht nur um die Produktion geht."}
{"doc_id": "xiSxNRoOzm", "seg_id": 50, "src_ref": "You know, all technologies work for everyone.", "tgt_ref": "Alle Technologien müssen für alle funktionieren."}
{"doc_id": "xiSxNRoOzm", "seg_id": 51, "src_ref": "And so that concludes our presentation.", "tgt_ref": "Und damit ist unsere Präsentation zu Ende."}
{"doc_id": "xiSxNRoOzm", "seg_id": 52, "src_ref": "But if you'd like to learn more, feel free to check out our dashboard for the most updated analysis results and our paper.", "tgt_ref": "Aber wenn Sie mehr erfahren möchten, können Sie sich die neuesten Analysen und unsere Arbeit auf unserem Dashboard ansehen."}
{"doc_id": "xiSxNRoOzm", "seg_id": 53, "src_ref": "Thank you.", "tgt_ref": "Vielen Dank."}
{"doc_id": "crgYiwKDfX", "seg_id": 0, "src_ref": "Hi, I'm Siyu Yuan from Fudan University.", "tgt_ref": "Hallo, ich bin Siyu Yuan von der Fudan Universität."}
{"doc_id": "crgYiwKDfX", "seg_id": 1, "src_ref": "I'm here to introduce our work \"Distilling Script Knowledge from Large Language Models for Constrained Language Planning\".", "tgt_ref": "Ich bin hier, um unsere Arbeit „Distilling Script Knowledge from Large Language Models for Constrained Language Planning“ vorzustellen."}
{"doc_id": "crgYiwKDfX", "seg_id": 2, "src_ref": "In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts.", "tgt_ref": "Im Alltag planen Menschen ihre Handlungen oft, indem sie Schritt-für-Schritt-Anweisungen in Form von zielorientierten Skripten folgen."}
{"doc_id": "crgYiwKDfX", "seg_id": 3, "src_ref": "Previous work has exploited language models to plan for abstract goals of stereotypical activities such as \"make a cake\".", "tgt_ref": "Frühere Arbeiten haben Sprachmodelle verwendet, um abstrakte Ziele für stereotype Aktivitäten wie „einen Kuchen backen“ zu planen."}
{"doc_id": "crgYiwKDfX", "seg_id": 4, "src_ref": "And show that large language models can effectively decompose goals into steps.", "tgt_ref": "Sie zeigen, dass Large Language Models Ziele effektiv in Schritte zerlegen können."}
{"doc_id": "crgYiwKDfX", "seg_id": 5, "src_ref": "However, previous work mainly focuses on planning for the abstract goals of stereotypical activities.", "tgt_ref": "Bisherige Arbeiten haben sich jedoch hauptsächlich auf die Planung abstrakter Ziele für stereotype Aktivitäten konzentriert."}
{"doc_id": "crgYiwKDfX", "seg_id": 6, "src_ref": "Planning for the goals with specific constraints, such as \"make a chocolate cake\", still remains under-studied.", "tgt_ref": "Die Planung von Zielen mit spezifischen Beschränkungen, wie zum Beispiel „einen Schokoladenkuchen backen“, ist noch wenig erforscht."}
{"doc_id": "crgYiwKDfX", "seg_id": 7, "src_ref": "In this paper, we define the problem of constrained language planning which imposes different constraints on the goals of planning.", "tgt_ref": "In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung, bei dem die Planungsziele verschiedenen Beschränkungen unterliegen."}
{"doc_id": "crgYiwKDfX", "seg_id": 8, "src_ref": "An abstract goal can be inherited by different real-life specific goals with multi-faceted constraints.", "tgt_ref": "Ein abstraktes Ziel kann von mehreren konkreten, spezifischen Zielen mit mehreren Beschränkungen abgeleitet werden."}
{"doc_id": "crgYiwKDfX", "seg_id": 9, "src_ref": "A good planner should write scripts that are reasonable and faithful to constraints.", "tgt_ref": "Ein guter Planer sollte Skripte schreiben, die vernünftig sind und sich an die Beschränkungen halten."}
{"doc_id": "crgYiwKDfX", "seg_id": 10, "src_ref": "In this paper, we first evaluate and improve the constrained language planning ability of large language models.", "tgt_ref": "In dieser Arbeit evaluieren und verbessern wir zunächst die Fähigkeit von Large Language Models zur Planung mit Beschränkungen."}
{"doc_id": "crgYiwKDfX", "seg_id": 11, "src_ref": "Since no dataset of specific goals exists to support our study, we have to acquire these goals first.", "tgt_ref": "Da es keinen Datensatz mit spezifischen Zielen für unsere Studie gibt, müssen wir uns diese Ziele erst beschaffen."}
{"doc_id": "crgYiwKDfX", "seg_id": 12, "src_ref": "As shown in the table, we extend the abstract goals with multi-faceted constraints for human-in-the-loop data acquisition using InstructGPT.", "tgt_ref": "Wie in der Tabelle zu sehen ist, erweitern wir die abstrakten Ziele mit mehrschichtigen Beschränkungen für die Human-in-the-Loop-Datenerfassung mit InstructGPT."}
{"doc_id": "crgYiwKDfX", "seg_id": 13, "src_ref": "We sample 100 specific goals and evaluate the scripts generated from large language models.", "tgt_ref": "Wir wählen 100 spezifische Ziele aus und evaluieren die Skripte, die aus Large Language Models generiert wurden."}
{"doc_id": "crgYiwKDfX", "seg_id": 14, "src_ref": "This table reports the overall accuracy of the results.", "tgt_ref": "Diese Tabelle zeigt die Gesamtgenauigkeit der Ergebnisse."}
{"doc_id": "crgYiwKDfX", "seg_id": 15, "src_ref": "We find that all language models achieve unsatisfactory results on planning for specific goals.", "tgt_ref": "Wir stellen fest, dass alle Sprachmodelle bei der Planung spezifischer Ziele unbefriedigende Ergebnisse liefern."}
{"doc_id": "crgYiwKDfX", "seg_id": 16, "src_ref": "Then we conduct detailed analysis to investigate why learning models fail.", "tgt_ref": "Anschließend führen wir eine detaillierte Analyse durch, um die Gründe für das Versagen der Lernmodelle zu untersuchen."}
{"doc_id": "crgYiwKDfX", "seg_id": 17, "src_ref": "Results in the figure show that the semantic completeness in generated scripts is acceptable but the faithfulness to the constraints cannot be guaranteed.", "tgt_ref": "Die in der Abbildung dargestellten Ergebnisse zeigen, dass die semantische Vollständigkeit der generierten Skripte akzeptabel ist, dass aber die Beschränkungstreue nicht garantiert werden kann."}
{"doc_id": "crgYiwKDfX", "seg_id": 18, "src_ref": "We dig into a more fine-grained topic categories of constraints defined in wikiHow.", "tgt_ref": "Wir betrachten einen feingliedrigeren Satz von Themenkategorien von Beschränkungen, die in wikiHow definiert sind."}
{"doc_id": "crgYiwKDfX", "seg_id": 19, "src_ref": "The heat map in the figure shows that the planning performance of InstructGPTs varies considerably for goals of different categories.", "tgt_ref": "Die Heatmap in der Abbildung zeigt, dass die Planungsleistung von InstructGPTs für Ziele verschiedener Kategorien erheblich variiert."}
{"doc_id": "crgYiwKDfX", "seg_id": 20, "src_ref": "Previous studies have shown that the output quality of language models falls in high variance, leading to bad performance.", "tgt_ref": "Frühere Studien haben gezeigt, dass die Ausgabequalität von Sprachmodellen mit hoher Varianz abnimmt, was zu einer schlechten Leistung führt."}
{"doc_id": "crgYiwKDfX", "seg_id": 21, "src_ref": "Thus, we adopt the idea of over-generate-then-filter to improve generation quality.", "tgt_ref": "Daher wenden wir die Idee der Übergenerierung und anschließenden Filterung an, um die Generierungsqualität zu verbessern."}
{"doc_id": "crgYiwKDfX", "seg_id": 22, "src_ref": "We first show constraint types with examples for InstructGPT and obtain specific goals based on the seed abstract goals.", "tgt_ref": "Zuerst werden Beschränkungsarten mit Beispielen für InstructGPT gezeigt und spezifische Ziele basierend auf den abstrakten Zielen des Seeds erhalten."}
{"doc_id": "crgYiwKDfX", "seg_id": 23, "src_ref": "Then, InstructGPT over-generates K scripts for specific goals.", "tgt_ref": "Dann übergeneriert InstructGPT K-Skripte für spezifische Ziele."}
{"doc_id": "crgYiwKDfX", "seg_id": 24, "src_ref": "Next, a filter model is developed to select the faithful scripts.", "tgt_ref": "Anschließend wird ein Filtermodell entwickelt, um treue Skripte auszuwählen."}
{"doc_id": "crgYiwKDfX", "seg_id": 25, "src_ref": "We convert scripts and goals into InstructGPT embeddings and calculate the cosine similarity as similarity scores to measure semantic similarity.", "tgt_ref": "Wir konvertieren die Skripte und Ziele in InstructGPT-Einbettungen und berechnen die Kosinusähnlichkeit als Ähnlichkeitswert, um die semantische Ähnlichkeit zu messen."}
{"doc_id": "crgYiwKDfX", "seg_id": 26, "src_ref": "In addition, we reward the script that contains the keywords of the target constraint.", "tgt_ref": "Zusätzlich belohnen wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält."}
{"doc_id": "crgYiwKDfX", "seg_id": 27, "src_ref": "We only keep the script if the target goal scores the highest in the goal set.", "tgt_ref": "Wir behalten das Skript nur, wenn das Ziel die höchste Punktzahl in der Zielmenge hat."}
{"doc_id": "crgYiwKDfX", "seg_id": 28, "src_ref": "With our method, InstructGPT can generate scripts of higher quality.", "tgt_ref": "Mit unserer Methode kann InstructGPT Skripte von höherer Qualität erzeugen."}
{"doc_id": "crgYiwKDfX", "seg_id": 29, "src_ref": "Our method greatly improves the planning ability both in semantic completeness and faithfulness to the constraint.", "tgt_ref": "Unsere Methode verbessert die Planbarkeit sowohl in Bezug auf semantische Vollständigkeit als auch in Bezug auf Beschränkungstreue erheblich."}
{"doc_id": "crgYiwKDfX", "seg_id": 30, "src_ref": "Since large language models are costly to deploy, it's essential to enable language planning ability of smaller and specialized models.", "tgt_ref": "Da Large Language Models teuer in der Bereitstellung sind, ist es wichtig, die Sprachplanungsfähigkeit auch für kleinere und spezialisiertere Modelle zu ermöglichen."}
{"doc_id": "crgYiwKDfX", "seg_id": 31, "src_ref": "Creating the dataset is an essential step to this end.", "tgt_ref": "Die Erstellung des Datensatzes ist ein wichtiger Schritt in diese Richtung."}
{"doc_id": "crgYiwKDfX", "seg_id": 32, "src_ref": "However, previous studies do not enable planning for specific goals and manual dataset annotation is expensive.", "tgt_ref": "Bisherige Studien erlauben jedoch keine Planung für spezifische Ziele, und die manuelle Annotation des Datensatzes ist teuer."}
{"doc_id": "crgYiwKDfX", "seg_id": 33, "src_ref": "Thus, we follow the idea of symbolic knowledge distillation, to distil constrained language planning datasets from large language models.", "tgt_ref": "Daher verfolgen wir die Idee der symbolischen Wissensdestillation, um eingeschränkte Sprachplanungsdatensätze aus großen Sprachmodellen zu destillieren."}
{"doc_id": "crgYiwKDfX", "seg_id": 34, "src_ref": "We appy our method for building a dataset of constrained language planning, named as CoScript.", "tgt_ref": "Wir wenden unsere Methode zur Erstellung eines Datensatzes zur eingeschränkten Sprachplanung an, der CoScript genannt wird."}
{"doc_id": "crgYiwKDfX", "seg_id": 35, "src_ref": "In total, we generate 55,000 specific goals with scripts.", "tgt_ref": "Insgesamt generieren wir 55.000 spezifische Ziele mit Skripten."}
{"doc_id": "crgYiwKDfX", "seg_id": 36, "src_ref": "To ensure the quality of the validation and test set, we ask crowd-sourced workers to find and revise the incorrect samples.", "tgt_ref": "Um die Qualität des Validierungs- und Testdatensatzes sicherzustellen, bitten wir die Crowdsourcer, die fehlerhaften Beispiele zu finden und zu überarbeiten."}
{"doc_id": "crgYiwKDfX", "seg_id": 37, "src_ref": "This figure shows the constraint distribution of CoScript.", "tgt_ref": "Diese Abbildung zeigt die Verteilung der Beschränkungen von CoScript."}
{"doc_id": "crgYiwKDfX", "seg_id": 38, "src_ref": "We find CoScript shows high pluralism in the generated specific goals.", "tgt_ref": "Es ist zu erkennen, dass CoScript einen hohen Pluralismus der generierten spezifischen Ziele aufweist."}
{"doc_id": "crgYiwKDfX", "seg_id": 39, "src_ref": "With CoScript we can try smaller but specialized models for constrained language planning.", "tgt_ref": "Mit CoScript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung ausprobieren."}
{"doc_id": "crgYiwKDfX", "seg_id": 40, "src_ref": "We find that T5 fine-tuned on CoScript can generate scripts of higher quality than most large language models, indicating that smaller models can surpass larger models when properly trained on suitable datasets.", "tgt_ref": "Wir stellen fest, dass T5, das an CoScript angepasst wurde, Skripte von höherer Qualität erzeugen kann als die meisten Large Language Models, was darauf hindeutet, dass kleinere Modelle größere Modelle übertreffen können, wenn sie auf geeigneten Datensätzen richtig trainiert werden."}
{"doc_id": "crgYiwKDfX", "seg_id": 41, "src_ref": "In summary, we establish the constrained language planning problem.", "tgt_ref": "Zusammenfassend stellen wir das Problem der begrenzten Sprachplanung vor."}
{"doc_id": "crgYiwKDfX", "seg_id": 42, "src_ref": "We evaluate constrained language planning ability of large language models and develop an over-generate-then-filter method for large language models.", "tgt_ref": "Wir evaluieren die Fähigkeit von Large Language Models zur eingeschränkten Sprachplanung und entwickeln eine Übergenerierungs- und Filterungsmethode für große Sprachmodelle."}
{"doc_id": "crgYiwKDfX", "seg_id": 43, "src_ref": "We use large language models to generate a high-quality script dataset, CoScript, for constrained language planning.", "tgt_ref": "Wir verwenden Large Language Models, um einen qualitativ hochwertigen Skriptdatensatz, CoScript, für die eingeschränkte Sprachplanung zu erzeugen."}
{"doc_id": "crgYiwKDfX", "seg_id": 44, "src_ref": "We hope the CoScript dataset can be a valuable resource to advance research on language planning.", "tgt_ref": "Wir hoffen, dass der CoScript-Datensatz eine wertvolle Ressource sein wird, um die Forschung auf dem Gebiet der Sprachplanung voranzutreiben."}
{"doc_id": "crgYiwKDfX", "seg_id": 45, "src_ref": "Thanks for your time.", "tgt_ref": "Vielen Dank für Ihre Zeit."}
{"doc_id": "crgYiwKDfX", "seg_id": 46, "src_ref": "Please find more details of CoScript in our paper.", "tgt_ref": "Weitere Details zu CoScript finden Sie in unserer Arbeit."}
{"doc_id": "QTlIuodOsA", "seg_id": 0, "src_ref": "Hello everyone, my name is Shuheng.", "tgt_ref": "Hallo zusammen, mein Name ist Shuheng."}
{"doc_id": "QTlIuodOsA", "seg_id": 1, "src_ref": "Today I'm going to present our paper Do CoNLL-2003 named entity taggers still work well in 2023?", "tgt_ref": "Heute werde ich Ihnen unsere Arbeit „Do CoNLL-2003 named entity taggers still work well in 2023?“ vorstellen."}
{"doc_id": "QTlIuodOsA", "seg_id": 2, "src_ref": "Let's get started.", "tgt_ref": "Fangen wir an."}
{"doc_id": "QTlIuodOsA", "seg_id": 3, "src_ref": "Our paper investigated the problem of generalization using the Named Entity Recognition Task or the NER task.", "tgt_ref": "In unserem Beitrag haben wir das Problem der Generalisierung anhand der Aufgabe der Erkennung benannter Entitäten (Named Entity Recognition, NER) untersucht."}
{"doc_id": "QTlIuodOsA", "seg_id": 4, "src_ref": "We observe that models have been used in CoNLL-2003 to develop NER for almost 20 years and this naturally raises several problems.", "tgt_ref": "Wir haben festgestellt, dass die Modelle, die in CoNLL-2003 zur Entwicklung von NER verwendet wurden, seit fast 20 Jahren in Gebrauch sind, was natürlich einige Probleme aufwirft."}
{"doc_id": "QTlIuodOsA", "seg_id": 5, "src_ref": "Firstly, can these models generalise to modern data?", "tgt_ref": "Erstens: Können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"doc_id": "QTlIuodOsA", "seg_id": 6, "src_ref": "And when we develop new taggers, what is needed for good generalization?", "tgt_ref": "Und wenn wir neue Tagger entwickeln, was ist dann für eine gute Generalisierung notwendig?"}
{"doc_id": "QTlIuodOsA", "seg_id": 7, "src_ref": "At the same time, if we do observe poor generalization, what causes the performance drop of these models?", "tgt_ref": "Wenn wir eine schlechte Generalisierung beobachten, was ist dann der Grund für den Leistungsabfall dieser Modelle?"}
{"doc_id": "QTlIuodOsA", "seg_id": 8, "src_ref": "To investigate these problems, we developed the CoNLL++ Dataset.", "tgt_ref": "Um diese Probleme zu untersuchen, haben wir den CoNLL++-Datensatz entwickelt."}
{"doc_id": "QTlIuodOsA", "seg_id": 9, "src_ref": "This is a data set that we collected from Reuters News from 2020, and then annotated them with the same CoNLL-2003 annotation guidelines.", "tgt_ref": "Dabei handelt es sich um einen Datensatz, den wir von Reuters News aus dem Jahr 2020 gesammelt und dann mit den gleichen CoNLL-2003 Annotationsrichtlinien annotiert haben."}
{"doc_id": "QTlIuodOsA", "seg_id": 10, "src_ref": "We then fine-tuned over 20 models on CoNLL-2003.", "tgt_ref": "Anschließend haben wir über 20 Modelle mit CoNLL-2003 feinjustiert."}
{"doc_id": "QTlIuodOsA", "seg_id": 11, "src_ref": "We evaluated them on both the CoNLL-03 test sets and the CoNLL++.", "tgt_ref": "Wir haben sie sowohl mit den CoNLL-03 als auch mit den CoNLL++ Testsätzen evaluiert."}
{"doc_id": "QTlIuodOsA", "seg_id": 12, "src_ref": "And last but not least, we calculated the percentage change in F1 to assess the generalization of each model.", "tgt_ref": "Schließlich haben wir die prozentuale Änderung von F1 berechnet, um die Generalisierung jedes Modells zu bewerten."}
{"doc_id": "QTlIuodOsA", "seg_id": 13, "src_ref": "So what is needed for a good generalization?", "tgt_ref": "Was ist also notwendig, um eine gute Generalisierung zu erreichen?"}
{"doc_id": "QTlIuodOsA", "seg_id": 14, "src_ref": "Throughout experiments we found that there are three main ingredients that are needed.", "tgt_ref": "Während der Experimente haben wir festgestellt, dass drei Hauptkomponenten erforderlich sind."}
{"doc_id": "QTlIuodOsA", "seg_id": 15, "src_ref": "The first one is the model architecture.", "tgt_ref": "Die erste ist die Modellarchitektur."}
{"doc_id": "QTlIuodOsA", "seg_id": 16, "src_ref": "Through our experiments we found that the transformer models normally generalize better to new data.", "tgt_ref": "In unseren Experimenten haben wir festgestellt, dass Transformer-Modelle tendenziell besser auf neue Daten verallgemeinern."}
{"doc_id": "QTlIuodOsA", "seg_id": 17, "src_ref": "The second ingredient is the model size.", "tgt_ref": "Die zweite Komponente ist die Modellgröße."}
{"doc_id": "QTlIuodOsA", "seg_id": 18, "src_ref": "We found that usually larger models lead to better generalization.", "tgt_ref": "Wir haben festgestellt, dass größere Modelle in der Regel zu einer besseren Generalisierung führen."}
{"doc_id": "QTlIuodOsA", "seg_id": 19, "src_ref": "And last but not least, we all know that the number of fine tuning examples directly affects the performance of a downstream task.", "tgt_ref": "Und nicht zuletzt wissen wir alle, dass die Anzahl der Beispiele, die für die Feinjustierung verwendet werden, einen direkten Einfluss auf die Leistung einer nachgeschalteten Aufgabe hat."}
{"doc_id": "QTlIuodOsA", "seg_id": 20, "src_ref": "Here we also found that more fine tuning examples, actually also leads to better generalization.", "tgt_ref": "Auch hier haben wir festgestellt, dass mehr Beispiele für die Feinjustierung tatsächlich zu einer besseren Generalisierung führen."}
{"doc_id": "QTlIuodOsA", "seg_id": 21, "src_ref": "To our next question, what causes the performance drop of some models, We had two hypothesis.", "tgt_ref": "Für unsere nächste Frage nach der Ursache für den Leistungsabfall einiger Modelle hatten wir zwei Hypothesen."}
{"doc_id": "QTlIuodOsA", "seg_id": 22, "src_ref": "The first one is adaptive overfitting, which is overfitting costs by reusing the same test set over and over again and this is usually manifested as the diminishing returns on a new test set.", "tgt_ref": "Die erste ist die adaptive Überanpassung, also eine Überanpassung der Kosten, die durch die wiederholte Verwendung desselben Testsatzes entsteht, was sich in der Regel in einer geringeren Leistung bei einem neuen Testsatz manifestiert."}
{"doc_id": "QTlIuodOsA", "seg_id": 23, "src_ref": "The second hypothesis is temporal drift which is the performance degradation that is caused by the increasing temporal gap between the train and the test data.", "tgt_ref": "Die zweite Hypothese ist die zeitliche Drift, d. h. die Verschlechterung der Leistung, die durch den zunehmenden zeitlichen Abstand zwischen Trainings- und Testdaten verursacht wird."}
{"doc_id": "QTlIuodOsA", "seg_id": 24, "src_ref": "For data overfitting, we saw that from the graph on the right, the red best fit line has a gradient that is greater than one.", "tgt_ref": "Bezüglich der Überanpassung der Daten zeigt das Diagramm rechts, dass die rote Best-Fit-Linie eine Steigung von mehr als eins aufweist."}
{"doc_id": "QTlIuodOsA", "seg_id": 25, "src_ref": "This means that every unit of improvement that we made, on CoNLL-2003 translates to more than one unit improvement on CoNLL++ which means that there is no diminishing returns.", "tgt_ref": "Das bedeutet, dass jede Einheit Verbesserung, die wir in CoNLL-2003 erreicht haben, zu mehr als einer Einheit Verbesserung in CoNLL++ führt, was bedeutet, dass keine sinkenden Erträge bestehen."}
{"doc_id": "QTlIuodOsA", "seg_id": 26, "src_ref": "And this shows us that adaptive overfitting in this case is not observed.", "tgt_ref": "Dies zeigt uns wiederum, dass in diesem Fall keine adaptive Überanpassung beobachtet wird."}
{"doc_id": "QTlIuodOsA", "seg_id": 27, "src_ref": "So what about temporal drift then?", "tgt_ref": "Und was ist mit der zeitlichen Drift?"}
{"doc_id": "QTlIuodOsA", "seg_id": 28, "src_ref": "For temporal drift, we did an experiment to retrain or continue to pre-train some models with more recent data and we found that the performance degrades with larger temporal gap and this confirms our hypothesis that the main cause of the performance drop is temporal drift.", "tgt_ref": "In Bezug auf die zeitliche Drift haben wir ein Experiment durchgeführt, um einige Modelle mit neueren Daten neu bzw. weiter zu trainieren. Dabei haben wir festgestellt, dass die Leistung mit zunehmendem Zeitabstand abnimmt, was unsere Hypothese bestätigt, dass die Hauptursache für den Leistungsabfall die zeitliche Drift ist."}
{"doc_id": "QTlIuodOsA", "seg_id": 29, "src_ref": "Our conclusion is that, for good generalization we would need a better model architecture, larger model size, as well as more fine tuning examples.", "tgt_ref": "Unsere Schlussfolgerung ist, dass wir für eine gute Generalisierung eine bessere Modellarchitektur, eine größere Modellgröße und mehr Feinabstimmungsbeispiele benötigen."}
{"doc_id": "QTlIuodOsA", "seg_id": 30, "src_ref": "And these goes hand in hand, we can't just have one ingredient but throw out the others.", "tgt_ref": "Das geht wohlgemerkt Hand in Hand, wir können nicht nur eine Komponente haben und die anderen wegwerfen."}
{"doc_id": "QTlIuodOsA", "seg_id": 31, "src_ref": "At the same time, we also found that the performance drop here is caused by temporal drift and kind of surprisingly, it is not caused by adaptive overfitting even though CoNLL-2003 has been used for over 20 years.", "tgt_ref": "Gleichzeitig haben wir festgestellt, dass der Leistungsabfall hier durch zeitliche Drift verursacht wird und überraschenderweise nicht durch adaptive Überanpassung, obwohl CoNLL-2003 seit über 20 Jahren im Einsatz ist."}
{"doc_id": "QTlIuodOsA", "seg_id": 32, "src_ref": "So going back to the question that we raised in the title of our paper Do CoNLL-2003 taggers still work in 2023?", "tgt_ref": "Um auf die im Titel unserer Arbeit gestellte Frage zurückzukommen: Werden CoNLL-2003 Tagger im Jahr 2023 noch funktionieren?"}
{"doc_id": "QTlIuodOsA", "seg_id": 33, "src_ref": "And we found that the answer is actually a resounding yes.", "tgt_ref": "Wir haben festgestellt, dass die Antwort eigentlich ein klares Ja ist."}
{"doc_id": "QTlIuodOsA", "seg_id": 34, "src_ref": "We hope our paper calls for more research on how to improve generalizations of the models.", "tgt_ref": "Wir hoffen, dass unser Artikel zu weiterer Forschung dazu anregt, wie die Generalisierung der Modelle verbessert werden kann."}
{"doc_id": "QTlIuodOsA", "seg_id": 35, "src_ref": "And lastly, please make sure to check out our paper, our data set and if you have any questions, feel free to contact me.", "tgt_ref": "Abschließend möchten wir Sie einladen, einen Blick auf unsere Arbeit und unseren Datensatz zu werfen. Wenn Sie Fragen haben, zögern Sie bitte nicht, mich zu kontaktieren."}
{"doc_id": "QTlIuodOsA", "seg_id": 36, "src_ref": "Thank you so much.", "tgt_ref": "Vielen Dank."}
{"doc_id": "yBDqNxQUwV", "seg_id": 0, "src_ref": "Hi!", "tgt_ref": "Hallo!"}
{"doc_id": "yBDqNxQUwV", "seg_id": 1, "src_ref": "I'm going to talk about our work on \"Resolving Indirect Referring Expressions for Entity Selection\", in which we introduce the AltEntities Corpus.", "tgt_ref": "Ich werde über unsere Arbeit „Resolving Indirect Referring Expressions for Entity Selection“ sprechen, in der wir das AltEntities-Korpus vorstellen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 2, "src_ref": "My name is Javad Hosseini and this is a joint work with Filip Radlinski, Silvia Pareti, and Annie Louis.", "tgt_ref": "Mein Name ist Javad Hosseini und diese Zusammenarbeit entstand mit Filip Radlinski, Silvia Pareti und Annie Louis."}
{"doc_id": "yBDqNxQUwV", "seg_id": 3, "src_ref": "Our goal is to understand users’ language when they want to make a choice.", "tgt_ref": "Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 4, "src_ref": "Consider this alternative question.", "tgt_ref": "Betrachten Sie diese Alternativen-Frage."}
{"doc_id": "yBDqNxQUwV", "seg_id": 5, "src_ref": "\"Did you mean 'Easy on Me' or 'I Gotta Feeling'?\"", "tgt_ref": "„Meinten Sie 'Easy on Me' oder 'I Gotta Feeling'?“"}
{"doc_id": "yBDqNxQUwV", "seg_id": 6, "src_ref": "Here, a user wants to select between one of these two songs.", "tgt_ref": "Hier möchte ein Benutzer zwischen diesen beiden Liedern wählen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 7, "src_ref": "The most obvious thing is to use a direct reference, for example by saying the name of the song \"Easy on Me\" or its position, \"the first one\".", "tgt_ref": "Am naheliegendsten ist es, einen direkten Bezug zu verwenden, etwa den Namen des Liedes, „Easy on Me“, oder seine Position, „das erste“."}
{"doc_id": "yBDqNxQUwV", "seg_id": 8, "src_ref": "But sometimes an indirect reference is more appropriate to have a more natural conversation.", "tgt_ref": "Manchmal ist jedoch ein indirekter Bezug besser geeignet, um ein natürlicheres Gespräch zu führen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 9, "src_ref": "This could happen when the user cannot remember the name of the song.", "tgt_ref": "Dies kann der Fall sein, wenn sich der Benutzer nicht an den Namen des Liedes erinnern kann."}
{"doc_id": "yBDqNxQUwV", "seg_id": 10, "src_ref": "Or the pronunciations are too similar to each other and hard to disambiguate.", "tgt_ref": "Oder die Aussprachen sind zu ähnlich und schwer zu unterscheiden."}
{"doc_id": "yBDqNxQUwV", "seg_id": 11, "src_ref": "Or when the user wants to specify a preference.", "tgt_ref": "Oder wenn der Benutzer eine Vorliebe ausdrücken möchte."}
{"doc_id": "yBDqNxQUwV", "seg_id": 12, "src_ref": "Here are some examples of indirect references for example, \"the newer one\" or \"the song that's not energetic.\"", "tgt_ref": "Hier sind einige Beispiele für indirekte Verweise wie „das neueste“ oder „das Lied, das nicht energiegeladen ist“."}
{"doc_id": "yBDqNxQUwV", "seg_id": 13, "src_ref": "This is an important problem in conversational systems and also for benchmarking LLMs' entity understanding.", "tgt_ref": "Dies ist ein wichtiges Problem für Konversationssysteme und auch für das Benchmarking des Entity Understanding von LLMs."}
{"doc_id": "yBDqNxQUwV", "seg_id": 14, "src_ref": "We're not aware of a larger-scale public data set for the task, so we collect one using crowd annotation.", "tgt_ref": "Uns ist kein großer öffentlicher Datensatz für diese Aufgabe bekannt, also sammeln wir selbst einen mit Hilfe von Crowd-Annotation."}
{"doc_id": "yBDqNxQUwV", "seg_id": 15, "src_ref": "Our data set covers three different domains: music, books, and recipes.", "tgt_ref": "Unser Datensatz umfasst drei verschiedene Domains: Musik, Bücher und Rezepte."}
{"doc_id": "yBDqNxQUwV", "seg_id": 16, "src_ref": "Our data set collection methodology emphasizes informality using a cartoon completion setup.", "tgt_ref": "Unsere Methode der Datensammlung betont den informellen Charakter, indem wir einen Cartoon als Ergänzung verwenden."}
{"doc_id": "yBDqNxQUwV", "seg_id": 17, "src_ref": "The cartoon has three speech bubbles.", "tgt_ref": "Der Cartoon besteht aus drei Sprechblasen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 18, "src_ref": "In the first bubble, Bob says, \"Remember that song we were listening to yesterday?\"", "tgt_ref": "In der ersten Sprechblase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“"}
{"doc_id": "yBDqNxQUwV", "seg_id": 19, "src_ref": "And with that, Bob sets the dialogue context.", "tgt_ref": "Damit gibt Bob den Kontext für den Dialog vor."}
{"doc_id": "yBDqNxQUwV", "seg_id": 20, "src_ref": "In the second speech bubble, Alice says, \"Do you mean 'Easy on Me' or 'I Gotta Feeling'?\"", "tgt_ref": "In der zweiten Sprechblase sagt Alice: „Meinst du ‚Easy on Me‘ oder ‚I Gotta Feeling‘?“"}
{"doc_id": "yBDqNxQUwV", "seg_id": 21, "src_ref": "Which is the alternative question.", "tgt_ref": "Das ist die Alternativfrage."}
{"doc_id": "yBDqNxQUwV", "seg_id": 22, "src_ref": "And in the third speech bubble, Bob uses an indirect reference to select one of these entities, for example, \"the newer one.\"", "tgt_ref": "Und in der dritten Sprechblase verwendet Bob einen indirekten Bezug, um eine der Entitäten auszuwählen, zum Beispiel „das neuere“."}
{"doc_id": "yBDqNxQUwV", "seg_id": 23, "src_ref": "We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator.", "tgt_ref": "Die erste und zweite Sprechblase werden von uns automatisch zur Verfügung gestellt, die dritte Sprechblase wird vom Annotator ausgefüllt."}
{"doc_id": "yBDqNxQUwV", "seg_id": 24, "src_ref": "The first speech bubble is chosen from a few manual prompts per domain.", "tgt_ref": "Die erste Sprechblase wird aus einer Anzahl manueller Prompts pro Domain ausgewählt."}
{"doc_id": "yBDqNxQUwV", "seg_id": 25, "src_ref": "The second one, which is the alternative question is generated as follows.", "tgt_ref": "Die zweite Sprechblase, die Alternativfrage, wird wie folgt generiert."}
{"doc_id": "yBDqNxQUwV", "seg_id": 26, "src_ref": "We always use a simple template.", "tgt_ref": "Wir benutzen immer eine einfache Vorlage."}
{"doc_id": "yBDqNxQUwV", "seg_id": 27, "src_ref": "Do you mean A or B?", "tgt_ref": "Meinst du A oder B?"}
{"doc_id": "yBDqNxQUwV", "seg_id": 28, "src_ref": "Where A and B are samples from Wikipedia.", "tgt_ref": "Wobei A und B Beispiele aus Wikipedia sind."}
{"doc_id": "yBDqNxQUwV", "seg_id": 29, "src_ref": "Here are the different sampling methods we've used.", "tgt_ref": "Hier sehen Sie die verschiedenen Stichprobenverfahren, die wir verwendet haben."}
{"doc_id": "yBDqNxQUwV", "seg_id": 30, "src_ref": "When we move higher in the list, the entities become more similar to each other and it's usually harder to make the disambiguation.", "tgt_ref": "Je höher wir in der Liste kommen, desto ähnlicher werden die Begriffe und desto schwieriger wird es, eine eindeutige Antwort zu finden."}
{"doc_id": "yBDqNxQUwV", "seg_id": 31, "src_ref": "The first one is uniform at random.", "tgt_ref": "Die erste ist zufällig gleichverteilt."}
{"doc_id": "yBDqNxQUwV", "seg_id": 32, "src_ref": "The second one is when the entities have similar titles, for example, two books with the name \"The Return\".", "tgt_ref": "Die zweite ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Titel „Die Rückkehr“."}
{"doc_id": "yBDqNxQUwV", "seg_id": 33, "src_ref": "The third one is when they have similar descriptions on Wikipedia.", "tgt_ref": "Die dritte ist, wenn sie ähnliche Beschreibungen in Wikipedia haben."}
{"doc_id": "yBDqNxQUwV", "seg_id": 34, "src_ref": "And finally when they have similar info boxes or attributes on Wikipedia.", "tgt_ref": "Und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben."}
{"doc_id": "yBDqNxQUwV", "seg_id": 35, "src_ref": "For example, the same genre or the same artist for a song.", "tgt_ref": "Zum Beispiel das gleiche Genre oder der gleiche Interpret bei einem Lied."}
{"doc_id": "yBDqNxQUwV", "seg_id": 36, "src_ref": "When we show this alternative question to the annotators, they know the name of these entities, but they don't necessarily know about the entities.", "tgt_ref": "Wenn wir den Annotatoren diese Alternativfrage stellen, kennen sie die Namen dieser Entitäten, aber sie wissen nicht unbedingt etwas von den Entitäten."}
{"doc_id": "yBDqNxQUwV", "seg_id": 37, "src_ref": "So what we do is that we show some background knowledge about the two entities.", "tgt_ref": "Wir zeigen also etwas Hintergrundwissen über die beiden Entitäten."}
{"doc_id": "yBDqNxQUwV", "seg_id": 38, "src_ref": "For songs, we simply show a Google search link to each song and then ask the annotators to listen to at least some of each song, and read about each song.", "tgt_ref": "Bei den Songs zeigen wir einfach einen Google-Suchlink zu jedem Song und bitten die Annotatoren, sich zumindest einen Teil des Lieds anzuhören und etwas über das Lied zu lesen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 39, "src_ref": "Here's for example, the Google search result for the song \"Easy on Me.\"", "tgt_ref": "Hier ist zum Beispiel das Google-Suchergebnis für das Lied „Easy on Me“."}
{"doc_id": "yBDqNxQUwV", "seg_id": 40, "src_ref": "For the recipes and books domain, we show some background text from Wikipedia.", "tgt_ref": "Bei den Domains Rezepte und Bücher zeigen wir einige Hintergrundtexte aus Wikipedia."}
{"doc_id": "yBDqNxQUwV", "seg_id": 41, "src_ref": "For recipes, we additionally show their images, again from Wikipedia, so that the annotators know how they look like.", "tgt_ref": "Bei den Rezepten zeigen wir auch Bilder, ebenfalls aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 42, "src_ref": "Then, we asked the annotators to pick one of these entities, for example, here's the first one, and describe them using three to five indirect referring expressions.", "tgt_ref": "Dann haben wir die Annotatoren gebeten, eine dieser Entitäten auszuwählen, zum Beispiel hier ist die erste, und sie mit drei bis fünf indirekten Bezugsausdrücken zu beschreiben."}
{"doc_id": "yBDqNxQUwV", "seg_id": 43, "src_ref": "For example, the one with the piano music.", "tgt_ref": "Zum Beispiel „das Lied mit Klaviermusik“."}
{"doc_id": "yBDqNxQUwV", "seg_id": 44, "src_ref": "Here are some examples from our dataset.", "tgt_ref": "Hier sind einige Beispiele aus unserem Datensatz."}
{"doc_id": "yBDqNxQUwV", "seg_id": 45, "src_ref": "For example, \"the one without words\", \"not the one with the 12 year old boy\", or \"the fictional one\", or \"comes from Azerbaijan\", and so on.", "tgt_ref": "Zum Beispiel „das ohne Worte“, „nicht das mit dem 12-jährigen Jungen“, oder „das fiktive“, oder „kommt aus Aserbaidschan“, und so weiter."}
{"doc_id": "yBDqNxQUwV", "seg_id": 46, "src_ref": "The AltEntities Corpus has 6,000 alternative questions across three domains, and it has 42,000 indirect referring expressions.", "tgt_ref": "Das AltEntities-Korpus enthält 6.000 Alternativfragen aus drei Domains und 42.000 indirekt verweisende Ausdrücke."}
{"doc_id": "yBDqNxQUwV", "seg_id": 47, "src_ref": "Results with T5 XL model are summarized below.", "tgt_ref": "Die Ergebnisse mit dem T5 XL Modell sind unten zusammengefasst."}
{"doc_id": "yBDqNxQUwV", "seg_id": 48, "src_ref": "If the language model has access to the exact same background knowledge as the annotators, then the accuracy is really high, it's around 92 to 95%.", "tgt_ref": "Wenn das Sprachmodell Zugriff auf genau dasselbe Hintergrundwissen hat wie die Annotatoren, dann ist die Genauigkeit wirklich hoch, sie liegt zwischen 92 und 95 %."}
{"doc_id": "yBDqNxQUwV", "seg_id": 49, "src_ref": "But this is not realistic.", "tgt_ref": "Dies ist jedoch nicht realistisch."}
{"doc_id": "yBDqNxQUwV", "seg_id": 50, "src_ref": "If the language model has access to some partially overlapping background knowledge, then the accuracy is between 82 to 87%, which is more realistic.", "tgt_ref": "Wenn das Sprachmodell Zugang zu Hintergrundwissen hat, das sich teilweise überschneidet, liegt die Genauigkeit zwischen 82 und 87 %, was realistischer ist."}
{"doc_id": "yBDqNxQUwV", "seg_id": 51, "src_ref": "For example, when the language model retrieves the background knowledge.", "tgt_ref": "Zum Beispiel, wenn das Sprachmodell auf Hintergrundwissen zurückgreift."}
{"doc_id": "yBDqNxQUwV", "seg_id": 52, "src_ref": "If the language model has access only to entity names, then the accuracy is only 60%, so there's a lot of room for improvement.", "tgt_ref": "Wenn das Sprachmodell nur auf die Namen der Entitäten zugreift, liegt die Genauigkeit nur bei 60 %, es gibt also noch viel Raum für Verbesserungen."}
{"doc_id": "yBDqNxQUwV", "seg_id": 53, "src_ref": "We've also shown that the models are domain-generalizable.", "tgt_ref": "Wir haben auch gezeigt, dass die Modelle auf verschiedene Domains verallgemeinert werden können."}
{"doc_id": "yBDqNxQUwV", "seg_id": 54, "src_ref": "Here is a link to our dataset.", "tgt_ref": "Hier ist ein Link zu unserem Datensatz."}
{"doc_id": "yBDqNxQUwV", "seg_id": 55, "src_ref": "Thanks.", "tgt_ref": "Vielen Dank."}
{"doc_id": "PJWMkwXVGI", "seg_id": 0, "src_ref": "Hi, I'm Sara Papi from the University of Trento and Foundazione Bruno Kessler and I will briefly introduce the \"Attention as a Guide for Simultaneous Speech Translation\" paper, that is a joint work with Matteo Negri and Marco Turchi.", "tgt_ref": "Hallo, ich bin Sara Papi von der Universität Trento und der Foundazione Bruno Kessler. Ich werde kurz den Artikel „Attention as a Guide for Simultaneous Speech Translation“ vorstellen, den ich zusammen mit Matteo Negri und Marco Turchi verfasst habe."}
{"doc_id": "PJWMkwXVGI", "seg_id": 1, "src_ref": "What is simultaneous speech translation?", "tgt_ref": "Was ist Simultanübersetzung?"}
{"doc_id": "PJWMkwXVGI", "seg_id": 2, "src_ref": "Simultaneous speech translation, or SimulST, is the process of translating spoken language into a text in another language in real time, enabling cross-language communication.", "tgt_ref": "Simultanübersetzung oder SimulST ist der Prozess, bei dem gesprochene Sprache in Echtzeit in einen Text in einer anderen Sprache übersetzt wird, um eine interlinguale Kommunikation zu ermöglichen."}
{"doc_id": "PJWMkwXVGI", "seg_id": 3, "src_ref": "And what are the problems of the current SimulST models?", "tgt_ref": "Und wo liegen die Probleme der aktuellen SimulST-Modelle?"}
{"doc_id": "PJWMkwXVGI", "seg_id": 4, "src_ref": "Specific architectures are usually trained, introducing additional modules to be optimized.", "tgt_ref": "In der Regel werden bestimmte Architekturen durch die Einführung zusätzlicher Module, die optimiert werden müssen, trainiert."}
{"doc_id": "PJWMkwXVGI", "seg_id": 5, "src_ref": "Long and complicated training procedures, for example, training involving different optimization objectives.", "tgt_ref": "Lange und komplizierte Trainingsverfahren, z. B. Training mit verschiedenen Optimierungszielen."}
{"doc_id": "PJWMkwXVGI", "seg_id": 6, "src_ref": "And training and maintaining several models to reach different latency regimes.", "tgt_ref": "Und Training und Wartung mehrerer Modelle, um verschiedene Latenzzeiten zu erreichen."}
{"doc_id": "PJWMkwXVGI", "seg_id": 7, "src_ref": "For example, training a model with an average of one second latency and another one with two seconds latency, and so on.", "tgt_ref": "Beispielsweise kann ein Modell mit einer durchschnittlichen Latenz von einer Sekunde, ein anderes mit einer Latenz von zwei Sekunden usw. trainiert werden."}
{"doc_id": "PJWMkwXVGI", "seg_id": 8, "src_ref": "So what is our solution?", "tgt_ref": "Was ist also unsere Lösung?"}
{"doc_id": "PJWMkwXVGI", "seg_id": 9, "src_ref": "First, to use already existing offline ST models without re-training or adopting specific architecture for SimulST.", "tgt_ref": "Zunächst einmal verwenden wir bestehende Offline-ST-Modelle, ohne sie neu zu trainieren oder eine spezielle Architektur für SimulST einzuführen."}
{"doc_id": "PJWMkwXVGI", "seg_id": 10, "src_ref": "Use only one model for every latency regime and handle latency through specific parameters.", "tgt_ref": "Wir verwenden nur ein Modell für jede Latenzzeit und adressieren die Latenzzeit mit spezifischen Parametern."}
{"doc_id": "PJWMkwXVGI", "seg_id": 11, "src_ref": "And leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output.", "tgt_ref": "Außerdem nutzen wir das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und Textausgabe erworben hat."}
{"doc_id": "PJWMkwXVGI", "seg_id": 12, "src_ref": "That is the cross-attention mechanism, and you can see an example on the right.", "tgt_ref": "Dies ist der Cross-Attention-Mechanismus, und rechts sehen Sie ein Beispiel."}
{"doc_id": "PJWMkwXVGI", "seg_id": 13, "src_ref": "Our solution is to propose EDAtt, or Encoder-Decoder Attention, and it is a strategy for which we decide whether to emit or not a partial translation, based on where attention points to.", "tgt_ref": "Unsere Lösung heißt EDAtt, Encoder-Decoder Attention, und ist eine Strategie, bei der wir entscheiden, ob wir eine Teilübersetzung ausgeben oder nicht, je nachdem, wohin die Aufmerksamkeit gerichtet ist."}
{"doc_id": "PJWMkwXVGI", "seg_id": 14, "src_ref": "A word is emitted if the attention is not concentrated, that is, its sum is below a certain threshold alpha towards the last lambda speech frames, meaning that the received information is enough stable.", "tgt_ref": "Ein Wort wird ausgegeben, wenn die Aufmerksamkeit nicht fokussiert ist, das heißt wenn seine Summe unter einem bestimmten Alpha-Schwellenwert zu den letzten Lambda-Sprachrahmen liegt, was bedeutet, dass die empfangene Information ausreichend stabil ist."}
{"doc_id": "PJWMkwXVGI", "seg_id": 15, "src_ref": "For example, if we receive a speech chunk containing \"I'm going to talk about...\" and our model predicts the translation in German, and we will look at the cross-attention weights, we'll see that the first two words points to the earliest received speech frames, while the last word points to the last received speech frames, as lambda speech frames.", "tgt_ref": "Wenn wir z. B. ein Sprachfragment erhalten, das „I'm going to talk about …“ enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt, und wir die Cross-Attention-Gewichte betrachten, sehen wir, dass die ersten beiden Wörter auf die ersten empfangenen Sprachrahmen verweisen, während das letzte Wort auf die letzten empfangenen Sprachrahmen als Lambda-Sprachrahmen verweist."}
{"doc_id": "PJWMkwXVGI", "seg_id": 16, "src_ref": "This means that the first two words will be emitted while since the sum of the cross-attention is above a certain threshold alpha, we will not emit the last word and we wait for another speech chunk.", "tgt_ref": "Das bedeutet, dass die ersten beiden Wörter ausgegeben werden, aber da die Summe der Cross-Attention-Gewichte über einem bestimmten Alpha-Schwellenwert liegt, wird das letzte Wort nicht ausgegeben und wir warten auf ein weiteres Sprachfragment."}
{"doc_id": "PJWMkwXVGI", "seg_id": 17, "src_ref": "If we go on and we receive another speech chunk, and our model predicts other three words and we will look at those cross-attention weights, we will see that no word points to the last lambda speech frames.", "tgt_ref": "Wenn wir fortfahren und ein weiteres Sprachpaket erhalten und unser Modell drei weitere Wörter vorhersagt und wir uns diese Cross-Attention-Gewichte ansehen, werden wir feststellen, dass keines der Wörter auf die letzten Lambda-Sprachframes verweist."}
{"doc_id": "PJWMkwXVGI", "seg_id": 18, "src_ref": "This means that these three words will be emitted.", "tgt_ref": "Das bedeutet, dass diese drei Wörter ausgesprochen werden."}
{"doc_id": "PJWMkwXVGI", "seg_id": 19, "src_ref": "If we look at the main results of EDAtt, we'll plot the simultaneous speech translation results on graphs in which we have BLEU on one side that measures the translation quality, and average lagging that is the latency measure, and we also consider the computational aware average lagging that accounts for the model's computational times to predict the output.", "tgt_ref": "Wenn wir uns die wichtigsten Ergebnisse von EDAtt ansehen, stellen wir die Ergebnisse der simultanen Sprachübersetzung in Diagrammen dar. Auf der einen Seite haben wir den BLEU, der die Qualität der Übersetzung misst, und die durchschnittliche Verzögerung, die ein Maß für die Latenz ist, und wir berücksichtigen auch die berechnete durchschnittliche Verzögerung, die die Rechenzeit des Modells für die Vorhersage der Ausgabe berücksichtigt."}
{"doc_id": "PJWMkwXVGI", "seg_id": 20, "src_ref": "So we want our curves to be as high as possible on this plot.", "tgt_ref": "Wir wollen also, dass unsere Kurven in diesem Diagramm so hoch wie möglich liegen."}
{"doc_id": "PJWMkwXVGI", "seg_id": 21, "src_ref": "But also we want that they are shifted on the left.", "tgt_ref": "Wir wollen sie aber auch nach links verschieben."}
{"doc_id": "PJWMkwXVGI", "seg_id": 22, "src_ref": "And we compare with popular strategies that are also applied to offline models that are the Wait-k strategy and the Local Agreement.", "tgt_ref": "Und wir vergleichen sie mit beliebten Strategien, die auch in Offline-Modellen verwendet werden, nämlich der Wait-k-Strategie und der lokalen Übereinstimmung."}
{"doc_id": "PJWMkwXVGI", "seg_id": 23, "src_ref": "And we compare also with the state-of-the-art architecture specifically tailored for simultaneous pre-translation.", "tgt_ref": "Und wir vergleichen sie auch mit dem Stand der Technik der Architektur, die speziell für die simultane Vorübersetzung entwickelt wurde."}
{"doc_id": "PJWMkwXVGI", "seg_id": 24, "src_ref": "These are all the results of the simultaneous speech translation strategy on German.", "tgt_ref": "Das sind die Ergebnisse der Simultanübersetzungsstrategie für Deutsch."}
{"doc_id": "PJWMkwXVGI", "seg_id": 25, "src_ref": "And we see that it outperforms all the strategies applied to offline models since the curves are shifted over the left.", "tgt_ref": "Wir sehen, dass sie alle Strategien für Offline-Modelle übertrifft, weil die Kurven nach links verschoben sind."}
{"doc_id": "PJWMkwXVGI", "seg_id": 26, "src_ref": "And we also see that if we consider the actual elapsed time or the computational-aware time, that is the fastest strategy.", "tgt_ref": "Und wir sehen auch, dass es die schnellste Strategie ist, egal ob wir die tatsächlich benötigte Zeit oder die Rechenzeit betrachten."}
{"doc_id": "PJWMkwXVGI", "seg_id": 27, "src_ref": "If you want to discover more results, read our paper.", "tgt_ref": "Wenn Sie mehr über die Ergebnisse erfahren möchten, lesen Sie unsere Arbeit."}
{"doc_id": "PJWMkwXVGI", "seg_id": 28, "src_ref": "And we also released open source the code and models and simultaneous output to facilitate the reproducibility of our work.", "tgt_ref": "Wir haben auch den Code und die Modelle sowie die simultane Ausgabe Open Source veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern."}
{"doc_id": "PJWMkwXVGI", "seg_id": 29, "src_ref": "Thanks for your attention.", "tgt_ref": "Vielen Dank für Ihre Aufmerksamkeit."}
{"doc_id": "vrydRuOXbT", "seg_id": 0, "src_ref": "Hello everyone, my name is Ying and my colleague Zhiyang and I will be presenting our research on MultiInstruct improving Multi-Modal Zero-Shot Learning via Instruction Tuning.", "tgt_ref": "Hallo zusammen, mein Name ist Ying und mein Kollege Zhiyang und ich werden unsere Forschung zu MultiInstruct vorstellen, die das multimodale Zero-Shot-Lernen durch anweisungsbasierte Abstimmung verbessert."}
{"doc_id": "vrydRuOXbT", "seg_id": 1, "src_ref": "So with the advances in large language models, many works started to explore new learning paradigms of reusing pre-trained language models for different downstream tasks in a parameter and data-efficient way.", "tgt_ref": "Mit den Fortschritten bei Large Language Models haben viele Arbeiten begonnen, neue Lernparadigmen zu erforschen, um vortrainierte Sprachmodelle für verschiedene nachgelagerte Aufgaben in einer parameter- und datensparenden Weise wiederzuverwenden."}
{"doc_id": "vrydRuOXbT", "seg_id": 2, "src_ref": "Recently, many studies have shown that instruction tuning enables large language models to perform on unseen tasks in a zero-shot manner by following natural instructions.", "tgt_ref": "In jüngster Zeit haben viele Studien gezeigt, dass Large Language Models durch die Anweisungsabstimmung in der Lage sind, unbekannte Aufgaben in kürzester Zeit zu bewältigen, indem sie natürliche Anweisungen befolgen."}
{"doc_id": "vrydRuOXbT", "seg_id": 3, "src_ref": "However, most previous works on instruction tuning focused on improving the zero-shot performance on language only tasks, while computer vision and multi-modal tasks have been left out.", "tgt_ref": "Die meisten bisherigen Arbeiten zur Anweisungsabstimmung haben sich jedoch auf die Verbesserung der Zero-Shot-Leistung bei rein sprachlichen Aufgaben konzentriert und Computer Vision und multimodale Aufgaben außer Acht gelassen."}
{"doc_id": "vrydRuOXbT", "seg_id": 4, "src_ref": "Therefore, in this work we want to investigate whether instruction tuning a multi-modal pre-trained models can actually improve generalisation to unseen multi-modal tasks.", "tgt_ref": "Daher wollen wir in dieser Arbeit untersuchen, ob die Anweisungsabstimmung eines vortrainierten multimodalen Modells tatsächlich die Generalisierung auf ungesehene multimodale Aufgaben verbessern kann."}
{"doc_id": "vrydRuOXbT", "seg_id": 5, "src_ref": "Additionally, at the time of our research, we discovered a considerable discrepancy in the availability of instructional datasets between NLP and multi-modal.", "tgt_ref": "Darüber hinaus haben wir zum Zeitpunkt unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit von Anweisungsdatensätzen zwischen NLP und Multimodal festgestellt."}
{"doc_id": "vrydRuOXbT", "seg_id": 6, "src_ref": "There exist more than 1600 language-only instruction tasks.", "tgt_ref": "Es gibt mehr als 1600 reine Sprachanweisungsaufgaben."}
{"doc_id": "vrydRuOXbT", "seg_id": 7, "src_ref": "However, there is no large-scale publicly-available multi-modal instruction task.", "tgt_ref": "Es gibt jedoch keine großen multimodalen Anweisungsaufgaben, die öffentlich verfügbar sind."}
{"doc_id": "vrydRuOXbT", "seg_id": 8, "src_ref": "Therefore, this motivates us to build a multi-modal instruction tuning dataset.", "tgt_ref": "Dies hat uns motiviert, einen Datensatz mit multimodaler Anweisungsabstimmung zu erstellen."}
{"doc_id": "vrydRuOXbT", "seg_id": 9, "src_ref": "Here we present MultiInstruct, the first multi-modal instruction tuning benchmark dataset that consists of 62 diverse multi-modal tasks covering 10 broad categories.", "tgt_ref": "Wir stellen hier MultiInstruct vor, den ersten multimodalen Benchmark-Datensatz für die Anweisungsabstimmung, der aus 62 verschiedenen multimodalen Aufgaben aus 10 verschiedenen Kategorien besteht."}
{"doc_id": "vrydRuOXbT", "seg_id": 10, "src_ref": "These tasks are derived from 21 existing open-source dataset and each task is equipped with five expert written instructions.", "tgt_ref": "Diese Aufgaben stammen aus 21 bestehenden Open-Source-Datensätzen und jede Aufgabe ist mit fünf von Experten geschriebenen Anweisungen versehen."}
{"doc_id": "vrydRuOXbT", "seg_id": 11, "src_ref": "For investigating multi-modal instruction tuning on our proposed dataset, we take OFA, a unified multi-modal pre-trained model, as our base model.", "tgt_ref": "Um die multimodale Anweisungsabstimmung in unserem vorgeschlagenen Datensatz zu untersuchen, verwenden wir OFA, ein einheitliches multimodales vortrainiertes Modell, als Basismodell."}
{"doc_id": "vrydRuOXbT", "seg_id": 12, "src_ref": "OFA uses a unified vocabulary for language, image tokens and the coordinates of a bounding box.", "tgt_ref": "OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und Bounding-Box-Koordinaten."}
{"doc_id": "vrydRuOXbT", "seg_id": 13, "src_ref": "Here we show some example instances from our MultiInstruct dataset, to unify the processing of various input and output data types.", "tgt_ref": "Hier zeigen wir einige Beispielinstanzen aus unserem MultiInstruct-Datensatz, um die Verarbeitung verschiedener Eingabe- und Ausgabedatentypen zu vereinheitlichen."}
{"doc_id": "vrydRuOXbT", "seg_id": 14, "src_ref": "We follow the method from OFA and formulate all the tasks in a unified sequence-to-sequence format.", "tgt_ref": "Wir folgen der OFA-Methode und formulieren alle Aufgaben in einem einheitlichen Sequence-to-Sequence-Format,"}
{"doc_id": "vrydRuOXbT", "seg_id": 15, "src_ref": "In which the input text, images, instructions and bounding boxes are represented in the same token space.", "tgt_ref": "in dem Eingabetext, Bilder, Anweisungen und Bounding-Boxes im gleichen Tokenraum dargestellt werden."}
{"doc_id": "vrydRuOXbT", "seg_id": 16, "src_ref": "Ok, now I'm going to talk about multi-modal instruction tuning.", "tgt_ref": "Ok, jetzt werde ich über die multimodale anweisungsbasierte Abstimmung sprechen."}
{"doc_id": "vrydRuOXbT", "seg_id": 17, "src_ref": "So for the training dataset, we use 53 tasks from 9 groups for training and we sample 10,000 instances per task.", "tgt_ref": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus 9 Gruppen für das Training und 10.000 Instanzen pro Aufgabe."}
{"doc_id": "vrydRuOXbT", "seg_id": 18, "src_ref": "For testing, we reserve the entire common sense reasoning group for testing, and we select additional 5 tasks from VQ and Miscellaneous groups.", "tgt_ref": "Für den Test reservieren wir die gesamte Gruppe Common Sense Reasoning und wählen zusätzlich 5 Aufgaben aus den Gruppen VQ und Miscellaneous aus."}
{"doc_id": "vrydRuOXbT", "seg_id": 19, "src_ref": "We use all the instances in the test split for each task.", "tgt_ref": "Für jede Aufgabe werden alle Instanzen der Testgruppe verwendet."}
{"doc_id": "vrydRuOXbT", "seg_id": 20, "src_ref": "In addition, we randomly sample 20 tasks from the test split of natural instructions as an unseen task for NLP.", "tgt_ref": "Zusätzlich wählen wir zufällig 20 Aufgaben aus der Testgruppe Natürliche Anweisungen als ungesehene Aufgaben für NLP aus."}
{"doc_id": "vrydRuOXbT", "seg_id": 21, "src_ref": "So we use pre-trained OFA large model as a base model.", "tgt_ref": "Wir verwenden also das vortrainierte große OFA-Modell als Basismodell."}
{"doc_id": "vrydRuOXbT", "seg_id": 22, "src_ref": "During training, we mix all the instances for all the tasks.", "tgt_ref": "Während des Trainings mischen wir alle Instanzen für alle Aufgaben."}
{"doc_id": "vrydRuOXbT", "seg_id": 23, "src_ref": "Each instance is randomly combined with one of its five instruction templates.", "tgt_ref": "Jede Instanz wird zufällig mit einer der fünf Anweisungsvorlagen kombiniert."}
{"doc_id": "vrydRuOXbT", "seg_id": 24, "src_ref": "So during test for each task, we conduct a total of 5 experiments by evaluating the model using one of the five instructions.", "tgt_ref": "Beim Testen führen wir insgesamt 5 Experimente für jede Aufgabe durch und evaluieren das Modell mit einer der fünf Anweisungsvorlagen."}
{"doc_id": "vrydRuOXbT", "seg_id": 25, "src_ref": "In each experiment, we report the min and max performance and the standard deviation of the performance across all 5 experiments.", "tgt_ref": "Für jedes Experiment geben wir die minimale und maximale Leistung sowie die Standardabweichung der Leistung über alle 5 Experimente an."}
{"doc_id": "vrydRuOXbT", "seg_id": 26, "src_ref": "If the task is a multi-model classification task, we report accuracy.", "tgt_ref": "Handelt es sich bei der Aufgabe um eine multimodale Klassifikationsaufgabe, geben wir die Genauigkeit an."}
{"doc_id": "vrydRuOXbT", "seg_id": 27, "src_ref": "If it's a multi-modal generation task, we report Rouge-L. For NLP task, we report Rouge-L as well.", "tgt_ref": "Wenn es sich um eine multimodale Generierungsaufgabe handelt, geben wir Rouge-L an. Für die NLP-Aufgabe geben wir ebenfalls Rouge-L an."}
{"doc_id": "vrydRuOXbT", "seg_id": 28, "src_ref": "We also introduce an additional evaluation metric called sensitivity.", "tgt_ref": "Wir führen auch eine zusätzliche Metrik ein, die Sensitivität genannt wird."}
{"doc_id": "vrydRuOXbT", "seg_id": 29, "src_ref": "So this measures the model's ability to consistently produce the same outputs for the same task regardless of the slight variation in the wording of the instruction.", "tgt_ref": "Diese misst die Fähigkeit des Modells, konsistent die gleichen Ergebnisse für die gleiche Aufgabe zu liefern, unabhängig von kleinen Unterschieden in der Formulierung der Anweisungen."}
{"doc_id": "vrydRuOXbT", "seg_id": 30, "src_ref": "Here is our main result.", "tgt_ref": "Dies ist unser Hauptergebnis."}
{"doc_id": "vrydRuOXbT", "seg_id": 31, "src_ref": "As we can see, instruction tuning can significantly improve OFA's performance on seen multi-modal tasks.", "tgt_ref": "Wie wir sehen, kann die Anweisungsabstimmung die Leistung der OFA bei visuellen multimodalen Aufgaben deutlich verbessern."}
{"doc_id": "vrydRuOXbT", "seg_id": 32, "src_ref": "Also, transfer learning from natural instruction dataset can benefit instruction tuning.", "tgt_ref": "Die Anweisungsabstimmung kann auch vom Transferlernen aus dem Datensatz der natürlichen Anweisungen profitieren."}
{"doc_id": "vrydRuOXbT", "seg_id": 33, "src_ref": "Here we can see, as the amount of task increases, the model achieves better performance and in the meantime, lower sensitivity.", "tgt_ref": "Hier sehen wir, dass das Modell mit zunehmender Anzahl von Aufgaben eine bessere Leistung bei gleichzeitig geringerer Sensitivität erreicht."}
{"doc_id": "vrydRuOXbT", "seg_id": 34, "src_ref": "So we also did one experiment.", "tgt_ref": "Deshalb haben wir auch ein Experiment durchgeführt."}
{"doc_id": "vrydRuOXbT", "seg_id": 35, "src_ref": "We use one instruction versus 5 instruction.", "tgt_ref": "Wir verwenden eine Anweisung im Vergleich zu 5 Anweisungen."}
{"doc_id": "vrydRuOXbT", "seg_id": 36, "src_ref": "As we can see, using more instructions can improve the model's overall performance and reduce its sensitivity a lot.", "tgt_ref": "Wie zu sehen ist, kann die Verwendung von mehr Anweisungen die Gesamtleistung des Modells verbessern und seine Sensitivität deutlich verringern."}
{"doc_id": "vrydRuOXbT", "seg_id": 37, "src_ref": "So this shows the effect of different fine-tuning strategies on the model sensitivity.", "tgt_ref": "Dies zeigt die Auswirkung verschiedener Tuning-Strategien auf die Empfindlichkeit des Modells."}
{"doc_id": "vrydRuOXbT", "seg_id": 38, "src_ref": "As we can see by transfer learning from natural instruction datasets, the model can achieve much better sensitivity compared to the original OFA model.", "tgt_ref": "Wie wir sehen können, kann das Modell durch Transferlernen aus natürlichen Anweisungsdatensätzen eine viel bessere Empfindlichkeit im Vergleich zum ursprünglichen OFA-Modell erreichen."}
{"doc_id": "vrydRuOXbT", "seg_id": 39, "src_ref": "We also can see transfer learning from natural instruction datasets can help OFA to attain much better performance on the natural instruct dataset.", "tgt_ref": "Wir können auch sehen, dass Transfer-Lernen aus natürlichen Anweisungsdatensätzen OFA dabei helfen kann, eine viel bessere Leistung auf dem natürlichen Anweisungsdatensatz zu erreichen."}
{"doc_id": "vrydRuOXbT", "seg_id": 40, "src_ref": "So overall, we propose the first large scale multi-model instruction tuning dataset with significantly improved their short capability of OFA, and we explore different transfer learning technique and show their benefits.", "tgt_ref": "Zusammenfassend stellen wir den ersten großen Multi-Modell-Datensatz für die Anweisungsabstimmung vor, der die kurzen Fähigkeiten von OFA signifikant verbessert, und wir untersuchen verschiedene Transfer-Learning-Techniken und zeigen deren Vorteile auf."}
{"doc_id": "vrydRuOXbT", "seg_id": 41, "src_ref": "We design a new metric called sensitivity.", "tgt_ref": "Wir entwickeln eine neue Metrik, die Sensitivität."}
{"doc_id": "vrydRuOXbT", "seg_id": 42, "src_ref": "So one more thing, we are collecting a much larger multi-model instruction tuning dataset with around 150 additional vision language tasks and we will release them.", "tgt_ref": "Und noch etwas: Wir sind gerade dabei, einen viel größeren multimodalen Anweisungsdatensatz mit etwa 150 zusätzlichen Bildverarbeitungsaufgaben zu erstellen und anschließend zu veröffentlichen."}
{"doc_id": "vrydRuOXbT", "seg_id": 43, "src_ref": "So this is a QR code for our data and model.", "tgt_ref": "Das ist der QR-Code für unsere Daten und unser Modell."}
{"doc_id": "vrydRuOXbT", "seg_id": 44, "src_ref": "Thank you.", "tgt_ref": "Vielen Dank."}
{"doc_id": "gUAIqKCjIt", "seg_id": 0, "src_ref": "Hi, everyone.", "tgt_ref": "Hallo zusammen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 1, "src_ref": "I'm Koustav Sinha, and I'm pleased to welcome you to our talk of our ACL 2023 paper.", "tgt_ref": "Mein Name ist Koustav Sinha und ich freue mich, Sie zu unserer Präsentation unserer Arbeit für die ACL 2023 begrüßen zu dürfen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 2, "src_ref": "Language model acceptability judgments are not always robust to context.", "tgt_ref": "Die Bewertung der Akzeptanz von Sprachmodellen ist nicht immer kontextabhängig."}
{"doc_id": "gUAIqKCjIt", "seg_id": 3, "src_ref": "This is a joint work with John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy, and Adina Williams.", "tgt_ref": "Dies ist eine gemeinsame Arbeit mit John Gauthier, Aaron Mueller, Kanishka Misra, Karen Fences, Roger Levy und Adina Williams."}
{"doc_id": "gUAIqKCjIt", "seg_id": 4, "src_ref": "So in this work, we revisit the minimal pair paradigms.", "tgt_ref": "In dieser Arbeit greifen wir auf das Minimal-Pair-Paradigma zurück."}
{"doc_id": "gUAIqKCjIt", "seg_id": 5, "src_ref": "So the minimal pair paradigm basically evaluates language models on top of acceptability judgments.", "tgt_ref": "Das Minimal-Pair-Paradigma bewertet Sprachmodelle im Wesentlichen auf der Basis von Akzeptanzurteilen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 6, "src_ref": "Which can also include grammaticality like BLiMP, SyntaxGym, or acceptability in terms of stereotypes such as CrowS pairs.", "tgt_ref": "Dies kann Grammatikalität wie BLiMP, SyntaxGym oder die Akzeptanz von Stereotypen wie CrowS-Paare betreffen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 7, "src_ref": "And in this, minimal pair paradigm, the typical way to evaluate language models is that you show like an acceptable sentence or a grammatical sentence and then you show an acceptable sentence or an ungrammatical sentence.", "tgt_ref": "Und in diesem Paradigma der minimalen Paare besteht die typische Art und Weise, Sprachmodelle zu evaluieren, darin, einen akzeptablen Satz oder einen grammatikalischen Satz und dann einen akzeptablen Satz oder einen nicht grammatikalischen Satz zu zeigen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 8, "src_ref": "And then the hope is that the model, basically, puts more probability to the acceptable sentence.", "tgt_ref": "Dann hofft man, dass das Modell dem akzeptablen Satz eine höhere Wahrscheinlichkeit einräumt."}
{"doc_id": "gUAIqKCjIt", "seg_id": 9, "src_ref": "The current MPP pipeline basically doesn't allow us to evaluate a model's acceptance towards longer sentences.", "tgt_ref": "Die aktuelle MPP-Pipeline erlaubt es uns im Grunde nicht, die Akzeptanz eines Modells für längere Sätze zu bewerten."}
{"doc_id": "gUAIqKCjIt", "seg_id": 10, "src_ref": "These days large language models are coming up with longer and longer context windows.", "tgt_ref": "Heutzutage haben große Sprachmodelle immer längere Kontextfenster."}
{"doc_id": "gUAIqKCjIt", "seg_id": 11, "src_ref": "So it's crucial that we evaluate the models' acceptability throughout the context window and that is what we are trying to do here.", "tgt_ref": "Daher ist es wichtig, die Akzeptanz der Modelle über das gesamte Kontextfenster zu bewerten, und genau das versuchen wir hier."}
{"doc_id": "gUAIqKCjIt", "seg_id": 12, "src_ref": "We're trying to revisit the MPP pipeline by asking the model to evaluate acceptability on longer and longer sequences.", "tgt_ref": "Wir versuchen, die MPP-Pipeline zu überdenken, indem wir das Modell auffordern, die Akzeptanz in immer längeren Sequenzen zu bewerten."}
{"doc_id": "gUAIqKCjIt", "seg_id": 13, "src_ref": "So that is the approach.", "tgt_ref": "Das ist also der Ansatz."}
{"doc_id": "gUAIqKCjIt", "seg_id": 14, "src_ref": "So what we do is that to simulate these longer sequences, we revisit the data sets themselves and then we recreate sentences by choosing acceptable or unacceptable sentences from those datasets.", "tgt_ref": "Um diese längeren Sequenzen zu simulieren, verwenden wir die Datensätze selbst und erstellen dann Sätze, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 15, "src_ref": "So for example, here we have chosen like a typical pair of grammaticality from the BLiMP data set from the Adjunct Island case.", "tgt_ref": "Hier haben wir zum Beispiel ein typisches Grammatikalitätspaar aus dem BLiMP-Datensatz für den Fall Adjunct Island ausgewählt."}
{"doc_id": "gUAIqKCjIt", "seg_id": 16, "src_ref": "And what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure.", "tgt_ref": "Und wir reproduzieren längere Sequenzen, die akzeptabel sind und die gleiche grammatikalische Struktur aufweisen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 17, "src_ref": "We extract grammatical sentences from Adjunct Island and then we add it as a prefix to both the acceptable query and the unacceptable query.", "tgt_ref": "Wir extrahieren grammatikalische Sätze aus Adjunct Island und fügen sie als Präfix sowohl der akzeptablen als auch der inakzeptablen Abfrage hinzu."}
{"doc_id": "gUAIqKCjIt", "seg_id": 18, "src_ref": "So we can do the same thing by choosing unacceptable sentences from the same matching, and that could also be used to test the models acceptability.", "tgt_ref": "Wir können dasselbe tun, indem wir inakzeptable Sätze aus der gleichen Konkordanz auswählen, und dies könnte auch verwendet werden, um die Akzeptanz der Modelle zu testen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 19, "src_ref": "And we can also do the same by choosing sentences from a different subset or a different data set.", "tgt_ref": "Und wir können dasselbe tun, indem wir Sätze aus einer anderen Teilmenge oder einem anderen Datensatz auswählen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 20, "src_ref": "So that is what we call as the mismatch scenario.", "tgt_ref": "Dies wird als Mismatch-Szenario bezeichnet."}
{"doc_id": "gUAIqKCjIt", "seg_id": 21, "src_ref": "So here the sentences are still coming from a, relevant data sets but it's not from the same data set that you are evaluating with.", "tgt_ref": "In diesem Fall stammen die Datensätze immer noch aus einem relevanten Datensatz, aber es ist nicht derselbe Datensatz, mit dem die Auswertung durchgeführt wird."}
{"doc_id": "gUAIqKCjIt", "seg_id": 22, "src_ref": "And we can do the same for unacceptability case.", "tgt_ref": "Dasselbe können wir für den Fall der Nichtakzeptanz tun."}
{"doc_id": "gUAIqKCjIt", "seg_id": 23, "src_ref": "Finally, we can choose sentences from a completely unrelated domain such as Wikipedia.", "tgt_ref": "Schließlich können wir auch Sätze aus einer völlig fremden Domain wie Wikipedia auswählen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 24, "src_ref": "So this will tell us like whether the models acceptability judgments are actually impacted by any context, like, whether the context is coming from a different subset of the data set, or whether it's like completely irrelevant, to the current like to the sentence that we are looking at.", "tgt_ref": "Auf diese Weise können wir feststellen, ob die Akzeptanzurteile des Modells tatsächlich von einem Kontext beeinflusst werden, das heißt ob der Kontext aus einer anderen Teilmenge des Datensatzes stammt oder ob er für den aktuell betrachteten Satz völlig irrelevant ist."}
{"doc_id": "gUAIqKCjIt", "seg_id": 25, "src_ref": "So how does the model do?", "tgt_ref": "Wie funktioniert das Modell?"}
{"doc_id": "gUAIqKCjIt", "seg_id": 26, "src_ref": "So first, we look at the Wikipedia sentences, which are completely irrelevant to the current query pair, and there we find that the MPP judgments are mostly robust for arbitrary context length.", "tgt_ref": "Nun, zunächst schauen wir uns die Wikipedia-Sätze an, die für das aktuelle Abfragepaar völlig irrelevant sind, und stellen fest, dass die MPP-Urteile für beliebige Kontextlängen weitgehend robust sind."}
{"doc_id": "gUAIqKCjIt", "seg_id": 27, "src_ref": "We increase the context length toward up to 1024 for to max out OPT and GPT 2 models.", "tgt_ref": "Wir erhöhen die Kontextlänge auf bis zu 1024, um die Modelle OPT und GPT 2 voll auszunutzen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 28, "src_ref": "And we saw here in the orange dotted line, the MPP judgments are relatively stable.", "tgt_ref": "Und wir haben hier an der orange gepunkteten Linie gesehen, dass die MPP-Urteile relativ stabil sind."}
{"doc_id": "gUAIqKCjIt", "seg_id": 29, "src_ref": "Now, what happens when we choose sentences from the same data set?", "tgt_ref": "Was passiert nun, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"doc_id": "gUAIqKCjIt", "seg_id": 30, "src_ref": "So here we are choosing or creating sentences from acceptable and unacceptable domains from the same BLiMP or SyntaxGym dataset.", "tgt_ref": "Hier wählen oder erzeugen wir Sätze aus akzeptablen und inakzeptablen Domains aus demselben BLiMP- oder SyntaxGym-Datensatz."}
{"doc_id": "gUAIqKCjIt", "seg_id": 31, "src_ref": "And there we see that the MPP judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes.", "tgt_ref": "Und wir sehen, dass die MPP-Werte entweder signifikant steigen oder fallen, wenn wir entweder akzeptable oder inakzeptable Präfixe hinzufügen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 32, "src_ref": "But when we match the structure, that is when we choose the sentences from the same phenomena in BLiMP or SyntaxGym, we see a massive increase or a massive decrease of the MPP judgement for the model, depending on whether the chosen prefix is acceptable or unacceptable.", "tgt_ref": "Aber wenn wir die Struktur anpassen, also wenn wir Sätze aus den gleichen Phänomenen in BLiMP oder SyntaxGym auswählen, sehen wir einen massiven Anstieg oder einen massiven Abfall der MPP-Werte für das Modell, je nachdem, ob das ausgewählte Präfix akzeptabel oder inakzeptabel ist."}
{"doc_id": "gUAIqKCjIt", "seg_id": 33, "src_ref": "Now this and this is very large like this effect, increases throughout the context length and this would probably affect like newer language models which has large context window.", "tgt_ref": "Dieser Effekt ist sehr stark und nimmt mit der Länge des Kontexts zu. Dies könnte sich auf neuere Sprachmodelle auswirken, die ein großes Kontextfenster haben."}
{"doc_id": "gUAIqKCjIt", "seg_id": 34, "src_ref": "So why does the match prefix affect the language model judgement so much?", "tgt_ref": "Warum also beeinflusst das Match-Präfix die Bewertung des Sprachmodells so stark?"}
{"doc_id": "gUAIqKCjIt", "seg_id": 35, "src_ref": "So we did a series of analysis where we tried to perturb the input sentence by, trying to preserve the relevant structure but adding like noise to the input.", "tgt_ref": "Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, den Eingabesatz zu stören, indem wir versucht haben, die relevante Struktur beizubehalten, aber eine Art Rauschen hinzuzufügen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 36, "src_ref": "And after doing like several of these perturbations, we find that none of these noises are actually making the model like change its course in terms of how it shows us the MPP judgement print.", "tgt_ref": "Und nachdem wir mehrere dieser Störungen durchgeführt hatten, stellten wir fest, dass keine dieser Störungen das Modell tatsächlich dazu veranlasste, seinen Kurs in Bezug auf die Darstellung des MPP-Bewertungsdrucks zu ändern."}
{"doc_id": "gUAIqKCjIt", "seg_id": 37, "src_ref": "Basically, we find that the models are sensitive to the perturbed sentences in similar ways.", "tgt_ref": "Wir stellten fest, dass die Modelle ähnlich empfindlich auf die Störungen reagierten."}
{"doc_id": "gUAIqKCjIt", "seg_id": 38, "src_ref": "That is, when we perturb the sentences in the acceptable domain, we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain, we see decrease in MPP judgments in similar fashion.", "tgt_ref": "Wenn wir die Sätze in der akzeptablen Domain stören, sehen wir also einen ähnlichen Anstieg bei allen Störungen, und wenn wir die Sätze in der inakzeptablen Domain stören, sehen wir einen ähnlichen Rückgang bei den MPP-Urteilen."}
{"doc_id": "gUAIqKCjIt", "seg_id": 39, "src_ref": "So, the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.", "tgt_ref": "Das wichtigste Ergebnis unserer Arbeit ist also, dass Sprachmodelle empfindlich auf latente syntaktische und semantische Merkmale reagieren, die in allen Sätzen vorhanden sind."}
{"doc_id": "gUAIqKCjIt", "seg_id": 40, "src_ref": "And the MPP evaluation the way that we do it currently with short and single sentence input, may not fully capture the language models abstract knowledge throughout the context window.", "tgt_ref": "Und die MPP-Evaluierung, wie wir sie derzeit mit kurzen, satzweisen Eingaben durchführen, erfasst möglicherweise nicht vollständig das abstrakte Wissen der Sprachmodelle im gesamten Kontextfenster."}
{"doc_id": "gUAIqKCjIt", "seg_id": 41, "src_ref": "Please read our paper for more details of our experiments.", "tgt_ref": "Weitere Details zu unseren Experimenten finden Sie in unserer Arbeit."}
{"doc_id": "gUAIqKCjIt", "seg_id": 42, "src_ref": "Thank you for listening.", "tgt_ref": "Vielen Dank fürs Zuhören."}
{"doc_id": "wJAPXMIoIG", "seg_id": 0, "src_ref": "Hello everyone, my name is Yusen Zhang from the Penn State University.", "tgt_ref": "Hallo zusammen, mein Name ist Yusen Zhang von der Penn State University."}
{"doc_id": "wJAPXMIoIG", "seg_id": 1, "src_ref": "Today I'm going to present our work \"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations\".", "tgt_ref": "Heute werde ich unsere Arbeit „XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations“ vorstellen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 2, "src_ref": "So, semantic parsing is a task to build semantic representations of user queries such as SQL and Lambda Calculus.", "tgt_ref": "Semantisches Parsing ist die Aufgabe, semantische Repräsentationen von Benutzerabfragen wie SQL und Lambda Calculus zu erstellen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 3, "src_ref": "And Cross-Lingual Semantic Parsing is the task to translate queries in multiple natural languages into multiple meaning representations.", "tgt_ref": "Und sprachübergreifendes semantisches Parsing ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 4, "src_ref": "As shown in this figure, we need to translate the query in multiple natural languages using neural models to SQL, Lambda or FunQL, and etcetera.", "tgt_ref": "Wie in der Abbildung dargestellt, müssen wir die Abfrage in mehreren natürlichen Sprachen in SQL, Lambda oder FunQL usw. übersetzen, indem wir neuronale Modelle verwenden."}
{"doc_id": "wJAPXMIoIG", "seg_id": 5, "src_ref": "Existing cross-lingual semantic parsing models are separately proposed and evaluated on data set of limited tasks and applications.", "tgt_ref": "Bestehende sprachübergreifende semantische Parsingmodelle werden separat vorgeschlagen und anhand von Datensätzen für begrenzte Aufgaben und Anwendungen evaluiert."}
{"doc_id": "wJAPXMIoIG", "seg_id": 6, "src_ref": "For instance, there are lots of coverage on certain natural languages.", "tgt_ref": "Beispielsweise gibt es eine große Menge an Daten für bestimmte natürliche Sprachen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 7, "src_ref": "But Chinese is missing and lack of coverage on certain meaning representation.", "tgt_ref": "Chinesisch fehlt jedoch und auch bestimmte Bedeutungsrepräsentationen werden nicht abgedeckt."}
{"doc_id": "wJAPXMIoIG", "seg_id": 8, "src_ref": "The Lambda calculus is missing, or they're only evaluated on certain neural models.", "tgt_ref": "Der Lambda-Kalkül fehlt oder wird nur mit bestimmten neuronalen Modellen evaluiert."}
{"doc_id": "wJAPXMIoIG", "seg_id": 9, "src_ref": "For example, there's only one single model to evaluate them.", "tgt_ref": "Zum Beispiel gibt es nur ein Modell, um sie zu bewerten."}
{"doc_id": "wJAPXMIoIG", "seg_id": 10, "src_ref": "So to this end we propose XSemPLR.", "tgt_ref": "Deshalb bieten wir XSemPLR an."}
{"doc_id": "wJAPXMIoIG", "seg_id": 11, "src_ref": "We provide a uniform data set XSemPLR for cross-lingual semantic parsing in multiple natural languages and meaning representations.", "tgt_ref": "Wir stellen einen einheitlichen Datensatz XSemPLR für sprachübergreifendes semantisches Parsing in mehreren natürlichen Sprachen und Bedeutungsrepräsentationen zur Verfügung."}
{"doc_id": "wJAPXMIoIG", "seg_id": 12, "src_ref": "It contains 9 datasets in various domains, 5 semantic parsing tasks, 8 meaning representations, and 22 natural languages in 15 language families.", "tgt_ref": "Er enthält 9 Datensätze in verschiedenen Domains, 5 semantische Parsing-Aufgaben, 8 Bedeutungsrepräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"doc_id": "wJAPXMIoIG", "seg_id": 13, "src_ref": "And to better evaluate our benchmark, we consider the six settings for training and evaluation.", "tgt_ref": "Um unsere Benchmark besser beurteilen zu können, betrachten wir sechs Einstellungen zum Training und zur Evaluierung."}
{"doc_id": "wJAPXMIoIG", "seg_id": 14, "src_ref": "The first one is Translate-Test.", "tgt_ref": "Die erste ist der Übersetzungstest."}
{"doc_id": "wJAPXMIoIG", "seg_id": 15, "src_ref": "We use Google Translate API to translate source to the target language, then use monolingual model to train and evaluation.", "tgt_ref": "Wir verwenden die Google-Translate-API, um die Ausgangssprache in die Zielsprache zu übersetzen, und anschließend das einsprachige Modell für das Training und die Evaluierung."}
{"doc_id": "wJAPXMIoIG", "seg_id": 16, "src_ref": "And for example, we train the English model on English query and during inference we translate the German query using API to English and then use the trained model to predict the SQL.", "tgt_ref": "Zum Beispiel trainieren wir das englische Modell auf eine englische Anfrage und während der Inferenz übersetzen wir die deutsche Anfrage mit Hilfe der API ins Englische und verwenden dann das trainierte Modell, um die SQL vorherzusagen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 17, "src_ref": "And we'll also test Monolingual Model.", "tgt_ref": "Wir testen auch das einsprachige Modell."}
{"doc_id": "wJAPXMIoIG", "seg_id": 18, "src_ref": "In this setting, the source language is the same as target language, for example German to German or English to English.", "tgt_ref": "In dieser Einstellung ist die Ausgangssprache dieselbe wie die Zielsprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch."}
{"doc_id": "wJAPXMIoIG", "seg_id": 19, "src_ref": "We also test Monolingual Few-shot setting by training monolingual models with only 10% of training data.", "tgt_ref": "Wir testen auch die Einstellung Monolingual Few-shot, bei der wir monolinguale Modelle mit nur 10 % der Trainingsdaten trainieren."}
{"doc_id": "wJAPXMIoIG", "seg_id": 20, "src_ref": "And we test Multilingual Model which we train one multilingual model for all languages.", "tgt_ref": "Und wir testen das multilinguale Modell, bei dem wir ein multilinguales Modell für alle Sprachen trainieren."}
{"doc_id": "wJAPXMIoIG", "seg_id": 21, "src_ref": "For example, we put the German, English, Chinese queries together to train a multilingual model.", "tgt_ref": "Zum Beispiel fügen wir deutsche, englische und chinesische Anfragen zusammen, um ein mehrsprachiges Modell zu trainieren."}
{"doc_id": "wJAPXMIoIG", "seg_id": 22, "src_ref": "And during inference we can use this model to translate German queries or Chinese queries, et cetera.", "tgt_ref": "Und während der Inferenz können wir dieses Modell verwenden, um deutsche oder chinesische Anfragen zu übersetzen, und so weiter."}
{"doc_id": "wJAPXMIoIG", "seg_id": 23, "src_ref": "And we also consider Cross-lingual Zero-shot and Few-shot transfer.", "tgt_ref": "Wir betrachten auch den interlingualen Zero-Shot- und Little-Shot-Transfer."}
{"doc_id": "wJAPXMIoIG", "seg_id": 24, "src_ref": "We train on one source language and transfer to another language.", "tgt_ref": "Wir trainieren mit einer Ausgangssprache und übersetzen dann in eine andere Sprache."}
{"doc_id": "wJAPXMIoIG", "seg_id": 25, "src_ref": "So during training, we train it on English queries or the combination of English and German Few-shot queries to train a multilingual model to predict the SQL output.", "tgt_ref": "Während des Trainings trainieren wir also englische Abfragen oder die Kombination von englischen und deutschen Zero-Shot-Abfragen, um ein mehrsprachiges Modell zur Vorhersage von SQL-Ausgaben zu trainieren."}
{"doc_id": "wJAPXMIoIG", "seg_id": 26, "src_ref": "And we also find many interesting results.", "tgt_ref": "Dabei erhalten wir viele interessante Ergebnisse."}
{"doc_id": "wJAPXMIoIG", "seg_id": 27, "src_ref": "So, regarding analysis of monolingual models, we evaluate on two groups of models including Encoder-PTR which stands for Multilingual Pretrained Encoders with Pointer-based Decoders, such as XLM-R + PTR and mBERT + PTR.", "tgt_ref": "Im Hinblick auf die Analyse einsprachiger Modelle evaluieren wir zwei Gruppen von Modellen, darunter Encoder-PTR, das steht für Multilingual Pretrained Encoders with Pointer-based Decoders, wie XLM-R + PTR und mBERT + PTR."}
{"doc_id": "wJAPXMIoIG", "seg_id": 28, "src_ref": "And, we also evaluate Encoder-Decoder models, which is Multilingual Pretrained Encoder-Decoder Models, such as mBART and mT5.", "tgt_ref": "Wir haben auch Encoder-Decoder-Modelle evaluiert, die für Multilingual Pretrained Encoder-Decoder Models stehen, wie mBART und mT5."}
{"doc_id": "wJAPXMIoIG", "seg_id": 29, "src_ref": "We found that Encoder-Decoder obtains the best performance on all nine datasets.", "tgt_ref": "Wir haben festgestellt, dass Encoder-Decoder bei allen neun Datensätzen die beste Leistung erzielt."}
{"doc_id": "wJAPXMIoIG", "seg_id": 30, "src_ref": "And we evaluate on mT5 and XLM-R + PTR on multilingual setting.", "tgt_ref": "Und wir evaluieren mT5 und XLM-R + PTR in einer mehrsprachigen Umgebung."}
{"doc_id": "wJAPXMIoIG", "seg_id": 31, "src_ref": "We found that Encoder-Decoder or Encoder-PTR can be improved by training in a mixture of various languages.", "tgt_ref": "Wir haben festgestellt, dass Encoder-Decoder oder Encoder-PTR durch Training mit einer Mischung aus verschiedenen Sprachen verbessert werden können."}
{"doc_id": "wJAPXMIoIG", "seg_id": 32, "src_ref": "We found it is because most of the major natural languages can obtain performance gain, except that English performance drops in seven datasets and only gains in three datasets.", "tgt_ref": "Wir haben herausgefunden, dass dies darauf zurückzuführen ist, dass die meisten der wichtigsten natürlichen Sprachen eine Leistungsverbesserung aufweisen, mit Ausnahme von Englisch, wo die Leistung in sieben Datensätzen abnimmt und nur in drei Datensätzen zunimmt."}
{"doc_id": "wJAPXMIoIG", "seg_id": 33, "src_ref": "I think this is known as the \"Curse of Multilinguality\".", "tgt_ref": "Das ist, so weit ich weiß, als „Fluch der Mehrsprachigkeit“ bekannt."}
{"doc_id": "wJAPXMIoIG", "seg_id": 34, "src_ref": "We also compare the cross-language performance gap.", "tgt_ref": "Wir vergleichen auch die Leistungsunterschiede zwischen den Sprachen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 35, "src_ref": "In this figure, the blue line is Cross-lingual Few-shot transfer.", "tgt_ref": "In dieser Abbildung stellt die blaue Linie den interlingualen Transfer mit wenigen Shots dar."}
{"doc_id": "wJAPXMIoIG", "seg_id": 36, "src_ref": "The orange line is Cross-lingual Zero-shot transfer.", "tgt_ref": "Die orangefarbene Linie stellt den interlingualen Zero-Shot-Transfer dar."}
{"doc_id": "wJAPXMIoIG", "seg_id": 37, "src_ref": "While the green line is the Monolingual Setting.", "tgt_ref": "Die grüne Linie ist der einsprachige Transfer."}
{"doc_id": "wJAPXMIoIG", "seg_id": 38, "src_ref": "We found that, by comparing the green and orange line, we found the Zero-shot setting, the Cross-lingual transfer performance gap is significant, and then comparing the blue and orange lines, we found that with the Few-shot setting the transfer gap is shortened rapidly.", "tgt_ref": "Wenn wir die grüne und die orange Linie vergleichen, sehen wir, dass der Leistungsunterschied beim sprachübergreifenden Transfer in der Zero-Shot-Einstellung beträchtlich ist. Wenn wir dann die blaue und die orangefarbene Linie vergleichen, sehen wir, dass der Leistungsunterschied beim Transfer in der Few-Shot-Einstellung rasch abnimmt."}
{"doc_id": "wJAPXMIoIG", "seg_id": 39, "src_ref": "We also find some other interesting findings.", "tgt_ref": "Wir finden auch einige andere interessante Ergebnisse."}
{"doc_id": "wJAPXMIoIG", "seg_id": 40, "src_ref": "For example, Encoder-Decoder outperforms previous work or achieves comparable results.", "tgt_ref": "Zum Beispiel übertrifft der Encoder-Decoder frühere Arbeiten oder erzielt vergleichbare Ergebnisse."}
{"doc_id": "wJAPXMIoIG", "seg_id": 41, "src_ref": "Pretraining on English natural language can significantly boost the performance of Few-shot on target natural languages, and we found multilingual language models such as Codex and BLOOM are still inadequate for cross-lingual semantic parsing tasks.", "tgt_ref": "Ein Vortraining in englischer Sprache kann die Few-Shot-Leistung in den natürlichen Zielsprachen erheblich verbessern. Außerdem haben wir festgestellt, dass multilinguale Sprachmodelle wie Codex und BLOOM für sprachübergreifende semantische Parsing-Aufgaben noch unzureichend sind."}
{"doc_id": "wJAPXMIoIG", "seg_id": 42, "src_ref": "To sum up, we build XSemPLR, a unified benchmark for cross-lingual semantic parsing with multiple natural languages and meaning representations.", "tgt_ref": "Zusammenfassend haben wir XSemPLR entwickelt, eine einheitliche Benchmark für sprachübergreifendes semantisches Parsing mit mehreren natürlichen Sprachen und Bedeutungsrepräsentationen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 43, "src_ref": "We conduct a comprehensive benchmark study on three representative types of multilingual language models.", "tgt_ref": "Wir führen eine umfassende Benchmark-Studie mit drei repräsentativen Typen von mehrsprachigen Sprachmodellen durch."}
{"doc_id": "wJAPXMIoIG", "seg_id": 44, "src_ref": "And our results show many interesting findings.", "tgt_ref": "Und unsere Ergebnisse zeigen viele interessante Resultate."}
{"doc_id": "wJAPXMIoIG", "seg_id": 45, "src_ref": "And et cetera.", "tgt_ref": "Und so weiter."}
{"doc_id": "wJAPXMIoIG", "seg_id": 46, "src_ref": "And welcome to visit our paper and code.", "tgt_ref": "Gerne können Sie unserer Arbeit und unserem Code ansehen."}
{"doc_id": "wJAPXMIoIG", "seg_id": 47, "src_ref": "Thanks for listening.", "tgt_ref": "Vielen Dank fürs Zuhören."}
{"doc_id": "miPjvjWOvI", "seg_id": 0, "src_ref": "Hello everyone, my name is David Vilar, and I will be giving a short review of the paper \"Prompting PaLM for Translation: Assessing Strategies and Performance.\"", "tgt_ref": "Hallo zusammen, mein Name ist David Vilar und ich werde einen kurzen Überblick über die Arbeit „Prompting PaLM for Translation: Evaluating Strategies and Performance“ geben."}
{"doc_id": "miPjvjWOvI", "seg_id": 1, "src_ref": "This is joint work with my colleagues from Google Translate.", "tgt_ref": "Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"doc_id": "miPjvjWOvI", "seg_id": 2, "src_ref": "PaLM is a 540 billion-parameter large language model presented last year in 2022.", "tgt_ref": "PaLM ist ein Large Language Model mit 540 Milliarden Parametern, das im Jahr 2022 vorgestellt wurde."}
{"doc_id": "miPjvjWOvI", "seg_id": 3, "src_ref": "It's trained on a large collection of text, comprising 780 billion tokens.", "tgt_ref": "Es wurde mit einer großen Sammlung von 780 Milliarden Token trainiert."}
{"doc_id": "miPjvjWOvI", "seg_id": 4, "src_ref": "At the time of publication, it achieved state-of-the-art in hundreds of NLP tasks.", "tgt_ref": "Zum Zeitpunkt der Veröffentlichung hatte es in hunderten von NLP-Aufgaben die beste Leistung erzielt."}
{"doc_id": "miPjvjWOvI", "seg_id": 5, "src_ref": "In this work, we present the first systematic study of large language model prompting for machine translation.", "tgt_ref": "In dieser Arbeit stellen wir die erste systematische Studie über Prompts in Large Language Models für die maschinelle Übersetzung vor."}
{"doc_id": "miPjvjWOvI", "seg_id": 6, "src_ref": "We evaluated the transition capability of such models using the best practices of the MT community.", "tgt_ref": "Wir haben die Übertragbarkeit dieser Modelle auf der Grundlage der Best Practices der MT-Community bewertet."}
{"doc_id": "miPjvjWOvI", "seg_id": 7, "src_ref": "This involves using the latest test sets to avoid an overlap of the test data with the training data of the language model.", "tgt_ref": "Dazu gehört die Verwendung der neuesten Testsätze, um Überschneidungen zwischen den Testdaten und den Trainingsdaten der Sprachmodelle zu vermeiden."}
{"doc_id": "miPjvjWOvI", "seg_id": 8, "src_ref": "And we compared to state-of-the-art systems, so the best performing system, so the WMT evaluation.", "tgt_ref": "Und wir haben sie mit Systemen verglichen, die dem neuesten Stand der Technik entsprechen, das heißt mit dem leistungsfähigsten System, der WMT-Evaluation."}
{"doc_id": "miPjvjWOvI", "seg_id": 9, "src_ref": "We use state-of-the-art, neural MT metrics, and additionally also show expert-based human evaluation results.", "tgt_ref": "Wir verwenden neuronale MT-Metriken, die dem neuesten Stand der Technik entsprechen, und zeigen zusätzlich die Ergebnisse der menschlichen Bewertung durch Experten."}
{"doc_id": "miPjvjWOvI", "seg_id": 10, "src_ref": "Finally, we provide some recommendations for prompt selection strategies.", "tgt_ref": "Abschließend geben wir einige Empfehlungen für Strategien zur Auswahl von Prompts ab."}
{"doc_id": "miPjvjWOvI", "seg_id": 11, "src_ref": "The prompting has a big influence on the performance of the LLMs for translation, as we can see in a simple experiment, where we used one-shot prompting and provided two different prompts for each sentence.", "tgt_ref": "Prompting hat einen großen Einfluss auf die Übersetzungsleistung von LLMs, wie ein einfaches Experiment mit One-Shot-Prompting zeigt, bei dem für jeden Satz zwei verschiedene Prompts ausgegeben wurden."}
{"doc_id": "miPjvjWOvI", "seg_id": 12, "src_ref": "The majority of sentences 516 out of 1,000.", "tgt_ref": "Die Mehrheit der Sätze waren 516 von 1.000."}
{"doc_id": "miPjvjWOvI", "seg_id": 13, "src_ref": "The difference observed is of more than one BLEURT points.", "tgt_ref": "Der beobachtete Unterschied betrug mehr als einen BLEURT-Punkt."}
{"doc_id": "miPjvjWOvI", "seg_id": 14, "src_ref": "And this can go, in extreme cases, up to 40 BLEURT points.", "tgt_ref": "Im Extremfall können es bis zu 40 BLEURT-Punkte sein."}
{"doc_id": "miPjvjWOvI", "seg_id": 15, "src_ref": "So, it's important to select a good prompting strategy.", "tgt_ref": "Es ist also wichtig, eine gute Prompting-Strategie zu wählen."}
{"doc_id": "miPjvjWOvI", "seg_id": 16, "src_ref": "In our experiments, we settled for a 5-shot prompting strategy where we just marked each sentence that we provide to the system, with the language it's in.", "tgt_ref": "In unseren Experimenten haben wir uns für eine 5-Shot-Prompting-Strategie entschieden, bei der wir einfach jeden Satz, den wir dem System geben, mit der Sprache markieren, in der er geschrieben ist."}
{"doc_id": "miPjvjWOvI", "seg_id": 17, "src_ref": "So in this example here, where we perform translation from German into English, the German sentences, the source sentences, are marked with German colon and the English translations with English colon.", "tgt_ref": "In diesem Beispiel, in dem wir vom Deutschen ins Englische übersetzen, sind also die deutschen Sätze, die Ausgangssätze, mit einem deutschen Doppelpunkt, und die englischen Übersetzungen mit einem englischen Doppelpunkt markiert."}
{"doc_id": "miPjvjWOvI", "seg_id": 18, "src_ref": "We saw that the actual form of the prompting doesn't have a big influence in the case of several short promptings.", "tgt_ref": "Wir haben gesehen, dass die Form des Prompts selbst keinen großen Einfluss hat, wenn es mehrere kurze Prompts gibt."}
{"doc_id": "miPjvjWOvI", "seg_id": 19, "src_ref": "It's crucial for zero and one-shot prompting.", "tgt_ref": "Bei Null- und One-Shot-Prompts ist sie entscheidend."}
{"doc_id": "miPjvjWOvI", "seg_id": 20, "src_ref": "And when we go, as in our case, to five-shot prompting, there is nearly no difference to the actual form of the prompting.", "tgt_ref": "Und wenn wir, wie in unserem Fall, zu Five-Shot-Prompts übergehen, gibt es fast keinen Unterschied in der Form des Prompts selbst."}
{"doc_id": "miPjvjWOvI", "seg_id": 21, "src_ref": "It's the examples that carry most of the weight.", "tgt_ref": "Die Beispiele haben das größte Gewicht."}
{"doc_id": "miPjvjWOvI", "seg_id": 22, "src_ref": "The summary of our experimental results is that the example quality is more important than the similarity to the source sentence.", "tgt_ref": "Zusammenfassend kann gesagt werden, dass die Qualität des Beispiels wichtiger ist als seine Ähnlichkeit mit dem Ausgangssatz."}
{"doc_id": "miPjvjWOvI", "seg_id": 23, "src_ref": "So it's important to select the examples from high-quality translations.", "tgt_ref": "Daher ist es wichtig, Beispiele aus qualitativ hochwertigen Übersetzungen auszuwählen."}
{"doc_id": "miPjvjWOvI", "seg_id": 24, "src_ref": "In particular, we compare the selecting prompts from the training data for the WMT evaluations on the dev data.", "tgt_ref": "Wir vergleichen insbesondere die Auswahlprompts der Trainingsdaten für die WMT-Auswertungen mit den Dev-Daten."}
{"doc_id": "miPjvjWOvI", "seg_id": 25, "src_ref": "The dev data is much more curated, and with higher quality than the training data, that it's more noisy.", "tgt_ref": "Die Dev-Daten sind sehr viel stärker kuratiert und von höherer Qualität als die Trainingsdaten, das heißt sie sind stärker mit Rauschen durchsetzt."}
{"doc_id": "miPjvjWOvI", "seg_id": 26, "src_ref": "And their results so a better performance when using the dev data.", "tgt_ref": "Daher sind die Ergebnisse besser, wenn die Dev-Daten verwendet werden."}
{"doc_id": "miPjvjWOvI", "seg_id": 27, "src_ref": "Nevertheless, specialized state-of-the-art systems have a substantial advantage over the PaLM translations.", "tgt_ref": "Dennoch haben spezialisierte State-of-the-Art-Systeme einen klaren Vorteil gegenüber PaLM-Übersetzungen."}
{"doc_id": "miPjvjWOvI", "seg_id": 28, "src_ref": "But, PaLM comes pretty close to a commercial system.", "tgt_ref": "Aber PaLM kommt einem kommerziellen System sehr nahe."}
{"doc_id": "miPjvjWOvI", "seg_id": 29, "src_ref": "In our case, we chose to evaluate with Google Translate.", "tgt_ref": "In unserem Fall haben wir uns für eine Bewertung mit Google Translate entschieden."}
{"doc_id": "miPjvjWOvI", "seg_id": 30, "src_ref": "The insights that we gained from the human evaluation that we performed using the MQM framework said that the fluency of PaLM is comparable to state-of-the-art systems but the main difference comes from the accuracy.", "tgt_ref": "Die Ergebnisse der menschlichen Evaluierung, die wir mithilfe des MQM-Frameworks durchgeführt haben, zeigen, dass PaLM in der Flüssigkeit mit den modernsten Systemen vergleichbar ist, der Hauptunterschied jedoch in der Genauigkeit liegt."}
{"doc_id": "miPjvjWOvI", "seg_id": 31, "src_ref": "So, in particular, the most common errors are omission errors.", "tgt_ref": "Insbesondere sind die häufigsten Fehler Auslassungsfehler."}
{"doc_id": "miPjvjWOvI", "seg_id": 32, "src_ref": "So, it seems that PaLM chooses to produce a better-sounding translation, sometimes by dropping parts of the source sentence that are made in translation.", "tgt_ref": "Es scheint also, dass PaLM eine besser klingende Übersetzung erstellt, indem es manchmal Teile des Ausgangssatzes in der Übersetzung weglässt."}
{"doc_id": "miPjvjWOvI", "seg_id": 33, "src_ref": "However, the \"Style/Awkward\" category for PaLM is lower than for the state-of-the-art systems, which is an additional signal that PaLM provides really fluent output, but still with some problems of accuracy.", "tgt_ref": "Allerdings ist die Kategorie „Stil/Schwierigkeit“ für PaLM niedriger als für die modernsten Systeme, was ein weiteres Signal dafür ist, dass PaLM eine wirklich flüssige Ausgabe liefert, aber immer noch einige Probleme bei der Genauigkeit bestehen."}
{"doc_id": "miPjvjWOvI", "seg_id": 34, "src_ref": "And that's it for this really short overview.", "tgt_ref": "Und das war‘s für diesen wirklich kurzen Überblick."}
{"doc_id": "miPjvjWOvI", "seg_id": 35, "src_ref": "For more details, please come to the full presentation of the paper.", "tgt_ref": "Weitere Details finden Sie in der vollständigen Präsentation der Arbeit."}
{"doc_id": "miPjvjWOvI", "seg_id": 36, "src_ref": "Thank you very much.", "tgt_ref": "Vielen Dank."}
{"doc_id": "krJSAnVcGR", "seg_id": 0, "src_ref": "Hello, I am Dawei, a PhD student at Saarland University in Germany.", "tgt_ref": "Hallo, ich bin Dawei, Doktorand an der Universität des Saarlandes in Deutschland."}
{"doc_id": "krJSAnVcGR", "seg_id": 1, "src_ref": "In this video, I would like to present our recent work \"Weaker Than You Think: A Critical Look at Weakly Supervised Learning.\"", "tgt_ref": "In diesem Video möchte ich Ihnen unsere aktuelle Arbeit „Weaker Than You Think: A Critical Look at Weakly Supervised Learning“ vorstellen."}
{"doc_id": "krJSAnVcGR", "seg_id": 2, "src_ref": "This is joint work with Xiaoyu Shen, Marius Mosbach, Andreas Stephan, and Dietrich Klakow.", "tgt_ref": "Dies ist eine gemeinsame Arbeit mit Xiaoyu Shen, Marius Mosbach, Andreas Stephan und Dietrich Klakow."}
{"doc_id": "krJSAnVcGR", "seg_id": 3, "src_ref": "I'd like to begin with a brief introduction to weak supervision and weakly supervised learning.", "tgt_ref": "Ich möchte mit einer kurzen Einführung in die schwache Überwachung und das schwach überwachte Lernen beginnen."}
{"doc_id": "krJSAnVcGR", "seg_id": 4, "src_ref": "In weak supervision, you do not manually label the data.", "tgt_ref": "Bei der schwachen Überwachung werden die Daten nicht manuell mit Labeln versehen."}
{"doc_id": "krJSAnVcGR", "seg_id": 5, "src_ref": "Instead, we label the data using weak labeling sources, such as simple heuristic rules, knowledge bases, or low-quality crowdsourcing, as illustrated in the figure on the right.", "tgt_ref": "Stattdessen werden die Daten mit schwachen Annotationsquellen wie einfachen heuristischen Regeln, Wissensdatenbanken oder minderwertigem Crowdsourcing annotiert, wie in der Abbildung rechts dargestellt."}
{"doc_id": "krJSAnVcGR", "seg_id": 6, "src_ref": "When compared to human annotations, the weaker annotations are much cheaper, yet they are also noisy, meaning that a certain amount of the annotations are incorrect.", "tgt_ref": "Im Vergleich zu menschlichen Annotationen sind diese schwächeren Annotationen viel billiger, aber sie weisen auch Rauschen auf, was bedeutet, dass ein gewisser Prozentsatz der Annotationen falsch sein wird."}
{"doc_id": "krJSAnVcGR", "seg_id": 7, "src_ref": "If we directly train neural networks on weakly labeled data, the neural networks tend to memorize the label noise and do not generalize.", "tgt_ref": "Wenn wir neuronale Netze direkt mit schwach annotierten Daten trainieren, erinnern sich die neuronalen Netze tendenziell an das Rauschen der Annotationen und können nicht verallgemeinern."}
{"doc_id": "krJSAnVcGR", "seg_id": 8, "src_ref": "In weakly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generalize well.", "tgt_ref": "Das schwach überwachte Lernen schlägt Trainingsalgorithmen vor, mit denen neuronale Netze auch in einem solchen Label-Rauschen robust trainiert werden können, sodass die trainierten Modelle noch gut verallgemeinert werden können."}
{"doc_id": "krJSAnVcGR", "seg_id": 9, "src_ref": "In recent works in WSL, so WSL stands for Weakly Supervised Learning, a common claim is that people say that they only train models on the weakly labeled data and achieve high performance on clean test sets.", "tgt_ref": "In neueren Arbeiten auf dem Gebiet des WSL (WSL steht für: Weakly Supervised Learning) wird oft behauptet, dass man Modelle nur auf schwach markierten Daten trainieren müsse, um eine hohe Leistung auf sauberen Testdatensätzen zu erzielen."}
{"doc_id": "krJSAnVcGR", "seg_id": 10, "src_ref": "Technically, this claim is not wrong, but there's a catch, which is that people do assume that there's an additional clean validation set available for model selection.", "tgt_ref": "Technisch gesehen ist diese Aussage nicht falsch, aber die Sache hat einen Haken: Man geht davon aus, dass ein zusätzlicher sauberer Validierungssatz für die Modellauswahl zur Verfügung steht."}
{"doc_id": "krJSAnVcGR", "seg_id": 11, "src_ref": "We can't stop on this problem setting, but this implies that additional manual annotations are required in weakly supervised learning.", "tgt_ref": "Dies impliziert jedoch, dass beim schwach überwachten Lernen zusätzliche manuelle Anmerkungen erforderlich sind."}
{"doc_id": "krJSAnVcGR", "seg_id": 12, "src_ref": "But like an elephant in the room this necessity is often overlooked.", "tgt_ref": "Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"doc_id": "krJSAnVcGR", "seg_id": 13, "src_ref": "The aforementioned doubt is asked to ask three research questions.", "tgt_ref": "Die oben genannten Zweifel führen zu drei Forschungsfragen."}
{"doc_id": "krJSAnVcGR", "seg_id": 14, "src_ref": "First, is clean validation data necessary for WSL or can we maybe use a noisy validation set instead?", "tgt_ref": "Erstens: Sind saubere Validierungsdaten für die WSL erforderlich, oder können wir stattdessen einen Validierungsdatensatz verwenden, der ein Rauschen enthält?"}
{"doc_id": "krJSAnVcGR", "seg_id": 15, "src_ref": "Second, if clean data is required, or if clean data is mandatory for WSL to work, then how many clean samples do we need?", "tgt_ref": "Zweitens: Wenn saubere Daten erforderlich sind, oder wenn saubere Daten für WSL zwingend benötigt werden, wie viele saubere Proben brauchen wir dann?"}
{"doc_id": "krJSAnVcGR", "seg_id": 16, "src_ref": "Finally, should we only use the clean samples for validation, or there are better ways to utilize them?", "tgt_ref": "Und drittens: Sollen wir nur die sauberen Proben für die Validierung verwenden oder gibt es bessere Möglichkeiten?"}
{"doc_id": "krJSAnVcGR", "seg_id": 17, "src_ref": "We addressed these research questions in our work and our findings are as follows.", "tgt_ref": "Wir haben uns in unserer Arbeit mit diesen Forschungsfragen beschäftigt und sind zu folgenden Ergebnissen gekommen."}
{"doc_id": "krJSAnVcGR", "seg_id": 18, "src_ref": "First, we find that, interestingly, recent WSL methods indeed require clean validation samples to work properly.", "tgt_ref": "Erstens haben wir festgestellt, dass die neuesten WSL-Methoden tatsächlich saubere Validierungsproben benötigen, um richtig zu funktionieren."}
{"doc_id": "krJSAnVcGR", "seg_id": 19, "src_ref": "Otherwise, there is a large performance drop.", "tgt_ref": "Andernfalls nimmt die Leistungsfähigkeit stark ab."}
{"doc_id": "krJSAnVcGR", "seg_id": 20, "src_ref": "As shown in this figure, if there are no clean validation samples, then the trained models cannot generalize beyond the original weak labels, meaning that the training is pointless.", "tgt_ref": "Wie in dieser Abbildung zu sehen ist, können die trainierten Modelle ohne saubere Validierungsmuster nicht über die ursprünglichen schwachen Labels hinaus verallgemeinern, was bedeutet, dass das Training sinnlos ist."}
{"doc_id": "krJSAnVcGR", "seg_id": 21, "src_ref": "This indicates that WSL approaches actually require cleanly labeled data to work properly, and the annotation cost for obtaining clean validation samples should not be overlooked.", "tgt_ref": "Dies deutet darauf hin, dass WSL-Ansätze tatsächlich sauber annotierte Daten benötigen, um richtig zu funktionieren, und dass die Annotationskosten für die Beschaffung sauberer Validierungsproben nicht vernachlässigt werden sollten."}
{"doc_id": "krJSAnVcGR", "seg_id": 22, "src_ref": "Our second finding is that increasing the number of clean validation samples will help WSL approaches to achieve better performance, as shown in the figure on the left.", "tgt_ref": "Unsere zweite Erkenntnis ist, dass WSL-Ansätze besser funktionieren, wenn wir die Anzahl der sauberen Validierungsproben erhöhen, wie in der Abbildung links dargestellt."}
{"doc_id": "krJSAnVcGR", "seg_id": 23, "src_ref": "Typically we only need 20 samples per class to attain high performance.", "tgt_ref": "Normalerweise brauchen wir nur 20 Beispiele pro Klasse, um eine gute Leistung zu erzielen."}
{"doc_id": "krJSAnVcGR", "seg_id": 24, "src_ref": "But that's not the end of the story, because if we either way decide to access clean samples, then training on them directly will even achieve better performance.", "tgt_ref": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entscheiden, auf saubere Proben zuzugreifen, dann wird das Training direkt auf diesen Proben eine noch bessere Leistung erzielen."}
{"doc_id": "krJSAnVcGR", "seg_id": 25, "src_ref": "The right figure shows the performance difference between fine-tuning approaches, which are directly applied on the clean data, and WSL approaches, which use the clean data for validation only.", "tgt_ref": "Die Abbildung rechts zeigt den Leistungsunterschied zwischen Fine-Tuning-Ansätzen, die direkt auf sauberen Daten trainieren, und WSL-Ansätzen, bei denen saubere Daten nur zur Validierung verwendet werden."}
{"doc_id": "krJSAnVcGR", "seg_id": 26, "src_ref": "As we can see, if we have 10 samples per class, direct fine-tuning starts to beat WSL approaches.", "tgt_ref": "Wie man sehen kann, beginnt die direkte Feinabstimmung ab 10 Proben pro Klasse die WSL-Ansätze zu schlagen."}
{"doc_id": "krJSAnVcGR", "seg_id": 27, "src_ref": "Finally, the performance improvement claimed in previous WSL approaches can be easily achieved by allowing to continue fine-tuning on the clean validation samples.", "tgt_ref": "Schließlich kann die geforderte Leistungssteigerung der bisherigen WSL-Ansätze leicht durch eine weitere Feinabstimmung an den eigenen Validierungsproben erreicht werden."}
{"doc_id": "krJSAnVcGR", "seg_id": 28, "src_ref": "As we can see from the figures, the vanilla model, termed FTw, initially underperforms more complicated WSL methods, like COSINE.", "tgt_ref": "Wie in den Abbildungen zu sehen ist, schneidet das Vanilla-Modell FTw zunächst schlechter ab als die komplexeren WSL-Methoden wie COSINE."}
{"doc_id": "krJSAnVcGR", "seg_id": 29, "src_ref": "However, if we allow to continue fine-tuning on the clean samples, then FTw performs equally well as other methods.", "tgt_ref": "Wenn wir jedoch die Feinabstimmung an den sauberen Proben fortsetzen, schneidet FTw gleich gut ab wie die anderen Methoden."}
{"doc_id": "krJSAnVcGR", "seg_id": 30, "src_ref": "So in practice, there's no reason to choose more complex WSL methods which require more computation time and disk space.", "tgt_ref": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz benötigen."}
{"doc_id": "krJSAnVcGR", "seg_id": 31, "src_ref": "To summarize, we showed that recent WSL approaches require clean, manually annotated samples for them to work properly.", "tgt_ref": "Zusammenfassend haben wir gezeigt, dass neuere WSL-Ansätze saubere, manuell annotierte Stichproben benötigen, um richtig zu funktionieren."}
{"doc_id": "krJSAnVcGR", "seg_id": 32, "src_ref": "Their performance gain and practicality are heavily overestimated.", "tgt_ref": "Ihr Leistungsgewinn und ihre Praxistauglichkeit werden stark überschätzt."}
{"doc_id": "krJSAnVcGR", "seg_id": 33, "src_ref": "Our concrete recommendations for future work are as follows.", "tgt_ref": "Unsere konkreten Empfehlungen für zukünftige Arbeiten lauten wie folgt."}
{"doc_id": "krJSAnVcGR", "seg_id": 34, "src_ref": "First, report the model selection criteria.", "tgt_ref": "Erstens sollten die Kriterien für die Modellauswahl spezifiziert werden."}
{"doc_id": "krJSAnVcGR", "seg_id": 35, "src_ref": "For example, report if the model selection is done via clean validation samples.", "tgt_ref": "Zum Beispiel sollte angegeben werden, ob die Modellauswahl durch eigene Validierungsstichproben erfolgt."}
{"doc_id": "krJSAnVcGR", "seg_id": 36, "src_ref": "Second, WSL approaches should be compared with few-shot learning baselines, as both work on clean samples.", "tgt_ref": "Zweitens sollten die WSL-Ansätze mit den Basismodellen für das Lernen mit wenigen Shots verglichen werden, da beide mit sauberen Stichproben arbeiten."}
{"doc_id": "krJSAnVcGR", "seg_id": 37, "src_ref": "Third, continuous fine-tuning is a simple yet strong baseline that should be considered in future work in WSL.", "tgt_ref": "Drittens ist das kontinuierliche Fein-Tuning eine einfache, aber wirkmächtige Grundlage, die bei zukünftigen Arbeiten an WSL berücksichtigt werden sollte."}
{"doc_id": "krJSAnVcGR", "seg_id": 38, "src_ref": "Finally, we have open-sourced our code.", "tgt_ref": "Schließlich haben wir unseren Code als Open Source zur Verfügung gestellt."}
{"doc_id": "krJSAnVcGR", "seg_id": 39, "src_ref": "You can find it via the QR code on this slide.", "tgt_ref": "Sie finden ihn über den QR-Code auf dieser Folie."}
{"doc_id": "krJSAnVcGR", "seg_id": 40, "src_ref": "Please feel free to check it out.", "tgt_ref": "Schauen Sie doch mal rein!"}
{"doc_id": "krJSAnVcGR", "seg_id": 41, "src_ref": "Thank you and enjoy the conference.", "tgt_ref": "Vielen Dank und viel Spaß bei der Konferenz."}
{"doc_id": "JhbtCwcsWY", "seg_id": 0, "src_ref": "Hello, I'm James Finch.", "tgt_ref": "Hallo, ich bin James Finch."}
{"doc_id": "JhbtCwcsWY", "seg_id": 1, "src_ref": "And I'm Sarah Finch.", "tgt_ref": "Und ich bin Sarah Finch."}
{"doc_id": "JhbtCwcsWY", "seg_id": 2, "src_ref": "And today we'll tell you all about ABC-Eval, a new dimensional approach to evaluating conversational AI.", "tgt_ref": "Heute stellen wir Ihnen ABC-Eval vor, einen neuen dimensionalen Ansatz zur Evaluierung konversationaler KI."}
{"doc_id": "JhbtCwcsWY", "seg_id": 3, "src_ref": "This work was done by the Emory NLP Lab led by Professor Jinho Choi at Emory University and in collaboration with Amazon Alexa AI.", "tgt_ref": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Jinho Choi an der Emory University in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"doc_id": "JhbtCwcsWY", "seg_id": 4, "src_ref": "So let's say that you just developed a dialogue model and you want to see how well it compares against the current state-of-the-art.", "tgt_ref": "Angenommen, Sie haben gerade ein Dialogmodell entwickelt und möchten wissen, wie gut es im Vergleich zum aktuellen Stand der Technik abschneidet."}
{"doc_id": "JhbtCwcsWY", "seg_id": 5, "src_ref": "The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.", "tgt_ref": "Ein gängiger Ansatz ist die Verwendung menschlicher Bewertungen, zum Beispiel indem menschliche Gutachter entscheiden, welcher von zwei Dialogen besser ist, oder indem Dialoge auf einer Likert-Skala bewertet werden."}
{"doc_id": "JhbtCwcsWY", "seg_id": 6, "src_ref": "These approaches work well to provide holistic evaluations of overall dialogue quality, but dialogue quality has many aspects.", "tgt_ref": "Diese Ansätze sind gut geeignet, um eine ganzheitliche Bewertung der Gesamtqualität des Dialogs vorzunehmen, aber die Dialogqualität hat viele Aspekte."}
{"doc_id": "JhbtCwcsWY", "seg_id": 7, "src_ref": "Therefore, you might want to evaluate multiple dimensions of chat quality to understand the strengths and weaknesses of the model on a finer-grained level.", "tgt_ref": "Daher kann es sinnvoll sein, mehrere Dimensionen der Gesprächsqualität zu bewerten, um die Stärken und Schwächen des Modells auf einer feingliedrigeren Ebene zu verstehen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 8, "src_ref": "One approach is to simply ask human judges to evaluate several dimensions of dialogue quality, such as the relevance of model responses using existing comparative or Likert scale methods.", "tgt_ref": "Ein Ansatz besteht darin, einfach menschliche Gutachter zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie zum Beispiel die Relevanz der Modellantworten unter Verwendung bestehender vergleichender oder Likert-Skala-Methoden."}
{"doc_id": "JhbtCwcsWY", "seg_id": 9, "src_ref": "However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation.", "tgt_ref": "Wir glauben jedoch, dass es eine genauere und zuverlässigere Strategie für die dimensionale Bewertung von Dialogen gibt."}
{"doc_id": "JhbtCwcsWY", "seg_id": 10, "src_ref": "Our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself.", "tgt_ref": "In unserem Ansatz versuchen wir, die Subjektivität der menschlichen Evaluierung zu reduzieren, indem wir explizit annotieren, ob jede Modellantwort bestimmte Verhaltensweisen ausdrückt, wie zum Beispiel mit irrelevanter Information antwortet oder sich selbst widerspricht."}
{"doc_id": "JhbtCwcsWY", "seg_id": 11, "src_ref": "We call this approach annotating behaviors in chat or ABC-Eval in short.", "tgt_ref": "Wir nennen diesen Ansatz Annotation von Verhaltensweisen im Chat oder kurz ABC-Eval."}
{"doc_id": "JhbtCwcsWY", "seg_id": 12, "src_ref": "We developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature.", "tgt_ref": "Wir haben diese Methode entwickelt, um die Verhaltensweisen von Chatmodellen umfassend zu erfassen, von denen in der neueren Literatur angenommen wird, dass sie die Chatqualität beeinflussen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 13, "src_ref": "ABC-Eval is capable of measuring the rates at which chat models will commit various thematic errors.", "tgt_ref": "ABC-Eval ist in der Lage, die Rate zu messen, mit der Chatmodelle verschiedene thematische Fehler begehen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 14, "src_ref": "For example, ABC-Eval measures the number of turns in which a chat model ignores its partner or says something irrelevant, contradicts itself or its partner, hallucinates incorrect facts or violates common sense knowledge, and when the model succeeds or fails to show empathy.", "tgt_ref": "ABC-Eval misst beispielsweise die Anzahl der Runden, in denen ein Chatmodell seinen Partner ignoriert oder etwas Irrelevantes sagt, sich selbst oder seinem Partner widerspricht, falsche Tatsachen halluziniert oder gegen den gesunden Menschenverstand verstößt, und in denen es dem Modell gelingt oder misslingt, Empathie zu zeigen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 15, "src_ref": "To determine what kind of evaluation is most effective, we selected four state-of-the-art chat models and evaluated them on 100 human-bot conversations per model using ABC-Eval.", "tgt_ref": "Um herauszufinden, welche Art der Evaluierung am effektivsten ist, haben wir vier hochmoderne Chat-Modelle ausgewählt und sie mit ABC-Eval anhand von 100 Mensch-Bot-Gesprächen pro Modell bewertet."}
{"doc_id": "JhbtCwcsWY", "seg_id": 16, "src_ref": "For comparison, we also evaluated these conversations using three existing methods: Likert ratings on the turn-level, Likert ratings on the dialogue-level, and dialogue-level pairwise comparisons.", "tgt_ref": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden evaluiert: Turn-Level Likert Ratings, Dialogue-Level Likert Ratings und Dialogue-Level Pairwise Comparisons."}
{"doc_id": "JhbtCwcsWY", "seg_id": 17, "src_ref": "For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue, since this is the standard practice for evaluating chat models along multiple dimensions.", "tgt_ref": "Für jede der bestehenden Methoden haben wir Bewertungen für acht der am häufigsten gemessenen Aspekte des Dialogs erhoben, da dies eine gängige Praxis bei der Bewertung von Chat-Modellen entlang mehrerer Dimensionen ist."}
{"doc_id": "JhbtCwcsWY", "seg_id": 18, "src_ref": "From our analysis of these evaluation results, we found that ABC-Eval behavior labels are overall more reliable than labels collected by existing methods, as measured by inter-annotator agreement on 100 doubly-labeled conversations.", "tgt_ref": "Unsere Analyse dieser Evaluationsergebnisse hat gezeigt, dass die ABC-Eval-Verhaltensattribute insgesamt zuverlässiger sind als die Attribute, die von bestehenden Methoden erzeugt werden. Dies wurde anhand der Übereinstimmung zwischen den Annotatoren bei 100 doppelt markierten Interviews gemessen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 19, "src_ref": "In addition, ABC-Eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis.", "tgt_ref": "Darüber hinaus sind die ABC-Eval-Kennzeichnungen aussagekräftiger für die allgemeine Gesprächsqualität als die Metriken bestehender Methoden, wie diese einfache lineare Regressionsanalyse zeigt."}
{"doc_id": "JhbtCwcsWY", "seg_id": 20, "src_ref": "For example, you can see how measuring the proportion of turns with self and partner contradictions explains 5% and 10% of conversation quality, respectively, while the average Likert consistency scores explain only 4% or less.", "tgt_ref": "Beispielsweise erklärt die Messung des Anteils der Turns mit Selbstwidersprüchen und Partnerwidersprüchen 5 % bzw. 10 % der Gesprächsqualität, während die durchschnittlichen Likert-Konsistenzwerte nur 4 % oder weniger erklären."}
{"doc_id": "JhbtCwcsWY", "seg_id": 21, "src_ref": "Finally, we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression.", "tgt_ref": "Schließlich haben wir eine schrittweise lineare Regression durchgeführt, um zu sehen, ob jeder Indikator einen bestimmten Aspekt der Gesprächsqualität erfasst."}
{"doc_id": "JhbtCwcsWY", "seg_id": 22, "src_ref": "You can see how the combination of all ABC-Eval metrics explains over 25% of conversation quality, and as you remove the metrics one at a time, most of them result in losing a decent amount of information about the quality.", "tgt_ref": "Es zeigt sich, dass die Kombination aller ABC-Eval-Kennzahlen mehr als 25 % der Gesprächsqualität erklärt. Wenn man die Kennzahlen einzeln herausnimmt, geht bei den meisten eine beträchtliche Menge an Information über die Qualität verloren."}
{"doc_id": "JhbtCwcsWY", "seg_id": 23, "src_ref": "On the other hand, the combination of all turn-level Likert metrics explains far less of the quality, and fewer of these metrics carry unique information.", "tgt_ref": "Andererseits erklärt die Kombination aller Likert-Kennzahlen auf Turn-Ebene weit weniger von der Qualität, und weniger dieser Kennzahlen enthalten eindeutige Informationen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 24, "src_ref": "These reliable, informative, and distinct ABC-Eval metrics enable us to evaluate conversational AI with a higher resolution than previous methods are able to achieve.", "tgt_ref": "Diese zuverlässigen, informativen und eindeutigen ABC-Eval-Metriken ermöglichen es uns, KI im Gespräch mit einer höheren Auflösung zu bewerten, als es mit früheren Methoden möglich war."}
{"doc_id": "JhbtCwcsWY", "seg_id": 25, "src_ref": "You can see that in the results of our experiment that several challenges still remain and have been precisely quantified.", "tgt_ref": "Sie können in den Ergebnissen unseres Experiments sehen, dass noch einige Herausforderungen bestehen bleiben und genau quantifiziert wurden."}
{"doc_id": "JhbtCwcsWY", "seg_id": 26, "src_ref": "For example, the bots we tested have common sense violations in around 20% of their responses.", "tgt_ref": "Die von uns getesteten Bots verstoßen beispielsweise in etwa 20 % ihrer Antworten gegen den gesunden Menschenverstand."}
{"doc_id": "JhbtCwcsWY", "seg_id": 27, "src_ref": "They produce irrelevant information in around 15% of the responses, and they contradict themselves or their partner around 10% of the time.", "tgt_ref": "Sie produzieren in etwa 15 % der Antworten irrelevante Informationen und widersprechen sich selbst oder ihrem Partner in etwa 10 % der Fälle."}
{"doc_id": "JhbtCwcsWY", "seg_id": 28, "src_ref": "With the rapid pace of improvement in the field, many of these error rates could see a decrease in new models released since our evaluation was conducted.", "tgt_ref": "Angesichts der raschen Fortschritte auf diesem Gebiet könnten viele dieser Fehlerraten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, sogar noch niedriger sein."}
{"doc_id": "JhbtCwcsWY", "seg_id": 29, "src_ref": "However, this is all the more reason to pursue reliable and precise evaluation metrics for comparing models.", "tgt_ref": "Dies ist jedoch ein Grund mehr, zuverlässige und genaue Bewertungsmetriken für den Vergleich von Modellen zu verfolgen."}
{"doc_id": "JhbtCwcsWY", "seg_id": 30, "src_ref": "We hope ABC-Eval can be leveraged by others in the field as a meaningful step in this direction.", "tgt_ref": "Wir hoffen, dass ABC-Eval von anderen in diesem Bereich als nützlicher Schritt in diese Richtung aufgegriffen werden kann."}
{"doc_id": "JhbtCwcsWY", "seg_id": 31, "src_ref": "And we look forward to seeing how conversational AI will advance in the coming months and years.", "tgt_ref": "Und wir sind gespannt, wie sich die konversationale KI in den nächsten Monaten und Jahren weiterentwickeln wird."}
{"doc_id": "JhbtCwcsWY", "seg_id": 32, "src_ref": "Thank you for watching.", "tgt_ref": "Vielen Dank fürs Zuschauen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 0, "src_ref": "Hello, my name is Kayo Yin and I will be presenting our work titled \"When Does Translation Require Context?", "tgt_ref": "Hallo, mein Name ist Kayo Yin und ich werde unsere Arbeit mit dem Titel „When Does Translation Require Context?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 1, "src_ref": "A Data-driven, Multilingual Exploration\".", "tgt_ref": "A Data-Based Multilingual Investigation“ vorstellen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 2, "src_ref": "This work was done in collaboration with Patrick Fernandes, Emmy Liu, André F. T. Martins, and Graham Neubig.", "tgt_ref": "Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emmy Liu, André F. T. Martins und Graham Neubig verfasst."}
{"doc_id": "xUDLtuhJUS", "seg_id": 3, "src_ref": "So a lot of translations depend on context.", "tgt_ref": "Ein großer Teil der Übersetzung hängt vom Kontext ab."}
{"doc_id": "xUDLtuhJUS", "seg_id": 4, "src_ref": "For example, how would we translate \"mole\" in this sentence?", "tgt_ref": "Wie würden wir zum Beispiel „mole“ in diesem Satz übersetzen?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 5, "src_ref": "Well, if the previous sentence was \"Things could start to get dangerous if the ministers find out\", then \"mole\" refers to a spy.", "tgt_ref": "Nun, wenn der vorherige Satz lautete: „Es könnte gefährlich werden, wenn die Minister das herausfinden“, dann bezieht sich „mole“ auf einen Spion."}
{"doc_id": "xUDLtuhJUS", "seg_id": 6, "src_ref": "But if the previous sentence was \"Could it be anything serious, doctor?\", then \"mole\" refers to a birthmark.", "tgt_ref": "Lautete der vorherige Satz aber „Könnte es etwas Ernstes sein, Doktor?“, dann bezieht sich „mole“ auf ein Muttermal."}
{"doc_id": "xUDLtuhJUS", "seg_id": 7, "src_ref": "So, depending on context, the meaning of the word changes, and therefore its translation changes as well.", "tgt_ref": "Je nach Kontext ändert sich also die Bedeutung des Wortes und damit auch seine Übersetzung."}
{"doc_id": "xUDLtuhJUS", "seg_id": 8, "src_ref": "However, evaluating how well models can translate cases like this is pretty hard.", "tgt_ref": "Es ist jedoch schwierig zu beurteilen, wie gut Modelle solche Fälle übersetzen können."}
{"doc_id": "xUDLtuhJUS", "seg_id": 9, "src_ref": "Firstly because only a small portion of translations depend on context which makes corpus-level metrics like BLEU unable to capture these translations.", "tgt_ref": "Erstens ist nur ein kleiner Teil der Übersetzungen kontextabhängig, sodass Metriken auf Korpusebene wie BLEU diese Übersetzungen nicht erfassen können."}
{"doc_id": "xUDLtuhJUS", "seg_id": 10, "src_ref": "And some people have suggested targeted evaluation on context-dependent translations, but these resources only support limited types of context-dependent translations and limited sets of languages since they usually rely on domain knowledge and human curation.", "tgt_ref": "Zweitens wurde eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sätze von Sprachen, da sie in der Regel auf Domain-Wissen und menschlicher Kuratierung basieren."}
{"doc_id": "xUDLtuhJUS", "seg_id": 11, "src_ref": "In this work, we try to answer these two questions.", "tgt_ref": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten."}
{"doc_id": "xUDLtuhJUS", "seg_id": 12, "src_ref": "First, when does translation require context?", "tgt_ref": "Erstens, wann wird Kontext für die Übersetzung benötigt?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 13, "src_ref": "And second, how well do models handle these cases?", "tgt_ref": "Und zweitens: Wie gut können die Modelle mit diesen Fällen umgehen?"}
{"doc_id": "xUDLtuhJUS", "seg_id": 14, "src_ref": "To answer the first question, we started by measuring how much a word depends on context during translation.", "tgt_ref": "Um die erste Frage zu beantworten, haben wir zunächst gemessen, wie stark ein Wort während der Übersetzung vom Kontext abhängt."}
{"doc_id": "xUDLtuhJUS", "seg_id": 15, "src_ref": "In the previous work, we introduced CXMI as a measure for context usage by machine translation models.", "tgt_ref": "In der vorangegangenen Arbeit haben wir CXMI als Maß für die Verwendung von Kontext durch maschinelle Übersetzungsmodelle eingeführt."}
{"doc_id": "xUDLtuhJUS", "seg_id": 16, "src_ref": "And this is done by measuring how much information the context C provides about the target Y, given the source X. You can think of CXMI as the information gained from giving context to the model.", "tgt_ref": "Es misst, wie viele Informationen der Kontext C über das Ziel Y liefert, wenn man die Quelle X betrachtet. CXMI kann als die Information aufgefasst werden, die durch die Bereitstellung von Kontext für das Modell gewonnen wird."}
{"doc_id": "xUDLtuhJUS", "seg_id": 17, "src_ref": "In this work, we extend CXMI to Pointwise CXMI which can measure context usage at the sentence level or at the word level.", "tgt_ref": "In dieser Arbeit erweitern wir CXMI zu Pointwise CXMI, das die Kontextnutzung auf Satz- oder Wortebene messen kann."}
{"doc_id": "xUDLtuhJUS", "seg_id": 18, "src_ref": "We can think of words that have high P-CXMI as ones that require context for translation.", "tgt_ref": "Wir können uns Wörter mit hohem P-CXMI als Wörter vorstellen, die Kontext für die Übersetzung benötigen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 19, "src_ref": "Now we analyze words with high P-CXMI to look for patterns between these words.", "tgt_ref": "Nun analysieren wir Wörter mit hohem P-CXMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 20, "src_ref": "And we perform our analysis on transcripts of TED talks that have been translated from English to 14 different languages.", "tgt_ref": "Und wir führen unsere Analyse an Transkripten von TED-Talks durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"doc_id": "xUDLtuhJUS", "seg_id": 21, "src_ref": "We perform our analysis at three different levels.", "tgt_ref": "Die Analyse erfolgt auf drei verschiedenen Ebenen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 22, "src_ref": "First, we look at part-of-speech tags that have high mean P-CXMI.", "tgt_ref": "Zunächst betrachten wir die Part-of-Speech-Tags, die einen hohen durchschnittlichen P-CXMI aufweisen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 23, "src_ref": "And this allows us to find, for example, dual pronouns in Arabic that have relatively high P-CXMI.", "tgt_ref": "Auf diese Weise können wir beispielsweise Dualpronomen im Arabischen finden, die einen relativ hohen P-CXMI aufweisen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 24, "src_ref": "And this can be explained because English doesn't have dual pronouns, so you need context to determine if a pronoun is dual when translating into Arabic.", "tgt_ref": "Dies liegt daran, dass es im Englischen keine Dualpronomen gibt, sodass man den Kontext braucht, um zu bestimmen, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird."}
{"doc_id": "xUDLtuhJUS", "seg_id": 25, "src_ref": "And similarly, we find that certain languages also require context when we want to choose the appropriate verb form.", "tgt_ref": "Ähnlich verhält es sich mit einigen Sprachen, bei denen wir ebenfalls den Kontext benötigen, um die richtige Verbform zu wählen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 26, "src_ref": "We then look at vocabulary items that have high P-CXMI averaged over all of its different occurrences.", "tgt_ref": "Dann schauen wir uns die Vokabeln an, die einen hohen P-CXMI-Wert haben, gemittelt über alle ihre verschiedenen Auftritte."}
{"doc_id": "xUDLtuhJUS", "seg_id": 27, "src_ref": "And this helps us identify cases like the one here, where in Chinese you need context to translate proper nouns to make sure that you're using the same translation within the document.", "tgt_ref": "Und das hilft uns, Fälle wie diesen zu identifizieren, bei denen man im Chinesischen bei der Übersetzung von Eigennamen den Kontext braucht, um sicherzustellen, dass man im Dokument die gleiche Übersetzung verwendet."}
{"doc_id": "xUDLtuhJUS", "seg_id": 28, "src_ref": "And similarly, we find that context is important to translate in the right formality.", "tgt_ref": "Und wir stellen fest, dass der Kontext auch wichtig ist, wenn es darum geht, in der richtigen Form zu übersetzen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 29, "src_ref": "And finally, we look at different individual tokens that have high P-CXMI.", "tgt_ref": "Schließlich untersuchen wir verschiedene einzelne Token, die einen hohen P-CXMI aufweisen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 30, "src_ref": "And this allows us to identify phenomena that cannot really be captured by the word itself, but that's rather expressed in the sentence structure, such as ellipses resolution.", "tgt_ref": "Auf diese Weise können wir Phänomene identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern sich eher in der Satzstruktur ausdrücken, wie zum Beispiel die Auflösung von Ellipsen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 31, "src_ref": "So now we use our findings from our analysis to design a benchmark for document-level translation.", "tgt_ref": "Wir verwenden nun die Ergebnisse unserer Analyse, um einen Benchmark für die Übersetzung auf Dokumentebene zu entwickeln."}
{"doc_id": "xUDLtuhJUS", "seg_id": 32, "src_ref": "For each of the five discourse phenomena we identified, we create taggers to automatically identify words that pertain to the phenomenon.", "tgt_ref": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, haben wir Tagger erstellt, die automatisch Wörter identifizieren, die zu diesem Phänomen gehören."}
{"doc_id": "xUDLtuhJUS", "seg_id": 33, "src_ref": "And we called our tagger the Multilingual Discourse-Aware, or MuDA tagger.", "tgt_ref": "Wir haben unseren Tagger Multilingual Discourse-Aware oder MuDA-Tagger genannt."}
{"doc_id": "xUDLtuhJUS", "seg_id": 34, "src_ref": "We can then also note that different languages have different proportions of these discourse phenomena.", "tgt_ref": "Wir können dann auch sehen, dass die verschiedenen Sprachen unterschiedliche Anteile dieser Diskursphänomene aufweisen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 35, "src_ref": "We then use the MuDA tagger, by applying the tagger on a parallel corpus that we want to use for evaluation and we apply our translation metrics of choice on the context-dependent examples that the MuDA tagger has identified.", "tgt_ref": "Anschließend wenden wir den MuDA-Tagger auf ein Parallelkorpus an, das wir für die Evaluierung verwenden wollen. Dann wenden wir die von uns ausgewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der MuDA-Tagger identifiziert hat."}
{"doc_id": "xUDLtuhJUS", "seg_id": 36, "src_ref": "And finally, we use our benchmark as well as other metrics to evaluate different models on the document-level machine translation.", "tgt_ref": "Schließlich verwenden wir unseren Benchmark und andere Metriken, um verschiedene maschinelle Übersetzungsmodelle auf Dokumentenebene zu evaluieren."}
{"doc_id": "xUDLtuhJUS", "seg_id": 37, "src_ref": "First of all, when we use corpus-level metrics: so for BLEU, we find that context-agnostic models have the best performance.", "tgt_ref": "Zuerst, wenn wir Metriken auf Korpusebene verwenden, wie bei BLEU, sehen wir, dass kontextunabhängige Modelle am besten abschneiden."}
{"doc_id": "xUDLtuhJUS", "seg_id": 38, "src_ref": "But then if we use COMET, context-aware models perform best.", "tgt_ref": "Aber wenn wir dann COMET verwenden, schneiden die kontextabhängigen Modelle am besten ab."}
{"doc_id": "xUDLtuhJUS", "seg_id": 39, "src_ref": "And if we use word f-measure, then models with and without context have comparable performance.", "tgt_ref": "Und wenn wir f-measure verwenden, dann haben kontextabhängige und kontextunabhängige Modelle eine vergleichbare Leistung."}
{"doc_id": "xUDLtuhJUS", "seg_id": 40, "src_ref": "This again demonstrates that it is difficult to determine the best document-level translation system if we use corpus-level metrics alone.", "tgt_ref": "Dies zeigt erneut, dass es schwierig ist, das beste Übersetzungssystem auf Dokumentebene zu bestimmen, wenn wir nur Metriken auf Korpusebene verwenden."}
{"doc_id": "xUDLtuhJUS", "seg_id": 41, "src_ref": "Now, we use the MuDA benchmark to evaluate models and we find that context-aware models are significantly more accurate than models that do not use context for certain discourse phenomena such as formality and lexical cohesion.", "tgt_ref": "Wir verwenden nun den MuDA-Benchmark, um die Modelle zu evaluieren, und stellen fest, dass die kontextbewussten Modelle für bestimmte Diskursphänomene wie Formalität und lexikalische Kohäsion deutlich genauer sind als Modelle, bei denen der Kontext nicht einfließt."}
{"doc_id": "xUDLtuhJUS", "seg_id": 42, "src_ref": "But these models are not much better than models that do not use context on other phenomena like ellipsis, pronouns, and verb form.", "tgt_ref": "Bei anderen Phänomenen wie Ellipsen, Pronomen und Verbformen sind diese Modelle jedoch nicht viel besser als Modelle, bei denen der Kontext einfließt."}
{"doc_id": "xUDLtuhJUS", "seg_id": 43, "src_ref": "So this sort of suggests where we would need to see more progress for document-level translation.", "tgt_ref": "Dies deutet darauf hin, dass bei der Übersetzung auf Dokumentebene noch weitere Fortschritte erzielt werden müssen."}
{"doc_id": "xUDLtuhJUS", "seg_id": 44, "src_ref": "We also compared different commercial systems and our benchmark shows that DeepL is usually more accurate than Google Translate for document-level translation.", "tgt_ref": "Wir haben auch verschiedene kommerzielle Systeme verglichen und unser Benchmark zeigt, dass DeepL bei der Übersetzung auf Dokumentenebene in der Regel genauer ist als Google Translate."}
{"doc_id": "xUDLtuhJUS", "seg_id": 45, "src_ref": "To summarize, we perform a data-driven analysis across 14 language pairs to identify when translations require context and then we use our findings to build a benchmark for document-level machine translation which can help us identify which discourse phenomena models can handle well or not, and which translation systems are good at document-level translation.", "tgt_ref": "Zusammenfassend lässt sich sagen, dass wir eine datenbasierte Analyse für 14 Sprachpaare durchführen, um festzustellen, wann Übersetzungen Kontext benötigen. Anschließend verwenden wir unsere Ergebnisse, um eine Benchmark für die maschinelle Übersetzung auf Dokumentebene zu erstellen, mit deren Hilfe wir feststellen können, mit welchen Diskursphänomenen die Modelle gut oder schlecht umgehen können und welche Übersetzungssysteme gut für die Übersetzung auf Dokumentebene geeignet sind."}
{"doc_id": "xUDLtuhJUS", "seg_id": 46, "src_ref": "Thank you so much for your attention.", "tgt_ref": "Vielen Dank für Ihre Aufmerksamkeit."}
{"doc_id": "xUDLtuhJUS", "seg_id": 47, "src_ref": "See you in Toronto.", "tgt_ref": "Wir sehen uns in Toronto."}
{"doc_id": "csJIsDTYMW", "seg_id": 0, "src_ref": "Hi, I am Yanis Labrak and I will present you our works on \"DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains.\"", "tgt_ref": "Hallo, mein Name ist Yanis Labrak und ich werde unsere Arbeit „DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains“ vorstellen."}
{"doc_id": "csJIsDTYMW", "seg_id": 1, "src_ref": "In this presentation, we first talk about language modeling in healthcare.", "tgt_ref": "In dieser Präsentation werden wir zunächst über Sprachmodellierung im Gesundheitswesen sprechen."}
{"doc_id": "csJIsDTYMW", "seg_id": 2, "src_ref": "Then we will present the main contribution of our article.", "tgt_ref": "Anschließend präsentieren wir den Hauptbeitrag unserer Arbeit."}
{"doc_id": "csJIsDTYMW", "seg_id": 3, "src_ref": "We introduce the first biomedical model in French named DrBERT, which is based on RoBERTa and trained on NACHOS, which is a data set of medical crawled data from the web.", "tgt_ref": "Wir werden das erste biomedizinische Modell in französischer Sprache namens DrBERT vorstellen, das auf RoBERTa basiert und auf NACHOS trainiert wurde, einem Datensatz mit medizinischen Daten, die aus dem Internet gecrawlt wurden."}
{"doc_id": "csJIsDTYMW", "seg_id": 4, "src_ref": "We also introduced a comparison of models with multiple pre-training settings and data sources.", "tgt_ref": "Wir werden auch einen Vergleich von Modellen mit verschiedenen Vortrainingseinstellungen und Datenquellen präsentieren."}
{"doc_id": "csJIsDTYMW", "seg_id": 5, "src_ref": "Then, we present our results on 11 biomedical and clinical downstream tasks in French.", "tgt_ref": "Anschließend präsentieren wir unsere Ergebnisse für 11 biomedizinische und klinische Aufgaben in französischer Sprache."}
{"doc_id": "csJIsDTYMW", "seg_id": 6, "src_ref": "And finally, we conclude about the experiments and give you more details about how to access those models.", "tgt_ref": "Abschließend fassen wir die Experimente zusammen und geben Ihnen weitere Informationen, wie Sie auf die Modelle zugreifen können."}
{"doc_id": "csJIsDTYMW", "seg_id": 7, "src_ref": "Since its release in 2018, BERT has become one of the most effective approach to solve natural language processing tasks and offers huge performance gains compared to historical static and contextualized methods such as Word2vec, fastText, or more.", "tgt_ref": "Seit seiner Veröffentlichung im Jahr 2018 hat sich BERT zu einem der effizientesten Ansätze für die Verarbeitung natürlicher Sprache entwickelt und bietet erhebliche Leistungsverbesserungen im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2vec oder fastText."}
{"doc_id": "csJIsDTYMW", "seg_id": 8, "src_ref": "Since then, this model has been adapted to many other languages, like in French with CamemBERT, and also in domains like biomedical with PubMedBERT and BioBERT and on clinical with ClinicalBERT, but mostly in English.", "tgt_ref": "Seitdem wurde dieses Modell an viele andere Sprachen angepasst, zum Beispiel an Französisch mit CamemBERT, an Domains wie Biomedizin mit PubMedBERT und BioBERT und an die klinische Domain mit ClinicalBERT, aber vor allem an Englisch."}
{"doc_id": "csJIsDTYMW", "seg_id": 9, "src_ref": "Specialized models for other languages are scarce and are often based on continual pre-training due to the lack of in-domain data.", "tgt_ref": "Für andere Sprachen gibt es nur wenige spezialisierte Modelle, die aufgrund des Mangels an Domain-eigenen Daten oft auf kontinuierlichem Vortraining basieren."}
{"doc_id": "csJIsDTYMW", "seg_id": 10, "src_ref": "However, French didn't have any open source model for biomedical until now.", "tgt_ref": "Für Französisch gibt es jedoch noch kein Open-Source-Modell für die Biomedizin."}
{"doc_id": "csJIsDTYMW", "seg_id": 11, "src_ref": "So we ask ourselves a question about what is the most appropriate data sources for a wide range of usage and those crawled data are good substitution for clinical data.", "tgt_ref": "Wir fragen uns also, welche Datenquellen für eine breite Palette von Anwendungen am besten geeignet sind, und diese gecrawlten Daten sind ein guter Ersatz für klinische Daten."}
{"doc_id": "csJIsDTYMW", "seg_id": 12, "src_ref": "To answer this question, we compare DrBERT with our ChuBERT model, which is based on anonymized data obtained from the Nantes University Hospital data warehouse.", "tgt_ref": "Um diese Frage zu beantworten, vergleichen wir DrBERT mit unserem Modell ChuBERT, das auf anonymisierten Daten aus dem Data Warehouse des Universitätsklinikums Nantes basiert."}
{"doc_id": "csJIsDTYMW", "seg_id": 13, "src_ref": "Afterwards, we ask ourselves how much data do we need to train a specialized model on French data?", "tgt_ref": "Dann fragen wir uns: Wie viele Daten brauchen wir, um ein spezialisiertes Modell auf französischen Daten zu trainieren?"}
{"doc_id": "csJIsDTYMW", "seg_id": 14, "src_ref": "Is it 4 gigabytes, 8 gigabytes, or more?", "tgt_ref": "Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"doc_id": "csJIsDTYMW", "seg_id": 15, "src_ref": "To answer this question, we first train and compare four from-scratch models: a first version of DrBERT, with 7 GB of NACHOS; a second version of 4 GB of set of NACHOS; a first version of ChuBERT, which is a clinical model with 4 GB of sentences taken from clinical notes; and a final version of ChuBERT with a mix of 4 GB of set of NACHOS and 4 GB of clinical notes.", "tgt_ref": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf: eine erste Version von DrBERT mit 7 GB NACHOS; eine zweite Version mit 4 GB NACHOS; eine erste Version von ChuBERT, das ist ein klinisches Modell, mit 4 GB klinischen Aufzeichnungen; und eine letzte Version von ChuBERT mit einer Mischung aus 4 GB NACHOS und 4 GB klinischen Aufzeichnungen."}
{"doc_id": "csJIsDTYMW", "seg_id": 16, "src_ref": "In addition to this comparison, we introduced three models trained on continual pre-training to analyze the impact of pre-training strategy.", "tgt_ref": "Zusätzlich zu diesem Vergleich haben wir drei Modelle eingeführt, die mit kontinuierlichem Vortraining trainiert wurden, um die Auswirkungen der Vortrainingsstrategie zu analysieren."}
{"doc_id": "csJIsDTYMW", "seg_id": 17, "src_ref": "One based on the weight of CamemBERT and trained on a 4 GB set of NACHOS.", "tgt_ref": "Ein Modell basiert auf der Gewichtung von CamemBERT und wurde mit einem Satz von 4 GB NACHOS trainiert."}
{"doc_id": "csJIsDTYMW", "seg_id": 18, "src_ref": "Another also based on CamemBERT, but trained this time on the 4 GB of clinical notes and finally, one based on English biomedical model PubMedBERT, and trained on 4 GB of set of NACHOS.", "tgt_ref": "Ein weiteres, das ebenfalls auf CamemBERT basiert, aber dieses Mal auf den 4 GB klinischen Aufzeichnungen trainiert wurde, und schließlich ein weiteres, das auf dem englischen biomedizinischen Modell PubMedBERT basiert und auf einem 4 GB großen Satz von NACHOS trainiert wurde."}
{"doc_id": "csJIsDTYMW", "seg_id": 19, "src_ref": "In total, we have seven models.", "tgt_ref": "Insgesamt verfügen wir also über sieben Modelle."}
{"doc_id": "csJIsDTYMW", "seg_id": 20, "src_ref": "To evaluate our seven models, we gather data for public and private downstream tasks such as named entity recognition, classification, part-of-speech tagging, and question answering.", "tgt_ref": "Um unsere sieben Modelle zu evaluieren, sammeln wir Daten für öffentliche und private nachgeschaltete Aufgaben wie Named Entity Recognition, Klassifikation, Part-of-Speech Tagging und Question Response."}
{"doc_id": "csJIsDTYMW", "seg_id": 21, "src_ref": "These models are compared to six baseline models which are CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT, and ClinicalBERT.", "tgt_ref": "Diese Modelle werden mit sechs Basismodellen verglichen: CamemBERT OSCAR 138 GB, CamemBERT OSCAR 4 GB, CamemBERT CCNET 4 GB, PubMedBERT, BioBERT und ClinicalBERT."}
{"doc_id": "csJIsDTYMW", "seg_id": 22, "src_ref": "The evaluation highlights that models performed best on the task with data of the same nature as those on which the model has been trained.", "tgt_ref": "Die Auswertung zeigt, dass die Modelle am besten abschneiden, wenn sie mit Daten desselben Typs arbeiten, auf dem das Modell trainiert wurde."}
{"doc_id": "csJIsDTYMW", "seg_id": 23, "src_ref": "However, we can observe that data from heterogeneous sources appear to be more versatile.", "tgt_ref": "Wir können jedoch feststellen, dass Daten aus heterogenen Quellen vielseitiger zu sein scheinen."}
{"doc_id": "csJIsDTYMW", "seg_id": 24, "src_ref": "We also observe that using more data translated to better performance.", "tgt_ref": "Wir beobachten auch, dass die Verwendung von mehr Daten zu einer besseren Leistung führt."}
{"doc_id": "csJIsDTYMW", "seg_id": 25, "src_ref": "Overall, from-scratch pre-training seems to obtain higher performance on most of the tasks.", "tgt_ref": "Insgesamt scheint das Vortraining bei den meisten Aufgaben zu einer besseren Leistung zu führen."}
{"doc_id": "csJIsDTYMW", "seg_id": 26, "src_ref": "However, our experiment on control pre-training using the weight and tokenization of CamemBERT trained on the four GB subset of NACHOS showed comparable results to those obtained with DrBERT 4 GB from-scratch.", "tgt_ref": "Unser Kontrollexperiment zum Vortraining mit der Gewichtung und Tokenisierung von CamemBERT, trainiert auf der 4 GB Untermenge von NACHOS, zeigte jedoch vergleichbare Ergebnisse wie mit nicht vortrainierten 4 GB DrBERT."}
{"doc_id": "csJIsDTYMW", "seg_id": 27, "src_ref": "Which is not the case for the model based on CamemBERT weights and tokenizer, which suffer from stability issues.", "tgt_ref": "Dies ist nicht der Fall für das Modell, das auf den CamemBERT-Gewichten und dem Tokenisierer basiert, bei denen Stabilitätsprobleme bestehen."}
{"doc_id": "csJIsDTYMW", "seg_id": 28, "src_ref": "Finally, as a conclusion our proper system offered better performance on nine of the 11 downstream tasks and surpassed globally the result of the generic model, here CamemBERT.", "tgt_ref": "Schließlich kommen wir zu dem Schluss, dass unser dediziertes System in neun der elf Downstream-Aufgaben eine bessere Leistung erbringt und insgesamt das Ergebnis des generischen Modells, in diesem Fall CamemBERT, übertrifft."}
{"doc_id": "csJIsDTYMW", "seg_id": 29, "src_ref": "We are also observing that more specialized data is better, but it doesn't scale well.", "tgt_ref": "Wir stellen auch fest, dass mehr spezialisierte Daten besser sind, aber nicht gut skalieren."}
{"doc_id": "csJIsDTYMW", "seg_id": 30, "src_ref": "All the pre-trained model obtained from NACHOS are freely available on Hugging Face, and under the MIT license, and all the training scripts are on our GitHub repository.", "tgt_ref": "Alle vortrainierten Modelle, die wir von NACHOS erhalten haben, sind auf Hugging Face und unter der MIT-Lizenz frei verfügbar und alle Trainingsskripte sind in unserem GitHub Repository zu finden."}
{"doc_id": "csJIsDTYMW", "seg_id": 31, "src_ref": "So thank you for this presentation, and we are looking forward to exchange at the poster session in Toronto.", "tgt_ref": "Vielen Dank für diese Präsentation und wir freuen uns auf den Austausch bei der Postersession in Toronto."}
{"doc_id": "ICWfTnUMio", "seg_id": 0, "src_ref": "Hi!", "tgt_ref": "Hallo!"}
{"doc_id": "ICWfTnUMio", "seg_id": 1, "src_ref": "My name is Matthias Lindemann, and today I'm going to give you a brief introduction to our paper on \"Compositional Generalization without Trees using Multiset Tagging and Latent Permutations\".", "tgt_ref": "Mein Name ist Matthias Lindemann und ich werde heute eine kurze Einführung in unsere Arbeit „Compositional Generalization without Trees using Multiset Tagging and Latent Permutations“ geben."}
{"doc_id": "ICWfTnUMio", "seg_id": 2, "src_ref": "This is joint work with my advisors Alexander Koller and Ivan Titov.", "tgt_ref": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Koller und Ivan Titov."}
{"doc_id": "ICWfTnUMio", "seg_id": 3, "src_ref": "Compositional generalization can be understood as the ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.", "tgt_ref": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lerners verstanden werden, mit tieferen Rekursionen und unsichtbaren Kompositionen von Phrasen umzugehen, die während des Trainings einzeln gesehen wurden."}
{"doc_id": "ICWfTnUMio", "seg_id": 4, "src_ref": "In the context of semantic parsing, testing for compositional generalization might look like this.", "tgt_ref": "Im Kontext des semantischen Parsens könnte ein Test der kompositionellen Generalisierung wie folgt aussehen."}
{"doc_id": "ICWfTnUMio", "seg_id": 5, "src_ref": "As usual, we have a training set of utterances.", "tgt_ref": "Wie üblich haben wir eine Trainingsmenge von Äußerungen."}
{"doc_id": "ICWfTnUMio", "seg_id": 6, "src_ref": "In this case, \"The girl slept.\"", "tgt_ref": "In diesem Fall: „Das Mädchen schlief“."}
{"doc_id": "ICWfTnUMio", "seg_id": 7, "src_ref": "And \"Mary knew that the girl slept.\"", "tgt_ref": "Und: „Maria wusste, dass das Mädchen schlief“."}
{"doc_id": "ICWfTnUMio", "seg_id": 8, "src_ref": "These utterances are paired with logical forms that represent core aspects of their meaning.", "tgt_ref": "Diesen Äußerungen werden logische Formen zugeordnet, die Kernaspekte ihrer Bedeutung darstellen."}
{"doc_id": "ICWfTnUMio", "seg_id": 9, "src_ref": "In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms.", "tgt_ref": "Im Gegensatz zur Standardauswertung des maschinellen Lernens ist die Testmenge nicht gleichverteilt, sondern enthält strukturell unsichtbare logische Formen."}
{"doc_id": "ICWfTnUMio", "seg_id": 10, "src_ref": "In this example, the model has seen shallow recursion during training and is tested on an example with deeper recursion.", "tgt_ref": "In diesem Beispiel hat das Modell während des Trainings eine flache Rekursion gesehen und wird an einem Beispiel mit einer tieferen Rekursion getestet."}
{"doc_id": "ICWfTnUMio", "seg_id": 11, "src_ref": "Naive seq2seq models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.", "tgt_ref": "Naive seq2seq-Modelle haben mit dieser Art von Generalisierung außerhalb der Verteilung zu kämpfen und produzieren oft Ausgaben, die nicht mit den Eingaben übereinstimmen."}
{"doc_id": "ICWfTnUMio", "seg_id": 12, "src_ref": "In particular, they often fail to reproduce the systematic correspondences between input and output, such as those that are color-coded in the example.", "tgt_ref": "Insbesondere sind sie oft nicht in der Lage, systematische Korrespondenzen zwischen Input und Output zu reproduzieren, wie diejenigen, die im Beispiel farblich markiert sind."}
{"doc_id": "ICWfTnUMio", "seg_id": 13, "src_ref": "A popular method to address this is to integrate trees into the models.", "tgt_ref": "Eine beliebte Methode, um dieses Problem zu lösen, ist die Einbeziehung von Bäumen in die Modelle."}
{"doc_id": "ICWfTnUMio", "seg_id": 14, "src_ref": "The trees are intended to capture the compositional process that relates utterances with the logical forms.", "tgt_ref": "Die Bäume sollen den Kompositionsprozess erfassen, der Aussagen mit logischen Formen in Beziehung setzt."}
{"doc_id": "ICWfTnUMio", "seg_id": 15, "src_ref": "This works well, but trees are usually not given and need to be obtained somehow.", "tgt_ref": "Das funktioniert gut, aber Bäume sind in der Regel nicht gegeben und müssen irgendwie beschafft werden."}
{"doc_id": "ICWfTnUMio", "seg_id": 16, "src_ref": "This can be complicated and sometimes a computationally expensive process.", "tgt_ref": "Dies kann ein komplizierter und manchmal rechenintensiver Prozess sein."}
{"doc_id": "ICWfTnUMio", "seg_id": 17, "src_ref": "Typically, this involves considerable formalism-specific pre-processing of the logical forms, for example, to handle variable symbols.", "tgt_ref": "In der Regel ist eine umfangreiche formalismusspezifische Vorverarbeitung der logischen Formen erforderlich, zum Beispiel um mit variablen Symbolen umgehen zu können."}
{"doc_id": "ICWfTnUMio", "seg_id": 18, "src_ref": "Obtaining trees may also involve specialized grammar-induction procedures.", "tgt_ref": "Die Extraktion von Bäumen kann auch spezielle Grammatikinduktionsverfahren umfassen."}
{"doc_id": "ICWfTnUMio", "seg_id": 19, "src_ref": "In this paper, we don't use trees and introduce a neural seq2seq model that directly models the correspondences between fragments of the input and fragments of the output.", "tgt_ref": "In dieser Arbeit verwenden wir keine Bäume und führen ein neuronales seq2seq-Modell ein, das direkt die Korrespondenzen zwischen Eingabe- und Ausgabefragmenten modelliert."}
{"doc_id": "ICWfTnUMio", "seg_id": 20, "src_ref": "For the first time, we show strong generalization to deeper recursion without relying on trees.", "tgt_ref": "Zum ersten Mal zeigen wir eine starke Generalisierung auf tiefere Rekursionen, ohne Bäume zu verwenden."}
{"doc_id": "ICWfTnUMio", "seg_id": 21, "src_ref": "Our approach predicts the output from the input in two steps.", "tgt_ref": "Unser Ansatz sagt den Output aus dem Input in zwei Schritten voraus."}
{"doc_id": "ICWfTnUMio", "seg_id": 22, "src_ref": "First, we tag each input token with an unordered multiset of tokens that will appear in the output.", "tgt_ref": "Im ersten Schritt markieren wir jedes Eingabe-Token mit einer ungeordneten Menge von Token, die in der Ausgabe vorkommen werden."}
{"doc_id": "ICWfTnUMio", "seg_id": 23, "src_ref": "After the first step, we have all the right tokens, but they're not ordered.", "tgt_ref": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"doc_id": "ICWfTnUMio", "seg_id": 24, "src_ref": "That's why in the second step we use another model to predict a permutation to put them into the right order.", "tgt_ref": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, die sie in die richtige Reihenfolge bringt."}
{"doc_id": "ICWfTnUMio", "seg_id": 25, "src_ref": "We introduce a new method to predict the permutation that does not put any hard constraints on the possible permutations.", "tgt_ref": "Wir führen eine neue Methode zur Vorhersage der Permutation ein, die den möglichen Permutationen keine harten Beschränkungen auferlegt."}
{"doc_id": "ICWfTnUMio", "seg_id": 26, "src_ref": "This makes our approach quite flexible and expressive.", "tgt_ref": "Dadurch wird unser Ansatz sehr flexibel und leistungsfähig."}
{"doc_id": "ICWfTnUMio", "seg_id": 27, "src_ref": "Conceptually, our permutation model works roughly like this.", "tgt_ref": "Konzeptionell funktioniert unser Permutationsmodell ungefähr so."}
{"doc_id": "ICWfTnUMio", "seg_id": 28, "src_ref": "We go from left to right over the output and determine which multiset token to put in every position.", "tgt_ref": "Wir gehen die Ausgabe von links nach rechts durch und entscheiden, welches Multiset-Token wir an die jeweilige Position setzen."}
{"doc_id": "ICWfTnUMio", "seg_id": 29, "src_ref": "For the first output position, we simply select one, as highlighted in red.", "tgt_ref": "Für die erste Ausgabeposition wählen wir einfach eine, die rot markiert ist."}
{"doc_id": "ICWfTnUMio", "seg_id": 30, "src_ref": "Then we jump to the next multiset token, to determine the second token in the output.", "tgt_ref": "Dann springen wir zum nächsten Multiset-Token, um das zweite Token in der Ausgabe zu bestimmen."}
{"doc_id": "ICWfTnUMio", "seg_id": 31, "src_ref": "We determine the third token in the output in a similar way by jumping to another multiset token.", "tgt_ref": "Das dritte Token in der Ausgabe bestimmen wir auf die gleiche Weise, indem wir zu einem weiteren Multiset-Token springen."}
{"doc_id": "ICWfTnUMio", "seg_id": 32, "src_ref": "We continue this process until every token from the first stage has been visited exactly once.", "tgt_ref": "So geht es weiter, bis jedes Token in der ersten Phase genau einmal besucht wurde."}
{"doc_id": "ICWfTnUMio", "seg_id": 33, "src_ref": "To give you a teaser of the experimental results, here we compare our method with other treeless models on the COGS benchmark.", "tgt_ref": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumlosen Modellen im COGS Benchmark."}
{"doc_id": "ICWfTnUMio", "seg_id": 34, "src_ref": "Our model outperforms the others by a large margin on generalization to deeper recursion.", "tgt_ref": "Unser Modell übertrifft die anderen bei der Generalisierung auf tiefere Rekursionen bei weitem."}
{"doc_id": "ICWfTnUMio", "seg_id": 35, "src_ref": "Some other kinds of structural generalization remain very challenging, though.", "tgt_ref": "Einige andere Arten der strukturellen Generalisierung bleiben jedoch eine große Herausforderung."}
{"doc_id": "ICWfTnUMio", "seg_id": 36, "src_ref": "In our paper, we solve a couple of interesting technical challenges.", "tgt_ref": "In unserem Beitrag lösen wir einige interessante technische Herausforderungen."}
{"doc_id": "ICWfTnUMio", "seg_id": 37, "src_ref": "First of all, the alignment between input and output is not given in the training data.", "tgt_ref": "Erstens ist das Alignment zwischen Input und Output in den Trainingsdaten nicht gegeben."}
{"doc_id": "ICWfTnUMio", "seg_id": 38, "src_ref": "As a consequence, for a given token we don't know which multiset it came from, which poses a challenge for training.", "tgt_ref": "Daher ist für ein bestimmtes Token nicht bekannt, aus welchem Multiset es stammt, was eine Herausforderung für das Training darstellt."}
{"doc_id": "ICWfTnUMio", "seg_id": 39, "src_ref": "In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent.", "tgt_ref": "Außerdem gibt es manchmal mehrere Permutationen, die den Daten entsprechen, aber die linguistisch korrekte ist nicht bekannt."}
{"doc_id": "ICWfTnUMio", "seg_id": 40, "src_ref": "We address this by inducing the alignment as part of the training.", "tgt_ref": "Wir lösen dieses Problem, indem wir das Alignment als Teil des Trainings durchführen."}
{"doc_id": "ICWfTnUMio", "seg_id": 41, "src_ref": "Our permutation method is very flexible, but it brings the challenge that finding the highest-scoring permutation is NP-hard.", "tgt_ref": "Unsere Permutationsmethode ist sehr flexibel, aber die Herausforderung besteht darin, dass das Auffinden der Permutation mit der höchsten Punktzahl NP-schwer ist."}
{"doc_id": "ICWfTnUMio", "seg_id": 42, "src_ref": "That's because this is related to the \"Traveling Salesman\" problem.", "tgt_ref": "Dies ist auf das Problem des „Traveling Salesman“ zurückzuführen."}
{"doc_id": "ICWfTnUMio", "seg_id": 43, "src_ref": "We approximate this with a GPU-friendly continuous relaxation that also allows us to backpropagate through the solution and learn the linguistically more plausible permutations.", "tgt_ref": "Wir nähern uns diesem Problem mit einer GPU-freundlichen kontinuierlichen Relaxation, die es uns auch erlaubt, die Lösung rückwärts zu verarbeiten und die linguistisch plausibleren Permutationen zu lernen."}
{"doc_id": "ICWfTnUMio", "seg_id": 44, "src_ref": "If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.", "tgt_ref": "Wenn Sie mehr über unsere Experimente und unsere Herangehensweise an diese Herausforderungen erfahren möchten, werfen Sie einen Blick auf unsere Arbeit oder besuchen Sie unser Poster."}
{"doc_id": "MmiKtcykVs", "seg_id": 0, "src_ref": "Hello everyone, I'm Akshatha, and today my co-author Martin and I are presenting our work \"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources.\"", "tgt_ref": "Hallo zusammen, ich bin Akshatha und heute stellen mein Co-Autor Martin und ich unsere Arbeit „The KITMUS Test: Assessing Knowledge Integration from Multiple Sources“ vor."}
{"doc_id": "MmiKtcykVs", "seg_id": 1, "src_ref": "This work is a collaboration between McGill University, Mila, and Microsoft Research.", "tgt_ref": "Diese Arbeit ist eine Kooperation zwischen der McGill University, Mila und Microsoft Research."}
{"doc_id": "MmiKtcykVs", "seg_id": 2, "src_ref": "Natural language understanding models draw on a variety of knowledge sources, such as knowledge contained in their parameters, usually acquired by a pretraining, and knowledge given in inputs at inference time.", "tgt_ref": "Modelle zum Verstehen natürlicher Sprache stützen sich auf eine Vielzahl von Wissensquellen, zum Beispiel das in ihren Parametern enthaltene Wissen, das normalerweise durch vorheriges Training erworben wird, und das Wissen, das in den Eingaben zur Inferenzzeit enthalten ist."}
{"doc_id": "MmiKtcykVs", "seg_id": 3, "src_ref": "Recent works in tasks like question answering show that models can use pretrained-time knowledge to solve the task.", "tgt_ref": "Jüngste Arbeiten zu Aufgaben wie dem Beantworten von Fragen haben gezeigt, dass Modelle vortrainiertes Wissen nutzen können, um die jeweilige Aufgabe zu lösen."}
{"doc_id": "MmiKtcykVs", "seg_id": 4, "src_ref": "But natural language understanding often requires knowledge that is also supplied at inference time.", "tgt_ref": "Das Verstehen natürlicher Sprache erfordert jedoch häufig Wissen, das auch während der Inferenzzeit zur Verfügung steht."}
{"doc_id": "MmiKtcykVs", "seg_id": 5, "src_ref": "For example, in the sentence, \"John saw the newly elected president on TV.\"", "tgt_ref": "Zum Beispiel in dem Satz „John hat den neu gewählten Präsidenten im Fernsehen gesehen“."}
{"doc_id": "MmiKtcykVs", "seg_id": 6, "src_ref": "Pretrained parameters can contain information about what presidents do and what a TV is but they cannot reliably know who this instance-specific entity \"John\" is, or who the new president is, because the president might have changed since pretraining.", "tgt_ref": "Vortrainierte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein Fernseher ist, aber sie können nicht zuverlässig wissen, wer diese instanzspezifische Entität „John“ ist oder wer der neue Präsident ist, da sich der Präsident seit dem Vortraining geändert haben kann."}
{"doc_id": "MmiKtcykVs", "seg_id": 7, "src_ref": "Therefore, successful models for knowledge-intensive NLU tasks require the ability to integrate and use both pretrain-time and inference-time knowledge.", "tgt_ref": "Erfolgreiche Modelle für wissensintensive NLU-Aufgaben erfordern daher die Fähigkeit, sowohl das Wissen zum Zeitpunkt des Vortrainings als auch das Wissen zur Inferenzzeit zu integrieren und zu nutzen."}
{"doc_id": "MmiKtcykVs", "seg_id": 8, "src_ref": "In this work, we propose a diagnostic test suite for knowledge integration.", "tgt_ref": "In dieser Arbeit schlagen wir eine diagnostische Testsuite für die Wissensintegration vor."}
{"doc_id": "MmiKtcykVs", "seg_id": 9, "src_ref": "We introduce a coreference resolution task, designed to probe for the ability to draw on knowledge available in different sources.", "tgt_ref": "Wir führen eine Koreferenz-Auflösungsaufgabe ein, um die Fähigkeit zu testen, auf Wissen aus verschiedenen Quellen zuzugreifen."}
{"doc_id": "MmiKtcykVs", "seg_id": 10, "src_ref": "We evaluate the data set with human study participants and established coreference resolution models.", "tgt_ref": "Wir evaluieren den Datensatz mit menschlichen Teilnehmern und etablierten Modellen zur Koreferenzauflösung."}
{"doc_id": "MmiKtcykVs", "seg_id": 11, "src_ref": "Here is an example from our data set.", "tgt_ref": "Hier ein Beispiel aus unserem Datensatz."}
{"doc_id": "MmiKtcykVs", "seg_id": 12, "src_ref": "Servin is a judge.", "tgt_ref": "Servin ist Richter."}
{"doc_id": "MmiKtcykVs", "seg_id": 13, "src_ref": "Kea is a Baker.", "tgt_ref": "Kea ist Bäcker."}
{"doc_id": "MmiKtcykVs", "seg_id": 14, "src_ref": "Servin and Kea met at a park.", "tgt_ref": "Servin und Kea trafen sich in einem Park."}
{"doc_id": "MmiKtcykVs", "seg_id": 15, "src_ref": "After a long day at work deciding cases in a law court, he was happy to relax.", "tgt_ref": "Nach einem langen Arbeitstag, an dem er Fälle vor Gericht verhandelt hat, wollte er sich entspannen."}
{"doc_id": "MmiKtcykVs", "seg_id": 16, "src_ref": "The task here is to identify the correct entity that the pronoun \"he\" refers to, which in this case is Servin.", "tgt_ref": "Die Aufgabe besteht darin, die richtige Entität zu identifizieren, auf die sich das Pronomen „er“ bezieht, in diesem Fall Servin."}
{"doc_id": "MmiKtcykVs", "seg_id": 17, "src_ref": "The resolution of a given pronoun requires two types of information.", "tgt_ref": "Die Auflösung eines bestimmten Pronomens erfordert zwei Arten von Informationen."}
{"doc_id": "MmiKtcykVs", "seg_id": 18, "src_ref": "First, entity-specific knowledge such as \"Servin is a judge.\"", "tgt_ref": "Erstens entitätsspezifisches Wissen wie „Servin ist Richter“."}
{"doc_id": "MmiKtcykVs", "seg_id": 19, "src_ref": "And second, background knowledge such as \"Judges decide cases in law courts.\"", "tgt_ref": "Und zweitens Hintergrundwissen wie „Richter entscheiden Fälle in Gerichten“."}
{"doc_id": "MmiKtcykVs", "seg_id": 20, "src_ref": "Generally, background knowledge is learned during the pretraining of large language models, while entity-specific knowledge is typically observed at inference time.", "tgt_ref": "Im Allgemeinen wird das Hintergrundwissen während des Vortrainings von Large Language Models erworben, während das entitätsspezifische Wissen typischerweise zum Zeitpunkt der Inferenz beobachtet wird."}
{"doc_id": "MmiKtcykVs", "seg_id": 21, "src_ref": "We vary the availability of these two pieces of information such that it may either be found in a single source, or in multiple sources.", "tgt_ref": "Wir variieren die Verfügbarkeit dieser beiden Arten von Informationen, sodass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können."}
{"doc_id": "MmiKtcykVs", "seg_id": 22, "src_ref": "We have defined three settings of KITMUS.", "tgt_ref": "Wir haben drei Einstellungen für KITMUS definiert."}
{"doc_id": "MmiKtcykVs", "seg_id": 23, "src_ref": "First, we have the typical setting: \"Background-Pretrain\", where background knowledge is assumed to be available at pretrain time.", "tgt_ref": "Erstens haben wir die typische Einstellung „Background-Pretrain“, bei der wir davon ausgehen, dass das Hintergrundwissen zum Zeitpunkt des Vortrainings verfügbar ist."}
{"doc_id": "MmiKtcykVs", "seg_id": 24, "src_ref": "Second, there's a \"Background-Both\" setting, where background knowledge is available both at pretrain time and inference time.", "tgt_ref": "Zweitens gibt es die Einstellung „Background-Both“, bei der das Hintergrundwissen sowohl zum Zeitpunkt des Vortrainings als auch zum Zeitpunkt der Inferenz verfügbar ist."}
{"doc_id": "MmiKtcykVs", "seg_id": 25, "src_ref": "Lastly, the \"Background-Inference\" setting, where both knowledge types are available only at inference time.", "tgt_ref": "Schließlich gibt es noch die Einstellung „Background-Inference“, bei der beide Arten von Wissen nur zum Zeitpunkt der Inferenz verfügbar sind."}
{"doc_id": "MmiKtcykVs", "seg_id": 26, "src_ref": "This last setting is especially interesting, since it simulates the case where the background knowledge necessary to solve a task is not part of the pretrain data of models.", "tgt_ref": "Dieser letzte Parameter ist von besonderem Interesse, da er den Fall simuliert, dass das für die Lösung einer Aufgabe erforderliche Hintergrundwissen in den Vortrainingsdaten der Modelle nicht enthalten ist."}
{"doc_id": "MmiKtcykVs", "seg_id": 27, "src_ref": "For example, because new occupations have developed since the time of pretraining.", "tgt_ref": "Zum Beispiel, weil sich seit der Zeit des Vortrainings neue Berufe herausgebildet haben."}
{"doc_id": "MmiKtcykVs", "seg_id": 28, "src_ref": "Here's an example of how we control the availability of facts in the true sources.", "tgt_ref": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in realen Quellen kontrollieren."}
{"doc_id": "MmiKtcykVs", "seg_id": 29, "src_ref": "In the Background-Pretrain setting, we assume that the background knowledge \"Politicians seek elected seats in government\" is contained in the pretrained parameters and in inference-time context we provide the entity-specific knowledge \"Chichester is a politician.\"", "tgt_ref": "In der Einstellung Background-Pretrain nehmen wir an, dass das Hintergrundwissen „Politiker streben nach gewählten Sitzen in der Regierung“ in den vortrainierten Parametern enthalten ist, und im Kontext der Inferenzzeit liefern wir das entitätsspezifische Wissen „Chichester ist ein Politiker“."}
{"doc_id": "MmiKtcykVs", "seg_id": 30, "src_ref": "In the Background-Both setting, we additionally provide not only entity-specific but also background knowledge about politicians in their inference-time context.", "tgt_ref": "In der Einstellung Background-Both liefern wir nicht nur entitätsspezifisches Wissen, sondern auch Hintergrundwissen über Politiker im Kontext der Inferenzzeit."}
{"doc_id": "MmiKtcykVs", "seg_id": 31, "src_ref": "In the Background-Inference setting, we provide the fictional occupation \"mirituer\" instead of politician because \"mirituer\" is unlikely to be contained in the pretrained parameters.", "tgt_ref": "In der Einstellung Background-Inference stellen wir den fiktiven Beruf „Mirituer“ anstelle von „Politiker“ zur Verfügung, da es unwahrscheinlich ist, dass „Mirituer“ in den vortrainierten Parametern enthalten ist."}
{"doc_id": "MmiKtcykVs", "seg_id": 32, "src_ref": "We evaluate the data set both with human study participants, and established coreference resolution models.", "tgt_ref": "Wir evaluieren den Datensatz sowohl mit menschlichen Teilnehmern als auch mit etablierten Modellen zur Koreferenzauflösung."}
{"doc_id": "MmiKtcykVs", "seg_id": 33, "src_ref": "In this figure, we show the results of the best-performing models on the most difficult variant of the Background-Pretrain setting.", "tgt_ref": "In dieser Abbildung zeigen wir die Ergebnisse der leistungsstärksten Modelle für die schwierigste Variante der Einstellung Background-Pretrain."}
{"doc_id": "MmiKtcykVs", "seg_id": 34, "src_ref": "Without task-specific training on KITMUS, both models do not perform well.", "tgt_ref": "Ohne aufgabenspezifisches Training auf KITMUS schneiden beide Modelle nicht gut ab."}
{"doc_id": "MmiKtcykVs", "seg_id": 35, "src_ref": "When trained on KITMUS, however, both C2F and BERT4Coref perform significantly better than the random choice.", "tgt_ref": "Wenn sie jedoch auf KITMUS trainiert werden, schneiden sowohl C2F als auch BERT4Coref deutlich besser ab als die Zufallsauswahl."}
{"doc_id": "MmiKtcykVs", "seg_id": 36, "src_ref": "This suggests that when trained on generic reference resolution data sets, most learn to exploit surface cues, which are not useful when testing on KITMUS where such queues have been removed.", "tgt_ref": "Dies deutet darauf hin, dass die meisten Modelle, wenn sie auf generischen Referenzresolutionsdatensätzen trainiert werden, lernen, Oberflächenmerkmale zu verwenden, die nicht nützlich sind, wenn sie auf KITMUS getestet werden, bei denen solche Merkmale entfernt wurden."}
{"doc_id": "MmiKtcykVs", "seg_id": 37, "src_ref": "Additional experiments with fictional knowledge indicated even the best performing models, cannot reliably integrate backward knowledge provided only at inference time.", "tgt_ref": "Zusätzliche Experimente mit fiktivem Wissen haben gezeigt, dass selbst die leistungsfähigsten Modelle nicht in der Lage sind, retrospektives Wissen zum Zeitpunkt der Inferenz zuverlässig zu integrieren."}
{"doc_id": "MmiKtcykVs", "seg_id": 38, "src_ref": "To summarize the main takeaways of our paper, many coreference resolution models appear unable to reason over knowledge from different sources without task-specific training.", "tgt_ref": "Um die wichtigsten Ergebnisse unserer Arbeit zusammenzufassen: Viele Modelle zur Koreferenzauflösung scheinen ohne aufgabenspezifisches Training nicht in der Lage zu sein, Wissen aus verschiedenen Quellen zu verarbeiten."}
{"doc_id": "MmiKtcykVs", "seg_id": 39, "src_ref": "However, with task-specific training, some models successfully integrate knowledge from multiple sources.", "tgt_ref": "Mit aufgabenspezifischem Training gelingt es jedoch einigen Modellen, Wissen aus verschiedenen Quellen zu integrieren."}
{"doc_id": "MmiKtcykVs", "seg_id": 40, "src_ref": "Still, even the best-performing models seem to have difficulties with reliably integrating backward knowledge presented only at inference time.", "tgt_ref": "Allerdings scheinen selbst die leistungsfähigsten Modelle Schwierigkeiten zu haben, retrospektives Wissen, das erst zum Zeitpunkt der Inferenz präsentiert wird, zuverlässig zu integrieren."}
{"doc_id": "MmiKtcykVs", "seg_id": 41, "src_ref": "If you're interested in more details, please see our paper and check out the data set and code on GitHub.", "tgt_ref": "Wenn Sie an weiteren Details interessiert sind, lesen Sie bitte unsere Arbeit und schauen Sie sich den Datensatz und den Code auf GitHub an."}
{"doc_id": "MmiKtcykVs", "seg_id": 42, "src_ref": "Thanks for listening.", "tgt_ref": "Vielen Dank fürs Zuhören."}
{"doc_id": "JRrbTnEZbF", "seg_id": 0, "src_ref": "Hi, I'm Myra and today I'll be talking about our paper \"Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models.\"", "tgt_ref": "Hallo, mein Name ist Myra und ich werde heute über unsere Arbeit „Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models“ sprechen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 1, "src_ref": "This work is done in collaboration with Esin Durmus and Dan Jurafsky.", "tgt_ref": "Es handelt sich dabei eine Zusammenarbeit mit Esin Durmus und Dan Jurafsky."}
{"doc_id": "JRrbTnEZbF", "seg_id": 2, "src_ref": "In recent years, many have documented the prevalence of social bias and stereotypes in large language models, or LLMs.", "tgt_ref": "In den letzten Jahren haben viele die Prävalenz von sozialen Vorurteilen und Stereotypen in großen Sprachmodellen (LLMs) dokumentiert."}
{"doc_id": "JRrbTnEZbF", "seg_id": 3, "src_ref": "However, these measures have various limitations.", "tgt_ref": "Diese Messungen weisen jedoch einige Einschränkungen auf."}
{"doc_id": "JRrbTnEZbF", "seg_id": 4, "src_ref": "They usually rely on hand-constructed data sets that are very time-consuming to curate and they also usually only. measure very specific stereotypes, meaning that they don't generalize well to other demographics or contexts, or they simply capture very general broad associations, like negative associations with particular groups.", "tgt_ref": "Sie basieren in der Regel auf manuell erstellten Datensätzen, deren Zusammenstellung sehr zeitaufwändig ist, und sie tendieren dazu, nur sehr spezifische Stereotypen zu messen, was bedeutet, dass sie nicht gut auf andere demografische Gruppen oder Kontexte verallgemeinert werden können, oder sie erfassen einfach sehr allgemeine Assoziationen, z. B. negative Assoziationen mit bestimmten Gruppen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 5, "src_ref": "Furthermore, most work in this space doesn't account for intersectionality, which is the notion that multi-faceted social identities can compound biases and be unique loci of harm.", "tgt_ref": "Darüber hinaus berücksichtigen die meisten Arbeiten in diesem Bereich nicht die Intersektionalität, das heißt die Idee, dass mehrere soziale Identitäten Vorurteile verstärken und einzigartige Orte der Benachteiligung sein können."}
{"doc_id": "JRrbTnEZbF", "seg_id": 6, "src_ref": "To overcome these limitations, we rely on the property that these newer instruction-tuned LLMs are very good at responding to instructions and prompts.", "tgt_ref": "Um diese Einschränkungen zu überwinden, machen wir uns die Tatsache zunutze, dass diese neueren LLMs sehr gut auf Anweisungen und Prompts reagieren können."}
{"doc_id": "JRrbTnEZbF", "seg_id": 7, "src_ref": "So we can ask the model to generate a persona, which is a depiction of an imagined individual using a prompt like \"Imagine you are an Asian woman.", "tgt_ref": "Beispielsweise können wir das Modell auffordern, eine Persona zu erstellen, das heißt die Darstellung einer imaginären Person, indem wir einen Prompt wie „Stellen Sie sich vor, Sie sind eine asiatische Frau."}
{"doc_id": "JRrbTnEZbF", "seg_id": 8, "src_ref": "Describe yourself.\".", "tgt_ref": "Beschreiben Sie sich selbst“ eingeben."}
{"doc_id": "JRrbTnEZbF", "seg_id": 9, "src_ref": "And we can immediately see that this is very generalizable to any demographic because we can just specify whatever identity marker that we want into this prompt.", "tgt_ref": "Und wir können sofort sehen, dass dies für jede Bevölkerungsgruppe verallgemeinerbar ist, da wir jedes Identitätsmerkmal in diesen Prompt einfügen können."}
{"doc_id": "JRrbTnEZbF", "seg_id": 10, "src_ref": "So here are some example generations from GPT-4.", "tgt_ref": "Hier sind also einige Beispielgenerationen von GPT-4."}
{"doc_id": "JRrbTnEZbF", "seg_id": 11, "src_ref": "Immediately we see that, while the outputs aren't overtly negative or toxic in the traditional sense of these words, there are some interesting patterns.", "tgt_ref": "Wir können sofort erkennen, dass die Ergebnisse nicht eindeutig negativ oder toxisch im traditionellen Sinne dieser Wörter sind, aber es gibt einige interessante Muster."}
{"doc_id": "JRrbTnEZbF", "seg_id": 12, "src_ref": "The Asian woman is depicted as unassuming; the Middle-Eastern woman is referred to using words like exotic and like, referring to a mesmerizing region.", "tgt_ref": "Die asiatische Frau wird als bescheiden dargestellt; die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch beschrieben und es wird bei ihr auf eine faszinierende Region hingewiesen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 13, "src_ref": "And both of the women of color personas make references to ancestry while the white man persona has nothing of the sort.", "tgt_ref": "Und die beiden Personas der Women-of-Colour verweisen auf ihre Abstammung, während die des weißen Mannes dies nicht tut."}
{"doc_id": "JRrbTnEZbF", "seg_id": 14, "src_ref": "To capture these patterns, our method has two parts.", "tgt_ref": "Unsere Methode zur Erfassung dieser Muster besteht aus zwei Teilen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 15, "src_ref": "The first one is generating these personas.", "tgt_ref": "Der erste Teil besteht in der Erstellung der Personas."}
{"doc_id": "JRrbTnEZbF", "seg_id": 16, "src_ref": "Our prompts to generate these personas were inspired by a study where they gave these prompts to human subjects, finding that by giving it to human subjects, they also were able to surface racial stereotypes.", "tgt_ref": "Unsere Prompts für die Erstellung dieser Personas wurden von einer Studie inspiriert, in der diese Prompts menschlichen Teilnehmern vorgelegt wurden und in der festgestellt wurde, dass dadurch auch rassistische Stereotypen aufgedeckt werden konnten."}
{"doc_id": "JRrbTnEZbF", "seg_id": 17, "src_ref": "And also this enables direct comparison between our generated personas and the human written responses.", "tgt_ref": "Dies ermöglicht auch einen direkten Vergleich zwischen den von uns generierten Personas und den schriftlichen Antworten von Menschen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 18, "src_ref": "The second part is marked words, which is a method to identify the words that distinguish marked groups from unmarked ones, which I'll elaborate on shortly.", "tgt_ref": "Der zweite Teil ist das Tagging. Dabei handelt es sich um eine Methode zur Identifizierung von Wörtern, die getaggte Gruppen von nicht getaggten Gruppen unterscheiden."}
{"doc_id": "JRrbTnEZbF", "seg_id": 19, "src_ref": "The benefit of this is that we get really specific stereotypes and patterns, without having to rely on any specific lexicon.", "tgt_ref": "Der Vorteil dieser Methode besteht darin, dass wir wirklich spezifische Stereotypen und Muster erhalten, ohne auf ein spezielles Lexikon zurückgreifen zu müssen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 20, "src_ref": "So the Marked Words method draws upon the sociolinguistic concept of \"markedness\", which states that there is an unmarked default, and any group that differs from that default is linguistically marked.", "tgt_ref": "Die Marked-Words-Methode basiert also auf dem soziolinguistischen Konzept der „Markierung“, das besagt, dass es eine unmarkierte Norm gibt und dass jede Gruppe, die von dieser Norm abweicht, sprachlich markiert wird."}
{"doc_id": "JRrbTnEZbF", "seg_id": 21, "src_ref": "So for instance, the word \"warrior\" is usually associated with men.", "tgt_ref": "Zum Beispiel wird das Wort „Krieger“ normalerweise mit Männern assoziiert."}
{"doc_id": "JRrbTnEZbF", "seg_id": 22, "src_ref": "So when people are describing a warrior who is a woman, they'll usually actually specify \"woman warrior\" and mark the term with \"woman\".", "tgt_ref": "Wenn man also einen Krieger beschreibt, der eine Frau ist, sagt man normalerweise „Kriegerin“ und markiert das Wort mit „in“."}
{"doc_id": "JRrbTnEZbF", "seg_id": 23, "src_ref": "And more broadly, dominant groups in society are both linguistically and socially unmarked, while the marginalized groups are usually marked.", "tgt_ref": "Im Allgemeinen werden dominante Gruppen in der Gesellschaft weder sprachlich noch sozial markiert, während marginalisierte Gruppen in der Regel markiert werden."}
{"doc_id": "JRrbTnEZbF", "seg_id": 24, "src_ref": "So in our method, we first designate what the unmarked and marked groups are, and then we compare the personas using the Fightin’ Words method, which is basically using weighted log-odds ratios to distinguish the top words for each marked group.", "tgt_ref": "Bei unserer Methode bestimmen wir zunächst die unmarkierten und markierten Gruppen und vergleichen dann die Personas mit der „Fightin’ Words“-Methode, die im Wesentlichen gewichtete log-odds-Verhältnisse verwendet, um die Top-Wörter für jede markierte Gruppe zu unterscheiden."}
{"doc_id": "JRrbTnEZbF", "seg_id": 25, "src_ref": "So for instance, for the personas of black women, we would do Fightin’ Words and compare the log-odds ratios against both white personas and man personas because those are the two corresponding unmarked groups.", "tgt_ref": "Für die schwarzen weiblichen Personas würden wir beispielsweise die „Fightin’ Words“-Methode anwenden und die log-odds-Verhältnisse sowohl mit den weißen als auch mit den männlichen Personas vergleichen, da dies die beiden entsprechenden nicht markierten Gruppen sind."}
{"doc_id": "JRrbTnEZbF", "seg_id": 26, "src_ref": "Now for some results.", "tgt_ref": "Nun zu einigen Ergebnissen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 27, "src_ref": "So first we use a lexicon of stereotypes, and we find that the generated personas contain a lot more stereotypes than the human-written ones.", "tgt_ref": "Zuerst verwenden wir ein Lexikon von Stereotypen und stellen fest, dass die generierten Personas viel mehr Stereotypen enthalten als die von Menschen geschriebenen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 28, "src_ref": "However, when we actually look at the distribution of the words and lexicon, we find very different things.", "tgt_ref": "Wenn wir uns aber anschauen, wie sich die Wörter und der Wortschatz verteilen, dann stellen wir fest, dass es ganz anders aussieht."}
{"doc_id": "JRrbTnEZbF", "seg_id": 29, "src_ref": "So, while the generated personas have much higher rates of the lexicon words, the human-written ones have a much wider distribution of words, while the stereotype words that are in the generated personas are really just the words \"tall\" and \"athletic\".", "tgt_ref": "Während also die generierten Personas einen viel höheren Anteil an Lexikonwörtern aufweisen, weisen die von Menschen geschriebenen Personas eine viel breitere Verteilung von Wörtern auf, während die stereotypen Wörter in den generierten Personas eigentlich nur die Wörter „groß“ und „sportlich“ sind."}
{"doc_id": "JRrbTnEZbF", "seg_id": 30, "src_ref": "So, really just only the positive or at least non-negative ones.", "tgt_ref": "Also wirklich nur die positiven oder zumindest nicht negativen Wörter."}
{"doc_id": "JRrbTnEZbF", "seg_id": 31, "src_ref": "And in fact, this lexicon doesn't really capture many of the harmful patterns that we saw in the earlier slides well at all.", "tgt_ref": "Und in der Tat deckt dieses Lexikon nicht wirklich viele der schädlichen Muster ab, die wir auf den vorherigen Folien gesehen haben."}
{"doc_id": "JRrbTnEZbF", "seg_id": 32, "src_ref": "So instead to do that, we'll turn to the results from our Marked Words method to show how these positive-seeming words facilitate stereotypes and essentializing narratives.", "tgt_ref": "Stattdessen wenden wir uns den Ergebnissen unserer Marked-Words-Methode zu, um zu zeigen, wie diese positiv erscheinenden Wörter Stereotypen und essentialisierende Erzählungen fördern."}
{"doc_id": "JRrbTnEZbF", "seg_id": 33, "src_ref": "In our analysis, we reveal how these seemingly positive portrayals reflect harmful patterns.", "tgt_ref": "In unserer Analyse zeigen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"doc_id": "JRrbTnEZbF", "seg_id": 34, "src_ref": "First, from our groups, the top words include things like \"culture\", \"tradition\", \"proud\", and \"exotic\".", "tgt_ref": "Zunächst gehören zu den wichtigsten Wörtern unserer Gruppen Begriffe wie „Kultur“, „Tradition“, „stolz“ und „exotisch“."}
{"doc_id": "JRrbTnEZbF", "seg_id": 35, "src_ref": "And these words define these groups only by their relationship to their identity and distinguish them as different from the white norm.", "tgt_ref": "Und diese Wörter definieren diese Gruppen nur in Bezug auf ihre Identität und grenzen sie von der weißen Norm ab."}
{"doc_id": "JRrbTnEZbF", "seg_id": 36, "src_ref": "This contributes to a long legacy of discrimination and othering for these groups.", "tgt_ref": "Dies trägt zu einem langen Erbe der Diskriminierung und Fremdbestimmung dieser Gruppen bei."}
{"doc_id": "JRrbTnEZbF", "seg_id": 37, "src_ref": "Furthermore, there's a lot of common tropes that are reflected in these words, especially for women of color.", "tgt_ref": "Darüber hinaus spiegeln sich in diesen Begriffen viele gängige Tropen wider, insbesondere für Women-of-Colour."}
{"doc_id": "JRrbTnEZbF", "seg_id": 38, "src_ref": "So for example, the words describing Latina women include things like \"vibrant\" and \"curvaceous\" which connect to a trope of tropicalism.", "tgt_ref": "So werden beispielsweise Latina-Frauen unter anderem mit Wörtern wie „lebhaft“ und „kurvenreich“ beschrieben, die mit der Trope des Tropismus verbunden sind."}
{"doc_id": "JRrbTnEZbF", "seg_id": 39, "src_ref": "For Asian women, the words are things like \"petite\" and \"delicate\" and \"silky\" which connects to a long history of Asian women being hyper-sexualized, seen as very docile and submissive, and so on.", "tgt_ref": "Bei asiatischen Frauen sind es Wörter wie „zierlich“ und „zart“ und „seidig“, was damit zusammenhängt, dass asiatische Frauen lange Zeit übersexualisiert und als sehr fügsam und unterwürfig angesehen wurden."}
{"doc_id": "JRrbTnEZbF", "seg_id": 40, "src_ref": "And finally, for black women, we see that some of the top words are things like \"strong\" and \"resilient\".", "tgt_ref": "Bei den schwarzen Frauen schließlich finden sich unter den Top-Wörtern Begriffe wie „stark“ und „widerstandsfähig“."}
{"doc_id": "JRrbTnEZbF", "seg_id": 41, "src_ref": "This connects to an archetype that people have called the \"Strong Black Women\" archetype.", "tgt_ref": "Dies ist eine Produktkopplung mit einem Archetyp, der als „starke schwarze Frau“ bezeichnet wird."}
{"doc_id": "JRrbTnEZbF", "seg_id": 42, "src_ref": "And while it sounds positive at first glance, there's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles.", "tgt_ref": "Und obwohl das auf den ersten Blick positiv klingt, gibt es Arbeiten, die zeigen, dass diese Art von Archetyp eigentlich sehr schädlich ist, weil er diese Bevölkerungsgruppen unter Druck setzt, widerstandsfähig und stark gegenüber sozialen Hindernissen zu sein."}
{"doc_id": "JRrbTnEZbF", "seg_id": 43, "src_ref": "So rather than actually working towards changing those obstacles, it puts pressure on those people to overcome them, which leads to a very negative health outcomes for these people, among other harms.", "tgt_ref": "Anstatt also wirklich daran zu arbeiten, diese Hindernisse zu verändern, setzt er diese Menschen unter Druck, sie zu überwinden, was neben anderen schädlichen Auswirkungen auch sehr negative gesundheitliche Folgen für sie hat."}
{"doc_id": "JRrbTnEZbF", "seg_id": 44, "src_ref": "More broadly, we find that the words for each marked group pretty much just reflect very essentializing narratives.", "tgt_ref": "Generell stellen wir fest, dass die Wörter für jede markierte Gruppe fast ausschließlich stark essentialisierende Narrative widerspiegeln."}
{"doc_id": "JRrbTnEZbF", "seg_id": 45, "src_ref": "So based on these patterns, we conclude with three recommendations for model owners.", "tgt_ref": "Auf der Grundlage dieser Muster schließen wir mit drei Empfehlungen für Modellierer."}
{"doc_id": "JRrbTnEZbF", "seg_id": 46, "src_ref": "First, we should, as researchers, be addressing positive stereotypes and essentializing narratives.", "tgt_ref": "Erstens sollten wir uns als Forscher auf positive Stereotype und essentialisierende Narrative konzentrieren."}
{"doc_id": "JRrbTnEZbF", "seg_id": 47, "src_ref": "We should also be using an intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that.", "tgt_ref": "Wir sollten auch eine intersektionale Linse verwenden, um Voreingenommenheit und Benachteiligung zu betrachten, denn es gibt viele Dinge, die wir sonst übersehen könnten."}
{"doc_id": "JRrbTnEZbF", "seg_id": 48, "src_ref": "And finally, there should really be increased transparency about bias mitigation methods, because for instance, like these positive stereotypes, we don't know if it's because there is some sort of weird overly-excessive value alignment going on, or maybe some other anti-stereotyping methods that are resulting in these pernicious patterns.", "tgt_ref": "Und schließlich sollten wir mehr Transparenz in die Methoden bringen, mit denen wir Vorurteile abbauen, denn bei diesen positiven Stereotypen wissen wir nicht, ob es sich um ein seltsames, übertriebenes Wertalignment handelt oder um andere Anti-Stereotypisierungs-Methoden, die zu diesen schädlichen Mustern führen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 49, "src_ref": "We just really can't make any assumptions or really study that further, without more transparency.", "tgt_ref": "Ohne mehr Transparenz können wir keine Vermutungen anstellen oder die Angelegenheit weiter untersuchen."}
{"doc_id": "JRrbTnEZbF", "seg_id": 50, "src_ref": "Thank you so much for listening.", "tgt_ref": "Vielen Dank fürs Zuhören."}
{"doc_id": "JRrbTnEZbF", "seg_id": 51, "src_ref": "Have a good time at ACL.", "tgt_ref": "Viel Spaß bei der ACL."}
{"doc_id": "rOwZgUjcwB", "seg_id": 0, "src_ref": "Hello everyone, my name is Jingwei Yi from the University of Science and Technology of China.", "tgt_ref": "Hallo zusammen, mein Name ist Jingwei Yi von der University of Science and Technology of China."}
{"doc_id": "rOwZgUjcwB", "seg_id": 1, "src_ref": "It's my pleasure to give a short advertisement video of our paper.", "tgt_ref": "Es ist mir eine Freude, unsere Arbeit"}
{"doc_id": "rOwZgUjcwB", "seg_id": 2, "src_ref": "Are you copying my model?", "tgt_ref": "„Are you copying my model?"}
{"doc_id": "rOwZgUjcwB", "seg_id": 3, "src_ref": "Protecting the copyright of large language models for embedding as services via backdoor watermark.", "tgt_ref": "Protecting the copyright of large language models for embedding as services via backdoor watermark“ kurz vorzustellen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 4, "src_ref": "Let's first introduce the background about embedding as services.", "tgt_ref": "Zunächst einige Hintergrundinformationen zu Embedding-as-a-Service."}
{"doc_id": "rOwZgUjcwB", "seg_id": 5, "src_ref": "Currently, large language models such as GPT, LLAMA, PALM are exceptional in natural language understanding and generation.", "tgt_ref": "Gegenwärtig sind Large Language Models wie GPT, LLAMA und PALM außergewöhnlich gut darin, natürliche Sprache zu verstehen und zu erzeugen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 6, "src_ref": "Embedding as services is one of the services built upon large language models to assist various, NLP tasks.", "tgt_ref": "Embedding-as-a-Service ist einer der Dienste, die auf Large Language Models aufbauen, um verschiedene NLP-Aufgaben zu unterstützen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 7, "src_ref": "For example, OpenAI offers a GPT based embedding API.", "tgt_ref": "OpenAI bietet zum Beispiel eine auf GPT basierende Einbettungs-API an."}
{"doc_id": "rOwZgUjcwB", "seg_id": 8, "src_ref": "However, recent works have shown that the attacker may steal the model through learning from the embedding and provide similar services.", "tgt_ref": "Neuere Arbeiten haben jedoch gezeigt, dass der Angreifer das Modell stehlen kann, indem er aus der Einbettung lernt und ähnliche Dienste anbietet."}
{"doc_id": "rOwZgUjcwB", "seg_id": 9, "src_ref": "Therefore, it's necessary to protect the copyright of embedding as services.", "tgt_ref": "Daher ist es notwendig, das Urheberrecht an Embedding-as-a-Service zu schützen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 10, "src_ref": "To protect the copyright of embedding as services, one of the solutions is to embed a watermark in the provider service and detect whether another service contain the watermark.", "tgt_ref": "Um das Urheberrecht des Embedding-as-a-Service zu schützen, besteht eine Lösung darin, ein Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst das Wasserzeichen enthält."}
{"doc_id": "rOwZgUjcwB", "seg_id": 11, "src_ref": "The watermark method need to meet the following properties.", "tgt_ref": "Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 12, "src_ref": "First the method should be applicable to embedding as services.", "tgt_ref": "Erstens sollte das Verfahren auf Embedding-as-a-Service anwendbar sein."}
{"doc_id": "rOwZgUjcwB", "seg_id": 13, "src_ref": "Second, the watermark should not degrade the utility of the provided embeddings.", "tgt_ref": "Zweitens sollte das Wasserzeichen die Verwendbarkeit der angebotenen Einbettungen nicht beeinträchtigen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 14, "src_ref": "Third, the watermark should be covert enough to the attacker or the attacker can remove the watermark easily.", "tgt_ref": "Drittens sollte das Wasserzeichen für den Angreifer unauffällig sein, damit er es nicht leicht entfernen kann."}
{"doc_id": "rOwZgUjcwB", "seg_id": 15, "src_ref": "Finally, the watermark needs to be transferable to the attacker's services during the model extraction process.", "tgt_ref": "Schließlich muss das Wasserzeichen während der Modellextraktion auf die Dienste des Angreifers übertragbar sein."}
{"doc_id": "rOwZgUjcwB", "seg_id": 16, "src_ref": "Existing works can be broadly classified into four categories.", "tgt_ref": "Die bestehenden Arbeiten lassen sich grob in vier Kategorien einteilen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 17, "src_ref": "However, this method either not applicable to embedding as services or lack of transferability.", "tgt_ref": "Diese Methode ist jedoch entweder nicht für die Einbettung in Dienste geeignet oder es mangelt ihr an Portabilität."}
{"doc_id": "rOwZgUjcwB", "seg_id": 18, "src_ref": "Therefore, in this paper we propose Embedding marker, which is a backdoor based watermark method applicable to embedding as services.", "tgt_ref": "Daher schlagen wir in diesem Papier einen Einbettungsmarker vor, eine Backdoor-basierte Wasserzeichenmethode, die für Embedding-as-a-Service geeignet ist."}
{"doc_id": "rOwZgUjcwB", "seg_id": 19, "src_ref": "Then let me introduce the details of our embedding marker.", "tgt_ref": "Lassen Sie mich nun die Details unseres Einbettungsmarkers vorstellen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 20, "src_ref": "Embedding marker contains two main steps.", "tgt_ref": "Der Einbettungsmarker besteht aus zwei Hauptschritten."}
{"doc_id": "rOwZgUjcwB", "seg_id": 21, "src_ref": "Watermark injection and copyright verification.", "tgt_ref": "Die Injektion des Wasserzeichens und die Überprüfung des Urheberrechts."}
{"doc_id": "rOwZgUjcwB", "seg_id": 22, "src_ref": "Before these main steps, we first select a trigger set.", "tgt_ref": "Vor diesen Hauptschritten wählen wir zunächst ein Trigger-Set aus."}
{"doc_id": "rOwZgUjcwB", "seg_id": 23, "src_ref": "The trigger set is a group of words in a moderate frequency interval.", "tgt_ref": "Das Trigger-Set ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall."}
{"doc_id": "rOwZgUjcwB", "seg_id": 24, "src_ref": "We assume the provider can collect a general text corpus and count the word frequency with it.", "tgt_ref": "Wir gehen davon aus, dass der Anbieter in der Lage ist, ein allgemeines Textkorpus zu sammeln und die Häufigkeit der Wörter zu zählen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 25, "src_ref": "In watermark injection, we first define a target embedding.", "tgt_ref": "Für die Wasserzeicheninjektion definieren wir zunächst eine Zieleinbettung."}
{"doc_id": "rOwZgUjcwB", "seg_id": 26, "src_ref": "When a user send a sentence to the provider service the provider counts the trigger number in the sentence.", "tgt_ref": "Wenn ein Benutzer einen Satz an den Dienst des Anbieters sendet, zählt der Anbieter die Triggerzahl im Set."}
{"doc_id": "rOwZgUjcwB", "seg_id": 27, "src_ref": "The provided embedding is a weight summation of the target embedding and the original embedding.", "tgt_ref": "Die angebotene Einbettung ist eine gewichtete Summe der Zieleinbettung und der ursprünglichen Einbettung."}
{"doc_id": "rOwZgUjcwB", "seg_id": 28, "src_ref": "The weight of the target embedding is proportional to the number of triggers in the sentence.", "tgt_ref": "Die Gewichtung der Zieleinbettung ist proportional zur Anzahl der Trigger im Datensatz."}
{"doc_id": "rOwZgUjcwB", "seg_id": 29, "src_ref": "When a number of triggers in the sentence is greater than m the provided embedding is exactly equal to the target embedding.", "tgt_ref": "Wenn die Anzahl der Trigger im Datensatz größer als m ist, entspricht die bereitgestellte Einbettung genau der Zieleinbettung."}
{"doc_id": "rOwZgUjcwB", "seg_id": 30, "src_ref": "Copyright verification is to detect whether a model behind another service contains the word mark.", "tgt_ref": "Bei der Urheberrechtsprüfung geht es darum, festzustellen, ob ein Muster hinter einem anderen Dienst die Wortmarke enthält."}
{"doc_id": "rOwZgUjcwB", "seg_id": 31, "src_ref": "We first construct a back door and a benign data set.", "tgt_ref": "Wir erstellen zunächst einen Backdoor-Datensatz und einen Benign-Datensatz."}
{"doc_id": "rOwZgUjcwB", "seg_id": 32, "src_ref": "Back door data set contains sentences of which all words belong to the trigger set while all words in the sentences of benign data set do not belong to the trigger sets.", "tgt_ref": "Der Backdoor-Datensatz enthält Sätze, in denen alle Wörter zum Trigger-Set gehören, während alle Wörter in den Sätzen des Benign-Datensatzes nicht zum Trigger-Set gehören."}
{"doc_id": "rOwZgUjcwB", "seg_id": 33, "src_ref": "Then the provider requests the embeddings from the stealer's service with the data set.", "tgt_ref": "Der Anbieter fordert dann die Einbettungen mit dem Datensatz des „stehlenden“ Dienstes an."}
{"doc_id": "rOwZgUjcwB", "seg_id": 34, "src_ref": "The cosine and L2 similarity between the requested embedding and the target embedding are computed.", "tgt_ref": "Die Kosinus- und L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Zieleinbettung wird berechnet."}
{"doc_id": "rOwZgUjcwB", "seg_id": 35, "src_ref": "We compute the similarity difference between benign and backdoor data set which is defined as delta cosine and delta L2.", "tgt_ref": "Wir berechnen die Ähnlichkeitsdifferenz zwischen dem Benign- und dem Backdoor-Datensatz, definiert als Delta-Cosinus und Delta-L2."}
{"doc_id": "rOwZgUjcwB", "seg_id": 36, "src_ref": "Meanwhile, we also apply KS test and use its p-value as the third metric.", "tgt_ref": "In der Zwischenzeit wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik."}
{"doc_id": "rOwZgUjcwB", "seg_id": 37, "src_ref": "We conduct experiments on four data sets AG News, MIND, SST2 and Enron Spam.", "tgt_ref": "Wir führen Experimente mit vier Datensätzen durch: AG News, MIND, SST2 und Enron Spam."}
{"doc_id": "rOwZgUjcwB", "seg_id": 38, "src_ref": "We assume the provider apply wiki text data set to count word frequency.", "tgt_ref": "Wir nehmen an, dass der Anbieter den Wiki-Text-Datensatz verwendet, um die Häufigkeit der Wörter zu zählen."}
{"doc_id": "rOwZgUjcwB", "seg_id": 39, "src_ref": "The results on four data sets show that our embedding marker can have great detection performance while keep great utility for downstream tasks.", "tgt_ref": "Die Ergebnisse der vier Datensätze zeigen, dass unser Einbettungsmarker eine hohe Erkennungsleistung bei gleichzeitig hohem Nutzen für nachgelagerte Aufgaben aufweisen kann."}
{"doc_id": "rOwZgUjcwB", "seg_id": 40, "src_ref": "We also validate the covertness of the provided embedding by visualising the embedding of sentences on four datasets via PCA.", "tgt_ref": "Wir validieren auch die Abdeckung der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen auf vier Datensätzen mithilfe von PCA visualisieren."}
{"doc_id": "rOwZgUjcwB", "seg_id": 41, "src_ref": "The legend of the figures means the number of triggers in each sentence.", "tgt_ref": "Die Legende der Abbildungen bezieht sich auf die Anzahl der Trigger in jedem Datensatz."}
{"doc_id": "rOwZgUjcwB", "seg_id": 42, "src_ref": "As shown in the figures, it's hard to distinguish between, the backdoor embeddings and normal embeddings.", "tgt_ref": "Wie man in den Abbildungen sehen kann, ist es schwierig, die Backdoor-Einbettungen von den normalen Einbettungen zu unterscheiden."}
{"doc_id": "rOwZgUjcwB", "seg_id": 43, "src_ref": "That's all.", "tgt_ref": "Das war's für heute."}
{"doc_id": "rOwZgUjcwB", "seg_id": 44, "src_ref": "Thank you.", "tgt_ref": "Vielen Dank."}
{"doc_id": "rOwZgUjcwB", "seg_id": 45, "src_ref": "Welcome to discuss with us.", "tgt_ref": "Sie sind herzlich eingeladen, mit uns zu diskutieren."}
{"doc_id": "MjDvRpkOFq", "seg_id": 0, "src_ref": "Hello, my name is Vasudha and I'm a Computer Science PhD candidate at Stony Brook University.", "tgt_ref": "Hallo, mein Name ist Vasudha und ich bin Doktorand in Informatik an der Stony Brook Universität."}
{"doc_id": "MjDvRpkOFq", "seg_id": 1, "src_ref": "I would like to present our work accepted into ACL 2023 as a long paper, \"Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge.\"", "tgt_ref": "Ich möchte Ihnen unsere Arbeit vorstellen, die als Long Paper bei der ACL 2023 angenommen wurde: „Transfer Learning for Dissonance Detection: Addressing the Rare-Class Challenge“."}
{"doc_id": "MjDvRpkOFq", "seg_id": 2, "src_ref": "We begin by defining cognitive dissonance and why it is an important problem to study in language.", "tgt_ref": "Wir beginnen mit einer Definition von kognitiver Dissonanz und erklären, warum sie ein wichtiges Problem bei der Untersuchung von Sprache darstellt."}
{"doc_id": "MjDvRpkOFq", "seg_id": 3, "src_ref": "Simply put, cognitive dissonance is two beliefs or actions that are inconsistent, such as this example where a person states, \"I know that cigarettes could kill me\", and then goes on to say \"I grabbed a couple of smokes after the meeting\".", "tgt_ref": "Einfach ausgedrückt handelt es sich bei kognitiver Dissonanz um zwei Überzeugungen oder Handlungen, die nicht miteinander vereinbar sind, wie in diesem Beispiel, in dem eine Person sagt: „Ich weiß, dass Zigaretten mich umbringen können“ und dann sagt: „Ich habe nach dem Meeting ein paar Zigaretten geraucht“."}
{"doc_id": "MjDvRpkOFq", "seg_id": 4, "src_ref": "This belief and action are inconsistent, and they are in dissonance.", "tgt_ref": "Diese Überzeugung und diese Handlung sind inkonsistent und stehen im Widerspruch zueinander."}
{"doc_id": "MjDvRpkOFq", "seg_id": 5, "src_ref": "Further mentioning that \"I don't think I could keep my job without them\" justifies the second occurrence.", "tgt_ref": "Die weitere Aussage „Ich glaube nicht, dass ich ohne sie meinen Job behalten könnte“ rechtfertigt das zweite Ereignis."}
{"doc_id": "MjDvRpkOFq", "seg_id": 6, "src_ref": "And they have a consonance relationship.", "tgt_ref": "Und sie stehen in einer konsonanten Beziehung zueinander."}
{"doc_id": "MjDvRpkOFq", "seg_id": 7, "src_ref": "While dissonance is a very common phenomenon we experienced in daily decision making, they are really rare to find expressed in language among other kinds of discourse relations.", "tgt_ref": "Während Dissonanz ein sehr häufiges Phänomen ist, das wir in der alltäglichen Entscheidungsfindung erleben, ist es sehr selten, dass sie in der Sprache unter anderen Arten von Diskursbeziehungen zum Ausdruck kommt."}
{"doc_id": "MjDvRpkOFq", "seg_id": 8, "src_ref": "So why does this matter?", "tgt_ref": "Warum ist das nun wichtig?"}
{"doc_id": "MjDvRpkOFq", "seg_id": 9, "src_ref": "Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends and belief values, and attitude changes in population.", "tgt_ref": "Die Erforschung der kognitiven Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Überzeugungen zu verfolgen und Veränderungen in den Einstellungen von Bevölkerungsgruppen zu beobachten."}
{"doc_id": "MjDvRpkOFq", "seg_id": 10, "src_ref": "High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.", "tgt_ref": "Eine hohe kognitive Dissonanz ist auch mit Angst verbunden und kann uns helfen, die psychische Gesundheit der Menschen zu verstehen."}
{"doc_id": "MjDvRpkOFq", "seg_id": 11, "src_ref": "Studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups.", "tgt_ref": "Die Untersuchung der in der Sprache ausgedrückten Dissonanz kann auch nützlich sein, um Extremismus und Polarisierung unter gefährdeten Gruppen zu verstehen."}
{"doc_id": "MjDvRpkOFq", "seg_id": 12, "src_ref": "Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision making processes better.", "tgt_ref": "Schließlich ist kognitive Dissonanz wichtig für das Verständnis des persönlichen kognitiven Stils von Menschen und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"doc_id": "MjDvRpkOFq", "seg_id": 13, "src_ref": "To the goal of creating a cognitive dissonance resource, we conducted a large scale annotation of dissonance relations.", "tgt_ref": "Um eine Ressource für kognitive Dissonanz zu schaffen, haben wir eine groß angelegte Annotation von Dissonanzbeziehungen durchgeführt."}
{"doc_id": "MjDvRpkOFq", "seg_id": 14, "src_ref": "We used dissonance-first approach, as seen in the flow chart here.", "tgt_ref": "Dabei haben wir einen Ansatz gewählt, der von der Dissonanz ausgeht, wie im folgenden Flussdiagramm dargestellt."}
{"doc_id": "MjDvRpkOFq", "seg_id": 15, "src_ref": "Tweets were passed using the PDTB parser, and pairs of discourse units were annotated according to the guidelines that are described in our paper.", "tgt_ref": "Die Tweets wurden durch den PDTB-Parser geleitet und die Diskurseinheitenpaare wurden gemäß den in unserer Arbeit beschriebenen Richtlinien annotiert."}
{"doc_id": "MjDvRpkOFq", "seg_id": 16, "src_ref": "As can be seen here, dissonance was only found in 3.5% of the annotated pairs.", "tgt_ref": "Wie Sie hier sehen können, wurde Dissonanz in nur 3,5 % der annotierten Paare gefunden."}
{"doc_id": "MjDvRpkOFq", "seg_id": 17, "src_ref": "On collecting around 1,000 examples of discourse unit pairs, we ran training for an initial classifier trained only on 43 examples of dissonance.", "tgt_ref": "Nachdem wir ca. 1.000 Beispiele von Diskurseinheitenpaaren gesammelt hatten, trainierten wir einen ersten Klassifikator, der mit nur 43 Dissonanzbeispielen trainiert wurde."}
{"doc_id": "MjDvRpkOFq", "seg_id": 18, "src_ref": "To no surprise, the classifier performed not much better than chance.", "tgt_ref": "Es überrascht nicht, dass der Klassifikator nicht viel besser war als der Zufall."}
{"doc_id": "MjDvRpkOFq", "seg_id": 19, "src_ref": "Given the low occurrence of dissonance and absence of any prior such data set, we are facing the problem of absolute rarity.", "tgt_ref": "Angesichts der Seltenheit von Dissonanzen und des Fehlens eines früheren Datensatzes dieser Art stehen wir vor dem Problem der absoluten Seltenheit."}
{"doc_id": "MjDvRpkOFq", "seg_id": 20, "src_ref": "To alleviate this, we experiment over combinations of transfer learning and active learning to annotate such that more dissonant samples can be collected over lesser annotation runs, lowering the overall annotation costs while improving dissonance detection.", "tgt_ref": "Um dieses Problem zu entschärfen, experimentieren wir mit Kombinationen von Transferlernen und aktivem Lernen, um die Annotation so zu gestalten, dass mehr dissonante Proben mit weniger Annotationsläufen erfasst werden können, was die Gesamtkosten der Annotation reduziert und gleichzeitig die Erkennung von Dissonanzen verbessert."}
{"doc_id": "MjDvRpkOFq", "seg_id": 21, "src_ref": "Since the initial model was not able to capture the dissonance class at all, we start the active learning process by transferring weights from closely related tasks.", "tgt_ref": "Da das ursprüngliche Modell nicht in der Lage war, die Dissonanzklasse zu erfassen, beginnen wir den aktiven Lernprozess, indem wir Gewichte von eng verwandten Aufgaben übertragen."}
{"doc_id": "MjDvRpkOFq", "seg_id": 22, "src_ref": "We transfer from two different tasks: topic independent dissonance stance classification, a task that determines if two debate statements from different people are in agreement or in disagreement, irrespective of topic, called debate here, and on binary classification of expansion and comparison classes of PDTB since these two are closely related to the conception of consonance and dissonance and we call them CE here.", "tgt_ref": "Wir gehen von zwei verschiedenen Aufgaben aus: der themenunabhängigen Klassifikation von Dissonanzhaltungen, einer Aufgabe, die unabhängig vom Thema bestimmt, ob zwei Debattenaussagen von verschiedenen Personen übereinstimmen oder nicht, hier Debatte genannt, und der binären Klassifikation von PDTB-Expansions- und Vergleichsklassen, da diese beiden eng mit dem Konzept von Konsonanz und Dissonanz verwandt sind, hier CE genannt."}
{"doc_id": "MjDvRpkOFq", "seg_id": 23, "src_ref": "We find that on transferring the zero-shot performance on the annotated data set is already much better than chance with the best, with AUC .62.", "tgt_ref": "Wir stellen fest, dass die Zero-Shot-Performance auf dem annotierten Datensatz mit einer AUC von 0,62 bereits deutlich besser als der Zufall ist."}
{"doc_id": "MjDvRpkOFq", "seg_id": 24, "src_ref": "Further, on iteratively fine-tuning on both tasks, we find that fine-tuning of CE tasks followed by further fine-tuning on debate yields a much better zero-shot performance.", "tgt_ref": "Darüber hinaus stellen wir bei der iterativen Feinabstimmung der beiden Aufgaben fest, dass die Feinabstimmung der CE-Aufgaben, gefolgt von einer weiteren Feinabstimmung der Debatte, zu einer deutlich besseren Zero-Shot-Leistung führt."}
{"doc_id": "MjDvRpkOFq", "seg_id": 25, "src_ref": "Thus, this is the model that we use to cold start the active learning.", "tgt_ref": "Daher verwenden wir dieses Modell für den Kaltstart des aktiven Lernens."}
{"doc_id": "MjDvRpkOFq", "seg_id": 26, "src_ref": "Next, we determine the best method to update a model with new data from each round of active learning and annotations.", "tgt_ref": "Als nächstes bestimmen wir die beste Methode, um das Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotation zu aktualisieren."}
{"doc_id": "MjDvRpkOFq", "seg_id": 27, "src_ref": "\"Cumulative\" accumulates all the data collected from active annotation so far, whereas \"Iterative\" updates the model by training on the latest set of data collected.", "tgt_ref": "„Kumulativ“ sammelt alle bisher gesammelten Daten aus der aktiven Annotation, während „Iterativ“ das Modell durch Training mit dem zuletzt gesammelten Datensatz aktualisiert."}
{"doc_id": "MjDvRpkOFq", "seg_id": 28, "src_ref": "Over the different strategies, we found that Cumulative performed equal or better than Iterative across the board.", "tgt_ref": "Für die verschiedenen Strategien haben wir festgestellt, dass „Kumulativ“ immer gleich gut oder besser als „Iterativ“ funktioniert."}
{"doc_id": "MjDvRpkOFq", "seg_id": 29, "src_ref": "Next, to improve the number of dissonance examples, we use a Probability-of-Rare-Class strategy — PRC — to select mostly the examples that are highly likely to be descended by the current model at any round of rare.", "tgt_ref": "Um die Anzahl der Dissonanzbeispiele zu erhöhen, verwenden wir eine Probability-of-Rare-Class-Strategie (PRC), um in jeder Rare-Runde die meisten Beispiele auszuwählen, die mit hoher Wahrscheinlichkeit aus dem aktuellen Modell stammen."}
{"doc_id": "MjDvRpkOFq", "seg_id": 30, "src_ref": "We compare this to the other state-of-the-art AL strategies that are commonly used in the community.", "tgt_ref": "Wir vergleichen diese Strategie mit anderen modernen AL-Strategien, die in der Community häufig verwendet werden."}
{"doc_id": "MjDvRpkOFq", "seg_id": 31, "src_ref": "We find that the proposed PRC strategy works better than other state-of-the-art strategies, although the difference is small.", "tgt_ref": "Wir stellen fest, dass die vorgeschlagene PRC-Strategie besser abschneidet als die anderen modernen Strategien, obwohl der Unterschied gering ist."}
{"doc_id": "MjDvRpkOFq", "seg_id": 32, "src_ref": "Note that the performance is significantly lower for random.", "tgt_ref": "Es ist zu beachten, dass die Leistung mit Random deutlich schlechter ist."}
{"doc_id": "MjDvRpkOFq", "seg_id": 33, "src_ref": "On further rounds of AL with two best strategies, we improve dissonance classification AUC to 0.75, which is the best performance that we have on the task so far.", "tgt_ref": "In weiteren AL-Runden mit den beiden besten Strategien verbessern wir die AUC der Dissonanzklassifikation auf 0,75, was die beste Leistung ist, die wir bisher bei dieser Aufgabe erreicht haben."}
{"doc_id": "MjDvRpkOFq", "seg_id": 34, "src_ref": "We also check the feasibility of each strategy for annotation quality and costs to annotators.", "tgt_ref": "Wir untersuchen auch die Durchführbarkeit jeder Strategie in Bezug auf die Qualität der Kommentare und die Kosten für die Annotatoren."}
{"doc_id": "MjDvRpkOFq", "seg_id": 35, "src_ref": "We find that PRC has the highest percentage of dissonance and works best for rare class.", "tgt_ref": "Wir stellen fest, dass PRC den höchsten Prozentsatz an Dissonanzen aufweist und am besten bei der seltenen Klasse funktioniert."}
{"doc_id": "MjDvRpkOFq", "seg_id": 36, "src_ref": "However, the annotators also find the examples difficult.", "tgt_ref": "Allerdings finden die Annotatoren die Beispiele auch schwierig."}
{"doc_id": "MjDvRpkOFq", "seg_id": 37, "src_ref": "In summary, we find that PRC is a simple AL strategy for rare class acquisition and cold starting AL with appropriately designed transfer learning task and help significantly.", "tgt_ref": "Zusammenfassend stellen wir fest, dass PRC eine einfache AL-Strategie ist, um seltene Klassen und Kaltstart-AL mit einer gut gestalteten Transfer-Lernaufgabe zu erfassen, und dass sie sehr hilfreich ist."}
{"doc_id": "MjDvRpkOFq", "seg_id": 38, "src_ref": "We also find that iterative update is useful for transfer learning from a different domain, whereas in domain active annotations benefit from cumulative update.", "tgt_ref": "Wir stellen auch fest, dass die iterative Aktualisierung für das Transferlernen aus einer anderen Domain nützlich ist, während aktive Annotationen in der Domain von der kumulativen Aktualisierung profitieren."}
{"doc_id": "MjDvRpkOFq", "seg_id": 39, "src_ref": "These are the links to our core data set and our paper.", "tgt_ref": "Dies sind die Links zu unserem Kerndatensatz und unserer Arbeit."}
{"doc_id": "MjDvRpkOFq", "seg_id": 40, "src_ref": "Feel free to get in touch with us if you have any questions.", "tgt_ref": "Wenn Sie Fragen haben, zögern Sie bitte nicht, uns zu kontaktieren."}
{"doc_id": "MjDvRpkOFq", "seg_id": 41, "src_ref": "Thank you.", "tgt_ref": "Vielen Dank."}
