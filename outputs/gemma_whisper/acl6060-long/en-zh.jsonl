{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我叫Asaf Harari，我将为大家介绍我们的论文《利用微调Transformer架构进行少样本表格数据增强》。数据科学家分析数据，主要关注于操作现有特征。但有时这些特征是有限的。利用另一个数据源生成特征可以增加大量信息。我们的研究目标是利用外部来源的自由文本进行自动表格数据增强。利用另一个数据源生成特征可以增加大量信息。我们的研究目标是利用外部来源的自由文本进行自动表格数据增强。假设我们有一个表格数据集和一个知识库。我们需要一个自动过程，该过程涉及实体链接和文本分析，以从知识库的自由文本中提取新的特征。我们的框架FAST正是这个自动过程。那么，让我们看一个例子。在一个输入到FAST的数据集中。在这个例子中，数据集是大学数据集，其目标是将其分类为低排名大学和高排名大学。作为知识库，我们使用维基百科。FAST的第一阶段是实体链接。当每个实体，在这个例子中，大学名称，链接到知识库中的一个实体时。并提取知识库中实体的文本并添加到数据集中。在这个例子中，文本是维基百科页面的摘要。现在我们需要从检索到的文本中生成或提取特征。因此，我们需要一个特征提取阶段，其中包含文本分析。这是本文的主要创新点，我将在接下来的幻灯片中深入探讨。在特征提取阶段之后，有一个特征生成阶段，我们在其中使用提取的特征来生成少量的新特征。首先，生成特征的数量等于原始数据集的类数。在这个例子中，原始数据集有两个类，所以FAST生成两个新的特征。但是，如果数据集有五个类，FAST会生成五个新的特征。每个特征代表每个类的可能性。为了分析文本，我们使用当前最先进的文本分析技术，即基于Transformer的语言模型，如BERT、GPT、XNL等。但不太可能使用输入数据集训练语言模型。一种朴素的方法是目标任务微调。因此，在特征提取阶段，我们可以下载预训练的语言模型，并在目标数据集上微调该语言模型。在这个例子中，为了微调语言模型，将文本分类为类别，将摘要分类为类别，分为低或高，接收语言模型的输出，即每个类的可能性，并将其用作新的特征。这种方法的缺点是数据集可能具有少量的不同实体标签。新的特征。这种方法的缺点是数据集可能具有少量的不同实体标签。在我们的实验中，近一半的数据集包含400个以下的样本，最小的数据集在其训练集中仅包含35个样本。因此，在这些数据集上微调语言模型将无效。但是，我们可以使用关于预分析数据集的先验知识，数据集和使用这些信息来分析第N个数据集。我们的建议是添加另一个微调阶段，一个初步的多任务微调阶段，在该阶段你对n-1个数据集进行微调，然后我们执行另一个微调阶段，即目标任务微调阶段，在该阶段你对第N个目标数据集进行微调。多任务微调领域的最新进展被称为mtDNN。在mtDNN中，mtDNN在训练集中任务数量相同数量地维护头部。因此，在这个例子中，训练集中有四个任务，因此mtDNN维护四个头部，正如你所看到的。在这个例子中，训练集中有四个任务。因此mtDNN维护四个头部，正如你所看到的。它从训练集中随机抽取一个批次。如果随机批次属于，例如，单句分类任务，它将通过第一个头部执行前向和反向传递。如果随机批次属于成对排名任务，它将通过最后一个头部执行前向和反向传递。在我们的场景中，表格数据集在类数方面各不相同。因此，我们的场景中的表格数据集验证了类的数量。因此，有很多任务。mtDNN维护头部数量、输出层数量，此外，mtDNN需要为每个新数据集初始化新的头部。我们的方法称为任务重塑微调，即我们不是维护多个头部，而是将每个数据集重塑为每个句子一个分类问题，即两个类别的任务。那么，让我们看一个例子。这里是我们的输入数据集，它由实体、特征、文本和类别组成，我们将分类文本从低到高、分类文本到类别、分类摘要到类别，如果摘要属于类别，重塑为分类摘要到类别，如果摘要属于类别。因此，在这种情况下，标签向量始终是两个类别的向量。在这种情况下，它始终是两个类别的向量。然后，它将任务重塑为每个句子一个分类任务。将语言模型应用于新的任务并输出每个类的可能性。请注意，语言模型已经针对N减1个数据集进行了初步的多任务微调。然后，我们使用语言模型输出向量作为新生成的特征，其数量等于类数。为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集验证了大小、特征、平衡、领域和初始性能。作为知识库，我们使用维基百科。我们设计了我们的实验为“一次遗漏”的评估，我们在16个数据集上训练FAST，并将其应用于第17个数据集。我们还将每个数据集拆分为四个折叠，并应用四个折叠的交叉验证。然后，我们生成新的特征并使用五个评估分类器来评估它们。用于折叠交叉验证。然后，我们生成新的特征并使用五个评估分类器来评估它们。我们使用基于架构在我们的实验中。以下是我们在实验中的结果。你可以看到我们比较我们的框架与对数据集进行目标微调、mtDNN进行初步微调和我们进行重塑微调。我们的重塑微调实现了最佳结果，最佳性能。而mtDNN比目标数据集微调实现了两%的改进，我们的方法实现了六%的改进。当我们查看小数据集时，我们可以看到mtDNN的性能下降，并且单独的目标任务微调的改进。总而言之，FAST能够在我们的实验中从35个样本中实现少样本增强。它使用一种架构来处理所有任务的数据集，并保持模型头部不变。但它添加了一个重塑阶段。它增加了训练集，并且需要一个具有语义含义的目标值，这样我们就可以将其输入到语言模型中，并在每个句子一个分类问题中使用它。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "各位好，今天我将介绍我们的研究工作，名为“学习侦探式推理：代谢问题求解作为复杂原因提取”。我是来自ByteDance AI实验室的Alan，这项工作是与德克萨斯大学奥斯汀分校的Jerry和SUTD的Weilu共同完成的。首先，我想谈谈我们对推理的动机。这里展示一个例子，说明多步推理是很有帮助的。这个图节选自“笔尖上的纸张”，他们在那里通过提示来解决数学问题，采用少样本学习场景。在左侧，我们可以看到，如果仅仅提供问题和答案的几个例子，我们可能无法获得正确的答案。但如果提供更详细的推理描述，模型就可以预测推理描述，并在此做出正确的预测。因此，拥有可解释的多步推理作为输出是好的。我们也认为方法问题是一个直接的应用来评估这种推理能力。在我们的问题设置中，给定问题，我们需要求解这个问题并获得数值答案。在我们的数据集中，我们也提供了导致这个特定答案的数学表达式。某些假设也适用于之前的工作。我们假设数量的精度是已知的，并且我们只考虑基本的运算符，例如加法、减法、乘法、除法和指数。此外，复杂的运算符实际上可以分解为这些基本的运算符。之前在方法问题求解领域的工作实际上可以归纳为序列到序列和序列到树模型。传统的序列到序列模型将表达式转换为一个特定的序列以便生成，这实现起来非常容易，并且可以推广到许多不同的复杂问题。但其性能的缺点是通常不如结构化模型好，而且缺乏对预测的可解释性。但是，这个方向由于transformer模型而仍然相当流行。在基于树的模型中，我们实际上将这些表达式结构化为树的形式，并遵循预序遍历进行三代。在基于树的模型中，我们实际上将这些表达式结构化为树的形式，并遵循预序遍历进行树代。在这里，我们不断生成运算符直到到达叶节点，叶节点是数量。这里的好处是它实际上为我们提供了这种二元树结构。结构，但实际上这有点反直觉，因为我们首先生成运算符，然后在最后生成数量，但实际上这有点反直觉，因为我们首先生成运算符，然后在最后生成数量。第二点是，它也包含一些重复计算。在这里，如果我们看一下这个表达式，a乘以3加3，实际上被生成了两次。但事实上我们应该重用结果。在我们的提出的方法中，我们希望以逐步和可解释的方式来解决这些问题。例如，在这里第二步，我们可以获得这个除数，即27，并且我们还可以回溯到原始问题以查找相关内容。在这些步骤中，我们获得除数。然后，在这个第三步，我们实际上得到商。好了。在经过这三步之后，我们实际上可以重用第二步的结果，然后得到第四步的结果。然后，最后我们可以获得被除数。在这里，我们实际上直接生成整个表达式，而不是生成单个运算符或数量。这使得过程更准确。在我们的演绎系统（deductive system）中，我们首先从问题中呈现的一堆数量开始，也包括一些常数作为我们的初始状态。表达式由 EIJOP 表示，我们在 QI 到 QJ 之间执行运算符，这种表达式实际上是有方向的。我们这里也有减法反向来表示相反的方向。这与关系提取（relation extraction）非常相似。在一个正式的演绎系统中，在时间步 t，我们应用 QI 和 QJ 之间的运算符，然后我们获得这个新的表达式。我们将它添加到下一个状态以成为一个新的数量。这个幻灯片实际上可视化了状态的演变，我们不断将表达式添加到当前状态。在我们的模型实现中，我们首先使用预训练的语言模型，可以是birds或rabbits，然后我们编码一个句子，然后我们获得这些数量表示。一旦我们获得数量表示，我们就可以开始进行推理。这里展示一个例子，从 Q1 获得 Q1 除以 Q2 和乘以 Q3 的表示。首先我们获得配对表示，它基本上只是 Q1 和 Q2 之间的连接。然后我们应用一个前馈网络，该网络由运算符参数化。然后，我们最终获得表达式表示 Q1 除以 Q2。但在实践中，在推理阶段，我们可能也能够获得不正确的表达式。这里所有可能的表达式等于运算符的数量乘以三。这里的好处是，我们可以轻松添加约束来控制这个搜索空间。例如，如果这个表达式不允许，我们可以简单地从我们的搜索空间中删除这个表达式。在第二步，我们做同样的事情，但唯一不同的是多了一个数量。这个数量来自先前计算的表达式。因此，我们最终可以获得这个最终表达式，Q3 乘以 Q4。我们可以看到所有可能的表达式的数量与之前的步骤不同。这种差异使得很难应用beam search，因为这两个步骤之间的概率分布是不平衡的。训练过程类似于训练序列到序列模型，我们在每个时间步优化损失。在这里，我们还使用 tau 来表示何时应该终止这个生成过程。这里的空间与序列到序列不同，因为空间在每个时间步都不同，在传统的序列到序列模型中，它是词汇数量，它也允许我们从先验知识中施加某些约束。我们对常用的方法问题数据集 mawps math23k mathqa MATHQA 和 SWAMP 进行了实验。在这里，我们简要显示了与先前最佳方法相比的结果。我们表现最好的变体是 Robeta deductive reasoner。事实上，我们没有使用 beam search，与最佳方法通常是基于树的模型。总的来说，我们的推理器能够明显优于这种基于树的模型，但我们可以看到 MathQA 或 SWAMP 上的绝对数字并不是很高。我们进一步研究了 Swamp 上的结果，这个数据集具有挑战性，因为作者试图手动添加一些东西来迷惑 NLP 模型，例如添加不相关的信息和额外的数量。在我们的预测中，我们发现某些中间值实际上是负数。例如，在这个问题中，我们正在询问杰克有多少个苹果，但我们有一些额外的关于 17 个较少的桃子，以及史蒂文有 8 个桃子的信息，这完全无关紧要。因此，我们的模型会做出一些预测，产生负数。我们观察到这两个表达式实际上具有相似的分数。因此，我们可以通过删除这些负数结果来限制这个搜索空间，从而使答案正确。我们进一步发现这种约束实际上可以相当大地改善某些模型。例如，对于 birds，我们提高了七分。然后，对于基于 Robeta 的模型，我们实际上提高了两分。具有更好的语言模型具有更好的语言理解能力，因此 Robeta 的此处数字更高，而 birds 的数字更低。我们还尝试分析所有这些数据集背后的难度。我们假设可以把未使用的数量的个数视为无关紧要的信息。在这里，我们可以看到我们拥有样本中未使用的数量的百分比，而 SWAMP 数据集具有最大的比例。我们还显示了对没有未使用的数量的样本的整体性能。对于这些样本，整体性能实际上高于整体性能。但是对于那些带有未使用的数量的样本，它的性能比整体性能差很多。对于 MAWPS，我们并没有太多死亡案例，所以我忽略这部分。最后，我们希望通过一个崩溃和参与示例来展示可解释性。在这里，我们的模型在第一步做出错误的预测。因此，我们可以将这个表达式与这里的句子相关联。我们认为这个句子可能会误导模型做出不正确的预测。这里，打印另一个 35 使得模型认为它应该是加法运算符。因此，我们尝试修改句子，使其表达为类似于苹果树的数目比梨树少 55 棵。我们将它修改为传达更准确的语义，从而使模型能够做出正确的预测。这项研究表明可解释的预测如何帮助我们理解模型的行为。总之，我们的工作，首先我们的模型相当有效，并且我们能够提供可解释的求解过程。我们可以轻松地将一些先验知识作为约束来纳入，这可以帮助提高性能。最后一件事是，底层机制不仅适用于方法问题求解任务，还适用于涉及多步推理的其他任务。但是，我们也有一些限制。如果我们有大量的运算符或常数，那么内存消耗可能会非常高。第二件事是，正如前面提到的，由于在不同的时间步概率分布不平衡，因此很难应用 beam search 策略。这就是演讲的结束，欢迎提问。感谢。"}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫安托万，来自马斯特里赫特大学。我将展示与杰里一起完成的工作，关于一个新的用于法定条文检索的数据集。法律问题是许多人生活中不可或缺的一部分，但大多数公民对他们的权利和基本的法律程序缺乏了解。因此，许多无力承担法律专家高昂援助费的弱势公民，往往得不到保护，甚至被剥削。我们的工作旨在通过开发有效的法定条文检索系统，弥合公民与法律之间的差距。这种系统可以为不具备专业技能的人提供免费的法律帮助服务。在深入探讨这项工作的主要贡献之前，让我们首先描述一下法定条文检索的问题。给定一个关于法律事务的简单问题，例如违反职业保密风险是什么，模型需要从大量的立法文本中检索所有相关的法定条文。这项信息检索任务面临着自身的挑战。首先，它需要处理两种类型的语言：用于问题的自然语言和用于法定条文的复杂法律语言。语言分布上的这种差异使得系统更难检索相关候选条文，因为它间接需要一种内在的解释系统，可以将自然语言问题翻译成匹配法定条文术语的法律问题。此外，法定法不是可以单独视为完整信息来源的一堆独立条文，例如新闻或食谱。相反，它是法律条款的结构化集合，只有在考虑其整体背景时，才能发挥全部意义，即与相邻条文、其所属的领域和子领域以及在法律结构中的位置补充信息一起考虑。最后，法定条文通常是小段落，这通常是大多数检索工作中典型的检索单元。在这里，处理的是长文档，可能长达 6000 字。自然语言处理 (NLP) 领域的最新进展引发了对许多法律任务的极大兴趣，例如法律判决预测或自动化合同审查，但由于缺乏大型且高质量的标注数据集，法定条文检索主要仍未得到关注。在这项工作中，我们提出了一个新的、以法语为母语的、以公民为中心的、用于评估检索模型能否逼近法律专家在法定条文检索任务中效率和可靠性的数据集。我们的比利时法定条文检索数据集（PSART）包含来自比利时公民提出的 1100 多个法律问题。这些问题涵盖了从家庭、住房、金钱到工作和社会保障等广泛主题。每一个问题都由经验丰富的法学家根据来自比利时法律法典的超过 22,600 篇法律条文的语料库中的相关条文进行标注。现在，让我们谈谈我们如何收集这个数据集。首先，我们开始编译一个大的法律条文语料库。我们考虑了 32 个公开可用的比利时法律法典，并提取了所有条文以及相应的章节标题。然后，我们收集了引用相关法令的法律问题。为此，我们与一家比利时律师事务所合作，该事务所每年从询问个人法律问题的比利时公民那里收到约 4000 封电子邮件。我们很幸运地获得了他们网站的访问权限，他们的经验丰富的法学家团队解决了比利时最常见的法律问题。我们收集了数千个问题，并对它们进行了分类、子分类和对相关法令的法律引用进行标注。最后，我们解析了法律引用，并过滤掉了引用不是我们在考虑的法律法典中条文的问题。剩余的引用被匹配并转换为我们语料库中相应条文 ID。我们最终得到了 1108 个问题，每个问题都经过精心标注，指向我们 22,633 篇法定条文的大型语料库中的相关条文 ID。此外，每个问题都附有一个主要类别以及子类别的串联，而每篇条文都附有一个在法律结构中其后续标题的串联。这些额外的信息在目前的工作中没有使用，但可能对未来关于法律信息检索或法律文本分类的研究感兴趣。现在让我们来看看我们数据集的一些特点。问题长度在 5 到 44 个单词之间，中位数为 40 个单词。条文要长得多，中位数为 77 个单词，其中 142 篇条文超过 1000 个单词，最长的条文甚至长达 5790 个单词。如前所述，问题涵盖了广泛的主题，其中约 85% 的问题与家庭、住房、金钱或司法有关，而剩余的 15% 涉及社会保障、外国人或工作。条文也非常多样化，因为它们来自 32 个不同的比利时法律法典，涵盖了大量的法律主题。以下是从每个比利时法律法典收集的文章总数。在 22,633 篇文章中，只有 1612 篇文章被认为是至少与数据集中一个问题相关。并且，这些引用的约 80% 来自民法、司法法典、刑事调查法典或刑法典。同时，32 个法典中有 18 个法典中引用的文章少于 5 篇，这可以解释为这些法典不太关注个人及其顾虑的事实。总的来说，这些引用的文章的中位引用次数为 2，并且少于 25% 的文章被引用超过 5 次。使用我们的数据集，我们对多种检索方法进行了基准测试，包括词汇和密集架构。给定一个查询和一个条文，词汇模型通过计算每个查询词权重的总和来为查询-条文对分配一个分数，这些权重存在于该条文中。我们试验标准 TF-IDF 和 BM25 排名函数。这些方法的主要问题是，它们只能检索包含查询中关键词的条文。为了克服这一限制，我们试验了能够捕捉查询和条文之间语义关系的神经网络架构。我们使用 b-encoder 模型，将查询和条文映射到密集向量表示，并通过计算其嵌入的相似度来计算查询-条文对的相关分数。这些嵌入通常是词嵌入模型的输出的池化操作的结果。首先，我们研究了在零样本评估设置中，暹罗 b-encoder 的有效性，这意味着将预训练的词嵌入模型直接应用于出厂设置，而无需任何额外的微调。我们试验了不依赖于上下文的文本编码器，例如 Word2Vec 和 FastText，以及依赖于上下文的嵌入模型，例如 Robota，以及更具体地是 Camembert，这是一个法语 Robota 模型。此外，我们还在我们的数据集上训练了自己的 Camembert 基础的 b-encoder 模型。需要注意的是，在训练过程中，我们试验了 b-encoder 架构的两种口味：暹罗，它使用一个独特的词嵌入模型，将查询和条文在共享的密集向量空间中一起映射；以及双塔模型，它使用两个独立的词嵌入模型，将查询和条文分别编码到不同的嵌入空间中。我们试验了平均、最大和 CLS 池化，以及点积和余弦来计算相似度。以下是我们的基线在带有词汇方法的集合上的结果，中间是零样本设置中评估的暹罗 b-encoder，以及底部是微调的 b-encoder。总的来说，微调的 b-encoder 明显优于所有其他基线。双塔模型在召回率 100 指标上优于其暹罗变体，但在其他指标上表现相似。尽管 BM25 的表现明显低于训练过的 B-Encoder，但其性能表明它仍然是特定领域的检索的强大基线。关于暹罗 B-Encoder 的零样本评估，我们发现直接使用预训练的 Camembert 模型的嵌入，而没有针对信息检索任务进行优化，会产生较差的结果，这与之前的发现一致。此外，我们观察到基于 Word2Vec 的 b-encoder 明显优于基于 FastText 和 BERT 的模型，这表明在开箱即用的情况下，预训练的词级别嵌入比字符级别或子词级别的嵌入更适合这项任务。虽然前景光明，但这些结果表明有充足的改进空间，以比能够最终检索任何问题的所有相关条文并获得完美分数的熟练法律专家更进一步。最后，我们讨论一下所有数据集的两个局限性。首先，文章语料库仅限于从 32 个考虑的法律法典中收集的文章，这并不涵盖整个比利时法律，缺少法令、指令和法规的文章。在数据集构建过程中，忽略了所有对这些未收集的文章的引用，这导致一些问题最终只有最初相关文章数量的一小部分。这种信息丢失意味着剩余的相关文章中的答案可能不完整，尽管它仍然完全合适。其次，我们应该指出，并非所有法律问题都可以通过法令来回答。例如，问题“如果租户制造了过多的噪音，我可以驱逐我的租户吗？”可能没有详细的法定法律规定定量特定的噪音阈值，从而允许驱逐。相反，房东可能应该更多地依赖案例法，并找到与其当前情况相似的先例。例如，租户每周派对两次，直到凌晨 2 点。因此，有些问题比其他问题更适合法定条文检索任务，而不太合适问题的领域仍有待确定。我们希望我们的工作能够激发对开发实用且可靠的法定条文检索模型的兴趣，从而有助于改善所有人的司法可及性。您可以在以下链接中查看我们的论文、数据集和代码。感谢您的收听。"}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "你好！我们很高兴地向大家介绍我们的 VALS 工作，这是一个与特定语言现象相关的、独立的任务基准，用于测试视觉和语言模型。我们为什么要费心搭建这个基准呢？嗯，在过去的几年里，我们目睹了基于 Transformer 的视觉和语言模型爆发式增长，它们在大量的图像文本对上进行预训练。这些模型中的每一个都在视觉和语言任务上实现了最先进的水平，例如视觉问答、视觉常识推理、图像检索、短语定位。因此，我们注意到这些特定任务基准上的准确率在稳步提高。但我们是否知道这些模型实际上学到了什么呢？当模型为某个图像和某个句子匹配时赋予一个高分，而为另一个赋予一个低分时，它究竟理解了什么？视觉和语言模型是否关注正确的事物，还是关注先前研究中已展示的偏差？为了更深入地了解这一方面，我们提出了一个更具任务独立性的方向，并引入了“阀门”，用于测试视觉和语言模型对影响视觉和语言模态的特定语言现象的敏感性。我们针对的是存在、复数、计数、空间关系、动作、实体指代。但是，我们如何测试视觉和语言模型是否捕捉到了这些现象呢？通过 FOIL 方法，该方法之前已应用于视觉和语言模型，由 Ravi Shekhar 及其合作者针对名词短语，以及我们在先前工作中使用该方法进行计数。FOIL 的基本原理是，我们获取图像的标题，然后通过改变标题，使其不再描述图像，从而生成一个 FOIL。我们通过关注六个特定方面进行这些短语更改，例如存在、复数、计数、空间关系、动作和实体指代，每个方面可能由一个或多个工具组成，以防我们发现创建 FOIL 实例的多种有趣方式。例如，在动作方面，我们有两个工具，一个工具是更改动作动词为不同的动作，另一个工具是交换行为者。计数和指代也是具有多个工具的方面。我们创建这些 FOIL，以确保它们无法描述图像，并且是语法上正确且其他方面有效的句子。这不容易做到，因为被 FOIL 过的标题可能不太可能比原始标题更常见。例如，虽然并非不可能，但植物砍伐男人的可能性比男人砍伐植物的可能性要小，而大型视觉和语言模型可能会抓住这一点。因此，为了获得有效的 FOIL，我们必须采取行动。首先，我们利用强大的语言模型来提出 FOIL。其次，我们使用自然语言推理（NLI），或简化的 NLI，来过滤掉仍然可能描述图像的 FOIL，因为在构建 FOIL 时，我们需要确保它们无法描述图像。为了自动测试这一点，我们使用自然语言推理，其原理如下。我们将图像视为前提，将其标题视为蕴含。此外，我们将标题视为前提，FOIL 视为假设。如果 NLI 模型预测 FOIL 与标题矛盾或中性，我们将此视为有效 FOIL 的指标。如果 NLI 预测 FOIL 被标题蕴含，那么它不能是一个好的 FOIL，因为通过传递性，它将给出图像的真实描述，我们会过滤掉这些 FOIL。但是，此过程并非完美无缺。它仅仅是有效 FOIL 的一个指标，因此作为生成有效 FOIL 的第三项措施，我们聘请了人工标注员来验证 VALS 中使用的数据。因此，经过过滤和人工评估，我们拥有本文表中描述的测试实例数量。需要注意的是，VALS 不提供任何训练数据，只提供测试数据，因为它是一个零样本测试基准。它旨在利用视觉和语言模型在预训练后的现有能力。微调只会使模型能够利用数据中的伪像或统计偏差。我们都知道这些模型喜欢作弊和采取捷径。正如我们所说，我们对评估视觉和语言模型在预训练后所具备的能力感兴趣。我们使用 CLIP、LXMERT、Wil VILBERT、VILBERT 12 in 1 和 VISUALBERT 五个视觉和语言模型在 VALS 上进行了实验。我们最重要的评估指标有两个：模型将图像-句子对分类为标题和 FOIL 的准确率。也许更重要的是对视频内容有帮助的，我们将展示我们的更宽松的指标，即成对准确率，它衡量的是图像-句子对齐分数是否大于其 FOIL 的对齐分数。有关更多指标和结果，请查阅我们的论文。成对准确率的结果在此处显示，这些结果与我们从其他指标获得的结果一致，即 Wilbert 12-in-1 实现了最佳零样本性能，其次是 Wilbert、Alex Mert、Clip 和 Visual Bird。值得注意的是，以单个对象为中心的工具，如存在和名词短语，几乎被 Wilbert 12-in-1 解决，这表明模型能够识别图像中的命名对象及其存在。但是，其余的方面都无法在我们的对抗性 FOIL 设置中可靠地解决。从复数和计数工具来看，我们发现视觉和语言模型难以区分对单个对象或图像中多个对象的引用或对它们的计数。关系方面表明，它们难以正确地对图像中命名对象之间的空间关系进行分类。它们也很难区分动作并识别其参与者，即使在存在合理性偏差的情况下，如我们在动作方面所看到的。从指代方面，我们发现通过使用代词追踪图像中对同一对象的多个引用也很困难。作为一个理智检查，也是因为这是一个有趣的实验，我们还对两个纯文本模型 GPT-1 和 GPT-2 进行了基准测试，以通过计算正确和 FOIL 标题的困惑度并预测困惑度最低的条目来评估 VALS 是否可由这些单模态模型解决。如果 FOIL 的困惑度更高，我们将此视为 FOIL 标题可能存在合理性偏差或其他语言偏差的指标。有趣的是，在某些情况下，纯文本 GPT 模型比视觉和语言模型更好地捕捉了世界的合理性。总而言之，VALS 是一个基准，它通过对视觉和语言模型进行严格测试，使用语言结构的视角来帮助社区改进视觉和语言模型，以提高其视觉定位能力。我们的实验表明，视觉和语言模型可以很好地识别图像中命名对象的存在，如存在方面所展示的那样，但当被迫尊重语言指示时，它们难以理解视觉场景中它们之间的相互依赖性和关系。我们真诚地鼓励社区使用 VALS 来衡量在视觉和语言模型上的语言定位进展。而且，VALS 还可以作为数据集的间接评估，可以在训练或微调前后评估模型，以查看数据集是否有助于模型在 VALS 测试的任何方面取得改进。如果您感兴趣，请在 GitHub 上查看 VALS 数据，如有任何疑问，请随时联系我们。"}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是东京大学的间泽。我将发表一篇题为《RNSUN：面向基于提交日志摘要的自动发布说明生成的大规模数据集》的论文。我将按照以下顺序进行讲解。首先，我将介绍我们正在进行的自动发布说明生成研究。发布说明是一份技术文档，用于总结软件产品每次发布所包含的更改。图片显示了 Vue.js 库 2.6.4 版本的发布说明。发布说明在开源开发中扮演着重要的角色，但手动准备它们非常耗时。因此，能够自动生成高质量的发布说明将非常有用。我将回顾两项关于自动发布说明生成的先前研究。第一项是 2014 年发布的名为 Arena 的系统。它采用基于规则的方法，例如，使用变更提取器从版本之间的差异中提取核心差异、库更改和文档更改，并最终将它们组合起来。该系统的最显著特征是右上角的 issue 提取器，必须链接到 Jira，即问题跟踪系统，并且只能应用于使用 Jira 的项目。换句话说，它无法用于 GitHub 上的许多项目。第二项是 Glyph，最近在 2020 年宣布。它可在互联网上使用，并通过 PIP 进行存储。该系统具有一个简单的基于学习的文本分类模型，并为每个输入提交消息输出五个级别之一，例如功能或错误修复。图片是一个示例用法，返回了修复或错误修复标签。Glyph 的训练数据相对较小，大约 5000 条，在以下描述的实验中，文本分类模型的性能并不高。我介绍了这两项相关研究，但它们存在适用性有限和数据资源匮乏的问题。我们的论文解决了这两个问题，并自动生成高质量的发布说明。为了解决适用性有限的问题，我们提出了一种仅使用提交消息作为输入的、高质量的分类器摘要方法。这种提出的方法可以用于所有英文仓库。对于数据资源匮乏的第二个问题，我们使用 RR 和一些数据集，从公共 GitHub 仓库中收集数据，构建了一个包含约 82,000 条数据的 R 和 sum 数据集。我们由约 82,000 条数据组成的 Rnsum 数据集是通过使用 GitHub API 从公共 GitHub 仓库中收集数据而构建的。接下来，我将描述我们的数据集。这里有一个数据示例。左侧是提交消息，右侧是发布说明。发布说明被标记为 faces 的改进等。我们设置了，左侧是提交消息，右侧是发布节点。发布节点被标记为改进、错误修复等。我们设置了一个任务，该任务将提交消息作为输入，并输出标记的发布节点。这可以被视为一个摘要任务。我们预定义了四个标签：功能、改进、错误修复、弃用、删除和破坏性更改。这些标签是根据先前研究和其他因素设置的。底部的节点是从底部的节点中提取的。此时，需要检测预先设置的四个标签。但是，标签并不总是与每个仓库一致。例如，改进标签包括改进、增强、优化等。我们准备了一个词汇表列表，用于我们研究中的每个标签，用于检测这些标记变异的发布说明类，并将后续文本修正为类需要标识的发布说明句子。对于版本 2.5 到 18，需要获取其 diff。这有点麻烦，仅获取发布列表并查看前后是不够的。我们创建了一个启发式匹配规则来获取前一个版本和下一个版本。数据集分析。最终收集了 7200 个仓库和 82,000 条数据。此外，发布节点标记的平均数量为 63，对于摘要任务来说，这相当高。此外，唯一标记的数量也非常大，为 8,830,000。这归因于仓库中发现的大量唯一类和方法名称。接下来，我将解释我们提出的方法。 类式提取式-抽象式摘要模型由两个神经网络组成。它使用分类器将每个提交消息分类为五个发布说明类别。我们选择实现、错误修复、弃用加等。将分类为其他类的提交消息将被丢弃。然后，CEAS 独立地将生成器应用于四个标签文档，并为每个类别生成发布说明。在这个任务中，提交消息和发布说明之间的直接对应关系并不明确。因此，为了训练分类器，我们使用每个提交消息的前 10 个字符，为每个输入提交消息分配伪标签。我们通过我们的方法对类式抽象式摘要进行建模，使用两种不同的方法。第一种模型，我们称之为 cssingle，由一个单向集合到集合网络组成，它生成一段长文本节点，给，给一个输入提交消息的连接。输出文本网络，每个网络对应于一个已知的类别之一。好的，让我解释一下实验。比较了五种方法：CAS、CASSingle、CASMatch、PlusSelling 和先前研究 GRIF。对于异常情况，在某些情况下，CSMatch、Blustering 和先前研究 Glyph。关于评估，在某些情况下，发布说明以多个句子输出。由于难以计算它们作为句子的数量，因此它们与空格组合并视为一个长句子。当系统输出短句子时，会进行惩罚。这种惩罚导致了下一次实验结果中较低的蓝色值。最后，我们还计算了 specificity，因为如果发布节点为空，则无法计算 rouge 和 blue。高 specificity 表示该模型在发布节点为空的情况下正确输出空文本。以下是结果。由于数据集包含电子邮件地址、哈希值等，因此我们还评估了排除它们的清理后的数据集。CES 和 CAS 的 rouge L 分数比基线高了 10 多分。特别是，在干净的测试集中，提出的方法和基线之间的分数差距增加到了 20 多分。这些结果表明，CAS 和 CAS 显著有效。CAS 的 root-A 分数优于 CAS，表明在训练分类器时，结合分类器和生成器是有效的，可以实现 CAS 的高覆盖率，可能是因为分类器可以专注于为每个类别选择相关的提交消息。CAS match 倾向于产生高于 CAS single 的 log L，表明独立开发针对每个发布说明类进行不同抽象的摘要模型也是有效的。以下是错误分析。CAS 方法倾向于输出比人工参考句子短的句子。在右侧的图中，参考句子有三个或四个句子，而 CAS 只有一句。这种模型犹豫不决的原因是，在训练数据中，只有 33% 的句子出现在功能标签中，而 40% 出现在改进标签中。此外，CES 方法在没有额外信息的情况下无法生成准确的发布说明。右侧的顶部示例是一个非常混乱的提交消息示例，在没有参考相应的 pro 请求或 issue 的情况下，无法生成完整的句子。下面的示例显示，输入中的两个提交消息是相关的，并且应该合并为一个句子，但它无法做到。最后，结论。我们构建了一个新的数据集，用于自动列表符号。我们还形成了输入提交消息并对其进行摘要的任务，使其适用于所有用英文编写的项目。我们的实验表明，提出的方法比基线生成了更少的噪声发布节点，并具有更高的覆盖率。请查看我们的 Descent only tab。谢谢。"}
