{"dataset_id": "mcif_v1.0", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, willkommen zu unserer Präsentation von DeepLing, einem neuen Korpus für die deutsche Textidentifikation auf Dokumenten- und Satzebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Regina Stodden und ich werde Sie durch den ersten Teil der Präsentation führen. Lassen Sie uns zunächst die Textvereinfachung definieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Textvereinfachung ist ein Prozess, bei dem ein Text so angepasst wird, dass er für eine bestimmte Zielgruppe, wie z. B. Menschen mit Leseproblemen oder Nicht-Muttersprachler, besser verständlich wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Um ein Textzusammenfassungsmodell zu trainieren, benötigen wir parallele Textpaare, z. B. Dokumente oder Sätze."}
{"dataset_id": "mcif_v1.0", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel sehen Sie ein parallel ausgerichtetes Satzpaar, das aus einem komplexen deutschen Satz und seiner Übersetzung in eine einfache Sprache besteht."}
{"dataset_id": "mcif_v1.0", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Um den Satz zu vereinfachen, sind verschiedene Techniken möglich, wie im Beispiel zu sehen ist, z. B. lexikalische Substitution, Klauselverknüpfung, Klausellöschung, Klauselneuordnung oder das Einfügen von Wörtern."}
{"dataset_id": "mcif_v1.0", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wir schlagen nun unseren neuen Korpus vor, Deplane, da es in den letzten Jahren einige Probleme mit bestehenden Korpora gab. Zum Beispiel sind diese Korpora hier zu klein, um ein Textverifizierungsmodell darauf zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie in ihren Ausrichtungen fehleranfällig sein können."}
{"dataset_id": "mcif_v1.0", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Daher schlagen wir unseren neuen Korpus D-Plane vor, der in zwei Unterkorpora aufgeteilt ist: D-Plane APA und D-Plane Web. D-Plane APA basiert auf Nachrichtentexten."}
{"dataset_id": "mcif_v1.0", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In der Ebene APA haben wir 483 Dokumente manuell ausgerichtet. Das ergibt etwa 30.000 parallele Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "Für DeepL Web umfasst dieser Korpus verschiedene Domänen und wir haben alle 750 Dokumente manuell und mit automatischen Ausrichtungsmethoden ausgerichtet."}
{"dataset_id": "mcif_v1.0", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ergaben sich 30.450 Satzpaare."}
{"dataset_id": "mcif_v1.0", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unsere Satzpaare etwas genauer analysiert, zum Beispiel nach der Art der Semantifizierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel die Nachrichtentexte oder die Texte für Sprachlerner."}
{"dataset_id": "mcif_v1.0", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Ebenen, z. B. bei der lexikalischen Vereinfachung, der strukturellen Vereinfachung oder der allgemeinen Vereinfachungsebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem sehen Sie, dass unser Deplane-Korpus eine hohe Vielfalt an verschiedenen Vereinfachungstransformationen aufweist. So haben wir beispielsweise im Deplane-API-Korpus viel mehr Umstellungen und Wortzusätze als im Deplane-Web-Korpus."}
{"dataset_id": "mcif_v1.0", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits gibt es im Webkorpus viel mehr Umformulierungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns nun an, was wir mit diesem Korpus machen können. Hallo, ich bin Omar und werde nun über die Anwendungsfälle für unseren Datensatz DeepL sprechen. Für den ersten Anwendungsfall können wir automatische Ausrichtungsmethoden bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren gab es viele Ausrichtungsmethoden, aber im Kontext der maschinellen Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei parallele Dokumente in verschiedenen Sprachen und möchten die Ausrichtung der Sätze in den Dokumenten extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Anwendungsfall versuchen wir jedoch, Übereinstimmungen zwischen Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache verwenden, denselben Inhalt haben, aber auf einem unterschiedlichen Komplexitätsniveau sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Da wir nun unseren Datensatz D-Plane haben, der manuell ausgerichtete Sätze enthält, können wir diese Sätze als Goldstandard-Ausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einige Anpassungen an den vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes zum Ausführen unserer Experimente im Papier veröffentlicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende kamen wir zu dem Schluss, dass die beste automatische Ausrichtungsmethode für die Vereinfachung von deutschen Texten die Methode von MassAlign ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch den Code finden, um diese Methode auf Ihren eigenen Dokumenten im Papier auszuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Anwendungsfall, den wir in unserem Artikel gezeigt haben, ist der Fall der automatischen Textvereinfachung."}
{"dataset_id": "mcif_v1.0", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Durch Feinabstimmung von Sprachmodellen, um vereinfachten Text aus dem komplexen Eingabetext zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Modelle feinabgestimmt. Wir haben das Modell von LongIMPART feinabgestimmt, um Vereinfachungen auf Dokumentebene zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die normale Basis in der Importfunktion angepasst, um Vereinfachungen auf Satzebene zu erzeugen."}
{"dataset_id": "mcif_v1.0", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Sie können auch alle Kontrollpunkte finden und die Punktzahlen und die Bewertungsmatrix unserer Experimente im Papier genauer betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen zu dem Schluss, dass diese grundlegende Feinabstimmung Ergebnisse erzielen könnte, die besser sind als die Ausgangsergebnisse."}
{"dataset_id": "mcif_v1.0", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schlagen diese Ergebnisse als Benchmark, einen Basis-Benchmark für das Problem der automatischen Textvereinfachung in der Zukunft vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Adam Spivakowski und dieses Gespräch dreht sich um die Abhängigkeitsstruktur der Koordination."}
{"dataset_id": "mcif_v1.0", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, gehen verschiedene Theorien und Korpusansätze von unterschiedlichen Abhängigkeitsstrukturen aus. So wird zum Beispiel in universellen Abhängigkeiten die Struktur der Koordination „Lisa, Bart und Maggie“"}
{"dataset_id": "mcif_v1.0", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "... so dass das erste Konjunkt das Hauptwort des gesamten Koordinationssatzes ist, in diesem Fall Lisa."}
{"dataset_id": "mcif_v1.0", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Ein ähnlicher Ansatz wird in der Bedeutungstheorie von Igor Mel'čuk angenommen, wo wiederum die gesamte Koordinationsstruktur durch das erste Konjunkt geführt wird. Diese beiden Ansätze sind also asymmetrisch, oder? Sie heben eines der Konjunkte hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt auch symmetrische Ansätze für Koordinationsstrukturen, wie den Prager Ansatz, den konjunktionsgesteuerten Ansatz, der in den Prager Abhängigkeitsbäumen verwendet wird, bei denen die Koordinationsstrukturen durch die Konjunktion gesteuert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "Wir erhalten also Abhängigkeiten von „and“ zu allen Konjunktionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich gibt es auch einen mehrköpfigen Ansatz, der beispielsweise in der Wortgrammatik von Hudson verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "wo alle Konjunkte Köpfe der Koordinationsstruktur sind. Wir erhalten also Abhängigkeiten vom Regens (hier „liebt“) zu allen Konjunkten einzeln. Diese sind in der Abbildung markiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "Ziel dieses Papiers ist es, ein neues Argument für symmetrische Koordinationsstrukturen wie diese beiden und gegen asymmetrische Koordinationsstrukturen wie diese zu liefern."}
{"dataset_id": "mcif_v1.0", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Das Argument basiert auf dem Prinzip der Abhängigkeitslängenminimierung, das ich anhand dieser Beispiele erläutern werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Wie Sie vielleicht wissen, bevorzugen direkte Objekte in der englischen Sprache die Nähe zum Verb, während Adjunkte weiter entfernt sein können, richtig? „Marge las es gestern“ ist also in Ordnung, weil das direkte Objekt „es“ in der Nähe des Verbs steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Während „Marge las es gestern“ viel schlechter ist, oder? Denn hier befindet sich zwischen dem Verb und dem direkten Objekt das Adjunkt „gestern“."}
{"dataset_id": "mcif_v1.0", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Effekt kann jedoch abgeschwächt werden, wenn das direkte Objekt sehr schwer und lang ist, da es dann hinter das Adjektiv verschoben werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Das wird hier veranschaulicht. Beide Sätze sind also in Ordnung. „Marge hat gestern dieses absolut faszinierende Buch über die Bienen gelesen“ ist okay, da wir anstelle von „es“ diesen langen NP haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist auch in Ordnung zu sagen: „Ich habe gestern dieses absolut faszinierende Buch über Bienen gelesen.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die Begründung hierfür ist, dass dies möglich ist, weil dieser Satz zwar das allgemeine grammatikalische Prinzip verletzt, dass direkte Objekte neben dem Verb stehen sollten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Es erfüllt das Prinzip der Minimierung der Abhängigkeitslänge, das besagt, dass kürzere Abhängigkeiten bevorzugt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Diese beiden Bäume zeigen nur die Länge der kritischen Abhängigkeiten, also diejenigen, die zwischen diesen beiden Strukturen nicht konstant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir eine Abhängigkeit von „rot“ zu dem Adjektiv der Länge 7, gemessen in Wörtern, und von „rot“ zu „Buch“ der Länge 4, zusammen also 11."}
{"dataset_id": "mcif_v1.0", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie diese beiden Bestandteile vertauschen, wird die Summe dieser beiden Abhängigkeiten zu sechs, richtig? Anstatt 11 also 6, viel kürzer. Deshalb klingt das ziemlich in Ordnung, richtig? Es verletzt ein Prinzip, erfüllt aber ein anderes."}
{"dataset_id": "mcif_v1.0", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Okay, was wir gemacht haben, wir haben verschiedene Statistiken über die Koordination aus der erweiterten Version der Penn Treebank extrahiert und sehen Sie den Artikel, warum wir keine universellen Abhängigkeiten verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Statistiken bestätigen die bereits oft getätigte Beobachtung, dass linke Konjunkte tendenziell kürzer sind, also „Salz und Pfeffer“ und nicht „Pfeffer und Salz“, gemessen in Silben."}
{"dataset_id": "mcif_v1.0", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "und auch die Beobachtung, die nebenbei gemacht wurde, dass diese Tendenz mit der Längendifferenz zunimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Wenn also der Unterschied zwischen den Längen der beiden Konjunktive wächst, bevorzugt der kürzere Konjunktiv stärker, als erster zu sein, richtig? Die Proportion des linken kurzen Konjunktivs ist also größer."}
{"dataset_id": "mcif_v1.0", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Was in dieser Arbeit neu ist, ist, dass wir festgestellt haben, dass dieser Trend nur auftritt, wenn die Gouverneure auf der linken Seite fehlen."}
{"dataset_id": "mcif_v1.0", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Der Gouverneur ist in diesem Beispiel links. Ich sah Bart und Lisa, also ist der Gouverneur links."}
{"dataset_id": "mcif_v1.0", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Hier fehlt es im zweiten Beispiel. Homer kam und nieste. Hier haben wir die Koordination zweier Verben und es gibt keinen externen Regenten. In solchen Fällen bevorzugt das linke Konjunkt kürzer zu sein, je größer der Unterschied zwischen den beiden Konjunkten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Regierung jedoch auf der rechten Seite ist, wie hier, verschwindet dieser Effekt, da die Linke die Koordination des Netzes regiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben gezeigt, dass durch die Messung der Länge in Zeichen (erste Spalte), Silben (mittlere Spalte) und Wörtern (rechte Spalte) – ich werde mich auf die rechte Spalte konzentrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Was wir hier sehen, ist, dass, wenn die Steuerung auf der linken Seite ist,"}
{"dataset_id": "mcif_v1.0", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Die Tendenz, dass die linke Konjunktion kürzer ist, steigt mit der absoluten Differenz der Wörter stetig an, und dasselbe wird beobachtet, wenn es keinen Regenten gibt, wie bei der Koordination von Sätzen, aber wenn der Regent auf der rechten Seite ist, verschwindet diese Tendenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "In der Arbeit zeigen wir, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese beiden und für symmetrische Strukturen wie diese beiden liefert."}
{"dataset_id": "mcif_v1.0", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Sehen Sie sich das Papier für die vollständige Vereinbarung und Argumente an und sprechen Sie in der Postersitzung mit uns. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Shangbing, Doktorand an der Universität von Washington. Heute stelle ich unsere Arbeit vor, die sich mit der Vorverarbeitung von Daten, Sprachmodellen und nachgelagerten Aufgaben beschäftigt und den Weg politischer Voreingenommenheiten zu unfairen NLP-Modellen nachverfolgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle werden also auf der Grundlage von umfangreichen Web-Crawling-Daten trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Politische Nachrichtenmedien sind in ihren Vordaten gut vertreten. Laut einer Umfrage des C4-Korpus sind die New York Times, die Los Angeles Times, The Guardian, die Huffington Post usw. in den Sprachmodell-Trainingsdaten gut vertreten."}
{"dataset_id": "mcif_v1.0", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Dies hat für Anwendungen von Sprachmodellen einen gemischten Segen geschaffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Einerseits konnten sie aus verschiedenen Perspektiven lernen, was Demokratie und die Vielfalt der Ideen feiert. Andererseits sind diese unterschiedlichen politischen Meinungen von Natur aus sozial voreingenommen und könnten zu potenziellen Fairnessproblemen bei der Anwendung auf nachgelagerte Aufgaben führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir vor, die politische Verzerrungspipeline von den Vordaten über Sprachmodelle bis hin zu nachgelagerten Aufgaben zu untersuchen, indem wir insbesondere die folgenden Fragen stellen:"}
{"dataset_id": "mcif_v1.0", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal: Wie bewerten wir die politische Ausrichtung von Sprachmodellen? Und welche Rolle könnte das Training der Daten bei solchen politischen Voreingenommenheiten spielen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wie verhalten sich Sprachmodelle mit unterschiedlichen politischen Grenzen bei der Ausführung von Downstream-Aufgaben und ob dies zu Fairness-Problemen bei NLP-Anwendungen führen könnte?"}
{"dataset_id": "mcif_v1.0", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Spezifischer gesagt, schlagen wir vor, Sprachmodelle mit verschiedenen Prompt-Formaten unter Verwendung politischer Fragebögen wie dem politischen Kompass-Test zu befragen. Dies stellt sicher, dass wir eine automatische Bewertung durchführen können, die auf der Literatur der Politikwissenschaft basiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle unterschiedliche politische Neigungen haben. Sie befinden sich in allen vier Quadranten des politischen Kompasses."}
{"dataset_id": "mcif_v1.0", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Man kann auch sehen, dass GPT-4 das liberalste Sprachmodell von allen ist und dass GPT-Modelle im Allgemeinen sozialliberaler sind als BERT-Modelle und deren Varianten."}
{"dataset_id": "mcif_v1.0", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens wollen wir untersuchen, inwieweit die politischen Voreingenommenheiten von Sprachmodellen tatsächlich aus den Trainingsdaten übernommen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir könnten ein kontrolliertes Experiment durchführen, indem wir Sprachmodell-Checkpoints auf sechs verschiedenen parteiischen Korpora weiter trainieren, die in Nachrichten und soziale Medien unterteilt sind, die wiederum nach ihrer politischen Ausrichtung unterteilt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir Sprachmodelle weiter auf solchen parteiischen Korpora trainieren, können wir sehen, dass sich die ideologischen Koordinaten des Sprachmodells entsprechend verschieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man beispielsweise RoBERTa weiter auf einem linkslastigen Reddit-Korpus trainiert, kann man eine deutliche Verschiebung in Richtung Liberalismus in Bezug auf seine"}
{"dataset_id": "mcif_v1.0", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Was seine politischen Vorurteile betrifft."}
{"dataset_id": "mcif_v1.0", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch versucht zu untersuchen, ob Sprachmodelle die Polarisierung aufgreifen können, die in unserer modernen Gesellschaft weit verbreitet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen also die Trainingskorpora in „vor dem 45. Präsidenten der Vereinigten Staaten“ und „nach dem 45. Präsidenten der Vereinigten Staaten“ auf und trainieren Sprachmodelle separat an den beiden unterschiedlichen zeitlichen Korpora."}
{"dataset_id": "mcif_v1.0", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Man kann sehen, dass Sprachmodelle im Allgemeinen eine politische Ausrichtung haben, die nach 2017 weiter vom Zentrum entfernt ist. Dies deutet darauf hin, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufgreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Zu guter Letzt bewerten wir Sprachmodelle mit unterschiedlichen politischen Neigungen bei der Erkennung von Hassreden und Fake News, zwei NLP-Anwendungen, die oft Sprachmodelle beinhalten und sehr weitreichende Auswirkungen haben könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir also die Leistung pro Kategorie untersuchen, das heißt, wenn wir die Leistung in"}
{"dataset_id": "mcif_v1.0", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Bei verschiedenen Demografien oder politischen Neigungen von Nachrichtenmedien kann man ein Muster erkennen, dass beispielsweise bei der Erkennung von Hassreden linksgerichtete Sprachmodelle besser sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Erkennung von Hassreden, die sich gegen sozial benachteiligte Gruppen richten,"}
{"dataset_id": "mcif_v1.0", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Sie sind jedoch weniger gut darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Und umgekehrt sind Sprachmodelle mit Recht besser darin, Hassreden zu erkennen, die sich gegen Weiße und Männer richten, aber schlechter darin, Hassreden zu erkennen, die sich gegen Schwarze, LGBTQ+ und andere Minderheiten richten."}
{"dataset_id": "mcif_v1.0", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Ähnliche Trends sind auch bei der Erkennung von Fake News zu beobachten, wo wir feststellen, dass Sprachmodelle mit linksgerichteter Ausrichtung besser darin sind, Fehlinformationen aus der entgegengesetzten politischen Ausrichtung zu erkennen, und umgekehrt."}
{"dataset_id": "mcif_v1.0", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen weiterhin viele qualitative Beispiele, um zu sehen, dass Sprachmodelle mit unterschiedlichen politischen Meinungen"}
{"dataset_id": "mcif_v1.0", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Geben Sie unterschiedliche Vorhersagen für Hassreden und Fehlinformationen basierend auf ihrer sozialen Kategorie an. Es gibt eine Menge weiterer Beispiele im Anhang, um dies weiter zu verdeutlichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Das deutet darauf hin, dass es ein sehr dringendes Fairnessproblem in Bezug auf die politischen Voreingenommenheiten von Sprachmodellen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Wenn beispielsweise ein Sprachmodell für eine Sprache, die von rechts nach links geschrieben wird, auf Hassreden oder Fehlinformationen oder was auch immer feinabgestimmt und auf einer beliebten Social-Media-Plattform eingesetzt würde,"}
{"dataset_id": "mcif_v1.0", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Das würde bedeuten, dass Menschen mit gegensätzlichen politischen Meinungen an den Rand gedrängt werden könnten und Hassreden, die Minderheiten angreifen, unkontrolliert um sich greifen könnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Das hat uns dazu veranlasst, die Fairnessprobleme, die durch politische Tendenzen von Sprachmodellen entstehen, anzuerkennen und zu bekämpfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten auch darauf hinweisen, dass wir das einzigartige Dilemma in Bezug auf politische Voreingenommenheiten in Sprachmodellen aufzeigen. Es ist wie zwischen Scylla und Charybdis."}
{"dataset_id": "mcif_v1.0", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir politische Meinungen in den Sprachmodell-Trainingsdaten nicht bereinigen, wird die Verzerrung von den Vordaten zum Sprachmodell und zu den nachgelagerten Aufgaben weitergegeben und letztlich zu Fairness-Problemen führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir versuchen, irgendwie zu desinfizieren, riskieren wir auch Zensur oder Ausschluss, und es ist unglaublich schwer zu bestimmen, was tatsächlich neutral ist und die Spracheinheitendaten behalten sollte. Es ist also sozusagen das elektrische Stuhlproblem."}
{"dataset_id": "mcif_v1.0", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Okay, großartig. Ich denke, das ist so ziemlich alles, was ich für heute zu sagen habe. Danke für Ihre Zeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Jenny, eine Doktorandin im ersten Jahr an der Carnegie Mellon University, und heute werde ich meine Arbeit „NL Positionality: Charakterisierung von Design durch sensible Datensätze und Modelle“ vorstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde in Zusammenarbeit mit einigen Personen der Universität Washington und des Allen Institute for AI durchgeführt, nämlich Sebastian Thrun, Ronan Le Bras, Katarina Grolinger und Martin Sahlén."}
{"dataset_id": "mcif_v1.0", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Stellen Sie sich vor, Sie arbeiten für eine Zeitung und durchsuchen die Kommentare unter Ihrem Artikel, um toxische Inhalte zu entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Sie könnten sich an eine beliebte API wie die Perspective API für die Erkennung von Toxizität wenden, und das funktioniert wirklich gut, wenn Sie Carl Jones sind, wo die Perspective API in der Lage ist, toxische Instanzen korrekt zu erkennen."}
{"dataset_id": "mcif_v1.0", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Das ist bei Aditya Sharma jedoch nicht der Fall, da die Perspektive der API nicht so empfindlich gegenüber beleidigenden Begriffen ist, die im indischen Kontext häufiger vorkommen."}
{"dataset_id": "mcif_v1.0", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Hierbei handelt es sich um ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede der Technologie zwischen Bevölkerungsgruppen feststellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Design-Bias wie der, den wir gerade gesehen haben, kann aufgrund der Positionalität von NLP-Forschern und Modellentwicklern auftreten. Positionalität ist einfach die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen einnehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein Konzept, das in der kritischen Theorie weit verbreitet ist, insbesondere in feministischen und queeren akademischen Räumen."}
{"dataset_id": "mcif_v1.0", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Als Forscher kann die Positionalität den Forschungsprozess und seine Ergebnisse beeinflussen, da sie die Entscheidungen der Forscher beeinflussen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Eine Frage, die sich die Leute stellen könnten, ist: Haben Datensätze und Modelle eine Position?"}
{"dataset_id": "mcif_v1.0", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen damit nicht sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren Urteile und Meinungen realer Menschen und können daher bestimmte Positionen gegenüber anderen repräsentieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben einige anekdotische Beweise für die Existenz von Positionalität, wie z. B. kulturelle Lücken in Modellen und Datensätzen, sowie theoretische Definitionen der Positionalität von Modellen nahegelegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeiten untersuchen jedoch nicht, wie Endbenutzer mit den Datensätzen und Modellen selbst verglichen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Die Untersuchung von Modell- und Datensatzpositionen wird immer wichtiger, da NLP-Aufgaben zunehmend subjektiver und sozialer Natur werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Es ist schwierig, die Verzerrung dieser Positionierungen zu charakterisieren, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Um die Datensatz- und Modellpositionalität zu untersuchen, vergleichen wir die Annotationen von echten Nutzern mit bestehenden Datensätzen und Modellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Wir machen dies über unseren NL-Positionierungsrahmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework arbeitet in zwei Hauptschritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "Der erste Schritt besteht darin, Datensätze mit diversen Annotatoren neu zu annotieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns entschieden, dies zu tun, anstatt die demografischen Daten der ursprünglichen Datensatz-Kennzeichner zu betrachten, da normalerweise nur wenige Kennzeichner jede Instanz kennzeichnen und weil demografische Daten selten gesammelt und geteilt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns entschieden, die Daten erneut zu annotieren, um viele Annotationen pro Instanz zu erhalten und einen umfangreichen Datensatz zu den demografischen Daten zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen dann die Anmerkungen nach demografischen Merkmalen und vergleichen sie mit den Modellen und Datensätzen anhand des Pearson-Korrelationskoeffizienten."}
{"dataset_id": "mcif_v1.0", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmen unterscheidet sich daher von der Literatur zur Diskrepanz zwischen Annotatoren, indem wir Endbenutzer mit Modellen und Datensätzen, Vorhersagen und Beschriftungen vergleichen, anstatt nur die Übereinstimmung zwischen Annotatoren zu betrachten oder die Verteilung der Annotatoren zu modellieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework wird hauptsächlich durch Lab-in-the-Wild ermöglicht, eine Online-Crowdsourcing-Plattform, die von einem ehemaligen HCI-Mitarbeiter entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Lab in the Wild ist eine Online-Experimentierplattform, auf der wir im Vergleich zu Plattformen wie MTurk, die hauptsächlich Teilnehmer aus den USA oder Indien haben, eine vielfältigere Gruppe von Freiwilligen rekrutieren können. Darüber hinaus kann Lab in the Wild weiterhin qualitativ hochwertige Daten liefern."}
{"dataset_id": "mcif_v1.0", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Wir bieten zwei Aufgaben auf Lab in the Wild an, eine davon ist die soziale Akzeptanz. Dabei lesen die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz und schreiben dann, wie sozial akzeptabel die Situation ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Danach können sie, um in der Stadt engagiert zu bleiben, ihre Antworten mit denen einer KI und anderer vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Annotationen dann mit Social Chemistry, Delphi und GPT-4 verglichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Danach haben wir eine sehr ähnliche Einrichtung für die Aufgabe der Erkennung von Toxizität und Hassreden repliziert, bei der sie eine Instanz aus DynaHate lesen und schreiben, ob sie der Meinung sind, dass es sich um eine Instanz von Hassreden handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Wir verglichen diese Annotationen dann mit DynaHate, Perspective API, ReWire API, Hate-Roberta und GPT-4. Unsere Studie umfasste schließlich über 16.000 Annotationen von über 1.000 Annotatoren aus 87 Ländern."}
{"dataset_id": "mcif_v1.0", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind jetzt besser in der Lage zu beantworten, mit wem sich NLP-Datensätze und -Modelle am meisten decken. Wir stellen fest, dass es in der NLP eine Positionierung gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise stellen wir fest, dass Datensätze und Modelle am besten mit englischsprachigen Ländern übereinstimmen. So stellen wir bei der GPD4-Analyse der sozialen Akzeptanz fest, dass sie am besten mit Konfuzianismus und englischsprachigen Ländern übereinstimmt. Wir stellen fest, dass die Dynamik des Hasses ebenfalls am besten mit englischsprachigen Ländern übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass die meisten zusätzlichen Übereinstimmungen mit Personen mit Hochschulbildung bestehen. So finden wir bei GPT-4 bei der Aufgabe der sozialen Akzeptanz, dass es am meisten mit Personen mit Hochschulbildung oder Hochschulabschluss übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und wir finden das Gleiche bei Danahate, wo es am meisten mit Menschen mit einer Hochschulbildung übereinstimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Modelle und Datensätze jedoch auf bestimmte Bevölkerungsgruppen ausgerichtet sind, bleiben andere zwangsläufig auf der Strecke."}
{"dataset_id": "mcif_v1.0", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Ein Beispiel dafür ist, dass Datensätze und Modelle weniger auf nichtbinäre Personen zugeschnitten sind als auf ihre männlichen und weiblichen Pendants. Dies zeigt sich in der GPD-4-Aufgabe zur sozialen Akzeptanz sowie in der Analyse der Aufgabe „Dynahate“."}
{"dataset_id": "mcif_v1.0", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Da es in der NLP eine Positionalität gibt, was können wir dagegen tun?"}
{"dataset_id": "mcif_v1.0", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Dazu haben wir einige Empfehlungen. Die erste lautet, ein Protokoll aller relevanten Designentscheidungen während des Forschungsprozesses zu führen. Die zweite ist, die NLP-Forschung aus der Perspektive des Perspektivismus zu betrachten."}
{"dataset_id": "mcif_v1.0", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Unsere dritte Empfehlung ist der Aufbau spezialisierter Datensätze und Modelle innerhalb spezifischer Gemeinschaften. Ein gutes Beispiel dafür ist die Masakhane-Initiative. Wir möchten betonen, dass inklusive NLP nicht nur bedeutet, dass alle Technologien für alle funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Damit schließen wir unsere Präsentation ab, aber wenn Sie mehr erfahren möchten, besuchen Sie gerne unser Dashboard für die aktuellsten Analyseergebnisse und unseren Artikel. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Si Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit vorzustellen: Unterscheidung von Skriptwissen in großen Sprachmodellen für die eingeschränkte Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Im Alltag planen Menschen ihre Handlungen oft, indem sie Schritt-für-Schritt-Anweisungen in Form von garantierten Skripten befolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten haben Sprachmodelle untersucht, um abstrakte Ziele stereotypischer Aktivitäten wie „einen Kuchen backen“ zu planen, und gezeigt, dass große Sprachmodelle Ziele effektiv in Schritte zerlegen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Bisherige Arbeiten konzentrieren sich jedoch hauptsächlich auf die Planung abstrakter Ziele stereotyper Aktivitäten. Die Planung von Zielen mit spezifischen Einschränkungen, wie z. B. die Herstellung einer Schokoladentorte, ist jedoch noch wenig untersucht."}
{"dataset_id": "mcif_v1.0", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit definieren wir das Problem der eingeschränkten Sprachplanung."}
{"dataset_id": "mcif_v1.0", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Dies legt unterschiedliche Einschränkungen für die Ziele der Planung fest. Ein abstraktes Ziel kann von verschiedenen realen, spezifischen Zielen mit multifaktoriellen Einschränkungen geerbt werden. Ein guter Planer sollte Skripte schreiben, die vernünftig und den Einschränkungen treu sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit bewerten und verbessern wir zunächst die Fähigkeit von großen Sprachmodellen zur Planung eingeschränkter Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Da es keine Daten über spezifische Ziele gibt, die unseren Startpunkt markieren,"}
{"dataset_id": "mcif_v1.0", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst müssen wir dieses Ziel erreichen. Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit multifaktoriellen Einschränkungen für die menschliche Datenakquise mit InstructGPT."}
{"dataset_id": "mcif_v1.0", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 100 spezifische Ziele beprobt und die von großen Sprachmodellen generierten Skripte bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Diese Tabelle zeigt die Gesamtgenauigkeit der Ergebnisse. Wir stellen fest, dass alle Sprachmodelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Dann führten wir eine detaillierte Analyse durch, um zu untersuchen, warum die Lernmodelle versagten."}
{"dataset_id": "mcif_v1.0", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse in der Abbildung zeigen, dass die semantische Vollständigkeit in den generierten Skripten akzeptabel ist, die Einhaltung der Einschränkungen jedoch nicht garantiert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen feiner unterteilte Kategorien von Einschränkungen, die in WikiHow definiert sind. Die Hitzekarte in der Abbildung zeigt, dass die Planungsleistung von InstructGPTs für verschiedene Kategorien stark variiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien haben gezeigt, dass die Ausgabequalität von Sprachmodellen stark variiert, was zu einer schlechten Leistung führt. Daher haben wir die Idee eines übergenerierten Z-Filters übernommen, um die Erzeugungsqualität zu verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen zunächst eingeschränkte Typen mit Beispielen für die induktive Typisierung und erhalten spezifische Ziele basierend auf den abstrakten Zielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Then instruct GPT to generate case scripts for specific goals."}
{"dataset_id": "mcif_v1.0", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes wird ein Filtermodell entwickelt, um die glaubwürdigen Skripte auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Wir wandeln Skripte und Ziele in InstructGPT-Einbettungen um und berechnen die Cosinus-Ähnlichkeit als Ähnlichkeitsbewertungen, um die semantische Ähnlichkeit zu messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich bewerten wir das Skript, das die Schlüsselwörter der Zielbeschränkung enthält. Wir behalten nur das Skript, wenn die Zielbewertung die höchste in der Bewertungsseite ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Mit unserer Methode kann InstructGPT Sequenzen höherer Qualität generieren. Unsere Methode verbessert die Planbarkeit sowohl in semantischer Vollständigkeit als auch in der Einhaltung der Einschränkungen erheblich."}
{"dataset_id": "mcif_v1.0", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Da große Sprachmodelle teuer im Einsatz sind, ist es wichtig, die Sprachplanungsfähigkeit kleinerer und spezialisierter Modelle zu ermöglichen. Die Erstellung von Datensätzen ist ein wesentlicher Schritt in diese Richtung."}
{"dataset_id": "mcif_v1.0", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Studien ermöglichen jedoch keine Planung für spezifische Ziele, und die manuelle Annotation von Datensätzen ist teuer."}
{"dataset_id": "mcif_v1.0", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Daher folgen wir der Idee der symbolischen Wissensdestillation, um Constrained Language Planning-Datensätze aus großen Sprachmodellen zu destillieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Wir wenden unsere Methode zur Erstellung eines Datensatzes für die Planung von Sprache mit Einschränkungen an, die als CoScript bezeichnet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir 55.000 spezifische Ziele mit Skripten generiert. Um die Qualität der Validierungs- und Testsets sicherzustellen, haben wir Crowdworker gebeten, falsche Proben zu finden und zu überarbeiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung zeigt die eingeschränkte Verteilung von CoScript. Wir haben festgestellt, dass CoScript eine hohe Übereinstimmung bei den generierten spezifischen Zielen aufweist. Mit CoScript können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Wir fanden heraus, dass T5-Fine-Tuning auf der C4-Datensammlung Skripte von ähnlicher Qualität wie die meisten großen Sprachmodelle erzeugen kann, was darauf hindeutet, dass kleinere Modelle größere Modelle übertreffen können, wenn sie auf geeigneten Datensätzen trainiert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst haben wir das Problem der eingeschränkten Sprachplanung definiert, die Fähigkeit großer Sprachmodelle zur eingeschränkten Sprachplanung bewertet und eine Methode zur Filterung von Übergenerierungen für große Sprachmodelle entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden große Sprachmodelle, um einen hochwertigen SQL-Datensatz zu generieren, um die Sprachplanung zu beschränken. Wir hoffen, dass der beschränkte Datensatz eine wertvolle Ressource für die Forschung zur Sprachplanung sein kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Zeit. Weitere Details zum Quellcode finden Sie in unserem Papier."}
{"dataset_id": "mcif_v1.0", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist Zhuo-Heng. Heute werde ich unseren Artikel vorstellen: „Funktionieren die NER-Tagger von Conll 2003 auch 2023 noch gut?“ Legen wir los."}
{"dataset_id": "mcif_v1.0", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit untersuchte das Problem der Generalisierung anhand der Aufgabe der Erkennung benannter Entitäten oder der NER-Aufgabe."}
{"dataset_id": "mcif_v1.0", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Modelle CONLL-2003 seit fast 20 Jahren zur Entwicklung von NER verwenden. Dies wirft natürlich mehrere Probleme auf. Erstens: Können diese Modelle auf moderne Daten verallgemeinert werden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neue Tags entwickeln, was ist für eine gute Generalisierung erforderlich?"}
{"dataset_id": "mcif_v1.0", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch eine schlechte Verallgemeinerung beobachten, was verursacht dann den Leistungsabfall dieser Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Probleme zu untersuchen, haben wir den Conll++-Datensatz entwickelt. Dabei handelt es sich um einen Datensatz, den wir aus Reuters-Nachrichten von 2020 gesammelt und dann mit denselben Conll-2003-Anmerkungen versehen haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dann über 20 Modelle auf ConLL-2003 feinabgestimmt. Wir haben sie sowohl auf dem ConLL-03-Testdatensatz als auch auf dem ConLL++-Testdatensatz bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich berechneten wir die prozentuale Änderung von F1, um die Generalisierung jedes Modells zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Was ist für eine gute Generalisierung erforderlich? In unseren Experimenten haben wir festgestellt, dass drei Hauptbestandteile erforderlich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist die Modellarchitektur. In unseren Experimenten haben wir festgestellt, dass die Transformer-Modelle normalerweise besser auf neue Daten verallgemeinert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Faktor ist die Modellgröße. Wir haben festgestellt, dass größere Modelle in der Regel zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich wissen wir alle, dass die Anzahl der Feinabstimmungsbeispiele die Leistung einer nachgelagerten Aufgabe direkt beeinflusst. Hier haben wir auch festgestellt, dass mehr Feinabstimmungsbeispiele tatsächlich auch zu einer besseren Verallgemeinerung führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Unsere nächste Frage lautet: Was verursacht den Leistungsabfall einiger Modelle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten zwei Hypothesen. Die erste ist das adaptive Overfitting, das durch die wiederholte Verwendung desselben Testdatensatzes verursacht wird, und das sich in der Regel als eine Verringerung der Renditen auf einem neuen Testdatensatz äußert."}
{"dataset_id": "mcif_v1.0", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Hypothese ist der zeitliche Drift, also die Leistungsverschlechterung, die durch die zunehmende zeitliche Lücke zwischen den Trainings- und den Testdaten verursacht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Bei der adaptiven Überanpassung haben wir gesehen, dass die rote Best-Fit-Linie auf dem rechten Diagramm eine Steigung von mehr als 1 hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass jede Einheit der Verbesserung, die wir an Cono 2003 vorgenommen haben, zu mehr als einer Einheit der Verbesserung an Cono++ führt, was bedeutet, dass es keine abnehmenden Erträge gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Das zeigt uns, dass in diesem Fall kein adaptives Overfitting beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Was ist mit der Zeitverschiebung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Für die zeitliche Drift haben wir ein Experiment durchgeführt, bei dem wir einige Modelle mit neueren Daten neu trainiert oder weiter vorab trainiert haben, und wir haben festgestellt, dass die Leistung mit einer größeren zeitlichen Lücke abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Dies bestätigt unsere Hypothese, dass die Hauptursache für den Leistungsabfall ein zeitlicher Drift ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Unser Schluss ist, dass wir für eine gute Verallgemeinerung eine bessere Modellarchitektur, eine größere Modellgröße und mehr Feinabstimmungsbeispiele benötigen. Und diese Ziele gehen Hand in Hand, wir können nicht nur eine Zutat haben, aber alle anderen."}
{"dataset_id": "mcif_v1.0", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig stellten wir fest, dass der hier festgestellte Leistungsabfall durch zeitliche Drift verursacht wird und – überraschenderweise – nicht durch adaptive Überanpassung, obwohl Connell 2003 seit über 20 Jahren verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Gehen wir also zurück zu der Frage, die wir im Titel unseres Papiers aufgeworfen haben: Funktionieren die Conll-2003-Tagger im Jahr 2023 noch? Und wir haben festgestellt, dass die Antwort ein klares Ja ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Artikel zu weiteren Forschungen darüber anregt, wie die Verallgemeinerungsfähigkeit der Modelle verbessert werden kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich, stellen Sie bitte sicher, dass Sie unseren Artikel und unseren Datensatz überprüfen, und wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich werde über unsere Arbeit zur Auflösung indirekter Verweise für die Entitätsauswahl sprechen, in der wir den Alt-Entitäts-Scorer einführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Mein Name ist Jawad Hosseini und dies ist eine gemeinsame Arbeit mit Filip Radlinski, Sylvia Parity und Ali Louis."}
{"dataset_id": "mcif_v1.0", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen wollen. Betrachten Sie diese alternative Frage: Meinten Sie „Easy on Me“ oder „I Got a Feeling“? Hier möchte ein Benutzer zwischen diesen beiden Songs wählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Das Offensichtlichste ist, eine direkte Referenz zu verwenden, z. B. indem man den Namen des Liedes „Easy on Me“ oder seine Position (der erste) nennt."}
{"dataset_id": "mcif_v1.0", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Manchmal ist jedoch eine indirekte Anrede natürlicher, um ein Gespräch zu führen. Dies kann passieren, wenn sich der Benutzer nicht an den Namen des Songs erinnert."}
{"dataset_id": "mcif_v1.0", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Alle Aussprachen sind zu ähnlich und schwer zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für direkte Unterschiede. Zum Beispiel das neuere oder das Lied, das nicht energiegeladen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist ein wichtiges Problem in konversationsbasierten Systemen und auch für die Bewertung des Verständnisses von Entitäten durch LLMs."}
{"dataset_id": "mcif_v1.0", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Uns ist kein öffentlicher Datensatz, also ein öffentlich zugänglicher Datensatz in großem Umfang für die Aufgabe bekannt, daher haben wir einen mit Hilfe von Crowd Annotation gesammelt. Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezensionen."}
{"dataset_id": "mcif_v1.0", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Datensatzsammlungsmethodik betont die Informalität durch die Verwendung eines Cartoon-Completion-Sets."}
{"dataset_id": "mcif_v1.0", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Der Comic hat drei Sprechblasen. In der ersten Sprechblase sagt Bob: „Erinnerst du dich an das Lied, das wir gestern gehört haben?“ Damit setzt Bob den Dialogkontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Sprechblase sagt Alice: „Meinst du ‚nimm es mir nicht übel‘ oder ‚ich habe ein Gefühl‘?“"}
{"dataset_id": "mcif_v1.0", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Und in der dritten Sprechblase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen, z. B. den neuen Flughafen."}
{"dataset_id": "mcif_v1.0", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wir liefern die ersten beiden Sprechblasen automatisch, die dritte wird jedoch vom Annotator ausgefüllt. Die erste Sprechblase wird aus einigen manuellen Eingabeaufforderungen pro Domäne ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite, die alternative Frage, wird wie folgt generiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden immer eine einfache Vorlage. Meinen Sie A oder B? wobei A und B Beispiele aus Wikipedia sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die verschiedenen Stichprobenverfahren, die wir verwendet haben. Wenn wir in der Liste nach oben gehen, werden die Entitäten einander ähnlicher und es ist in der Regel schwieriger, die Entzerrung vorzunehmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist Uniformatran."}
{"dataset_id": "mcif_v1.0", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Fall ist, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Titel „The Return“."}
{"dataset_id": "mcif_v1.0", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Das dritte ist, wenn sie ähnliche Beschreibungen in der Wikipedia haben, und schließlich, wenn sie ähnliche Infoboxen oder Attribute in der Wikipedia haben, z. B. dasselbe Genre oder denselben Künstler für ein Lied."}
{"dataset_id": "mcif_v1.0", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir diese alternative Frage den Administratoren vorlegen, kennen sie die Namen dieser Entitäten, wissen aber nicht unbedingt etwas über die Entität."}
{"dataset_id": "mcif_v1.0", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Was wir tun, ist, dass wir einige Hintergrundinformationen zu den beiden Entitäten zeigen. Bei Songs zeigen wir einfach einen Google-Suchlink zu jedem Song."}
{"dataset_id": "mcif_v1.0", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Und bitten Sie die Annotatoren dann, sich mindestens einen Teil jedes Liedes anzuhören und über jedes Lied zu lesen. Hier ist zum Beispiel das Ergebnis der Google-Suche für das Lied „Easy on Me“."}
{"dataset_id": "mcif_v1.0", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Für das Rezept- und Buchgebiet zeigen wir einige Hintergrundinformationen von Wikipedia. Bei Rezepten zeigen wir zusätzlich deren Bilder, ebenfalls von Wikipedia, damit die Annotatoren wissen, wie sie aussehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste, und sie mit drei bis fünf indirekten Referenzausdrücken zu beschreiben."}
{"dataset_id": "mcif_v1.0", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel das mit der Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel das ohne Worte, nicht das mit dem 12-jährigen Jungen oder das fiktive oder das aus Aserbaidschan usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Der AltEntitäten-Korpus enthält 6.000 alternative Fragen über drei Domänen und 42.000 indirekte Verweise. Die Ergebnisse mit dem T5-XL-Modell sind unten zusammengefasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf genau dasselbe Hintergrundwissen zugreifen kann wie die Annotatoren, dann ist die Genauigkeit wirklich hoch. Sie liegt bei etwa 92 bis 95 %. Aber das ist nicht realistisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell auf einige teilweise überlappende Hintergrundinformationen zugreifen kann, liegt die Genauigkeit zwischen 82 und 87 %, was realistischer ist, z. B. wenn das Sprachmodell die Hintergrundinformationen abruft."}
{"dataset_id": "mcif_v1.0", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Sprachmodell nur auf Entitätsnamen zugreifen kann, liegt die Genauigkeit nur bei 60 %, sodass noch viel Raum für Verbesserungen besteht. Wir haben auch gezeigt, dass die Modelle domänengeneralisierbar sind. Hier ist ein Link zu unserem Datensatz. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Sarah Papi von der Universität von Toronto und der Fondazione Bruno Kessler, und ich werde kurz das Papier „Attention as a Guide for Simultaneous Speech Translation“ vorstellen, das eine gemeinsame Arbeit mit Matteo Negri und Marco Turchi ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Was ist simultane Sprachübersetzung? Simultane Sprachübersetzung oder SimulST ist der Prozess der Übersetzung von gesprochener Sprache in einen Text in einer anderen Sprache in Echtzeit, wodurch eine Kommunikation über Sprachgrenzen hinweg ermöglicht wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Was sind die Probleme der derzeitigen SimulST-Modelle? Spezifische Architekturen werden normalerweise durch die Einführung zusätzlicher Module trainiert, die optimiert werden müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Lange und komplizierte Trainingsverfahren, z. B. Trainingsverfahren mit unterschiedlichen Optimierungszielen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "und das Trainieren und Pflegen mehrerer Modelle, um verschiedene Latenzregime zu erreichen, z. B. das Trainieren eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines weiteren mit einer Latenz von zwei Sekunden usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Was ist also unsere Lösung?"}
{"dataset_id": "mcif_v1.0", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal, um bereits existierende Offline-Sprachmodelle ohne erneutes Training oder Anpassung einer bestimmten Architektur für die SimulST zu verwenden. Verwenden Sie nur ein Modell für jedes Latenzregime und behandeln Sie die Latenz durch bestimmte Parameter."}
{"dataset_id": "mcif_v1.0", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "und nutzen Sie das Wissen, das das Modell bereits durch den Aufmerksamkeitsmechanismus zwischen Audioeingabe und Textausgabe erworben hat, d. h. den Cross-Attention-Mechanismus. Ein Beispiel finden Sie rechts."}
{"dataset_id": "mcif_v1.0", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Lösung besteht darin, eine EDA oder Encoder-Decoder-Attention vorzuschlagen, und es handelt sich um eine Strategie, bei der wir entscheiden, ob wir eine teilweise Übersetzung ausgeben oder nicht, basierend darauf, wohin die Aufmerksamkeit zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Ein Wort wird weggelassen, wenn die Spannung nicht konzentriert ist, d. h. wenn ihre Summe unter einem bestimmten Schwellenwert Alpha liegt, in Bezug auf die letzten Lambda Sprachrahmen, was bedeutet, dass die empfangenen Informationen stabil genug sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir beispielsweise einen Sprachwechsel erhalten, der „I'm going to talk about“ enthält, und unser Modell die Übersetzung ins Deutsche vorhersagt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden uns die Kreuzattentionsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass die ersten beiden Wörter auf die frühesten empfangenen Sprachrahmen hinweisen, während das letzte Wort auf die zuletzt empfangenen Sprachrahmen hinweist, also Lambda-Sprachrahmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass die ersten beiden Wörter ausgesendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Da die Summe der Kreuzaufmerksamkeit über einem bestimmten Schwellenwert Alpha liegt, geben wir das letzte Wort nicht aus und warten auf einen weiteren Sprachabschnitt."}
{"dataset_id": "mcif_v1.0", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir weitermachen und einen weiteren Sprachschluck erhalten, sagt unser Modell drei weitere Wörter voraus, und wir werden uns die Kreuzaufmerksamkeitsgewichte ansehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden sehen, dass kein Wort auf die letzten Lambda-Sprachrahmen verweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass diese drei Wörter ausgesprochen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die wichtigsten Ergebnisse der Studie ansehen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Ergebnisse der simultanen Sprachübersetzung in Diagrammen darstellen, in denen wir auf der einen Seite in Blau die Übersetzungsqualität und die durchschnittliche Verzögerung messen."}
{"dataset_id": "mcif_v1.0", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das ist das Latenzmaß. Wir berücksichtigen auch die durchschnittliche Verzögerung, die sich der Berechnung bewusst ist, die die Berechnungszeiten des Modells berücksichtigt, um die Ausgabe vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen also, dass unsere Kurven auf dieser Darstellung so hoch wie möglich sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Wir wollen aber auch, dass sie nach links verschoben werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen mit vorbereitenden Strategien, die auch auf Offline-Modelle angewendet werden, nämlich der Weighted Key-Strategie und der lokalen Übereinstimmung. Wir vergleichen auch mit der Spitzenarchitektur, die speziell für simultane Sprachübersetzung entwickelt wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind alle Ergebnisse der simultanen Übersetzungsstrategie für Deutsch."}
{"dataset_id": "mcif_v1.0", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sehen, dass es alle Strategien, die auf Offline-Modelle angewendet werden, übertrifft, da die Kurven nach links verschoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen auch, dass, wenn wir die tatsächliche verstrichene Zeit oder die wahrgenommene Zeit in Betracht ziehen, ADAPT die schnellste Strategie ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unseren Artikel. Wir haben auch den Quellcode, die Modelle und die simultanen Ausgaben als Open Source veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Ying und mein Kollege Jiyang und ich werden unsere Forschung zu Multi-Instruct vorstellen, bei der die multimodale Zero-Shot-Lernfähigkeit durch Instruktionsabstimmung verbessert wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen vorgelernte Sprachmodelle für verschiedene nachgelagerte Aufgaben auf eine parameter- und dateneffiziente Weise wiederverwendet werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "In letzter Zeit haben viele Studien gezeigt, dass die Anweisungsabstimmung große Sprachmodelle in die Lage versetzt, Aufgaben in einer Zero-Shot-Art und Weise durch Befolgen natürlicher Anweisungen auszuführen."}
{"dataset_id": "mcif_v1.0", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Die meisten früheren Arbeiten zum Anweisungstuning konzentrierten sich jedoch auf die Verbesserung der Null-Schuss-Leistung bei sprachbasierten Aufgaben, während Aufgaben aus dem Bereich der Computervision und der Multimodalität außen vor blieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit wollen wir daher untersuchen, ob die Anpassung von Anweisungen an multimodale vorgelernte Modelle tatsächlich die Verallgemeinerung auf multimodale Aufgaben ohne Anweisungen verbessern kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Zudem stellten wir bei unserer Forschung eine beträchtliche Diskrepanz bei der Verfügbarkeit von Anweisungsdatensätzen zwischen NLP und multimodalen Ansätzen fest."}
{"dataset_id": "mcif_v1.0", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt mehr als 1.600 Sprachbefehle. Allerdings gibt es keine öffentlich zugängliche multimodale Befehlsaufgabe in großem Umfang. Daher motiviert uns dies, einen multimodalen Befehlsabstimmungsdatensatz zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Hier stellen wir MultiInstruct vor, den ersten Benchmark-Datensatz für multimodales Instruction Tuning, der aus 62 verschiedenen multimodalen Aufgaben besteht, die 10 breite Kategorien abdecken."}
{"dataset_id": "mcif_v1.0", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgaben basieren auf 21 bestehenden Open-Source-Datensätzen und jede Aufgabe ist mit fünf Expertenanweisungen ausgestattet."}
{"dataset_id": "mcif_v1.0", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Um multimodale Instruktionsanpassungen an unserem vorgeschlagenen Datensatz zu untersuchen, verwenden wir OFA, ein vereinheitlichtes multimodales Präsentationsmodell, als unser Grundmodell. OFA verwendet ein vereinheitlichtes Vokabular für Sprache, Bild-Token und die Koordinaten eines Begrenzungsrahmens."}
{"dataset_id": "mcif_v1.0", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir einige Beispielinstanzen aus unserem Multi-Instanz-Datensatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Um die Verarbeitung verschiedener Eingabe- und Ausgabedatentypen zu vereinheitlichen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem der Eingabetext, Bilder, Anweisungen und Begrenzungsrahmen im gleichen Token-Raum dargestellt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Gut, jetzt werde ich über multimodale Instruktionsabstimmung sprechen."}
{"dataset_id": "mcif_v1.0", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Für den Trainingsdatensatz verwenden wir 53 Aufgaben aus der NIGHT-Gruppe zum Training und wir nehmen 10.000 Instanzen pro Aufgabe. Zum Testen reservieren wir die gesamte Gruppe des gesunden Menschenverstands zum Testen und wir wählen fünf zusätzliche Aufgaben aus der VQA- und der Misc-Gruppe aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden alle Instanzen im Testdatensatz für jede Aufgabe. Zusätzlich wählen wir zufällig 20 Aufgaben aus dem Testdatensatz der natürlichen Instruktionen als unsichtbare Aufgaben für NLP aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein vorab trainiertes OFA Large-Modell als Basismodell. Während des Trainings mischen wir alle Instanzen für alle Aufgaben. Jede Instanz wird zufällig mit einer von fünf Anweisungsvorlagen kombiniert."}
{"dataset_id": "mcif_v1.0", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Bei jedem Test führen wir für jede Aufgabe insgesamt fünf Experimente durch, indem wir das Modell in jedem Experiment mit einer der fünf Anweisungen bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Wir berichten über die mittlere und maximale Leistung und die Standardabweichung der Leistung über alle fünf Experimente."}
{"dataset_id": "mcif_v1.0", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es sich um eine multimodale Klassifizierungsaufgabe handelt, geben wir die Genauigkeit an. Wenn es sich um eine multimodale Generierungsaufgabe handelt, geben wir ROUGE-L an. Bei einer NLP-Aufgabe geben wir ebenfalls ROUGE-L an."}
{"dataset_id": "mcif_v1.0", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt. Diese misst die Fähigkeit des Modells, bei derselben Aufgabe unabhängig von geringfügigen Änderungen in der Formulierung der Anweisung konsistent dieselben Ergebnisse zu liefern."}
{"dataset_id": "mcif_v1.0", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind unsere Hauptergebnisse. Wie wir sehen können, kann die Anweisungsabstimmung die OFA-Leistung bei multimodalen Aufgaben erheblich verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Auch das Transferlernen aus natürlichen Instruktionsdatensätzen kann das Instruktions-Tuning verbessern."}
{"dataset_id": "mcif_v1.0", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass die Leistung des Modells mit zunehmender Aufgabenmenge besser wird und gleichzeitig die Empfindlichkeit abnimmt."}
{"dataset_id": "mcif_v1.0", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch ein Experiment durchgeführt, bei dem wir eine Anweisung mit fünf Anweisungen verglichen haben. Wie wir sehen können, kann die Verwendung mehrerer Anweisungen die Gesamtleistung des Modells verbessern und seine Empfindlichkeit erheblich reduzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt die Auswirkungen verschiedener Feinabstimmungsstrategien auf die Sensitivität des Modells. Wie wir sehen können, kann das Modell durch Transferlernen aus einem natürlichen Instruktionsdatensatz eine viel bessere Sensitivität erreichen als das ursprüngliche OFA-Modell."}
{"dataset_id": "mcif_v1.0", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass das Transferlernen aus dem Natural Instruction-Datensatz OFA helfen kann, eine viel bessere Leistung im Natural Instruction-Datensatz zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt haben wir den ersten groß angelegten multimodalen Datensatz für die Anweisungsabstimmung vorgeschlagen. Wir haben die Zero-Shot-Fähigkeit von OFA erheblich verbessert und verschiedene Transfer-Lerntechniken untersucht und deren Vorteile aufgezeigt. Wir haben eine neue Metrik namens Sensitivität entwickelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Also noch eine Sache: Wir erstellen einen viel größeren multimodalen Datensatz für die Anweisungsanpassung mit etwa 150 zusätzlichen visuellen Sprachaufgaben und werden diese veröffentlichen. Hier ist ein QR-Code für unsere Daten und unser Modell. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Ich bin Kostas Drossinos und freue mich, Sie zu unserem Vortrag über unseren ACL 2023 Artikel „Sprachmodell-Akzeptabilitätsurteile sind nicht immer kontextrobust“ begrüßen zu dürfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Es handelt sich um eine gemeinsame Arbeit mit John Gautier, Aaron Mueller, Kalishka Mishra, Karen Fuentes, Roger Levy und Adina Williams."}
{"dataset_id": "mcif_v1.0", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit untersuchen wir erneut die minimale Paarzeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das Minimalpaar-Paradigma bewertet Sprachmodelle im Wesentlichen anhand von Akzeptanzurteilen, die auch die grammatikalische Korrektheit umfassen können, wie z. B. BLiMP, SyntaxGym oder Akzeptanz in Bezug auf Stereotypen, wie z. B. CrowS-Pairs."}
{"dataset_id": "mcif_v1.0", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Bei diesem Minimalpaar-Paradigma wird die übliche Methode zur Bewertung von Sprachmodellen angewendet, bei der ein akzeptabler Satz oder ein grammatikalisch korrekter Satz gezeigt wird und dann ein inakzeptabler Satz oder ein ungrammatikalischer Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Die Hoffnung ist, dass das Modell den akzeptablen Sätzen eine höhere Wahrscheinlichkeit zuweist."}
{"dataset_id": "mcif_v1.0", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Die aktuelle MPP-Pipeline ermöglicht es uns im Grunde nicht, die Akzeptanz von Modellen für längere Sätze zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Heutzutage verfügen große Sprachmodelle über immer längere Kontextfenster, sodass es entscheidend ist, die Akzeptanz des Modells über das gesamte Kontextfenster hinweg zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist es, was wir hier versuchen. Wir versuchen, die NPP-Pipeline zu überdenken, indem wir das Modell auffordern, die Akzeptanz auf immer längeren Sequenzen zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Das ist der Ansatz. Was wir also tun, ist, dass wir, um diese längeren Sequenzen zu simulieren, die Datensätze selbst erneut besuchen und dann Sätze neu erstellen, indem wir akzeptable oder inakzeptable Sätze aus diesen Datensätzen auswählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Hier haben wir beispielsweise ein typisches Paar aus dem BLiMP-Datensatz mit grammatischer Korrektheit aus dem Adjunkt-Insel-Fall ausgewählt."}
{"dataset_id": "mcif_v1.0", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Und was wir tun, ist, dass wir, um längere Sequenzen zu erstellen, die akzeptabel sind und die gleiche Übereinstimmung der grammatikalischen Struktur aufweisen, grammatikalische Sätze aus Agent Thailand extrahieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Und dann fügen wir es als Präfix sowohl zur akzeptablen Abfrage als auch zur inakzeptablen Abfrage hinzu."}
{"dataset_id": "mcif_v1.0", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Daher können wir dasselbe tun, indem wir unannehmbare Sätze aus derselben Übereinstimmung auswählen, und das könnte auch verwendet werden, um die Akzeptanz des Modells zu testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können dasselbe auch tun, indem wir Sätze aus einem anderen Teilsatz oder einem anderen Datensatz auswählen. Das nennen wir das Missmatch-Szenario."}
{"dataset_id": "mcif_v1.0", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Hier stammen die Sätze weiterhin aus relevanten Datensätzen, aber nicht aus demselben Datensatz, den Sie bewerten. Und wir können dasselbe für unannehmbare Fälle tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir Sätze aus einem völlig anderen Bereich wählen, wie z. B. Wikipedia."}
{"dataset_id": "mcif_v1.0", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Das wird uns also sagen, ob die Urteile der Modelle über die Akzeptabilität tatsächlich von einem Kontext beeinflusst werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Ob der Kontext aus einem anderen Teildatensatz stammt oder ob er für den Satz, den wir uns gerade ansehen, völlig irrelevant ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Wie schneidet also das Modell ab? Zunächst betrachten wir die Wikipedia-Sätze, die für das aktuelle Abfragepaar völlig irrelevant sind, und dort finden wir, dass die MPP-Beurteilungen für beliebige Kontextlängen größtenteils robust sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Kontextlänge auf bis zu 1024 erhöht, um OPT- und GPT-2-Modelle maximal auszunutzen, und wir sehen hier in der orangefarbenen Linie, dass die MPP-Beurteilungen relativ stabil sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Was passiert, wenn wir Sätze aus demselben Datensatz auswählen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Hier wählen wir Sätze aus akzeptablen und inakzeptablen Bereichen aus demselben BLiMP- oder SyntaxGym-Datensatz aus."}
{"dataset_id": "mcif_v1.0", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Dort sehen wir, dass die MPP-Beurteilungen entweder deutlich steigen oder sinken, wenn entweder akzeptable Präfixe oder inakzeptable Präfixe hinzugefügt werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir die Struktur abgleichen, das heißt, wenn wir die Sätze aus demselben Phänomen im Blame-Person-Text auswählen, Jim,"}
{"dataset_id": "mcif_v1.0", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen einen massiven Anstieg oder einen massiven Rückgang der MPP-Bewertung des Modells, je nachdem, ob das gewählte Präfix akzeptabel oder nicht akzeptabel ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Das ist sehr groß, und dieser Effekt nimmt mit der Länge des Kontextes zu, was wahrscheinlich auch neuere Sprachmodelle mit einem großen Kontextfenster beeinflussen würde."}
{"dataset_id": "mcif_v1.0", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Warum beeinflusst das Präfix so stark die Beurteilung des Sprachmodells?"}
{"dataset_id": "mcif_v1.0", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versuchten, den Eingangssatz zu stören, indem wir die relevante Struktur beibehielten, aber Rauschen zum Eingang hinzufügten. Nach mehreren dieser Störungen stellten wir fest,"}
{"dataset_id": "mcif_v1.0", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass keiner dieser Störfaktoren die Modellvorhersage tatsächlich beeinflusst, wie sie uns den NPP-Just-in-Time-Trend zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Im Grunde genommen stellen wir fest, dass die Modelle auf die gestörten Sätze auf ähnliche Weise reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das heißt, wenn wir die Sätze im akzeptablen Bereich stören, sehen wir einen ähnlichen Anstieg bei allen Störungen, und wenn wir die Sätze im nicht akzeptablen Bereich stören, sehen wir einen ähnlichen Rückgang bei den MPP-Beurteilungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Die wichtigsten Erkenntnisse unserer Arbeit sind, dass Sprachmodelle auf latente syntaktische und semantische Merkmale reagieren, die in den Sätzen gemeinsam sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Die derzeitige MPP-Bewertung mit kurzen und einzelnen Eingaben kann das abstrakte Wissen des Sprachmodells über das Kontextfenster hinweg möglicherweise nicht vollständig erfassen."}
{"dataset_id": "mcif_v1.0", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "Bitte lesen Sie unseren Artikel für weitere Details zu unseren Experimenten. Vielen Dank fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Mein Name ist Yushin John von der Penn State University. Heute werde ich unsere Arbeit vorstellen, Exemplar, mehrsprachige semantische Analyse in mehreren natürlichen Sprachen und minimalen Repräsentationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Semantisches Parsing ist die Aufgabe, semantische Darstellungen von Benutzerabfragen zu erstellen, wie z. B. SQL und Lambda-Kalkül."}
{"dataset_id": "mcif_v1.0", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Die mehrsprachige semantische Parsing ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere bedeutungstragende Darstellungen zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der Abbildung gezeigt, müssen wir die Abfrage in mehrere natürliche Sprachen unter Verwendung neuronaler Modelle übersetzen, um SQL, Lambda oder FQL usw. zu erhalten."}
{"dataset_id": "mcif_v1.0", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Modelle für die mehrsprachige semantische Analyse wurden separat vorgeschlagen und auf Datensätzen mit begrenzten Aufgaben und Anwendungen bewertet. Zum Beispiel"}
{"dataset_id": "mcif_v1.0", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen. Chinesisch fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Mangelnde Berichterstattung über bestimmte Minderheiten."}
{"dataset_id": "mcif_v1.0", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Der Lambda-Kalkül fehlt."}
{"dataset_id": "mcif_v1.0", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Oder sie werden nur auf einem bestimmten neuronalen Modell bewertet. Zum Beispiel gibt es nur ein einziges Modell, um sie zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zweck schlagen wir Exemplar vor. Exemplar stellt einen einheitlichen Datensatz für die semantische Parsing-Übersetzung in mehreren natürlichen Sprachen und Bedeutungsdarstellungen bereit."}
{"dataset_id": "mcif_v1.0", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Es enthält 90 Datensätze in verschiedenen Domänen, 5 semantische Parsing-Aufgaben, 8 bedeutungstragende Darstellungen und 22 natürliche Sprachen in 15 Sprachfamilien."}
{"dataset_id": "mcif_v1.0", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Benchmark besser zu bewerten, haben wir sechs Einstellungen für das Training und die Bewertung in Betracht gezogen."}
{"dataset_id": "mcif_v1.0", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Der erste ist der Übersetzungstest. Wir verwenden die Google Translate API, um die Quellsprache in die Zielsprache zu übersetzen, und verwenden dann ein monolinguales Modell, um eine Bewertung zu trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Und zum Beispiel trainieren wir das englische Modell mit englischen Abfragen und übersetzen während der Inferenz die deutsche Abfrage mithilfe einer API in Englisch und verwenden dann das trainierte Modell, um die SQL-Abfrage vorherzusagen."}
{"dataset_id": "mcif_v1.0", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden auch ein monolinguales Modell testen."}
{"dataset_id": "mcif_v1.0", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Szenario ist die Quellsprache dieselbe wie die Zielsprache, z. B. Deutsch nach Deutsch oder Englisch nach Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Wir testeten auch monolinguale Few-Shot-Einstellungen, indem wir monolinguale Modelle mit nur 10 % der Trainingsdaten trainierten."}
{"dataset_id": "mcif_v1.0", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir testen ein mehrsprachiges Modell, bei dem wir ein einziges mehrsprachiges Modell für alle Sprachen trainieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben beispielsweise die deutschen, englischen und chinesischen Abfragen zusammengeführt, um ein mehrsprachiges Modell zu trainieren, und können dieses Modell während der Inferenz verwenden, um"}
{"dataset_id": "mcif_v1.0", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Um deutsche Abfragen oder chinesische Abfragen usw. zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "Wir berücksichtigen auch die Crosslinguale Zero-Shot- und Few-Shot-Übertragung. Wir trainieren auf einer Quellsprache und übertragen auf eine andere Sprache."}
{"dataset_id": "mcif_v1.0", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Während des Trainings trainieren wir es auf Englisch-Abfragen oder auf einer Kombination aus Englisch- und Deutsch-Abfragen, um ein mehrsprachiges Modell zu trainieren, das die SQL-Ausgabe vorhersagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch viele interessante Ergebnisse gefunden. Was die Analyse monolingualer Modelle betrifft, haben wir zwei Gruppen von Modellen bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Dazu gehören Encoder-PTR, was für multilinguale vorab trainierte Encoder mit pointerbasierten Decodern steht, wie z. B. XLM-R+PTR und BERT+PTR."}
{"dataset_id": "mcif_v1.0", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch Encoder-Decoder-Modelle bewertet, die mehrsprachig vorab trainierte Encoder-Decoder-Modelle sind, wie mBART und mT5."}
{"dataset_id": "mcif_v1.0", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass der Encoder-Decoder auf allen neun Datensätzen die beste Leistung erzielt."}
{"dataset_id": "mcif_v1.0", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten auf MT5 und XLM-R + BERT in einer mehrsprachigen Umgebung."}
{"dataset_id": "mcif_v1.0", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass Encoder-Decoder oder Encoder-PTR durch das Training in einer Mischung aus verschiedenen Sprachen verbessert werden können."}
{"dataset_id": "mcif_v1.0", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Und wir fanden heraus, dass dies daran liegt, dass die meisten der wichtigsten natürlichen Sprachen eine Leistungssteigerung erzielen, außer dass die Leistung in Englisch in sieben Datensätzen sinkt und nur in drei Datensätzen steigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Ich glaube, das nennt man den Fluch der Mehrsprachigkeit."}
{"dataset_id": "mcif_v1.0", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen auch die Lücke in der Leistung zwischen den Sprachen."}
{"dataset_id": "mcif_v1.0", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Abbildung ist die blaue Linie die mehrsprachige Few-Shot-Übertragung, die orange Linie die mehrsprachige Zero-Shot-Übertragung und die grüne Linie die einsprachige Einstellung."}
{"dataset_id": "mcif_v1.0", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass beim Vergleich der grünen und der orangen Linie die Lücke in der Leistung bei der Übertragung zwischen Sprachen im Null-Schuss-Szenario signifikant ist, und beim Vergleich der blauen und der orangen Linie haben wir festgestellt, dass sich die Lücke bei der Übertragung im Wenige-Schuss-Szenario schnell verringert."}
{"dataset_id": "mcif_v1.0", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch einige andere interessante Ergebnisse gefunden. Zum Beispiel übertrifft Encoder-Decoder die bisherigen Arbeiten oder erreicht vergleichbare Ergebnisse. Das Vorab-Training auf Englisch kann die Leistung von Few-Shot auf Zielsprachen erheblich steigern."}
{"dataset_id": "mcif_v1.0", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Und wir fanden, dass mehrsprachige Sprachmodelle wie CODA-S und BLOOM für die semantische Parsing zwischen Sprachen immer noch unzureichend sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst haben wir XAMPP, eine einheitliche Benchmark für die semantische Parsing über mehrere Sprachen und Repräsentationen hinweg, erstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine umfassende Benchmark-Studie an drei repräsentativen Arten von mehrsprachigen Sprachmodellen durchgeführt und unsere Ergebnisse zeigen viele interessante Erkenntnisse usw. Besuchen Sie unseren Artikel und den Code gerne. Vielen Dank fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Aydin Bilal und ich werde eine kurze Übersicht über den Artikel „Bewertung von Strategien und Leistung bei der maschinellen Übersetzung“ geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate."}
{"dataset_id": "mcif_v1.0", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Bram ist ein Sprachmodell mit 540 Milliarden Parametern, das im Jahr 2022 vorgestellt wurde. Es wurde an einer großen Textsammlung mit insgesamt 780 Milliarden Token trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Veröffentlichung erreicht es den Stand der Technik bei Hunderten von NLP-Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir die erste systematische Studie zur Prompting von großen Sprachmodellen für maschinelle Übersetzung vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Übertragbarkeit solcher Modelle unter Verwendung der besten Praktiken der NLP-Community bewertet. Dies beinhaltet die Verwendung der neuesten Testdatensätze, um eine Überschneidung der Testdaten mit den Trainingsdaten des Sprachmodells zu vermeiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen zwei Spitzenreiter-Systeme, also die leistungsstärksten Systeme der WMT-Bewertung."}
{"dataset_id": "mcif_v1.0", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden neueste LMT-Metriken und zeigen zusätzlich Ergebnisse von Expertenbewertungen durch Menschen. Schließlich geben wir einige Empfehlungen für Prompt-Auswahlstrategien."}
{"dataset_id": "mcif_v1.0", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Eingabe hat einen großen Einfluss auf die Leistung von LLM für die Übersetzung. Wie wir in einem einfachen Experiment sehen können, bei dem wir die Eingabe mit einem Beispiel verwenden und zwei verschiedene Eingaben für denselben Satz bereitstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Mehrheit der Sätze (516 von 1000) beträgt der beobachtete Unterschied mehr als einen BLEU-Punkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "In extremen Fällen kann dies bis zu 40 Blutzuckerpunkten gehen. Daher ist es wichtig, eine gute Prompting-Strategie auszuwählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Experimenten haben wir uns für eine Strategie mit fünf Beispielen entschieden, bei der wir jeden Satz, den wir dem System zur Verfügung stellen, mit der Sprache markieren, in der er verfasst ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hier, in dem wir eine Übersetzung von Deutsch nach Englisch durchführen, sind die deutschen Sätze, die Quellsätze, mit einem deutschen Doppelpunkt markiert und die englischen Übersetzungen mit einem englischen Doppelpunkt."}
{"dataset_id": "mcif_v1.0", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die tatsächliche Form des Promptings bei mehreren kurzen Prompts keinen großen Einfluss hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Es ist entscheidend für Null- und Ein-Schuss-Prompting, und wenn wir, wie in unserem Fall, zu Fünf-Schuss-Prompting übergehen, gibt es kaum einen Unterschied zur tatsächlichen Form des Promptings."}
{"dataset_id": "mcif_v1.0", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Es sind die Beispiele, die das meiste Gewicht tragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Qualität der Beispiele wichtiger ist als die Ähnlichkeit zum Quellsatz."}
{"dataset_id": "mcif_v1.0", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "Es ist daher wichtig, die Beispiele aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Auswahl von Prompts aus den Trainingsdaten der WMT-Bewertungen oder den Testdaten."}
{"dataset_id": "mcif_v1.0", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Die Entwicklungsdaten sind viel besser kuratiert und von höherer Qualität als die Trainingsdaten, die Ergebnisse sind also besser und die Leistung ist bei Verwendung der Entwicklungsdaten besser."}
{"dataset_id": "mcif_v1.0", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Dennoch haben spezialisierte SOTA-Systeme einen erheblichen Vorteil gegenüber den BAMT-Übersetzungen, aber BAMT kommt einem kommerziellen System ziemlich nahe. In unserem Fall haben wir uns entschieden, es mit Google Translate zu vergleichen."}
{"dataset_id": "mcif_v1.0", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Die Erkenntnisse, die wir aus der EMA-Ausschaltung gewonnen haben, die wir mit dem MQM-Rahmen durchgeführt haben, sind, dass die Flüssigkeit von PALM mit der von Spitzenreiter-Systemen vergleichbar ist, aber der Hauptunterschied in der Genauigkeit liegt."}
{"dataset_id": "mcif_v1.0", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere sind Auslassungsfehler die häufigsten Fehler."}
{"dataset_id": "mcif_v1.0", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es scheint, dass Palm manchmal eine bessere Übersetzung produziert, indem es Teile des Quelltextes weglässt, die in der Übersetzung redundant sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Die Kategorie „Out-of-Style“ für PAN ist jedoch niedriger als für die Spitzenreiter-Systeme, was ein zusätzliches Signal ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Das Programm liefert wirklich flüssige Ausgaben, hat aber immer noch einige Genauigkeitsprobleme."}
{"dataset_id": "mcif_v1.0", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Das war's für diese wirklich kurze Übersicht. Für weitere Details besuchen Sie bitte die vollständige Präsentation des Papiers. Vielen Dank."}
{"dataset_id": "mcif_v1.0", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Dawei, ein Doktorand an der Saarland-Universität in Deutschland. In diesem Video möchte ich Ihnen unsere neueste Arbeit vorstellen: „Weaker than you think: A critical look at weekly supervised learning“."}
{"dataset_id": "mcif_v1.0", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit Xiao-Yu Shen, Mario Smoos, und D. T. Clark."}
{"dataset_id": "mcif_v1.0", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Ich möchte mit einer kurzen Einführung in schwache Überwachung und schwach überwachtes Lernen beginnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Bei der schwachen Überwachung werden die Daten nicht manuell beschriftet. Stattdessen werden die Daten mit schwachen Beschriftungsquellen beschriftet, wie z. B. einfachen heuristischen Regeln, Wissensdatenbanken oder Crowdsourcing geringer Qualität, wie in der Abbildung rechts dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Im Vergleich zu menschlichen Annotationen sind schwache Annotationen viel günstiger, aber auch verrauschter, was bedeutet, dass ein bestimmter Prozentsatz der Annotationen falsch ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir neuronale Netzwerke direkt auf wöchentlich beschriftete Daten trainieren, neigen die neuronalen Netzwerke dazu, das Rauschen der Beschriftung auswendig zu lernen und verallgemeinern nicht."}
{"dataset_id": "mcif_v1.0", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "In „Weakly Supervised Learning“ werden Trainingsalgorithmen vorgeschlagen, die neuronale Netzwerke robust gegenüber solchen Etikettierungsfehlern trainieren, sodass die trainierten Modelle weiterhin gut generalisieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "In jüngsten Arbeiten zu WSL (WSL steht für Weekly Supervised Learning) wird häufig behauptet, dass die Modelle nur mit wöchentlichen Label-Daten trainiert werden und eine hohe Leistung auf sauberen Testdaten erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Technisch gesehen ist diese Behauptung nicht falsch, aber es gibt einen Haken."}
{"dataset_id": "mcif_v1.0", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Dabei wird davon ausgegangen, dass ein zusätzlicher sauberer Validierungssatz für die Modellauswahl zur Verfügung steht."}
{"dataset_id": "mcif_v1.0", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben uns auf diese Problemstellung festgelegt, was impliziert, dass für das wöchentliche Supervised Learning zusätzliche manuelle Annotationen erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Die oben genannten Zweifel führen uns zu drei Forschungsfragen. Erstens: Ist saubere Validierungsdaten für WSL notwendig? Oder können wir vielleicht stattdessen einen verrauschten Validierungssatz verwenden?"}
{"dataset_id": "mcif_v1.0", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten für die Funktion von WSL zwingend erforderlich sind, wie viele saubere Proben benötigen wir dann? Schließlich sollten wir die sauberen Proben nur zur Validierung verwenden oder gibt es bessere Möglichkeiten, sie zu nutzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese Forschungsfragen in unserer Arbeit behandelt und unsere Ergebnisse sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst stellen wir fest, dass interessanterweise die neuesten WSL-Methoden tatsächlich saubere Weißabgleichsproben benötigen, um richtig zu funktionieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kommt es zu einem großen Leistungsabfall, wie in dieser Abbildung gezeigt. Wenn keine sauberen Validierungsstichproben vorliegen, können die trainierten Modelle nicht über die ursprünglichen schwachen Labels hinaus verallgemeinert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Das bedeutet, dass das Training sinnlos ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Das deutet darauf hin, dass WSL-Ansätze tatsächlich sauber beschriftete Daten benötigen, um richtig zu funktionieren, und die Kosten für die Annotation, um saubere Validierungsbeispiele zu erhalten, sollten nicht übersehen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Unsere zweite Erkenntnis ist, dass die Erhöhung der Anzahl sauberer Validierungsbeispiele WSL-Ansätzen hilft, eine bessere Leistung zu erzielen, wie im linken Diagramm gezeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Typischerweise benötigen wir nur 20 Proben pro Klasse, um eine hohe Leistung zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Aber das ist noch nicht das Ende der Geschichte, denn wenn wir uns entscheiden, auf saubere Proben zuzugreifen, dann wird das Training direkt auf ihnen sogar eine bessere Leistung erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Die rechte Abbildung zeigt die Leistungsunterschiede zwischen Feinabstimmungsansätzen, die direkt auf den sauberen Daten angewendet werden, und WSL-Ansätzen, die die sauberen Daten nur zur Validierung verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Wie wir sehen können, beginnt die direkte Feinabstimmung, wenn wir 10 Proben pro Klasse haben, die WSL-Ansätze zu übertreffen."}
{"dataset_id": "mcif_v1.0", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich kann die in früheren WSL-Ansätzen beanspruchte Leistungssteigerung leicht erreicht werden, indem die Feinabstimmung an den sauberen Validierungsbeispielen fortgesetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Wie aus den Abbildungen hervorgeht, schneidet das Vanilla-Modell, das als FTW bezeichnet wird, anfänglich schlechter ab als die komplizierteren WSL-Methoden wie Cosine."}
{"dataset_id": "mcif_v1.0", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch die Feinabstimmung an den sauberen Proben fortsetzen, dann schneidet FTW genauso gut ab wie andere Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis gibt es also keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst haben wir gezeigt, dass aktuelle WSL-Ansätze saubere, manuell annotierte Beispiele benötigen, damit sie richtig funktionieren. Ihre Leistungssteigerung und Praktikabilität werden stark überschätzt."}
{"dataset_id": "mcif_v1.0", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Unsere konkreten Empfehlungen für zukünftige Arbeiten sind wie folgt."}
{"dataset_id": "mcif_v1.0", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst wird das Modellauswahlkriterium angegeben. Zum Beispiel wird angegeben, ob die Modellauswahl anhand von sauberen Validierungsstichproben durchgeführt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten WSL-Ansätze mit Full-Shot-Learning-Basislinien verglichen werden, da beide auf klaren Beispielen arbeiten. Drittens ist kontinuierliches Feintuning eine einfache, aber starke Basislinie, die in zukünftigen Arbeiten zu WSL berücksichtigt werden sollte."}
{"dataset_id": "mcif_v1.0", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir unseren Code als Open Source veröffentlicht. Sie finden ihn über den QR-Code auf dieser Folie. Schauen Sie sich das gerne an. Vielen Dank und viel Spaß auf der Konferenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute erzählen wir Ihnen alles über ABC-Eval, einen neuen dimensionalen Ansatz zur Bewertung von konversationeller KI."}
{"dataset_id": "mcif_v1.0", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Diese Arbeit wurde vom Emory NLP Lab unter der Leitung von Professor Gino Cormack an der Emory University in Zusammenarbeit mit Amazon Alexa AI durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, Sie haben gerade ein Dialogmodell entwickelt und möchten sehen, wie es sich im Vergleich zum aktuellen Stand der Technik schlägt."}
{"dataset_id": "mcif_v1.0", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Die übliche Praxis ist die menschliche Bewertung, z. B. indem man menschliche Richter bittet, auszuwählen, welche von zwei Unterhaltungen besser ist, oder Unterhaltungen auf einer Likert-Skala zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ansätze eignen sich gut, um umfassende Bewertungen der allgemeinen Dialogqualität zu liefern, aber die Dialogqualität hat viele Aspekte. Daher möchten Sie möglicherweise mehrere Dimensionen der Chatqualität bewerten, um die Stärken und Schwächen des Modells auf einer detaillierteren Ebene zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Ein Ansatz besteht darin, menschliche Beurteiler einfach zu bitten, mehrere Dimensionen der Dialogqualität zu bewerten, wie z. B. die Relevanz der Modellantworten, mit bestehenden vergleichenden oder Likert-Skalen-Methoden."}
{"dataset_id": "mcif_v1.0", "sample_id": 421, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben jedoch, dass es eine präzisere und zuverlässigere Strategie für die Bewertung von Dialogdimensionen gibt."}
{"dataset_id": "mcif_v1.0", "sample_id": 422, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem er explizit annotiert, ob jede Modellantwort bestimmte Verhaltensweisen ausdrückt, wie z. B. die Antwort mit irrelevanten Informationen oder sich widersprechend."}
{"dataset_id": "mcif_v1.0", "sample_id": 423, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen diesen Ansatz „Verhaltensbeschreibung im Chat“ oder kurz ABC-Evaluation. Wir haben diese Methode entwickelt, um die Verhaltensweisen von Chatmodellen umfassend abzudecken, die in der jüngsten Literatur als qualitätsbeeinflussend beschrieben wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 424, "src_lang": "en", "tgt_lang": "de", "output": "ABC-Eval kann die Häufigkeit messen, mit der Chatmodelle verschiedene thematische Fehler machen."}
{"dataset_id": "mcif_v1.0", "sample_id": 425, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise misst ABC-Eval die Anzahl der Züge, in denen ein Chatmodell seinen Partner ignoriert oder etwas Unrelevantes sagt."}
{"dataset_id": "mcif_v1.0", "sample_id": 426, "src_lang": "en", "tgt_lang": "de", "output": "wenn es sich selbst oder seinen Partner widerspricht, falsche Fakten erfindet oder gesunden Menschenverstand verletzt und wenn das Modell erfolgreich ist oder versagt, Mitgefühl zu zeigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 427, "src_lang": "en", "tgt_lang": "de", "output": "Um zu bestimmen, welche Art der Bewertung am effektivsten ist, haben wir vier Spitzenmodelle für Chatbots ausgewählt und diese mit 100 menschlichen Bot-Gesprächen pro Modell mit ABC-Eval bewertet."}
{"dataset_id": "mcif_v1.0", "sample_id": 428, "src_lang": "en", "tgt_lang": "de", "output": "Zum Vergleich haben wir diese Gespräche auch mit drei bestehenden Methoden bewertet: Likert-Bewertungen auf der Ebene der Äußerung, Likert-Bewertungen auf der Ebene des Dialogs und paarweise Vergleiche auf der Ebene des Dialogs."}
{"dataset_id": "mcif_v1.0", "sample_id": 429, "src_lang": "en", "tgt_lang": "de", "output": "Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekte des Dialogs gesammelt, da dies die übliche Vorgehensweise zur Bewertung von Chatmodellen entlang mehrerer Dimensionen ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 430, "src_lang": "en", "tgt_lang": "de", "output": "Aus unseren Analysen der Bewertungsergebnisse geht hervor, dass die ABC-Eval-Verhaltensmarkierungen insgesamt zuverlässiger sind als die mit bestehenden Methoden gesammelten Markierungen, gemessen an der Übereinstimmung der Bewerter bei 100 doppelt markierten Gesprächen."}
{"dataset_id": "mcif_v1.0", "sample_id": 431, "src_lang": "en", "tgt_lang": "de", "output": "Zudem sind ABC-EVAL-Labels im Vergleich zu den von bestehenden Methoden erzeugten Metriken besser in der Lage, die Gesamtqualität der Konversation vorherzusagen, wie diese einfache lineare Regressionsanalyse zeigt."}
{"dataset_id": "mcif_v1.0", "sample_id": 432, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können Sie sehen, wie das Messen des Anteils der Redebeiträge mit Selbst- und Partnerwidersprüchen 5 % bzw. 10 % der Gesprächsqualität erklären, während die durchschnittlichen Likert-Konsistenzwerte nur 4 % oder weniger erklären."}
{"dataset_id": "mcif_v1.0", "sample_id": 433, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir mit einer schrittweisen linearen Regression überprüft, ob jede Bewertungsmetrik einen einzigartigen Aspekt der Chatqualität erfasst."}
{"dataset_id": "mcif_v1.0", "sample_id": 434, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass die Kombination aller ABC-Evaluierungsmetriken mehr als 25 % der Gesprächsqualität erklärt, und wenn Sie die Metriken eine nach der anderen entfernen, führt dies meistens zu einem erheblichen Informationsverlust über die Qualität."}
{"dataset_id": "mcif_v1.0", "sample_id": 435, "src_lang": "en", "tgt_lang": "de", "output": "Andererseits erklärt die Kombination aller Metriken auf Turnierebene mit Likert-Skala weit weniger von der Qualität, und weniger dieser Metriken tragen einzigartige Informationen."}
{"dataset_id": "mcif_v1.0", "sample_id": 436, "src_lang": "en", "tgt_lang": "de", "output": "Diese zuverlässigen, informativen und einzigartigen ABC-Evaluierungsmetriken ermöglichen es uns, die Konversations-KI mit einer höheren Auflösung zu bewerten, als dies mit früheren Methoden möglich war."}
{"dataset_id": "mcif_v1.0", "sample_id": 437, "src_lang": "en", "tgt_lang": "de", "output": "In den Ergebnissen unseres Experiments können Sie sehen, dass noch einige Herausforderungen bestehen, die genau quantifiziert wurden. Zum Beispiel verletzen die Bots, die wir getestet haben, in etwa 20 % ihrer Antworten den gesunden Menschenverstand."}
{"dataset_id": "mcif_v1.0", "sample_id": 438, "src_lang": "en", "tgt_lang": "de", "output": "Sie produzieren in etwa 15 % der Antworten irrelevante Informationen und widersprechen sich oder ihrem Partner in etwa 10 % der Fälle."}
{"dataset_id": "mcif_v1.0", "sample_id": 439, "src_lang": "en", "tgt_lang": "de", "output": "Mit dem schnellen Fortschritt auf diesem Gebiet könnten viele dieser Fehlerraten bei neuen Modellen, die seit unserer Bewertung veröffentlicht wurden, sinken. Dies ist jedoch umso mehr ein Grund, zuverlässige und präzise Bewertungskriterien für den Vergleich von Modellen zu verfolgen."}
{"dataset_id": "mcif_v1.0", "sample_id": 440, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass ABC-Eval von anderen in diesem Bereich als bedeutender Schritt in diese Richtung genutzt werden kann, und wir freuen uns darauf, zu sehen, wie sich die konversationelle KI in den kommenden Monaten und Jahren weiterentwickeln wird. Vielen Dank fürs Zuschauen."}
{"dataset_id": "mcif_v1.0", "sample_id": 441, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kai Owen und ich werde unsere Arbeit mit dem Titel „Wann erfordert Übersetzung Kontext? Eine datengesteuerte mehrsprachige Untersuchung“ vorstellen. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernandes, Emily Liu, André F. T. Martins und Graham Neubig erstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 442, "src_lang": "en", "tgt_lang": "de", "output": "Viele Übersetzungen hängen vom Kontext ab. Zum Beispiel, wie würden wir „mol“ in diesem Satz übersetzen?"}
{"dataset_id": "mcif_v1.0", "sample_id": 443, "src_lang": "en", "tgt_lang": "de", "output": "Nun, wenn der vorherige Satz lautete: „Die Dinge könnten gefährlich werden, wenn die Minister davon erfahren“, dann bezieht sich „Mole“ auf einen Spion. Wenn der vorherige Satz jedoch lautete: „Könnte es etwas Ernstes sein, Doktor?“, dann bezieht sich „Mole“ auf ein Muttermal."}
{"dataset_id": "mcif_v1.0", "sample_id": 444, "src_lang": "en", "tgt_lang": "de", "output": "Je nach Kontext ändert sich die Bedeutung des Wortes und damit auch seine Übersetzung."}
{"dataset_id": "mcif_v1.0", "sample_id": 445, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung, wie gut Modelle Fälle wie diesen übersetzen können, ist jedoch ziemlich schwierig. Erstens, weil nur ein kleiner Teil der Übersetzungen vom Kontext abhängt, was bedeutet, dass Korpus-Metriken wie BLEU diese Übersetzungen nicht erfassen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 446, "src_lang": "en", "tgt_lang": "de", "output": "Einige haben eine gezielte Bewertung von kontextabhängigen Übersetzungen vorgeschlagen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachpaare, da sie in der Regel auf Fachwissen und menschliche Kuratierung angewiesen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 447, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten. Erstens, wann erfordert die Übersetzung einen Kontext? Und zweitens, wie gut bewältigen Modelle diese Fälle?"}
{"dataset_id": "mcif_v1.0", "sample_id": 448, "src_lang": "en", "tgt_lang": "de", "output": "Um die erste Frage zu beantworten, begannen wir damit, zu messen, wie sehr ein Wort im Rahmen der Übersetzung vom Kontext abhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 449, "src_lang": "en", "tgt_lang": "de", "output": "In der vorherigen Arbeit haben wir CXMI als Maß für die Nutzung von Kontext durch maschinelle Übersetzungsmodelle eingeführt. Dies geschieht durch die Messung der Menge an Informationen, die der Kontext C über das Ziel Y bereitstellt, wenn die Quelle X gegeben ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 450, "src_lang": "en", "tgt_lang": "de", "output": "CXMI kann man als die Informationen betrachten, die man durch das Hinzufügen von Kontext zum Modell erhält."}
{"dataset_id": "mcif_v1.0", "sample_id": 451, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit erweitern wir CXMI zu Punkt-CXMI, das den Kontextgebrauch auf Satzebene oder auf Wortebene messen kann. Wir können uns Wörter mit hohem P6MI als solche vorstellen, die für die Übersetzung Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 452, "src_lang": "en", "tgt_lang": "de", "output": "Nun analysieren wir Wörter mit hohem PCMI, um nach Mustern zwischen diesen Wörtern zu suchen."}
{"dataset_id": "mcif_v1.0", "sample_id": 453, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse an Transkripten von TED-Vorträgen durch, die aus dem Englischen in 14 verschiedene Sprachen übersetzt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 454, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst betrachten wir einen Teil der Sprachmarkierungen mit hohen PCXMI-Mittelwerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 455, "src_lang": "en", "tgt_lang": "de", "output": "Damit können wir beispielsweise arabische Dualpronomen finden, die eine relativ hohe P6MI aufweisen. Dies lässt sich damit erklären, dass es im Englischen keine Dualpronomen gibt, sodass der Kontext bestimmt, ob ein Pronomen dual ist, wenn es ins Arabische übersetzt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 456, "src_lang": "en", "tgt_lang": "de", "output": "Ähnlich finden wir, dass bestimmte Sprachen ebenfalls einen Kontext erfordern, wenn wir die passende Verbform wählen wollen. Wir untersuchen dann Vokabeln, die einen hohen Psexam-Wert aufweisen, der über alle ihre verschiedenen Vorkommen gemittelt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 457, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch können wir Fälle wie den hier identifizieren, bei dem im Chinesischen der Kontext erforderlich ist, um Eigennamen korrekt zu übersetzen, um sicherzustellen, dass im Dokument dieselbe Übersetzung verwendet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 458, "src_lang": "en", "tgt_lang": "de", "output": "Und ähnlich finden wir, dass Kontext hilft, in der richtigen Form zu übersetzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 459, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich betrachten wir verschiedene einzelne Token mit hohem PXMI. Dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich durch das Wort selbst erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie z. B. die Auflösung von Ellipsen."}
{"dataset_id": "mcif_v1.0", "sample_id": 460, "src_lang": "en", "tgt_lang": "de", "output": "Wir nutzen nun unsere Erkenntnisse aus unserer Analyse, um eine Benchmark für die Dokumentübersetzung zu entwerfen."}
{"dataset_id": "mcif_v1.0", "sample_id": 461, "src_lang": "en", "tgt_lang": "de", "output": "Für jedes der fünf Diskursphänomene, die wir identifiziert haben, haben wir Tagger erstellt, die automatisch Wörter identifizieren, die zu dem Phänomen gehören, und nennen unseren Tagger den mehrsprachigen diskursbewussten oder MUDA-Tagger."}
{"dataset_id": "mcif_v1.0", "sample_id": 462, "src_lang": "en", "tgt_lang": "de", "output": "Man kann auch feststellen, dass verschiedene Sprachen unterschiedliche Anteile dieser Diskursphänomene aufweisen."}
{"dataset_id": "mcif_v1.0", "sample_id": 463, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden dann den Muda-Tagger, indem wir den Tagger auf den parallelen Korpus anwenden, den wir für die Bewertung verwenden wollen, und wenden unsere gewählten Übersetzungsmetriken auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 464, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentebene für maschinelle Übersetzung zu bewerten."}
{"dataset_id": "mcif_v1.0", "sample_id": 465, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal haben wir bei der Verwendung von Korpus-Metriken festgestellt, dass kontextagnostische Modelle bei der BLEU-Metrik die beste Leistung erbringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 466, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch die Komma-Metrik verwenden, schneiden kontextbewusste Modelle am besten ab. Wenn wir die Wort-F1-Metrik verwenden, haben Modelle mit und ohne Kontext vergleichbare Leistungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 467, "src_lang": "en", "tgt_lang": "de", "output": "Dies zeigt erneut, dass es schwierig ist, das beste Dokumentübersetzungssystem zu bestimmen, wenn man nur auf Korpusebene-Metriken zurückgreift."}
{"dataset_id": "mcif_v1.0", "sample_id": 468, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben den MUDA-Benchmark verwendet, um Modelle zu bewerten, und festgestellt, dass kontextbasierte Modelle für bestimmte Diskursphänomene, wie Formalität und lexikalische Kohäsion, signifikant genauer sind als Modelle, die keinen Kontext verwenden."}
{"dataset_id": "mcif_v1.0", "sample_id": 469, "src_lang": "en", "tgt_lang": "de", "output": "Diese Modelle sind jedoch nicht viel besser als Modelle, die keinen Kontext für andere Phänomene wie Ellipsen, Pronomen und Verbformen verwenden. Das deutet darauf hin, dass wir bei der Dokumentübersetzung noch Fortschritte machen müssen."}
{"dataset_id": "mcif_v1.0", "sample_id": 470, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch verschiedene kommerzielle Systeme verglichen und unsere Benchmarks zeigen, dass DeepL in der Regel genauer ist als Google Translate für die Übersetzung auf Dokumentebene."}
{"dataset_id": "mcif_v1.0", "sample_id": 471, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst haben wir eine datengestützte Analyse über 14 Sprachpaare durchgeführt, um zu ermitteln, wann Übersetzungen einen Kontext erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 472, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend verwenden wir unsere Ergebnisse, um eine Benchmark für die maschinelle Übersetzung auf Dokumentebene zu erstellen, die uns helfen kann, zu erkennen, welche Diskursphänomene Modelle gut bewältigen können oder nicht, und welche Übersetzungssysteme gut für die Übersetzung auf Dokumentebene sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 473, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für Ihre Aufmerksamkeit. Wir sehen uns in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 474, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Yanis Lavrac und werde Ihnen unsere Arbeiten zu Dr. BERT vorstellen, einem robusten, vorab trainierten Modell auf Französisch für biomedizinische und klinische Bereiche."}
{"dataset_id": "mcif_v1.0", "sample_id": 475, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Präsentation sprechen wir zunächst über Sprachmodellierung im Gesundheitswesen. Danach stellen wir den Hauptbeitrag unseres Artikels vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 476, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen das erste biomedizinische Modell in französischer Sprache vor, das Dr. Bert heißt und auf Roberta basiert und mit Nachos trainiert wurde, einem Datensatz mit medizinischen Daten, die aus dem Web gesammelt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 477, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch einen Vergleich des Modells mit mehreren Pretraining-Einstellungen und Datenquellen vor. Dann präsentieren wir unsere Ergebnisse bei 11 biomedizinischen und klinischen Downstream-Aufgaben auf Französisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 478, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich fassen wir die Experimente zusammen und geben Ihnen weitere Details, wie Sie auf die Modelle zugreifen können."}
{"dataset_id": "mcif_v1.0", "sample_id": 479, "src_lang": "en", "tgt_lang": "de", "output": "Seit seiner Veröffentlichung im Jahr 2018 ist BERT zu einem der effektivsten Ansätze zur Lösung von Aufgaben der Verarbeitung natürlicher Sprache geworden und bietet im Vergleich zu historischen statischen und kontextualisierten Methoden wie Word2Vec, FastText oder GloVe erhebliche Leistungsgewinne."}
{"dataset_id": "mcif_v1.0", "sample_id": 480, "src_lang": "en", "tgt_lang": "de", "output": "Seitdem wurde dieses Modell an viele andere Sprachen angepasst, wie zum Beispiel Französisch mit CamemBERT, und an andere Bereiche wie biomedizinische mit BioMegatron und BioBERT, und klinische mit ClinicalBERT, aber hauptsächlich in Englisch."}
{"dataset_id": "mcif_v1.0", "sample_id": 481, "src_lang": "en", "tgt_lang": "de", "output": "Spezialisierte Modelle für andere Sprachen sind selten und basieren oft auf kontinuierlichem Pretraining aufgrund des Mangels an In-Domain-Daten."}
{"dataset_id": "mcif_v1.0", "sample_id": 482, "src_lang": "en", "tgt_lang": "de", "output": "Bisher gab es jedoch in Frankreich kein Open-Source-Modell für Biomedizin."}
{"dataset_id": "mcif_v1.0", "sample_id": 483, "src_lang": "en", "tgt_lang": "de", "output": "Wir fragen uns also, welche Datenquellen für eine Vielzahl von Anwendungen am besten geeignet sind und ob diese Crowd-Daten einen guten Ersatz für klinische Daten darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 484, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, vergleichen wir Dr. BERT mit unserem Schubert-Modell, das auf anonymisierten Daten basiert, die wir von dem Universitätsklinikum erhalten haben, das wir beherbergen."}
{"dataset_id": "mcif_v1.0", "sample_id": 485, "src_lang": "en", "tgt_lang": "de", "output": "Danach fragten wir uns, wie viel Daten wir benötigen, um ein spezialisiertes Modell auf französischen Daten zu trainieren. Sind es 4 Gigabyte, 8 Gigabyte oder mehr?"}
{"dataset_id": "mcif_v1.0", "sample_id": 486, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Frage zu beantworten, trainieren und vergleichen wir zunächst vier Modelle von Grund auf. Eine erste Version von Dr. BERT mit 7 GB Nachos, eine zweite Version mit 4 GB Nachos,"}
{"dataset_id": "mcif_v1.0", "sample_id": 487, "src_lang": "en", "tgt_lang": "de", "output": "Eine erste Version von Schubert, einem klinischen Modell, mit 4 Gigabyte Sätzen aus klinischen Notizen und eine endgültige Version von Schubert mit einer Mischung aus 4 Gigabyte Teilmenge von Naturtexten und 4 Gigabyte klinischen Notizen."}
{"dataset_id": "mcif_v1.0", "sample_id": 488, "src_lang": "en", "tgt_lang": "de", "output": "Neben diesem Vergleich führen wir drei Modelle ein, die auf kontinuierlichem Vortraining basieren, um die Auswirkungen der Vortrainingsstrategie zu analysieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 489, "src_lang": "en", "tgt_lang": "de", "output": "Einer basiert auf Camembert und wurde mit einer 4-GB-Untermenge von Nachos trainiert, der andere ebenfalls auf Camembert, aber diesmal mit den 4 GB von Klingon Lots trainiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 490, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich eines, das auf dem englischen biomedizinischen Modell BERT basiert und mit einem 4-GB-Subset von Snatch trainiert wurde. Insgesamt haben wir sieben Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 491, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere sieben Modelle zu bewerten, haben wir eine Reihe von öffentlichen und privaten NLP-Aufgaben gesammelt, wie z. B. Namens- und Entitätserkennung, Klassifizierung, POS-Tagging und Beantwortung von Fragen."}
{"dataset_id": "mcif_v1.0", "sample_id": 492, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Modell wird mit sechs Basislinienmodellen verglichen, nämlich CamemBERT-Oscar 138GB, CamemBERT-Oscar 4GB, CamemBERT-CCNet 4GB, PermedBERT, BioBERT und ClinicalBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 493, "src_lang": "en", "tgt_lang": "de", "output": "Die Bewertung hebt hervor, dass das Modell bei Aufgaben mit Daten derselben Art am besten abschneidet, mit denen das Modell trainiert wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 494, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können wir die Daten aus heterogenen Quellen beobachten, die vielseitiger zu sein scheinen. Wir stellen auch fest, dass die Verwendung von mehr Daten zu einer besseren Leistung führt."}
{"dataset_id": "mcif_v1.0", "sample_id": 495, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt scheint das Training von Grund auf höhere Leistungen bei den meisten Aufgaben zu erzielen."}
{"dataset_id": "mcif_v1.0", "sample_id": 496, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment zur kontinuierlichen Schulung unter Verwendung des Gewichts und des Tokenizers von PumiceBERT, das auf der 4-GB-Untermenge von NACHOS trainiert wurde, zeigte jedoch mit Dr. BERT 4GB von Grund auf vergleichbare Ergebnisse."}
{"dataset_id": "mcif_v1.0", "sample_id": 497, "src_lang": "en", "tgt_lang": "de", "output": "Das ist bei dem Modell, das auf Camembert-Gewichten und Tokenizer basiert, nicht der Fall, das unter Stabilitätsproblemen leidet."}
{"dataset_id": "mcif_v1.0", "sample_id": 498, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich bietet unser eigenes System in neun der elf Domänenaufgaben eine bessere Leistung und übertrifft insgesamt das Ergebnis des generischen Modells, hier CamemBERT."}
{"dataset_id": "mcif_v1.0", "sample_id": 499, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch beobachtet, dass spezialisierte Daten besser sind, mehr spezialisierte Daten besser sind, aber sie lassen sich nicht gut skalieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 500, "src_lang": "en", "tgt_lang": "de", "output": "Alle von Nachos erhaltenen vorab trainierten Modelle sind auf Hugging Face frei verfügbar und alle Trainings-Skripte befinden sich in unserem GitHub-Repository."}
{"dataset_id": "mcif_v1.0", "sample_id": 501, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank für diese Präsentation und wir freuen uns auf die Aktionen bei der Poststation in Toronto."}
{"dataset_id": "mcif_v1.0", "sample_id": 502, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Matthias Lindemann und heute werde ich Ihnen eine kurze Einführung in unseren Artikel über Kompositionelle Generalisierung ohne Bäume unter Verwendung von Multi-Set-Tagging und latenten Permutationen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 503, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist eine gemeinsame Arbeit mit meinen Betreuern Alexander Koller und Ivan Titov."}
{"dataset_id": "mcif_v1.0", "sample_id": 504, "src_lang": "en", "tgt_lang": "de", "output": "Kompositionelle Generalisierung kann als die Fähigkeit eines Lernenden verstanden werden, tiefere Rekursion und unvorhergesehene Kompositionen von Sätzen zu bewältigen, die während des Trainings einzeln gesehen wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 505, "src_lang": "en", "tgt_lang": "de", "output": "Im Kontext des semantischen Parsens könnte das Testen auf Kompositionalität wie folgt aussehen. Wie üblich haben wir einen Trainingsdatensatz von Äußerungen, in diesem Fall „Das Mädchen schlief“ und „Mary wusste, dass das Mädchen schlief“."}
{"dataset_id": "mcif_v1.0", "sample_id": 506, "src_lang": "en", "tgt_lang": "de", "output": "Diese Äußerungen werden mit logischen Formen gepaart, die grundlegende Aspekte ihrer Bedeutung darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 507, "src_lang": "en", "tgt_lang": "de", "output": "Im Gegensatz zur Standard-Maschinellen Lernbewertung stammt der Testdatensatz nicht aus derselben Verteilung, sondern enthält strukturell unbekannte logische Formen."}
{"dataset_id": "mcif_v1.0", "sample_id": 508, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das Modell während des Trainings nur flache Rekursion gesehen und wird an einem Beispiel mit tiefer Rekursion getestet."}
{"dataset_id": "mcif_v1.0", "sample_id": 509, "src_lang": "en", "tgt_lang": "de", "output": "Naive sequenzielle Modelle haben Schwierigkeiten mit dieser Art von Generalisierung außerhalb der Verteilung und erzeugen oft Ausgaben, die vom Eingang getrennt sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 510, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere gelingt es ihnen oft nicht, die systematischen Entsprechungen zwischen Eingabe und Ausgabe zu reproduzieren, wie sie im Beispiel farblich hervorgehoben sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 511, "src_lang": "en", "tgt_lang": "de", "output": "Eine beliebte Methode, um dies zu erreichen, ist die Integration von Bäumen in die Modelle."}
{"dataset_id": "mcif_v1.0", "sample_id": 512, "src_lang": "en", "tgt_lang": "de", "output": "Die Bäume sollen den kompositionellen Prozess erfassen, der Äußerungen mit logischen Formen in Verbindung bringt."}
{"dataset_id": "mcif_v1.0", "sample_id": 513, "src_lang": "en", "tgt_lang": "de", "output": "Das funktioniert gut, aber Bäume werden normalerweise nicht gegeben und müssen irgendwie beschafft werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 514, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann kompliziert und manchmal ein rechenintensiver Prozess sein. Typischerweise ist dies mit erheblicher, formalismusspezifischer Vorverarbeitung der logischen Formen verbunden, z. B. um Variablensymbole zu handhaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 515, "src_lang": "en", "tgt_lang": "de", "output": "Das Erhalten von Bäumen kann auch spezielle Verfahren zur Grammatikinduktion erfordern."}
{"dataset_id": "mcif_v1.0", "sample_id": 516, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit verwenden wir keine Bäume und stellen ein neuronales Sequenz-zu-Sequenz-Modell vor, das die Entsprechungen zwischen Fragmenten des Eingabesignals und Fragmenten des Ausgabesignals direkt modelliert."}
{"dataset_id": "mcif_v1.0", "sample_id": 517, "src_lang": "en", "tgt_lang": "de", "output": "Zum ersten Mal zeigen wir eine starke Verallgemeinerung zu tiefer Rekursion, ohne auf Bäume zurückzugreifen."}
{"dataset_id": "mcif_v1.0", "sample_id": 518, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz prognostiziert die Ausgabe aus der Eingabe in zwei Schritten."}
{"dataset_id": "mcif_v1.0", "sample_id": 519, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst versehen wir jedes Eingabetoken mit einer ungeordneten Multimenge von Token, die im Ausgabe-Text erscheinen werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 520, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht geordnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 521, "src_lang": "en", "tgt_lang": "de", "output": "Deshalb verwenden wir im zweiten Schritt ein anderes Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen."}
{"dataset_id": "mcif_v1.0", "sample_id": 522, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine neue Methode zur Vorhersage einer Permutation vor, die keine harten Einschränkungen für die möglichen Permutationen vorsieht. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark."}
{"dataset_id": "mcif_v1.0", "sample_id": 523, "src_lang": "en", "tgt_lang": "de", "output": "Unser Permutationsmodell funktioniert konzeptionell ungefähr so:"}
{"dataset_id": "mcif_v1.0", "sample_id": 524, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multimengen-Token wir in jede Position setzen. Für die erste Ausgabeposition wählen wir einfach eine, wie in Rot hervorgehoben."}
{"dataset_id": "mcif_v1.0", "sample_id": 525, "src_lang": "en", "tgt_lang": "de", "output": "Dann springen wir zum nächsten Multimengen-Token, um das zweite Token im Output zu bestimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 526, "src_lang": "en", "tgt_lang": "de", "output": "Wir bestimmen das dritte Token im Output auf ähnliche Weise, indem wir zu einem anderen Multimengen-Token springen. Wir setzen diesen Prozess fort."}
{"dataset_id": "mcif_v1.0", "sample_id": 527, "src_lang": "en", "tgt_lang": "de", "output": "Bis jeder Token aus der ersten Stufe genau einmal besucht wurde."}
{"dataset_id": "mcif_v1.0", "sample_id": 528, "src_lang": "en", "tgt_lang": "de", "output": "Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir hier unsere Methode mit anderen baumlosen Modellen auf der Cogs-Benchmark. Unser Modell übertrifft die anderen bei der Generalisierung auf tiefere Rekursion um einen großen Betrag."}
{"dataset_id": "mcif_v1.0", "sample_id": 529, "src_lang": "en", "tgt_lang": "de", "output": "Andere Arten der strukturellen Generalisierung bleiben jedoch sehr herausfordernd."}
{"dataset_id": "mcif_v1.0", "sample_id": 530, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Arbeit lösen wir einige interessante technische Herausforderungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 531, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal ist die Zuordnung zwischen Eingabe und Ausgabe in den Trainingsdaten nicht gegeben. Als Folge wissen wir für ein bestimmtes Token nicht, aus welchem Multisatz es stammt, was eine Herausforderung für das Training darstellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 532, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem gibt es manchmal mehrere Permutationen, die mit den Daten übereinstimmen, aber die sprachlich korrekte ist latent. Wir gehen damit um, indem wir die Ausrichtung als Teil des Trainings induzieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 533, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Permutationsmethode ist sehr flexibel, bringt aber die Herausforderung mit sich, dass die Suche nach der Permutation mit der höchsten Punktzahl NP-schwer ist. Das liegt daran, dass dies mit dem Problem des Handlungsreisenden zusammenhängt."}
{"dataset_id": "mcif_v1.0", "sample_id": 534, "src_lang": "en", "tgt_lang": "de", "output": "Wir nähern uns diesem Problem mit einer GPU-freundlichen kontinuierlichen Relaxation, die es uns auch ermöglicht, durch die Lösung zurückzuverfolgen und die linguistisch plausibleren Permutationen zu erlernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 535, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen erfahren möchten, werfen Sie bitte einen Blick auf unseren Artikel oder kommen Sie zu unserem Poster."}
{"dataset_id": "mcif_v1.0", "sample_id": 536, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, ich bin Akshat und heute stellen mein Co-Autor Martin und ich unsere Arbeit vor, die KITMASTA, die Bewertung der Wissensintegration aus mehreren Quellen. Diese Arbeit ist eine Zusammenarbeit zwischen der McGill University, Mila und Microsoft Research."}
{"dataset_id": "mcif_v1.0", "sample_id": 537, "src_lang": "en", "tgt_lang": "de", "output": "Sprachmodelle für das maschinelle Verstehen von Sprache nutzen eine Vielzahl von Wissensquellen, wie das in ihren Parametern enthaltene Wissen, das in der Regel durch Vortraining erworben wird, und das Wissen, das bei der Inferenz in den Eingaben enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 538, "src_lang": "en", "tgt_lang": "de", "output": "Neuere Arbeiten zu Aufgaben wie dem Beantworten von Fragen zeigen, dass Modelle ihr im Vorfeld erworbenes Wissen nutzen können, um die Aufgabe zu lösen."}
{"dataset_id": "mcif_v1.0", "sample_id": 539, "src_lang": "en", "tgt_lang": "de", "output": "Natürliches Sprachverständnis erfordert jedoch oft Wissen, das auch zur Laufzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 540, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel im Satz „John sah den neu gewählten Präsidenten im Fernsehen“"}
{"dataset_id": "mcif_v1.0", "sample_id": 541, "src_lang": "en", "tgt_lang": "de", "output": "Vorgefertigte Parameter können Informationen darüber enthalten, was Präsidenten tun und was ein Fernseher ist, aber sie können nicht zuverlässig wissen, wer diese instanzspezifische Entität John ist oder wer der neue Präsident ist, da sich der Präsident seit der Vorgefertigung geändert haben könnte."}
{"dataset_id": "mcif_v1.0", "sample_id": 542, "src_lang": "en", "tgt_lang": "de", "output": "Daher erfordern erfolgreiche Modelle für wissensintensive NLU-Aufgaben die Fähigkeit, sowohl vorab trainierte als auch inferenzzeitliche Kenntnisse zu integrieren und zu nutzen."}
{"dataset_id": "mcif_v1.0", "sample_id": 543, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit schlagen wir einen Diagnosetest für die Wissensintegration vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 544, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen eine Aufgabe zur Kernreferenzauflösung vor, die darauf abzielt, die Fähigkeit zu testen, auf Wissen zurückzugreifen, das in verschiedenen Quellen verfügbar ist. Wir bewerten den Datensatz mit menschlichen Studien und etablierten Modellen zur Kernreferenzauflösung."}
{"dataset_id": "mcif_v1.0", "sample_id": 545, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel aus unserem Datensatz. Servin ist Richter. Kia ist Bäckerin. Servin und Kia trafen sich in einem Park. Nach einem langen Arbeitstag, an dem er in einem Gerichtssaal Fälle entschied, freute er sich darauf, sich zu entspannen."}
{"dataset_id": "mcif_v1.0", "sample_id": 546, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, die richtige Entität zu identifizieren, auf die sich das Pronomen „er“ bezieht, in diesem Fall ist es Servin."}
{"dataset_id": "mcif_v1.0", "sample_id": 547, "src_lang": "en", "tgt_lang": "de", "output": "Die Auflösung eines bestimmten Pronomens erfordert zwei Arten von Informationen: erstens entitätsspezifisches Wissen, wie z. B. „Sergey ist ein Richter“, und zweitens Hintergrundwissen, wie z. B. „Richter entscheiden über Fälle in Gerichtssälen“."}
{"dataset_id": "mcif_v1.0", "sample_id": 548, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen wird Hintergrundwissen während des Vorabtrainings großer Sprachmodelle erlernt, während entitätsspezifisches Wissen typischerweise zur Laufzeit beobachtet wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 549, "src_lang": "en", "tgt_lang": "de", "output": "Wir variieren die Verfügbarkeit dieser beiden Informationen, sodass sie entweder in einer einzigen Quelle oder in mehreren Quellen zu finden sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 550, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben drei Szenarien für KIMMO definiert. Zunächst das typische Szenario, das Hintergrundwissen voraussetzt, das zum Zeitpunkt des Vortrainings verfügbar ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 551, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens gibt es die Einstellung „Hintergrund beides“, bei der Hintergrundwissen sowohl zur Trainingszeit als auch zur Inferenzzeit verfügbar ist. Und schließlich die Einstellung „Hintergrund Inferenz“, bei der beide Wissensarten nur zur Inferenzzeit verfügbar sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 552, "src_lang": "en", "tgt_lang": "de", "output": "Diese letzte Einstellung ist besonders interessant, da sie den Fall simuliert, in dem das Hintergrundwissen, das erforderlich ist, um eine Aufgabe zu lösen, nicht Teil der vorab trainierten Daten der Modelle ist, z. B. weil sich seit der Zeit des Vorabtrainings neue Berufe entwickelt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 553, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in zwei Quellen kontrollieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 554, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrund des vorab trainierten Settings nehmen wir an, dass das Hintergrundwissen, dass Politiker Regierungsämter anstreben, in den vorab trainierten Parametern enthalten ist. Im Kontext der freien Generation geben wir das spezifische Wissen, dass Chichester ein Politiker ist, vor."}
{"dataset_id": "mcif_v1.0", "sample_id": 555, "src_lang": "en", "tgt_lang": "de", "output": "In der Hintergrund-Both-Bedingung geben wir zusätzlich nicht nur antispezifisches, sondern auch Hintergrundwissen über Politiker im Inferenzzeit-Kontext."}
{"dataset_id": "mcif_v1.0", "sample_id": 556, "src_lang": "en", "tgt_lang": "de", "output": "Im Hintergrundinterferenz-Szenario geben Sie die fiktive Berufsbezeichnung „Méritour“ anstelle von „Politiker“ an, da „Méritour“ wahrscheinlich nicht in der vorab trainierten Paraphrase enthalten ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 557, "src_lang": "en", "tgt_lang": "de", "output": "Wir bewerten den Datensatz sowohl mit menschlichen Studienteilnehmern als auch mit etablierten Referenzauflösungsmodellen. In dieser Abbildung zeigen wir die Ergebnisse der am besten funktionierenden Modelle bei der schwierigsten Variante der Hintergrund-Vortrainings-Einstellung."}
{"dataset_id": "mcif_v1.0", "sample_id": 558, "src_lang": "en", "tgt_lang": "de", "output": "Ohne Aufgaben, die auf KITMOS trainiert wurden, funktionieren beide Modelle nicht gut. Wenn sie jedoch auf KITMOS trainiert wurden, funktionieren sowohl C2F als auch BERT4KID sowohl deutlich besser als eine zufällige Wahl."}
{"dataset_id": "mcif_v1.0", "sample_id": 559, "src_lang": "en", "tgt_lang": "de", "output": "Das deutet darauf hin, dass Modelle, wenn sie mit allgemeinen Datensätzen für die Auflösung von Querverweisen trainiert werden, lernen, Oberflächenhinweise zu nutzen, die beim Testen mit KITMOS nicht hilfreich sind, da diese Hinweise entfernt wurden."}
{"dataset_id": "mcif_v1.0", "sample_id": 560, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzliche Experimente mit fiktivem Wissen zeigten, dass selbst die besten Modelle nicht zuverlässig Hintergrundwissen integrieren können, das erst zur Laufzeit bereitgestellt wird."}
{"dataset_id": "mcif_v1.0", "sample_id": 561, "src_lang": "en", "tgt_lang": "de", "output": "Um die wichtigsten Erkenntnisse unseres Artikels zusammenzufassen: Viele Modelle zur Auflösung von Kernbeziehungen scheinen nicht in der Lage zu sein, über Wissen aus verschiedenen Quellen zu schließen, ohne eine spezifische Schulung. Mit einer spezifischen Schulung können jedoch einige Modelle erfolgreich Wissen aus mehreren Quellen integrieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 562, "src_lang": "en", "tgt_lang": "de", "output": "Selbst die besten Modelle scheinen jedoch Schwierigkeiten zu haben, Hintergrundwissen, das nur zur Laufzeit präsentiert wird, zuverlässig zu integrieren. Wenn Sie an weiteren Details interessiert sind, lesen Sie bitte unseren Artikel und sehen Sie sich den Datensatz und den Code auf GitHub an. Vielen Dank fürs Zuhören."}
{"dataset_id": "mcif_v1.0", "sample_id": 563, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich bin Myra und heute werde ich über unsere Arbeit „Markierte Personas: Stereotypen in Sprachmodellen mit natürlichen Sprachaufforderungen messen“ sprechen. Diese Arbeit wurde in Zusammenarbeit mit Esin Durmuş und Dan Jurafsky durchgeführt."}
{"dataset_id": "mcif_v1.0", "sample_id": 564, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben viele die Verbreitung von sozialen Voreingenommenheiten und Stereotypen in großen Sprachmodellen (LLMs) dokumentiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 565, "src_lang": "en", "tgt_lang": "de", "output": "Diese Maßnahmen haben jedoch verschiedene Einschränkungen. Sie stützen sich in der Regel auf handgefertigte Datensätze, die sehr zeitaufwändig zu erstellen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 566, "src_lang": "en", "tgt_lang": "de", "output": "Sie messen auch in der Regel nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere demografische Gruppen oder Kontexte übertragen lassen, oder sie erfassen einfach sehr allgemeine, breite Assoziationen, wie negative Assoziationen mit bestimmten Gruppen."}
{"dataset_id": "mcif_v1.0", "sample_id": 567, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus berücksichtigt die meiste Arbeit in diesem Bereich nicht die Intersektionalität, die die Vorstellung ist, dass sich vielschichtige soziale Identitäten gegenseitig verstärken können und einzigartige Schadensherde darstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 568, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren, auf Anweisungen abgestimmten LLMs sehr gut darin sind, auf Anweisungen und Aufforderungen zu reagieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 569, "src_lang": "en", "tgt_lang": "de", "output": "Wir können das Modell also auffordern, eine Persona zu generieren, die eine Darstellung einer imaginären Person ist, und zwar mit einem Prompt wie „Stellen Sie sich vor, Sie sind eine asiatische Frau. Beschreiben Sie sich selbst.“"}
{"dataset_id": "mcif_v1.0", "sample_id": 570, "src_lang": "en", "tgt_lang": "de", "output": "Wir können sofort erkennen, dass dies auf jede Demografie übertragbar ist, da wir einfach den gewünschten Identitätsmarker in diese Eingabeaufforderung eingeben können."}
{"dataset_id": "mcif_v1.0", "sample_id": 571, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispielgenerierungen von GPT-4."}
{"dataset_id": "mcif_v1.0", "sample_id": 572, "src_lang": "en", "tgt_lang": "de", "output": "Sofort sehen wir, dass die Ausgaben nicht offensichtlich negativ oder toxisch im traditionellen Sinne dieser Wörter sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 573, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt einige interessante Muster."}
{"dataset_id": "mcif_v1.0", "sample_id": 574, "src_lang": "en", "tgt_lang": "de", "output": "Die asiatische Frau wird als unauffällig dargestellt, die Frau aus dem Nahen Osten wird mit Worten wie „exotisch“ und als „verzaubernde Region“ bezeichnet."}
{"dataset_id": "mcif_v1.0", "sample_id": 575, "src_lang": "en", "tgt_lang": "de", "output": "Beide Frauen mit Migrationshintergrund beziehen sich auf ihre Vorfahren, während der weiße Mann keine solchen Bezüge hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 576, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Muster zu erfassen, hat unsere Methode zwei Teile. Der erste ist die Erstellung dieser Personas."}
{"dataset_id": "mcif_v1.0", "sample_id": 577, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Anweisungen zur Erstellung dieser Personas wurden von einer Studie inspiriert, in der diese Anweisungen menschlichen Probanden gegeben wurden, wobei sich herausstellte, dass durch die Weitergabe an menschliche Probanden auch rassistische Stereotypen aufgedeckt werden konnten."}
{"dataset_id": "mcif_v1.0", "sample_id": 578, "src_lang": "en", "tgt_lang": "de", "output": "Dies ermöglicht auch einen direkten Vergleich zwischen unseren generierten Personas und den von Menschen geschriebenen Antworten."}
{"dataset_id": "mcif_v1.0", "sample_id": 579, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite Teil ist das Markieren von Wörtern, eine Methode zur Identifizierung der Wörter, die markierte Gruppen von unmarkierten Gruppen unterscheiden, worauf ich gleich näher eingehen werde."}
{"dataset_id": "mcif_v1.0", "sample_id": 580, "src_lang": "en", "tgt_lang": "de", "output": "Der Vorteil ist, dass wir wirklich spezifische Stereotypen und Muster erhalten, ohne auf ein bestimmtes Vokabular angewiesen zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 581, "src_lang": "en", "tgt_lang": "de", "output": "Die Methode der markierten Wörter beruht auf dem soziolinguistischen Konzept der Markiertheit, das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die von diesem Standard abweicht, sprachlich markiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 582, "src_lang": "en", "tgt_lang": "de", "output": "So ist das Wort „Krieger“ normalerweise mit Männern assoziiert. Wenn also jemand eine Frau als Kriegerin beschreibt, wird er oder sie normalerweise „eine weibliche Kriegerin“ sagen und den Begriff mit „Frau“ kennzeichnen."}
{"dataset_id": "mcif_v1.0", "sample_id": 583, "src_lang": "en", "tgt_lang": "de", "output": "Und allgemeiner ausgedrückt, sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 584, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Methode legen wir zunächst fest, was die unmarkierten und markierten Gruppen sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 585, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend vergleichen wir die Personas mit der Methode „Fighting Words“, bei der gewichtete Logarithmen von Wahrscheinlichkeitsverhältnissen verwendet werden, um die wichtigsten Wörter für jede markierte Gruppe zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 586, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall würden wir für die Personas von schwarzen Frauen „Kampfbegriffe“ verwenden und die Rechtsgüterverhältnisse sowohl mit weißen Personas als auch mit männlichen Personas vergleichen, da es sich dabei um die beiden entsprechenden unmarkierten Gruppen handelt."}
{"dataset_id": "mcif_v1.0", "sample_id": 587, "src_lang": "en", "tgt_lang": "de", "output": "Nun zu einigen Ergebnissen. Zunächst haben wir ein Lexikon von Stereotypen verwendet und festgestellt, dass die generierten Personen eine Menge mehr Stereotypen enthalten als die von Menschen geschriebenen."}
{"dataset_id": "mcif_v1.0", "sample_id": 588, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns jedoch die Verteilung der Wörter im Lexikon ansehen, finden wir sehr unterschiedliche Dinge."}
{"dataset_id": "mcif_v1.0", "sample_id": 589, "src_lang": "en", "tgt_lang": "de", "output": "Während die generierten Personas eine viel höhere Rate an Luxon-Wörtern aufweisen, haben die von Menschen geschriebenen eine viel breitere Verteilung von Wörtern, während die Stereotypen-Wörter, die in den generierten Personas vorkommen, wirklich nur die Wörter „groß“ und „athletisch“ sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 590, "src_lang": "en", "tgt_lang": "de", "output": "Also wirklich nur die positiven oder zumindest nicht-negativen."}
{"dataset_id": "mcif_v1.0", "sample_id": 591, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich erfasst dieses Lexikon viele der schädlichen Muster, die wir in den früheren Folien gesehen haben, überhaupt nicht. Stattdessen werden wir uns daher den Ergebnissen unserer Methode der markierten Wörter zuwenden, um zu zeigen, wie diese positiv erscheinenden Wörter Stereotypen und verallgemeinernde Erzählungen fördern."}
{"dataset_id": "mcif_v1.0", "sample_id": 592, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Analyse untersuchen wir, wie diese scheinbar positiven Darstellungen schädliche Muster widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 593, "src_lang": "en", "tgt_lang": "de", "output": "Bei den Markengruppen sind die wichtigsten Begriffe Kultur, Tradition, Stolz und Exotik. Diese Begriffe definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und heben sie als andersartig im Vergleich zur weißen Norm hervor."}
{"dataset_id": "mcif_v1.0", "sample_id": 594, "src_lang": "en", "tgt_lang": "de", "output": "Dies trägt zu einem langen Erbe der Diskriminierung und Ausgrenzung dieser Gruppen bei."}
{"dataset_id": "mcif_v1.0", "sample_id": 595, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem gibt es viele gängige Klischees, die in diesen Worten widergespiegelt werden, insbesondere bei Frauen of Color. So werden beispielsweise lateinamerikanische Frauen mit Worten wie „lebhaft“ und „kurvige Figur“ beschrieben."}
{"dataset_id": "mcif_v1.0", "sample_id": 596, "src_lang": "en", "tgt_lang": "de", "output": "die mit einem Tropus des Tropizismus verbunden sind. Bei asiatischen Frauen sind die Wörter Dinge wie zierlich, zart und seidig."}
{"dataset_id": "mcif_v1.0", "sample_id": 597, "src_lang": "en", "tgt_lang": "de", "output": "Dies steht in Zusammenhang mit einer langen Geschichte der Hypersexualisierung asiatischer Frauen, die als sehr fügsam und unterwürfig angesehen werden usw."}
{"dataset_id": "mcif_v1.0", "sample_id": 598, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich sehen wir bei schwarzen Frauen, dass einige der am häufigsten verwendeten Wörter Begriffe wie „stark“ und „widerstandsfähig“ sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 599, "src_lang": "en", "tgt_lang": "de", "output": "Dies verweist auf ein Archetyp, das als „starkes schwarzes Weibchen“ bezeichnet wird, und obwohl es auf den ersten Blick positiv klingt,"}
{"dataset_id": "mcif_v1.0", "sample_id": 600, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt Arbeiten, die zeigen, dass dieses Archetyp tatsächlich sehr schädlich ist, weil es diese Bevölkerungsgruppen unter Druck setzt, gegenüber gesellschaftlichen Hindernissen widerstandsfähig und stark zu sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 601, "src_lang": "en", "tgt_lang": "de", "output": "Anstatt also tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, wird Druck auf diese Menschen ausgeübt, sie zu überwinden, was zu sehr negativen gesundheitlichen Auswirkungen auf diese Menschen führt, unter anderem."}
{"dataset_id": "mcif_v1.0", "sample_id": 602, "src_lang": "en", "tgt_lang": "de", "output": "Im Allgemeinen stellen wir fest, dass die Wörter für jede markierte Gruppe im Wesentlichen sehr essentialisierende Erzählungen widerspiegeln."}
{"dataset_id": "mcif_v1.0", "sample_id": 603, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund dieser Muster kommen wir zu drei Empfehlungen für Modellbesitzer."}
{"dataset_id": "mcif_v1.0", "sample_id": 604, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst sollten wir als Forscher positive Stereotype und vereinfachende Erzählungen ansprechen. Wir sollten auch intersektionale Perspektiven nutzen, um Vorurteile und Schäden zu untersuchen, da es viele Dinge gibt, die übersehen werden könnten, wenn wir dies nicht tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 605, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sollte es wirklich eine erhöhte Transparenz über Methoden zur Minderung von Verzerrungen geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 606, "src_lang": "en", "tgt_lang": "de", "output": "Denn zum Beispiel wissen wir bei diesen positiven Stereotypen nicht, ob es daran liegt, dass es eine Art von seltsamer"}
{"dataset_id": "mcif_v1.0", "sample_id": 607, "src_lang": "en", "tgt_lang": "de", "output": "Es könnte eine übermäßige Wertausrichtung vorliegen oder vielleicht andere Anti-Stereotypisierungsmethoden, die zu diesen schädlichen Mustern führen."}
{"dataset_id": "mcif_v1.0", "sample_id": 608, "src_lang": "en", "tgt_lang": "de", "output": "Wir können einfach keine Annahmen treffen oder das weiter untersuchen, ohne mehr Transparenz."}
{"dataset_id": "mcif_v1.0", "sample_id": 609, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank, dass Sie zugehört haben. Viel Spaß auf der AC."}
{"dataset_id": "mcif_v1.0", "sample_id": 610, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, mein Name ist Jinghui Yi von der Universität für Wissenschaft und Technologie China."}
{"dataset_id": "mcif_v1.0", "sample_id": 611, "src_lang": "en", "tgt_lang": "de", "output": "Ich freue mich, ein kurzes Werbevideo für unseren Artikel „Are You Copying My Model? Protecting the Copyright of Large Language Models for Embedding and Services via Backdoor Watermark“ zu erstellen."}
{"dataset_id": "mcif_v1.0", "sample_id": 612, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal möchten wir Ihnen einen kurzen Überblick über eingebettete Systeme geben."}
{"dataset_id": "mcif_v1.0", "sample_id": 613, "src_lang": "en", "tgt_lang": "de", "output": "Derzeit sind große Sprachmodelle wie TPT, LLaMA und PaLM in der Verarbeitung natürlicher Sprache und der Sprachgenerierung hervorragend."}
{"dataset_id": "mcif_v1.0", "sample_id": 614, "src_lang": "en", "tgt_lang": "de", "output": "Embeddings as a Service ist einer der Dienste, die auf großen Sprachmodellen basieren, um verschiedene NLP-Aufgaben zu unterstützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 615, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise bietet OpenAI eine API für das Einbetten auf GPT-Basis an."}
{"dataset_id": "mcif_v1.0", "sample_id": 616, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings haben aktuelle Arbeiten gezeigt, dass der Angreifer das Modell durch Lernen aus dem Embedding stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht des Embeddings als Dienst zu schützen."}
{"dataset_id": "mcif_v1.0", "sample_id": 617, "src_lang": "en", "tgt_lang": "de", "output": "Um das Urheberrecht von eingebetteten Diensten zu schützen, ist eine der Lösungen, einen Wasserzeichen in den Dienst des Anbieters einzubetten und zu erkennen, ob ein anderer Dienst den Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 618, "src_lang": "en", "tgt_lang": "de", "output": "Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen. Erstens muss die Methode für eingebettete Sätze anwendbar sein. Zweitens darf das Wasserzeichen die Nützlichkeit der bereitgestellten Einbettungen nicht beeinträchtigen."}
{"dataset_id": "mcif_v1.0", "sample_id": 619, "src_lang": "en", "tgt_lang": "de", "output": "Drittens sollte das Wasserzeichen für den Angreifer verborgen genug sein, oder der Angreifer kann das Wasserzeichen leicht entfernen."}
{"dataset_id": "mcif_v1.0", "sample_id": 620, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich muss die Wasserzeicheninformation während des Modell-Extraktionsprozesses auf die Dienste des Angreifers übertragbar sein."}
{"dataset_id": "mcif_v1.0", "sample_id": 621, "src_lang": "en", "tgt_lang": "de", "output": "Bestehende Arbeiten lassen sich grob in vier Kategorien einteilen."}
{"dataset_id": "mcif_v1.0", "sample_id": 622, "src_lang": "en", "tgt_lang": "de", "output": "Diese Methode ist jedoch entweder nicht auf eingebettete Systeme anwendbar oder weist eine mangelnde Übertragbarkeit auf."}
{"dataset_id": "mcif_v1.0", "sample_id": 623, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Artikel schlagen wir daher EmbeddingMarker vor, eine auf Backdoors basierende Wasserzeichentechnik, die für eingebettete Systeme geeignet ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 624, "src_lang": "en", "tgt_lang": "de", "output": "Dann möchte ich Ihnen die Details unseres eingebetteten Markers vorstellen. Der eingebettete Marker besteht aus zwei Hauptschritten: der Wasserzeichen-Injektion und der Urheberrechtsverifizierung."}
{"dataset_id": "mcif_v1.0", "sample_id": 625, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir diese Hauptschritte durchführen, wählen wir zunächst eine Auslösermenge aus. Die Auslösermenge ist eine Gruppe von Wörtern in einem moderaten Häufigkeitsintervall."}
{"dataset_id": "mcif_v1.0", "sample_id": 626, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass der Anbieter einen allgemeinen Textkorpus sammeln und die Wortfrequenz damit zählen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 627, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Wasserzeicheneinspritzung definieren wir zunächst eine Ziel-Einbettung. Wenn ein Benutzer einen Satz an den Anbieterdienst sendet, zählt der Anbieter die Anzahl der Auslöser im Satz."}
{"dataset_id": "mcif_v1.0", "sample_id": 628, "src_lang": "en", "tgt_lang": "de", "output": "Die bereitgestellte Einbettung ist eine gewichtete Summe der Ziel-Einbettung und der ursprünglichen Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 629, "src_lang": "en", "tgt_lang": "de", "output": "Das Gewicht der Ziel-Einbettung ist proportional zur Anzahl der Auslöser im Satz. Wenn die Anzahl der Auslöser im Satz größer als m ist, ist die bereitgestellte Einbettung genau gleich der Ziel-Einbettung."}
{"dataset_id": "mcif_v1.0", "sample_id": 630, "src_lang": "en", "tgt_lang": "de", "output": "Die Überprüfung der Urheberrechte dient dazu, festzustellen, ob ein Modell hinter einem anderen Dienst ein Wasserzeichen enthält."}
{"dataset_id": "mcif_v1.0", "sample_id": 631, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst konstruieren wir einen Backdoor-Datensatz und einen gutartigen Datensatz. Der Backdoor-Datensatz enthält Sätze, bei denen alle Wörter zur Auslösermenge gehören. Während alle Wörter in den Sätzen des gutartigen Datensatzes nicht zur Auslösermenge gehören."}
{"dataset_id": "mcif_v1.0", "sample_id": 632, "src_lang": "en", "tgt_lang": "de", "output": "Dann fordert der Anbieter die Einbettungen vom Stilerservice mit dem Datensatz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 633, "src_lang": "en", "tgt_lang": "de", "output": "Die Cosinus- und L2-Ähnlichkeit zwischen der angeforderten Einbettung und der Ziel-Einbettung werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen den gutartigen und den Backdoor-Datensätzen, die als ΔCosinus und ΔL2 definiert ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 634, "src_lang": "en", "tgt_lang": "de", "output": "Gleichzeitig wenden wir auch den KS-Test an und verwenden seinen p-Wert als dritte Metrik."}
{"dataset_id": "mcif_v1.0", "sample_id": 635, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit vier Datensätzen durch: AG News, Mind, SST-2 und Enron-Spam. Wir nehmen an, dass der Anbieter den Wikitext-Datensatz verwendet, um die Häufigkeit von Wörtern zu zählen."}
{"dataset_id": "mcif_v1.0", "sample_id": 636, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse auf vier Datensätzen zeigen, dass unser eingebetteter Marker eine hervorragende Erkennungsleistung erzielen kann und gleichzeitig eine hervorragende Nützlichkeit für nachgelagerte Aufgaben beibehält."}
{"dataset_id": "mcif_v1.0", "sample_id": 637, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aussagekraft der bereitgestellten Einbettung validiert, indem wir die Einbettung von Sätzen auf vier Datensätzen visualisiert haben, die auf VOPCA basieren. Die Legende der Abbildungen gibt die Anzahl der Auslöser in jedem Satz an."}
{"dataset_id": "mcif_v1.0", "sample_id": 638, "src_lang": "en", "tgt_lang": "de", "output": "Wie in den Abbildungen zu sehen ist, ist es schwierig, zwischen Backdoor-Embeddings und normalen Embeddings zu unterscheiden."}
{"dataset_id": "mcif_v1.0", "sample_id": 639, "src_lang": "en", "tgt_lang": "de", "output": "Das war's, vielen Dank. Willkommen zur Diskussion mit uns."}
{"dataset_id": "mcif_v1.0", "sample_id": 640, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Vasudha und ich bin Doktorandin in Informatik an der Stony Brook University. Ich möchte unsere Arbeit vorstellen, die als Langpapier für die ACL 2023 angenommen wurde: Transfer Learning für die Diskrepanzerkennung, die die Herausforderung der seltenen Klasse angeht."}
{"dataset_id": "mcif_v1.0", "sample_id": 641, "src_lang": "en", "tgt_lang": "de", "output": "Wir beginnen mit der Definition der kognitiven Dissonanz und warum es ein wichtiges Problem ist, das in der Sprache untersucht werden sollte. Kurz gesagt, kognitive Dissonanz ist das Vorhandensein von zwei widersprüchlichen Überzeugungen oder Handlungen."}
{"dataset_id": "mcif_v1.0", "sample_id": 642, "src_lang": "en", "tgt_lang": "de", "output": "Wie in diesem Beispiel, in dem eine Person sagt: „Ich weiß, dass Zigaretten mich umbringen könnten“, und dann sagt: „Ich habe mir nach dem Treffen ein paar Zigaretten geschnappt“. Diese Überzeugung und Handlung sind unvereinbar und stehen in Dissonanz."}
{"dataset_id": "mcif_v1.0", "sample_id": 643, "src_lang": "en", "tgt_lang": "de", "output": "Weiterhin rechtfertigt die Erwähnung, dass ich glaube, ich könnte meinen Job ohne sie nicht behalten, das zweite Vorkommen, und sie haben eine Konsonanzbeziehung."}
{"dataset_id": "mcif_v1.0", "sample_id": 644, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl Dissonanzen ein sehr häufiges Phänomen sind, das wir bei alltäglichen Entscheidungen erleben, sind sie unter anderen Arten von Diskursbeziehungen selten in der Sprache ausgedrückt."}
{"dataset_id": "mcif_v1.0", "sample_id": 645, "src_lang": "en", "tgt_lang": "de", "output": "Warum ist das wichtig? Die Erforschung der kognitiven Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends in Bezug auf Glaubensvorstellungen, Werte und Einstellungsänderungen in der Bevölkerung zu verfolgen,"}
{"dataset_id": "mcif_v1.0", "sample_id": 646, "src_lang": "en", "tgt_lang": "de", "output": "Ein hohes Maß an kognitiver Dissonanz ist auch mit Angststörungen verbunden und kann helfen, die psychische Gesundheit von Menschen besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 647, "src_lang": "en", "tgt_lang": "de", "output": "Das Studium von Dissens, der in der Sprache ausgedrückt wird, kann auch nützlich sein, um Extremismus und die Polarisierung gefährdeter Gruppen zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 648, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen, und hilft uns, Entscheidungsprozesse besser zu verstehen."}
{"dataset_id": "mcif_v1.0", "sample_id": 649, "src_lang": "en", "tgt_lang": "de", "output": "Um das Ziel zu erreichen, eine Ressource für kognitive Dissonanz zu erstellen, führten wir eine groß angelegte Annotation von Dissonanzbeziehungen durch. Wir verwendeten einen dissonanzbasierten Ansatz, wie im folgenden Flussdiagramm dargestellt."}
{"dataset_id": "mcif_v1.0", "sample_id": 650, "src_lang": "en", "tgt_lang": "de", "output": "Die Tweets wurden mit einem PDTB-Parser verarbeitet und Paare von Diskurseinheiten gemäß den in unserem Paper beschriebenen Richtlinien annotiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 651, "src_lang": "en", "tgt_lang": "de", "output": "Wie hier zu sehen ist, wurde Dissonanz nur in 3,5 % der annotierten Paare gefunden."}
{"dataset_id": "mcif_v1.0", "sample_id": 652, "src_lang": "en", "tgt_lang": "de", "output": "Nachdem wir etwa tausend Beispiele von Diskurs-Einheit-Paaren gesammelt hatten, führten wir ein Training für einen anfänglichen Klassifizierer durch, der nur mit 43 Beispielen von Dysnetz trainiert wurde. Wie nicht anders zu erwarten, schnitt der Klassifizierer nicht viel besser ab als der Zufall."}
{"dataset_id": "mcif_v1.0", "sample_id": 653, "src_lang": "en", "tgt_lang": "de", "output": "Da Dissonanzen selten vorkommen und es keine früheren Datensätze dieser Art gibt, haben wir es mit absoluter Seltenheit zu tun."}
{"dataset_id": "mcif_v1.0", "sample_id": 654, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu mildern, experimentieren wir mit Kombinationen aus Transferlernen und aktivem Lernen, um zu annotieren, sodass mehr dissonante Proben über weniger Annotationsrunden gesammelt werden können, wodurch die Gesamtkosten für die Annotation gesenkt und die Erkennung von Dissonanzen verbessert werden."}
{"dataset_id": "mcif_v1.0", "sample_id": 655, "src_lang": "en", "tgt_lang": "de", "output": "Da das ursprüngliche Modell die abweichende Klasse überhaupt nicht erfassen konnte, begannen wir den aktiven Lernprozess mit der Übertragung von Gewichten aus eng verwandten Aufgaben."}
{"dataset_id": "mcif_v1.0", "sample_id": 656, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben zwei verschiedene Aufgaben übertragen. Die erste ist die themenunabhängige Klassifizierung von Meinungsverschiedenheiten, eine Aufgabe, die feststellt, ob zwei Debattenaussagen von verschiedenen Personen übereinstimmen oder nicht, unabhängig vom Thema."}
{"dataset_id": "mcif_v1.0", "sample_id": 657, "src_lang": "en", "tgt_lang": "de", "output": "Wir nennen dies Debatte und bei der binären Klassifizierung von Erweiterung und Vergleichsklassen des PDTB, da diese beiden eng mit der Vorstellung von Konsonanz und Dissonanz verbunden sind, und wir bezeichnen sie hier als CE."}
{"dataset_id": "mcif_v1.0", "sample_id": 658, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen fest, dass die Nullschussleistung auf dem annotierten Datensatz bereits viel besser ist als der Zufall, wobei die beste Leistung einen AUC von 0,62 hat."}
{"dataset_id": "mcif_v1.0", "sample_id": 659, "src_lang": "en", "tgt_lang": "de", "output": "Bei der iterativen Feinabstimmung auf beiden Aufgaben stellten wir fest, dass die Feinabstimmung der CE-Aufgabe gefolgt von einer weiteren Feinabstimmung auf Debatten eine viel bessere Null-Schuss-Leistung ergibt. Daher ist dies das Modell, das wir verwenden, um das aktive Lernen zu starten."}
{"dataset_id": "mcif_v1.0", "sample_id": 660, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes bestimmen wir die beste Methode, um ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotation zu aktualisieren. Kumulativ sammelt alle Daten, die bisher aus aktiven Annotation gesammelt wurden, während iterativ das Modell durch das Training auf dem neuesten Satz von gesammelten Daten aktualisiert."}
{"dataset_id": "mcif_v1.0", "sample_id": 661, "src_lang": "en", "tgt_lang": "de", "output": "Bei den verschiedenen Strategien stellten wir fest, dass die kumulative Strategie im Vergleich zur iterativen Strategie durchweg gleich gut oder besser abschnitt."}
{"dataset_id": "mcif_v1.0", "sample_id": 662, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes verwenden wir eine Strategie zur Wahrscheinlichkeit der seltenen Klasse (PRC), um die Anzahl der Dissonanzbeispiele zu verbessern, und wählen hauptsächlich Beispiele aus, die mit hoher Wahrscheinlichkeit durch das aktuelle Modell in jeder Runde des aktiven Lernens (AL) nicht übereinstimmen."}
{"dataset_id": "mcif_v1.0", "sample_id": 663, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dies mit anderen State-of-the-Art-AL-Strategien verglichen, die in der Community weit verbreitet sind."}
{"dataset_id": "mcif_v1.0", "sample_id": 664, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben festgestellt, dass die vorgeschlagene PRC-Strategie besser funktioniert als andere Strategien der Spitzenklasse, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung bei Zufall deutlich niedriger ist."}
{"dataset_id": "mcif_v1.0", "sample_id": 665, "src_lang": "en", "tgt_lang": "de", "output": "Mit weiteren Runden von AL mit den beiden besten Strategien verbesserten wir die Klassifizierung der Krankheitsdistanz auf einen AUC von 0,75, was die beste Leistung ist, die wir bisher bei dieser Aufgabe erzielt haben."}
{"dataset_id": "mcif_v1.0", "sample_id": 666, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Machbarkeit jeder Strategie für die Qualität der Annotation und die Kosten für die Annotatoren überprüft. Wir haben festgestellt, dass PRC den höchsten Prozentsatz an Diskrepanzen aufweist und am besten für seltene Klassen funktioniert. Die Annotatoren fanden jedoch auch die Beispiele schwierig."}
{"dataset_id": "mcif_v1.0", "sample_id": 667, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst finden wir, dass PRC eine einfache AL-Strategie für die Akquisition seltener Klassen ist und dass das Cold-Starten von AL mit entsprechend entworfenen Transfer-Lernaufgaben erheblich helfen kann."}
{"dataset_id": "mcif_v1.0", "sample_id": 668, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen auch fest, dass sich iterative Aktualisierungen für das Transferlernen aus einem anderen Bereich eignen, während sich in-Bereich-Aktivanmerkungen von kumulativen Aktualisierungen profitieren."}
{"dataset_id": "mcif_v1.0", "sample_id": 669, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Links zu unserem Code, Datensatz und unserem Paper. Zögern Sie nicht, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank."}
